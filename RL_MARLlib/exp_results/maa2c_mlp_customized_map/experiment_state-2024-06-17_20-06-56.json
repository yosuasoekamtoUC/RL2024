{
  "checkpoints": [
    "{\n  \"trainable_name\": \"MAA2CTrainer\",\n  \"trial_id\": \"b5ab8_00000\",\n  \"config\": {\n    \"train_batch_size\": 5000,\n    \"batch_mode\": \"truncate_episodes\",\n    \"use_gae\": true,\n    \"lambda\": 1.0,\n    \"vf_loss_coeff\": 1.0,\n    \"entropy_coeff\": 0.01,\n    \"lr\": 0.0005,\n    \"model\": {\n      \"custom_model\": \"Centralized_Critic_Model\",\n      \"max_seq_len\": 500,\n      \"custom_model_config\": {\n        \"env\": \"rware\",\n        \"env_args\": {\n          \"n_agents\": 4,\n          \"column_height\": 1,\n          \"max_inactivity_steps\": null,\n          \"max_steps\": 500,\n          \"fast_obs\": true,\n          \"msg_bits\": 0,\n          \"sensor_range\": 1,\n          \"shelf_rows\": 1,\n          \"shelf_columns\": 3,\n          \"request_queue_size\": 4,\n          \"reward_type\": {\n            \"_type\": \"CLOUDPICKLE_FALLBACK\",\n            \"value\": \"80059528000000000000008c0f72776172652e77617265686f757365948c0a526577617264547970659493944b01859452942e\"\n          },\n          \"map_name\": \"customized_map\",\n          \"map_size\": \"tiny\",\n          \"difficulty\": \"medium\"\n        },\n        \"mask_flag\": false,\n        \"global_state_flag\": false,\n        \"opp_action_in_cc\": true,\n        \"agent_level_batch_update\": true,\n        \"force_coop\": true,\n        \"local_mode\": false,\n        \"share_policy\": \"group\",\n        \"evaluation_interval\": 50,\n        \"framework\": \"torch\",\n        \"num_workers\": 4,\n        \"num_gpus\": 1,\n        \"num_cpus_per_worker\": 1,\n        \"num_gpus_per_worker\": 0,\n        \"checkpoint_freq\": 100,\n        \"checkpoint_end\": true,\n        \"restore_path\": {\n          \"model_path\": \"\",\n          \"params_path\": \"\"\n        },\n        \"stop_iters\": 9999999,\n        \"stop_timesteps\": 2000000,\n        \"stop_reward\": 999999,\n        \"seed\": 321,\n        \"local_dir\": \"\",\n        \"model_arch_args\": {\n          \"hidden_state_size\": 256,\n          \"core_arch\": \"mlp\",\n          \"fc_layer\": 2,\n          \"out_dim_fc_0\": 128,\n          \"out_dim_fc_1\": 64\n        },\n        \"algorithm\": \"maa2c\",\n        \"space_obs\": {\n          \"_type\": \"CLOUDPICKLE_FALLBACK\",\n          \"value\": \"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\"\n        },\n        \"space_act\": {\n          \"_type\": \"CLOUDPICKLE_FALLBACK\",\n          \"value\": \"80059582000000000000008c1367796d2e7370616365732e6469736372657465948c0844697363726574659493942981947d94288c016e944b058c065f736861706594298c056474797065948c056e756d707994680793948c02693894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494628c0a5f6e705f72616e646f6d944e75622e\"\n        },\n        \"num_agents\": 4,\n        \"episode_limit\": 500,\n        \"policy_mapping_info\": {\n          \"all_scenario\": {\n            \"description\": \"rware all scenarios\",\n            \"team_prefix\": [\n              \"agent_\"\n            ],\n            \"all_agents_one_policy\": true,\n            \"one_agent_one_policy\": true\n          }\n        },\n        \"agent_name_ls\": [\n          \"agent_0\",\n          \"agent_1\",\n          \"agent_2\",\n          \"agent_3\"\n        ]\n      }\n    },\n    \"seed\": 321,\n    \"env\": \"rware_customized_map\",\n    \"num_gpus_per_worker\": 0,\n    \"num_gpus\": 1,\n    \"num_workers\": 4,\n    \"multiagent\": {\n      \"policies\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059516000000000000008f94288c0e64656661756c745f706f6c69637994902e\"\n      },\n      \"policy_mapping_fn\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595bc020000000000008c1b7261792e636c6f75647069636b6c652e636c6f75647069636b6c65948c0d5f6275696c74696e5f747970659493948c0a4c616d6264615479706594859452942868028c08436f6465547970659485945294284b024b004b004b034b014b1b430488005300944e8594298c086167656e745f6964948c07657069736f6465948c066b77617267739487948c2e2f686f6d652f796f732f4d41524c6c69622f6d61726c6c69622f6d61726c2f616c676f732f72756e5f63632e7079948c083c6c616d6264613e944b7b4300948c127368617265645f706f6c6963795f6e616d6594859429749452947d94288c0b5f5f7061636b6167655f5f948c126d61726c6c69622e6d61726c2e616c676f73948c085f5f6e616d655f5f948c196d61726c6c69622e6d61726c2e616c676f732e72756e5f6363948c085f5f66696c655f5f948c2e2f686f6d652f796f732f4d41524c6c69622f6d61726c6c69622f6d61726c2f616c676f732f72756e5f63632e707994754e4e68008c105f6d616b655f656d7074795f63656c6c9493942952948594749452948c207261792e636c6f75647069636b6c652e636c6f75647069636b6c655f66617374948c125f66756e6374696f6e5f736574737461746594939468227d947d9428681968108c0c5f5f7175616c6e616d655f5f948c1872756e5f63632e3c6c6f63616c733e2e3c6c616d6264613e948c0f5f5f616e6e6f746174696f6e735f5f947d948c0e5f5f6b7764656661756c74735f5f944e8c0c5f5f64656661756c74735f5f944e8c0a5f5f6d6f64756c655f5f94681a8c075f5f646f635f5f944e8c0b5f5f636c6f737572655f5f9468008c0a5f6d616b655f63656c6c9493948c0e64656661756c745f706f6c696379948594529485948c175f636c6f75647069636b6c655f7375626d6f64756c6573945d948c0b5f5f676c6f62616c735f5f947d947586948652302e\"\n      }\n    },\n    \"framework\": \"torch\",\n    \"evaluation_interval\": 50,\n    \"simple_optimizer\": false\n  },\n  \"local_dir\": \"/home/yos/MARLlib/exp_results/maa2c_mlp_customized_map\",\n  \"evaluated_params\": {},\n  \"experiment_tag\": \"0\",\n  \"location\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"8005953a000000000000008c0e7261792e74756e652e747269616c948c084c6f636174696f6e9493942981947d94288c08686f73746e616d65944e8c03706964944e75622e\"\n  },\n  \"resources\": {\n    \"cpu\": 1,\n    \"gpu\": 0,\n    \"memory\": 0,\n    \"object_store_memory\": 0,\n    \"extra_cpu\": 0,\n    \"extra_gpu\": 0,\n    \"extra_memory\": 0,\n    \"extra_object_store_memory\": 0,\n    \"custom_resources\": {},\n    \"extra_custom_resources\": {}\n  },\n  \"placement_group_factory\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059506010000000000008c1f7261792e74756e652e7574696c732e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d94287d94288c0343505594473ff00000000000008c0347505594473ff0000000000000757d94286808473ff00000000000006809470000000000000000757d94286808473ff00000000000006809470000000000000000757d94286808473ff00000000000006809470000000000000000757d94286808473ff0000000000000680947000000000000000075658c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\"\n  },\n  \"stopping_criterion\": {\n    \"episode_reward_mean\": 999999,\n    \"timesteps_total\": 2000000,\n    \"training_iteration\": 9999999\n  },\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_last_result\": {\n    \"trial_id\": \"b5ab8_00000\"\n  },\n  \"_default_result_or_future\": null,\n  \"last_update_time\": -Infinity,\n  \"metric_analysis\": {},\n  \"n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {},\n  \"export_formats\": [],\n  \"status\": \"ERROR\",\n  \"start_time\": 1718622416.2970967,\n  \"logdir\": \"/home/yos/MARLlib/exp_results/maa2c_mlp_customized_map/MAA2CTrainer_rware_customized_map_b5ab8_00000_0_2024-06-17_20-06-56\",\n  \"runner\": null,\n  \"last_debug\": 0,\n  \"error_file\": \"/home/yos/MARLlib/exp_results/maa2c_mlp_customized_map/MAA2CTrainer_rware_customized_map_b5ab8_00000_0_2024-06-17_20-06-56/error.txt\",\n  \"error_msg\": \"Traceback (most recent call last):\\n  File \\\"/home/yos/miniconda3/envs/rl_final/lib/python3.8/site-packages/ray/tune/trial_runner.py\\\", line 890, in _process_trial\\n    results = self.trial_executor.fetch_result(trial)\\n  File \\\"/home/yos/miniconda3/envs/rl_final/lib/python3.8/site-packages/ray/tune/ray_trial_executor.py\\\", line 788, in fetch_result\\n    result = ray.get(trial_future[0], timeout=DEFAULT_GET_TIMEOUT)\\n  File \\\"/home/yos/miniconda3/envs/rl_final/lib/python3.8/site-packages/ray/_private/client_mode_hook.py\\\", line 105, in wrapper\\n    return func(*args, **kwargs)\\n  File \\\"/home/yos/miniconda3/envs/rl_final/lib/python3.8/site-packages/ray/worker.py\\\", line 1627, in get\\n    raise value\\nray.exceptions.RayActorError: The actor died because of an error raised in its creation task, \\u001b[36mray::MAA2CTrainer.__init__()\\u001b[39m (pid=105309, ip=192.168.46.185)\\n  File \\\"/home/yos/miniconda3/envs/rl_final/lib/python3.8/site-packages/ray/rllib/agents/trainer_template.py\\\", line 137, in __init__\\n    Trainer.__init__(self, config, env, logger_creator)\\n  File \\\"/home/yos/miniconda3/envs/rl_final/lib/python3.8/site-packages/ray/rllib/agents/trainer.py\\\", line 623, in __init__\\n    super().__init__(config, logger_creator)\\n  File \\\"/home/yos/miniconda3/envs/rl_final/lib/python3.8/site-packages/ray/tune/trainable.py\\\", line 107, in __init__\\n    self.setup(copy.deepcopy(self.config))\\n  File \\\"/home/yos/miniconda3/envs/rl_final/lib/python3.8/site-packages/ray/rllib/agents/trainer_template.py\\\", line 147, in setup\\n    super().setup(config)\\n  File \\\"/home/yos/miniconda3/envs/rl_final/lib/python3.8/site-packages/ray/rllib/agents/trainer.py\\\", line 776, in setup\\n    self._init(self.config, self.env_creator)\\n  File \\\"/home/yos/miniconda3/envs/rl_final/lib/python3.8/site-packages/ray/rllib/agents/trainer_template.py\\\", line 171, in _init\\n    self.workers = self._make_workers(\\n  File \\\"/home/yos/miniconda3/envs/rl_final/lib/python3.8/site-packages/ray/rllib/agents/trainer.py\\\", line 858, in _make_workers\\n    return WorkerSet(\\n  File \\\"/home/yos/miniconda3/envs/rl_final/lib/python3.8/site-packages/ray/rllib/evaluation/worker_set.py\\\", line 110, in __init__\\n    self._local_worker = self._make_worker(\\n  File \\\"/home/yos/miniconda3/envs/rl_final/lib/python3.8/site-packages/ray/rllib/evaluation/worker_set.py\\\", line 406, in _make_worker\\n    worker = cls(\\n  File \\\"/home/yos/miniconda3/envs/rl_final/lib/python3.8/site-packages/ray/rllib/evaluation/rollout_worker.py\\\", line 584, in __init__\\n    self._build_policy_map(\\n  File \\\"/home/yos/miniconda3/envs/rl_final/lib/python3.8/site-packages/ray/rllib/evaluation/rollout_worker.py\\\", line 1384, in _build_policy_map\\n    self.policy_map.create_policy(name, orig_cls, obs_space, act_space,\\n  File \\\"/home/yos/miniconda3/envs/rl_final/lib/python3.8/site-packages/ray/rllib/policy/policy_map.py\\\", line 143, in create_policy\\n    self[policy_id] = class_(observation_space, action_space,\\n  File \\\"/home/yos/miniconda3/envs/rl_final/lib/python3.8/site-packages/ray/rllib/policy/policy_template.py\\\", line 280, in __init__\\n    self._initialize_loss_from_dummy_batch(\\n  File \\\"/home/yos/miniconda3/envs/rl_final/lib/python3.8/site-packages/ray/rllib/policy/policy.py\\\", line 731, in _initialize_loss_from_dummy_batch\\n    self.compute_actions_from_input_dict(\\n  File \\\"/home/yos/miniconda3/envs/rl_final/lib/python3.8/site-packages/ray/rllib/policy/torch_policy.py\\\", line 302, in compute_actions_from_input_dict\\n    return self._compute_action_helper(input_dict, state_batches,\\n  File \\\"/home/yos/miniconda3/envs/rl_final/lib/python3.8/site-packages/ray/rllib/utils/threading.py\\\", line 21, in wrapper\\n    return func(self, *a, **k)\\n  File \\\"/home/yos/miniconda3/envs/rl_final/lib/python3.8/site-packages/ray/rllib/policy/torch_policy.py\\\", line 366, in _compute_action_helper\\n    dist_inputs, state_out = self.model(input_dict, state_batches,\\n  File \\\"/home/yos/miniconda3/envs/rl_final/lib/python3.8/site-packages/ray/rllib/models/modelv2.py\\\", line 243, in __call__\\n    res = self.forward(restored, state or [], seq_lens)\\n  File \\\"/home/yos/MARLlib/marllib/marl/models/zoo/mlp/base_mlp.py\\\", line 101, in forward\\n    self._features = self.p_encoder(self.inputs)\\n  File \\\"/home/yos/miniconda3/envs/rl_final/lib/python3.8/site-packages/torch/nn/modules/module.py\\\", line 1051, in _call_impl\\n    return forward_call(*input, **kwargs)\\n  File \\\"/home/yos/MARLlib/marllib/marl/models/zoo/encoder/base_encoder.py\\\", line 107, in forward\\n    output = self.encoder(inputs)\\n  File \\\"/home/yos/miniconda3/envs/rl_final/lib/python3.8/site-packages/torch/nn/modules/module.py\\\", line 1051, in _call_impl\\n    return forward_call(*input, **kwargs)\\n  File \\\"/home/yos/miniconda3/envs/rl_final/lib/python3.8/site-packages/torch/nn/modules/container.py\\\", line 139, in forward\\n    input = module(input)\\n  File \\\"/home/yos/miniconda3/envs/rl_final/lib/python3.8/site-packages/torch/nn/modules/module.py\\\", line 1051, in _call_impl\\n    return forward_call(*input, **kwargs)\\n  File \\\"/home/yos/miniconda3/envs/rl_final/lib/python3.8/site-packages/ray/rllib/models/torch/misc.py\\\", line 160, in forward\\n    return self._model(x)\\n  File \\\"/home/yos/miniconda3/envs/rl_final/lib/python3.8/site-packages/torch/nn/modules/module.py\\\", line 1051, in _call_impl\\n    return forward_call(*input, **kwargs)\\n  File \\\"/home/yos/miniconda3/envs/rl_final/lib/python3.8/site-packages/torch/nn/modules/container.py\\\", line 139, in forward\\n    input = module(input)\\n  File \\\"/home/yos/miniconda3/envs/rl_final/lib/python3.8/site-packages/torch/nn/modules/module.py\\\", line 1051, in _call_impl\\n    return forward_call(*input, **kwargs)\\n  File \\\"/home/yos/miniconda3/envs/rl_final/lib/python3.8/site-packages/torch/nn/modules/linear.py\\\", line 96, in forward\\n    return F.linear(input, self.weight, self.bias)\\n  File \\\"/home/yos/miniconda3/envs/rl_final/lib/python3.8/site-packages/torch/nn/functional.py\\\", line 1847, in linear\\n    return torch._C._nn.linear(input, weight, bias)\\nRuntimeError: CUDA error: no kernel image is available for execution on the device\\nCUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.\\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\\n\",\n  \"trial_name_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"saving_to\": null,\n  \"remote_checkpoint_dir_prefix\": null,\n  \"sync_to_cloud\": null,\n  \"checkpoint_freq\": 100,\n  \"checkpoint_at_end\": true,\n  \"keep_checkpoints_num\": null,\n  \"checkpoint_score_attr\": \"training_iteration\",\n  \"sync_on_checkpoint\": true,\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059566010000000000008c1b7261792e74756e652e636865636b706f696e745f6d616e61676572948c11436865636b706f696e744d616e616765729493942981947d94288c146b6565705f636865636b706f696e74735f6e756d94477ff00000000000008c165f636865636b706f696e745f73636f72655f6465736394898c165f636865636b706f696e745f73636f72655f61747472948c12747261696e696e675f697465726174696f6e948c1c6e65776573745f70657273697374656e745f636865636b706f696e749468008c0a436865636b706f696e749493942981947d94288c0773746f72616765948c0a70657273697374656e74948c0576616c7565944e8c06726573756c74947d9475628c195f6e65776573745f6d656d6f72795f636865636b706f696e7494680b2981947d9428680e8c066d656d6f72799468104e68117d9475628c115f626573745f636865636b706f696e7473945d948c0b5f6d656d62657273686970948f9475622e\"\n  },\n  \"restore_path\": null,\n  \"restoring_from\": null,\n  \"num_failures\": 1,\n  \"has_new_resources\": false,\n  \"results\": \"80054e2e\",\n  \"best_result\": \"80054e2e\",\n  \"param_config\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_state_json\": null,\n  \"_state_valid\": false\n}"
  ],
  "runner_data": {
    "_max_pending_trials": 35,
    "_metric": null,
    "_total_time": 0,
    "_iteration": 9,
    "_has_errored": true,
    "_fail_fast": false,
    "_server_port": null,
    "_cached_trial_decisions": {},
    "_queued_trial_decisions": {},
    "_updated_queue": true,
    "_result_wait_time": 1,
    "_should_stop_experiment": false,
    "_local_checkpoint_dir": "/home/yos/MARLlib/exp_results/maa2c_mlp_customized_map",
    "_remote_checkpoint_dir": null,
    "_stopper": {
      "_type": "CLOUDPICKLE_FALLBACK",
      "value": "80059527000000000000008c107261792e74756e652e73746f70706572948c0b4e6f6f7053746f707065729493942981942e"
    },
    "_resumed": false,
    "_start_time": 1718622416.1678662,
    "_last_checkpoint_time": -Infinity,
    "_session_str": "2024-06-17_20-06-56",
    "checkpoint_file": "/home/yos/MARLlib/exp_results/maa2c_mlp_customized_map/experiment_state-2024-06-17_20-06-56.json",
    "_checkpoint_period": "auto",
    "launch_web_server": false
  },
  "stats": {
    "start_time": 1718622416.1678662,
    "timestamp": 1718622416.2797058
  }
}