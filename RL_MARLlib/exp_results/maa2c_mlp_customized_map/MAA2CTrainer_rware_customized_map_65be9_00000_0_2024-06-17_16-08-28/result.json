{"episode_reward_max": NaN, "episode_reward_min": NaN, "episode_reward_mean": NaN, "episode_len_mean": NaN, "episode_media": {}, "episodes_this_iter": 0, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [], "episode_lengths": []}, "sampler_perf": {}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 5120, "timesteps_this_iter": 0, "agent_timesteps_total": 5120, "timers": {"sample_time_ms": 1380.537, "sample_throughput": 3708.702, "load_time_ms": 0.227, "load_throughput": 22557601.345, "learn_time_ms": 92.833, "learn_throughput": 55153.06, "update_time_ms": 2.48}, "info": {"learner": {"default_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 15.908553123474121, "policy_entropy": 8047.1708984375, "policy_loss": 7.39456033706665, "vf_loss": 1.4888427257537842}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 5120, "num_agent_steps_sampled": 5120, "num_steps_trained": 5120, "num_agent_steps_trained": 5120}, "done": false, "episodes_total": 0, "training_iteration": 1, "trial_id": "65be9_00000", "experiment_id": "b9e963105bdc4382843b68ace23a11d3", "date": "2024-06-17_16-08-30", "timestamp": 1718608110, "time_this_iter_s": 1.4662809371948242, "time_total_s": 1.4662809371948242, "pid": 4998, "hostname": "DESKTOP-LQ219J4", "node_ip": "192.168.46.185", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 20, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 5000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 500, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "rware", "env_args": {"n_agents": 4, "column_height": 1, "max_inactivity_steps": null, "max_steps": 500, "fast_obs": true, "msg_bits": 0, "sensor_range": 1, "shelf_rows": 1, "shelf_columns": 3, "request_queue_size": 4, "reward_type": "RewardType.INDIVIDUAL", "map_name": "customized_map", "map_size": "tiny", "difficulty": "medium"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": true, "force_coop": false, "local_mode": true, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 4, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 100, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64}, "algorithm": "maa2c", "space_obs": "Dict(obs:Box([-100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100.], [100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.], (112,), float32))", "space_act": "Discrete(5)", "num_agents": 4, "episode_limit": 500, "policy_mapping_info": {"all_scenario": {"description": "rware all scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2", "agent_3"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "rware_customized_map", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 10, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.policy_template.MAA2CTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x7f7c1d170f70>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "grad_clip": 40.0, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "microbatch_size": null}, "time_since_restore": 1.4662809371948242, "timesteps_since_restore": 0, "iterations_since_restore": 1, "perf": {"cpu_util_percent": 6.066666666666667, "ram_util_percent": 22.066666666666666}}
{"episode_reward_max": 5.0, "episode_reward_min": 0.0, "episode_reward_mean": 1.45, "episode_len_mean": 500.0, "episode_media": {}, "episodes_this_iter": 20, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 1.0, 3.0, 1.0, 1.0, 1.0, 2.0, 3.0, 2.0, 2.0, 1.0, 1.0, 5.0, 2.0, 1.0], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.14321771358210605, "mean_inference_ms": 0.3812203015026555, "mean_action_processing_ms": 0.028487627227370083, "mean_env_wait_ms": 0.3906780131696538, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 46080, "timesteps_this_iter": 0, "agent_timesteps_total": 46080, "timers": {"sample_time_ms": 1310.664, "sample_throughput": 3906.416, "load_time_ms": 0.116, "load_throughput": 44227352.018, "learn_time_ms": 69.255, "learn_throughput": 73930.068, "update_time_ms": 2.494}, "info": {"learner": {"default_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 43.41445541381836, "policy_entropy": 8040.5595703125, "policy_loss": 11.39175033569336, "vf_loss": 19.857370376586914}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 46080, "num_agent_steps_sampled": 46080, "num_steps_trained": 46080, "num_agent_steps_trained": 46080, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 20, "training_iteration": 2, "trial_id": "65be9_00000", "experiment_id": "b9e963105bdc4382843b68ace23a11d3", "date": "2024-06-17_16-08-41", "timestamp": 1718608121, "time_this_iter_s": 10.375566959381104, "time_total_s": 11.841847896575928, "pid": 4998, "hostname": "DESKTOP-LQ219J4", "node_ip": "192.168.46.185", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 20, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 5000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 500, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "rware", "env_args": {"n_agents": 4, "column_height": 1, "max_inactivity_steps": null, "max_steps": 500, "fast_obs": true, "msg_bits": 0, "sensor_range": 1, "shelf_rows": 1, "shelf_columns": 3, "request_queue_size": 4, "reward_type": "RewardType.INDIVIDUAL", "map_name": "customized_map", "map_size": "tiny", "difficulty": "medium"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": true, "force_coop": false, "local_mode": true, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 4, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 100, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64}, "algorithm": "maa2c", "space_obs": "Dict(obs:Box([-100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100.], [100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.], (112,), float32))", "space_act": "Discrete(5)", "num_agents": 4, "episode_limit": 500, "policy_mapping_info": {"all_scenario": {"description": "rware all scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2", "agent_3"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "rware_customized_map", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 10, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.policy_template.MAA2CTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x7f7c1cdf6d30>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "grad_clip": 40.0, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "microbatch_size": null}, "time_since_restore": 11.841847896575928, "timesteps_since_restore": 0, "iterations_since_restore": 2, "perf": {"cpu_util_percent": 4.021428571428571, "ram_util_percent": 22.849999999999998}}
{"episode_reward_max": 5.0, "episode_reward_min": 0.0, "episode_reward_mean": 1.65, "episode_len_mean": 500.0, "episode_media": {}, "episodes_this_iter": 20, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 1.0, 3.0, 1.0, 1.0, 1.0, 2.0, 3.0, 2.0, 2.0, 1.0, 1.0, 5.0, 2.0, 1.0, 3.0, 1.0, 5.0, 3.0, 2.0, 1.0, 1.0, 2.0, 2.0, 1.0, 1.0, 0.0, 2.0, 3.0, 1.0, 1.0, 3.0, 1.0, 4.0, 0.0], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.14431870174521017, "mean_inference_ms": 0.38388239066214125, "mean_action_processing_ms": 0.028615209907879052, "mean_env_wait_ms": 0.3938203429933638, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 87040, "timesteps_this_iter": 0, "agent_timesteps_total": 87040, "timers": {"sample_time_ms": 1343.607, "sample_throughput": 3810.637, "load_time_ms": 0.105, "load_throughput": 48640626.229, "learn_time_ms": 66.988, "learn_throughput": 76431.446, "update_time_ms": 2.552}, "info": {"learner": {"default_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 37.20698165893555, "policy_entropy": 8023.25927734375, "policy_loss": 4.205785751342773, "vf_loss": 17.162372589111328}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 87040, "num_agent_steps_sampled": 87040, "num_steps_trained": 87040, "num_agent_steps_trained": 87040, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 40, "training_iteration": 3, "trial_id": "65be9_00000", "experiment_id": "b9e963105bdc4382843b68ace23a11d3", "date": "2024-06-17_16-08-51", "timestamp": 1718608131, "time_this_iter_s": 10.810100078582764, "time_total_s": 22.65194797515869, "pid": 4998, "hostname": "DESKTOP-LQ219J4", "node_ip": "192.168.46.185", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 20, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 5000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 500, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "rware", "env_args": {"n_agents": 4, "column_height": 1, "max_inactivity_steps": null, "max_steps": 500, "fast_obs": true, "msg_bits": 0, "sensor_range": 1, "shelf_rows": 1, "shelf_columns": 3, "request_queue_size": 4, "reward_type": "RewardType.INDIVIDUAL", "map_name": "customized_map", "map_size": "tiny", "difficulty": "medium"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": true, "force_coop": false, "local_mode": true, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 4, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 100, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64}, "algorithm": "maa2c", "space_obs": "Dict(obs:Box([-100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100.], [100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.], (112,), float32))", "space_act": "Discrete(5)", "num_agents": 4, "episode_limit": 500, "policy_mapping_info": {"all_scenario": {"description": "rware all scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2", "agent_3"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "rware_customized_map", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 10, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.policy_template.MAA2CTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x7f7c1a77daf0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "grad_clip": 40.0, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "microbatch_size": null}, "time_since_restore": 22.65194797515869, "timesteps_since_restore": 0, "iterations_since_restore": 3, "perf": {"cpu_util_percent": 4.18125, "ram_util_percent": 23.549999999999997}}
{"episode_reward_max": 5.0, "episode_reward_min": 0.0, "episode_reward_mean": 1.59375, "episode_len_mean": 500.0, "episode_media": {}, "episodes_this_iter": 24, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 1.0, 3.0, 1.0, 1.0, 1.0, 2.0, 3.0, 2.0, 2.0, 1.0, 1.0, 5.0, 2.0, 1.0, 3.0, 1.0, 5.0, 3.0, 2.0, 1.0, 1.0, 2.0, 2.0, 1.0, 1.0, 0.0, 2.0, 3.0, 1.0, 1.0, 3.0, 1.0, 4.0, 0.0, 2.0, 3.0, 3.0, 1.0, 0.0, 2.0, 1.0, 3.0, 2.0, 2.0, 2.0, 3.0, 1.0, 2.0, 1.0, 0.0, 0.0, 2.0, 0.0, 1.0, 1.0, 0.0, 3.0, 1.0], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.14463993568660027, "mean_inference_ms": 0.3846616320759363, "mean_action_processing_ms": 0.028626564448457126, "mean_env_wait_ms": 0.3948400643581399, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 128000, "timesteps_this_iter": 0, "agent_timesteps_total": 128000, "timers": {"sample_time_ms": 1323.388, "sample_throughput": 3868.858, "load_time_ms": 0.101, "load_throughput": 50624319.849, "learn_time_ms": 66.935, "learn_throughput": 76492.348, "update_time_ms": 2.703}, "info": {"learner": {"default_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 93.84149932861328, "policy_entropy": 8000.57568359375, "policy_loss": 34.748355865478516, "vf_loss": 26.63272476196289}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 128000, "num_agent_steps_sampled": 128000, "num_steps_trained": 128000, "num_agent_steps_trained": 128000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 64, "training_iteration": 4, "trial_id": "65be9_00000", "experiment_id": "b9e963105bdc4382843b68ace23a11d3", "date": "2024-06-17_16-09-02", "timestamp": 1718608142, "time_this_iter_s": 10.601808547973633, "time_total_s": 33.253756523132324, "pid": 4998, "hostname": "DESKTOP-LQ219J4", "node_ip": "192.168.46.185", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 20, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 5000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 500, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "rware", "env_args": {"n_agents": 4, "column_height": 1, "max_inactivity_steps": null, "max_steps": 500, "fast_obs": true, "msg_bits": 0, "sensor_range": 1, "shelf_rows": 1, "shelf_columns": 3, "request_queue_size": 4, "reward_type": "RewardType.INDIVIDUAL", "map_name": "customized_map", "map_size": "tiny", "difficulty": "medium"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": true, "force_coop": false, "local_mode": true, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 4, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 100, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64}, "algorithm": "maa2c", "space_obs": "Dict(obs:Box([-100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100.], [100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.], (112,), float32))", "space_act": "Discrete(5)", "num_agents": 4, "episode_limit": 500, "policy_mapping_info": {"all_scenario": {"description": "rware all scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2", "agent_3"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "rware_customized_map", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 10, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.policy_template.MAA2CTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x7f7c1d170f70>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "grad_clip": 40.0, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "microbatch_size": null}, "time_since_restore": 33.253756523132324, "timesteps_since_restore": 0, "iterations_since_restore": 4, "perf": {"cpu_util_percent": 4.34, "ram_util_percent": 24.233333333333334}}
{"episode_reward_max": 5.0, "episode_reward_min": 0.0, "episode_reward_mean": 1.5238095238095237, "episode_len_mean": 500.0, "episode_media": {}, "episodes_this_iter": 20, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 1.0, 3.0, 1.0, 1.0, 1.0, 2.0, 3.0, 2.0, 2.0, 1.0, 1.0, 5.0, 2.0, 1.0, 3.0, 1.0, 5.0, 3.0, 2.0, 1.0, 1.0, 2.0, 2.0, 1.0, 1.0, 0.0, 2.0, 3.0, 1.0, 1.0, 3.0, 1.0, 4.0, 0.0, 2.0, 3.0, 3.0, 1.0, 0.0, 2.0, 1.0, 3.0, 2.0, 2.0, 2.0, 3.0, 1.0, 2.0, 1.0, 0.0, 0.0, 2.0, 0.0, 1.0, 1.0, 0.0, 3.0, 1.0, 1.0, 1.0, 2.0, 0.0, 0.0, 2.0, 2.0, 2.0, 1.0, 1.0, 3.0, 2.0, 2.0, 3.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.144798922611363, "mean_inference_ms": 0.3850429663029048, "mean_action_processing_ms": 0.028623097117741143, "mean_env_wait_ms": 0.39502074222023814, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 168960, "timesteps_this_iter": 0, "agent_timesteps_total": 168960, "timers": {"sample_time_ms": 1328.42, "sample_throughput": 3854.203, "load_time_ms": 0.1, "load_throughput": 51130563.048, "learn_time_ms": 66.147, "learn_throughput": 77403.032, "update_time_ms": 2.647}, "info": {"learner": {"default_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 111.49913787841797, "policy_entropy": 7991.9326171875, "policy_loss": -44.46177673339844, "vf_loss": 13.879353523254395}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 168960, "num_agent_steps_sampled": 168960, "num_steps_trained": 168960, "num_agent_steps_trained": 168960, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 84, "training_iteration": 5, "trial_id": "65be9_00000", "experiment_id": "b9e963105bdc4382843b68ace23a11d3", "date": "2024-06-17_16-09-13", "timestamp": 1718608153, "time_this_iter_s": 10.591166019439697, "time_total_s": 43.84492254257202, "pid": 4998, "hostname": "DESKTOP-LQ219J4", "node_ip": "192.168.46.185", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 20, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 5000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 500, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "rware", "env_args": {"n_agents": 4, "column_height": 1, "max_inactivity_steps": null, "max_steps": 500, "fast_obs": true, "msg_bits": 0, "sensor_range": 1, "shelf_rows": 1, "shelf_columns": 3, "request_queue_size": 4, "reward_type": "RewardType.INDIVIDUAL", "map_name": "customized_map", "map_size": "tiny", "difficulty": "medium"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": true, "force_coop": false, "local_mode": true, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 4, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 100, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64}, "algorithm": "maa2c", "space_obs": "Dict(obs:Box([-100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100.], [100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.], (112,), float32))", "space_act": "Discrete(5)", "num_agents": 4, "episode_limit": 500, "policy_mapping_info": {"all_scenario": {"description": "rware all scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2", "agent_3"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "rware_customized_map", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 10, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.policy_template.MAA2CTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x7f7c1cdf6280>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "grad_clip": 40.0, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "microbatch_size": null}, "time_since_restore": 43.84492254257202, "timesteps_since_restore": 0, "iterations_since_restore": 5, "perf": {"cpu_util_percent": 4.653333333333333, "ram_util_percent": 24.973333333333333}}
{"episode_reward_max": 5.0, "episode_reward_min": 0.0, "episode_reward_mean": 1.71, "episode_len_mean": 500.0, "episode_media": {}, "episodes_this_iter": 20, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [2.0, 0.0, 1.0, 3.0, 1.0, 1.0, 1.0, 2.0, 3.0, 2.0, 2.0, 1.0, 1.0, 5.0, 2.0, 1.0, 3.0, 1.0, 5.0, 3.0, 2.0, 1.0, 1.0, 2.0, 2.0, 1.0, 1.0, 0.0, 2.0, 3.0, 1.0, 1.0, 3.0, 1.0, 4.0, 0.0, 2.0, 3.0, 3.0, 1.0, 0.0, 2.0, 1.0, 3.0, 2.0, 2.0, 2.0, 3.0, 1.0, 2.0, 1.0, 0.0, 0.0, 2.0, 0.0, 1.0, 1.0, 0.0, 3.0, 1.0, 1.0, 1.0, 2.0, 0.0, 0.0, 2.0, 2.0, 2.0, 1.0, 1.0, 3.0, 2.0, 2.0, 3.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 4.0, 4.0, 1.0, 0.0, 2.0, 2.0, 2.0, 1.0, 1.0, 3.0, 3.0, 1.0, 3.0, 5.0, 3.0, 2.0, 1.0, 2.0, 2.0, 2.0], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.14499410208117627, "mean_inference_ms": 0.3855712645400749, "mean_action_processing_ms": 0.028638181490600267, "mean_env_wait_ms": 0.39571437610176113, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 209920, "timesteps_this_iter": 0, "agent_timesteps_total": 209920, "timers": {"sample_time_ms": 1339.1, "sample_throughput": 3823.464, "load_time_ms": 0.103, "load_throughput": 49504002.951, "learn_time_ms": 65.323, "learn_throughput": 78379.75, "update_time_ms": 2.773}, "info": {"learner": {"default_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 44.65245056152344, "policy_entropy": 7976.138671875, "policy_loss": -13.78547477722168, "vf_loss": 21.87148666381836}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 209920, "num_agent_steps_sampled": 209920, "num_steps_trained": 209920, "num_agent_steps_trained": 209920, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 104, "training_iteration": 6, "trial_id": "65be9_00000", "experiment_id": "b9e963105bdc4382843b68ace23a11d3", "date": "2024-06-17_16-09-23", "timestamp": 1718608163, "time_this_iter_s": 10.728079557418823, "time_total_s": 54.573002099990845, "pid": 4998, "hostname": "DESKTOP-LQ219J4", "node_ip": "192.168.46.185", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 20, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 5000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 500, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "rware", "env_args": {"n_agents": 4, "column_height": 1, "max_inactivity_steps": null, "max_steps": 500, "fast_obs": true, "msg_bits": 0, "sensor_range": 1, "shelf_rows": 1, "shelf_columns": 3, "request_queue_size": 4, "reward_type": "RewardType.INDIVIDUAL", "map_name": "customized_map", "map_size": "tiny", "difficulty": "medium"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": true, "force_coop": false, "local_mode": true, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 4, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 100, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64}, "algorithm": "maa2c", "space_obs": "Dict(obs:Box([-100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100.], [100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.], (112,), float32))", "space_act": "Discrete(5)", "num_agents": 4, "episode_limit": 500, "policy_mapping_info": {"all_scenario": {"description": "rware all scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2", "agent_3"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "rware_customized_map", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 10, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.policy_template.MAA2CTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x7f7c1d450c10>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "grad_clip": 40.0, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "microbatch_size": null}, "time_since_restore": 54.573002099990845, "timesteps_since_restore": 0, "iterations_since_restore": 6, "perf": {"cpu_util_percent": 4.02, "ram_util_percent": 25.613333333333333}}
{"episode_reward_max": 5.0, "episode_reward_min": 0.0, "episode_reward_mean": 1.62, "episode_len_mean": 500.0, "episode_media": {}, "episodes_this_iter": 20, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [2.0, 1.0, 1.0, 2.0, 2.0, 1.0, 1.0, 0.0, 2.0, 3.0, 1.0, 1.0, 3.0, 1.0, 4.0, 0.0, 2.0, 3.0, 3.0, 1.0, 0.0, 2.0, 1.0, 3.0, 2.0, 2.0, 2.0, 3.0, 1.0, 2.0, 1.0, 0.0, 0.0, 2.0, 0.0, 1.0, 1.0, 0.0, 3.0, 1.0, 1.0, 1.0, 2.0, 0.0, 0.0, 2.0, 2.0, 2.0, 1.0, 1.0, 3.0, 2.0, 2.0, 3.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 4.0, 4.0, 1.0, 0.0, 2.0, 2.0, 2.0, 1.0, 1.0, 3.0, 3.0, 1.0, 3.0, 5.0, 3.0, 2.0, 1.0, 2.0, 2.0, 2.0, 4.0, 2.0, 3.0, 0.0, 3.0, 3.0, 2.0, 1.0, 1.0, 2.0, 2.0, 0.0, 2.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 2.0], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.14542499898175396, "mean_inference_ms": 0.3866479914837511, "mean_action_processing_ms": 0.028670611842842728, "mean_env_wait_ms": 0.3967619488227187, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 250880, "timesteps_this_iter": 0, "agent_timesteps_total": 250880, "timers": {"sample_time_ms": 1339.446, "sample_throughput": 3822.476, "load_time_ms": 0.106, "load_throughput": 48171459.13, "learn_time_ms": 66.111, "learn_throughput": 77445.461, "update_time_ms": 2.831}, "info": {"learner": {"default_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 150.66488647460938, "policy_entropy": 8020.41845703125, "policy_loss": -65.83895874023438, "vf_loss": 0.7242112755775452}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 250880, "num_agent_steps_sampled": 250880, "num_steps_trained": 250880, "num_agent_steps_trained": 250880, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 124, "training_iteration": 7, "trial_id": "65be9_00000", "experiment_id": "b9e963105bdc4382843b68ace23a11d3", "date": "2024-06-17_16-09-34", "timestamp": 1718608174, "time_this_iter_s": 10.719085216522217, "time_total_s": 65.29208731651306, "pid": 4998, "hostname": "DESKTOP-LQ219J4", "node_ip": "192.168.46.185", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 20, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 5000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 500, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "rware", "env_args": {"n_agents": 4, "column_height": 1, "max_inactivity_steps": null, "max_steps": 500, "fast_obs": true, "msg_bits": 0, "sensor_range": 1, "shelf_rows": 1, "shelf_columns": 3, "request_queue_size": 4, "reward_type": "RewardType.INDIVIDUAL", "map_name": "customized_map", "map_size": "tiny", "difficulty": "medium"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": true, "force_coop": false, "local_mode": true, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 4, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 100, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64}, "algorithm": "maa2c", "space_obs": "Dict(obs:Box([-100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100.], [100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.], (112,), float32))", "space_act": "Discrete(5)", "num_agents": 4, "episode_limit": 500, "policy_mapping_info": {"all_scenario": {"description": "rware all scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2", "agent_3"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "rware_customized_map", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 10, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.policy_template.MAA2CTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x7f7c1d54a9d0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "grad_clip": 40.0, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "microbatch_size": null}, "time_since_restore": 65.29208731651306, "timesteps_since_restore": 0, "iterations_since_restore": 7, "perf": {"cpu_util_percent": 4.2749999999999995, "ram_util_percent": 26.28125}}
{"episode_reward_max": 5.0, "episode_reward_min": 0.0, "episode_reward_mean": 1.51, "episode_len_mean": 500.0, "episode_media": {}, "episodes_this_iter": 20, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 2.0, 1.0, 3.0, 2.0, 2.0, 2.0, 3.0, 1.0, 2.0, 1.0, 0.0, 0.0, 2.0, 0.0, 1.0, 1.0, 0.0, 3.0, 1.0, 1.0, 1.0, 2.0, 0.0, 0.0, 2.0, 2.0, 2.0, 1.0, 1.0, 3.0, 2.0, 2.0, 3.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 4.0, 4.0, 1.0, 0.0, 2.0, 2.0, 2.0, 1.0, 1.0, 3.0, 3.0, 1.0, 3.0, 5.0, 3.0, 2.0, 1.0, 2.0, 2.0, 2.0, 4.0, 2.0, 3.0, 0.0, 3.0, 3.0, 2.0, 1.0, 1.0, 2.0, 2.0, 0.0, 2.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 2.0, 0.0, 2.0, 3.0, 2.0, 2.0, 0.0, 1.0, 1.0, 2.0, 0.0, 1.0, 2.0, 1.0, 1.0, 1.0, 0.0, 3.0, 0.0, 1.0, 0.0], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.1455333397261478, "mean_inference_ms": 0.3868962828166598, "mean_action_processing_ms": 0.0286607749077009, "mean_env_wait_ms": 0.39674675600652504, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 291840, "timesteps_this_iter": 0, "agent_timesteps_total": 291840, "timers": {"sample_time_ms": 1332.368, "sample_throughput": 3842.782, "load_time_ms": 0.102, "load_throughput": 50304137.925, "learn_time_ms": 66.668, "learn_throughput": 76798.81, "update_time_ms": 2.859}, "info": {"learner": {"default_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 57.17440414428711, "policy_entropy": 8030.2109375, "policy_loss": -25.896854400634766, "vf_loss": 2.162933349609375}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 291840, "num_agent_steps_sampled": 291840, "num_steps_trained": 291840, "num_agent_steps_trained": 291840, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 144, "training_iteration": 8, "trial_id": "65be9_00000", "experiment_id": "b9e963105bdc4382843b68ace23a11d3", "date": "2024-06-17_16-09-45", "timestamp": 1718608185, "time_this_iter_s": 10.661348581314087, "time_total_s": 75.95343589782715, "pid": 4998, "hostname": "DESKTOP-LQ219J4", "node_ip": "192.168.46.185", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 20, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 5000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 500, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "rware", "env_args": {"n_agents": 4, "column_height": 1, "max_inactivity_steps": null, "max_steps": 500, "fast_obs": true, "msg_bits": 0, "sensor_range": 1, "shelf_rows": 1, "shelf_columns": 3, "request_queue_size": 4, "reward_type": "RewardType.INDIVIDUAL", "map_name": "customized_map", "map_size": "tiny", "difficulty": "medium"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": true, "force_coop": false, "local_mode": true, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 4, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 100, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64}, "algorithm": "maa2c", "space_obs": "Dict(obs:Box([-100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100.], [100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.], (112,), float32))", "space_act": "Discrete(5)", "num_agents": 4, "episode_limit": 500, "policy_mapping_info": {"all_scenario": {"description": "rware all scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2", "agent_3"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "rware_customized_map", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 10, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.policy_template.MAA2CTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x7f7c1afbc940>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "grad_clip": 40.0, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "microbatch_size": null}, "time_since_restore": 75.95343589782715, "timesteps_since_restore": 0, "iterations_since_restore": 8, "perf": {"cpu_util_percent": 4.273333333333334, "ram_util_percent": 26.953333333333337}}
{"episode_reward_max": 5.0, "episode_reward_min": 0.0, "episode_reward_mean": 1.54, "episode_len_mean": 500.0, "episode_media": {}, "episodes_this_iter": 20, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [1.0, 1.0, 2.0, 0.0, 0.0, 2.0, 2.0, 2.0, 1.0, 1.0, 3.0, 2.0, 2.0, 3.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 4.0, 4.0, 1.0, 0.0, 2.0, 2.0, 2.0, 1.0, 1.0, 3.0, 3.0, 1.0, 3.0, 5.0, 3.0, 2.0, 1.0, 2.0, 2.0, 2.0, 4.0, 2.0, 3.0, 0.0, 3.0, 3.0, 2.0, 1.0, 1.0, 2.0, 2.0, 0.0, 2.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 2.0, 0.0, 2.0, 3.0, 2.0, 2.0, 0.0, 1.0, 1.0, 2.0, 0.0, 1.0, 2.0, 1.0, 1.0, 1.0, 0.0, 3.0, 0.0, 1.0, 0.0, 3.0, 0.0, 0.0, 1.0, 4.0, 2.0, 1.0, 0.0, 1.0, 1.0, 2.0, 2.0, 2.0, 2.0, 3.0, 0.0, 3.0, 2.0, 0.0, 1.0], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.1457235851268424, "mean_inference_ms": 0.38728809308508266, "mean_action_processing_ms": 0.028667378539637304, "mean_env_wait_ms": 0.39628236710677434, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 332800, "timesteps_this_iter": 0, "agent_timesteps_total": 332800, "timers": {"sample_time_ms": 1338.159, "sample_throughput": 3826.153, "load_time_ms": 0.101, "load_throughput": 50743942.533, "learn_time_ms": 66.386, "learn_throughput": 77125.184, "update_time_ms": 2.82}, "info": {"learner": {"default_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 112.76138305664062, "policy_entropy": 8018.5859375, "policy_loss": -49.65869903564453, "vf_loss": 0.3344321846961975}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 332800, "num_agent_steps_sampled": 332800, "num_steps_trained": 332800, "num_agent_steps_trained": 332800, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 164, "training_iteration": 9, "trial_id": "65be9_00000", "experiment_id": "b9e963105bdc4382843b68ace23a11d3", "date": "2024-06-17_16-09-56", "timestamp": 1718608196, "time_this_iter_s": 10.643298387527466, "time_total_s": 86.59673428535461, "pid": 4998, "hostname": "DESKTOP-LQ219J4", "node_ip": "192.168.46.185", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 20, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 5000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 500, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "rware", "env_args": {"n_agents": 4, "column_height": 1, "max_inactivity_steps": null, "max_steps": 500, "fast_obs": true, "msg_bits": 0, "sensor_range": 1, "shelf_rows": 1, "shelf_columns": 3, "request_queue_size": 4, "reward_type": "RewardType.INDIVIDUAL", "map_name": "customized_map", "map_size": "tiny", "difficulty": "medium"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": true, "force_coop": false, "local_mode": true, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 4, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 100, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64}, "algorithm": "maa2c", "space_obs": "Dict(obs:Box([-100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100.], [100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.], (112,), float32))", "space_act": "Discrete(5)", "num_agents": 4, "episode_limit": 500, "policy_mapping_info": {"all_scenario": {"description": "rware all scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2", "agent_3"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "rware_customized_map", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 10, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.policy_template.MAA2CTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x7f7c1cdf6280>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "grad_clip": 40.0, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "microbatch_size": null}, "time_since_restore": 86.59673428535461, "timesteps_since_restore": 0, "iterations_since_restore": 9, "perf": {"cpu_util_percent": 4.1066666666666665, "ram_util_percent": 27.61333333333333}}
{"episode_reward_max": 5.0, "episode_reward_min": 0.0, "episode_reward_mean": 1.47, "episode_len_mean": 500.0, "episode_media": {}, "episodes_this_iter": 20, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [4.0, 4.0, 1.0, 0.0, 2.0, 2.0, 2.0, 1.0, 1.0, 3.0, 3.0, 1.0, 3.0, 5.0, 3.0, 2.0, 1.0, 2.0, 2.0, 2.0, 4.0, 2.0, 3.0, 0.0, 3.0, 3.0, 2.0, 1.0, 1.0, 2.0, 2.0, 0.0, 2.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 2.0, 0.0, 2.0, 3.0, 2.0, 2.0, 0.0, 1.0, 1.0, 2.0, 0.0, 1.0, 2.0, 1.0, 1.0, 1.0, 0.0, 3.0, 0.0, 1.0, 0.0, 3.0, 0.0, 0.0, 1.0, 4.0, 2.0, 1.0, 0.0, 1.0, 1.0, 2.0, 2.0, 2.0, 2.0, 3.0, 0.0, 3.0, 2.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 2.0, 0.0, 3.0, 2.0, 2.0, 0.0, 1.0, 0.0, 2.0, 0.0, 0.0, 0.0, 1.0, 0.0, 2.0, 2.0], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.1458892499421024, "mean_inference_ms": 0.38764920151356314, "mean_action_processing_ms": 0.02868158018248477, "mean_env_wait_ms": 0.39637859471945375, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 373760, "timesteps_this_iter": 0, "agent_timesteps_total": 373760, "timers": {"sample_time_ms": 1335.817, "sample_throughput": 3832.86, "load_time_ms": 0.115, "load_throughput": 44498210.692, "learn_time_ms": 66.997, "learn_throughput": 76420.866, "update_time_ms": 2.781}, "info": {"learner": {"default_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 70.5760726928711, "policy_entropy": 8003.982421875, "policy_loss": 27.087276458740234, "vf_loss": 18.276363372802734}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 373760, "num_agent_steps_sampled": 373760, "num_steps_trained": 373760, "num_agent_steps_trained": 373760, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 184, "training_iteration": 10, "trial_id": "65be9_00000", "experiment_id": "b9e963105bdc4382843b68ace23a11d3", "date": "2024-06-17_16-10-06", "timestamp": 1718608206, "time_this_iter_s": 10.705274820327759, "time_total_s": 97.30200910568237, "pid": 4998, "hostname": "DESKTOP-LQ219J4", "node_ip": "192.168.46.185", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 20, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 5000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 500, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "rware", "env_args": {"n_agents": 4, "column_height": 1, "max_inactivity_steps": null, "max_steps": 500, "fast_obs": true, "msg_bits": 0, "sensor_range": 1, "shelf_rows": 1, "shelf_columns": 3, "request_queue_size": 4, "reward_type": "RewardType.INDIVIDUAL", "map_name": "customized_map", "map_size": "tiny", "difficulty": "medium"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": true, "force_coop": false, "local_mode": true, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 4, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 100, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64}, "algorithm": "maa2c", "space_obs": "Dict(obs:Box([-100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100.], [100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.], (112,), float32))", "space_act": "Discrete(5)", "num_agents": 4, "episode_limit": 500, "policy_mapping_info": {"all_scenario": {"description": "rware all scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2", "agent_3"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "rware_customized_map", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 10, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.policy_template.MAA2CTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x7f7c1afbcee0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "grad_clip": 40.0, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "microbatch_size": null}, "time_since_restore": 97.30200910568237, "timesteps_since_restore": 0, "iterations_since_restore": 10, "perf": {"cpu_util_percent": 3.9799999999999995, "ram_util_percent": 28.253333333333334}}
{"episode_reward_max": 4.0, "episode_reward_min": 0.0, "episode_reward_mean": 1.3, "episode_len_mean": 500.0, "episode_media": {}, "episodes_this_iter": 20, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [4.0, 2.0, 3.0, 0.0, 3.0, 3.0, 2.0, 1.0, 1.0, 2.0, 2.0, 0.0, 2.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 2.0, 0.0, 2.0, 3.0, 2.0, 2.0, 0.0, 1.0, 1.0, 2.0, 0.0, 1.0, 2.0, 1.0, 1.0, 1.0, 0.0, 3.0, 0.0, 1.0, 0.0, 3.0, 0.0, 0.0, 1.0, 4.0, 2.0, 1.0, 0.0, 1.0, 1.0, 2.0, 2.0, 2.0, 2.0, 3.0, 0.0, 3.0, 2.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 2.0, 0.0, 3.0, 2.0, 2.0, 0.0, 1.0, 0.0, 2.0, 0.0, 0.0, 0.0, 1.0, 0.0, 2.0, 2.0, 2.0, 0.0, 1.0, 1.0, 1.0, 2.0, 2.0, 0.0, 4.0, 3.0, 0.0, 1.0, 2.0, 0.0, 0.0, 0.0, 1.0, 4.0, 2.0, 1.0], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.14599916541982527, "mean_inference_ms": 0.38787945143653885, "mean_action_processing_ms": 0.02868189066586973, "mean_env_wait_ms": 0.39631017039988825, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 414720, "timesteps_this_iter": 0, "agent_timesteps_total": 414720, "timers": {"sample_time_ms": 1333.939, "sample_throughput": 3838.256, "load_time_ms": 0.115, "load_throughput": 44711298.105, "learn_time_ms": 66.478, "learn_throughput": 77017.696, "update_time_ms": 2.759}, "info": {"learner": {"default_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 70.60041046142578, "policy_entropy": 8015.97509765625, "policy_loss": 28.516563415527344, "vf_loss": 14.069668769836426}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 414720, "num_agent_steps_sampled": 414720, "num_steps_trained": 414720, "num_agent_steps_trained": 414720, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 204, "training_iteration": 11, "trial_id": "65be9_00000", "experiment_id": "b9e963105bdc4382843b68ace23a11d3", "date": "2024-06-17_16-10-17", "timestamp": 1718608217, "time_this_iter_s": 10.682600021362305, "time_total_s": 107.98460912704468, "pid": 4998, "hostname": "DESKTOP-LQ219J4", "node_ip": "192.168.46.185", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 20, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 5000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 500, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "rware", "env_args": {"n_agents": 4, "column_height": 1, "max_inactivity_steps": null, "max_steps": 500, "fast_obs": true, "msg_bits": 0, "sensor_range": 1, "shelf_rows": 1, "shelf_columns": 3, "request_queue_size": 4, "reward_type": "RewardType.INDIVIDUAL", "map_name": "customized_map", "map_size": "tiny", "difficulty": "medium"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": true, "force_coop": false, "local_mode": true, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 4, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 100, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64}, "algorithm": "maa2c", "space_obs": "Dict(obs:Box([-100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100.], [100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.], (112,), float32))", "space_act": "Discrete(5)", "num_agents": 4, "episode_limit": 500, "policy_mapping_info": {"all_scenario": {"description": "rware all scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2", "agent_3"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "rware_customized_map", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 10, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.policy_template.MAA2CTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x7f7c1cdf6f70>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "grad_clip": 40.0, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "microbatch_size": null}, "time_since_restore": 107.98460912704468, "timesteps_since_restore": 0, "iterations_since_restore": 11, "perf": {"cpu_util_percent": 3.96875, "ram_util_percent": 28.91875}}
{"episode_reward_max": 5.0, "episode_reward_min": 0.0, "episode_reward_mean": 1.26, "episode_len_mean": 500.0, "episode_media": {}, "episodes_this_iter": 20, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 2.0, 3.0, 2.0, 2.0, 0.0, 1.0, 1.0, 2.0, 0.0, 1.0, 2.0, 1.0, 1.0, 1.0, 0.0, 3.0, 0.0, 1.0, 0.0, 3.0, 0.0, 0.0, 1.0, 4.0, 2.0, 1.0, 0.0, 1.0, 1.0, 2.0, 2.0, 2.0, 2.0, 3.0, 0.0, 3.0, 2.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 2.0, 0.0, 3.0, 2.0, 2.0, 0.0, 1.0, 0.0, 2.0, 0.0, 0.0, 0.0, 1.0, 0.0, 2.0, 2.0, 2.0, 0.0, 1.0, 1.0, 1.0, 2.0, 2.0, 0.0, 4.0, 3.0, 0.0, 1.0, 2.0, 0.0, 0.0, 0.0, 1.0, 4.0, 2.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 3.0, 0.0, 3.0, 2.0, 1.0, 0.0, 0.0, 2.0, 2.0, 3.0, 5.0, 1.0, 0.0], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.1460884384341622, "mean_inference_ms": 0.38802961263130425, "mean_action_processing_ms": 0.02867869632354859, "mean_env_wait_ms": 0.3960111292309599, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 455680, "timesteps_this_iter": 0, "agent_timesteps_total": 455680, "timers": {"sample_time_ms": 1322.63, "sample_throughput": 3871.075, "load_time_ms": 0.105, "load_throughput": 48762117.348, "learn_time_ms": 66.457, "learn_throughput": 77041.79, "update_time_ms": 2.799}, "info": {"learner": {"default_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 133.95455932617188, "policy_entropy": 8023.728515625, "policy_loss": 51.726497650146484, "vf_loss": 31.654560089111328}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 455680, "num_agent_steps_sampled": 455680, "num_steps_trained": 455680, "num_agent_steps_trained": 455680, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 224, "training_iteration": 12, "trial_id": "65be9_00000", "experiment_id": "b9e963105bdc4382843b68ace23a11d3", "date": "2024-06-17_16-10-28", "timestamp": 1718608228, "time_this_iter_s": 10.60262417793274, "time_total_s": 118.58723330497742, "pid": 4998, "hostname": "DESKTOP-LQ219J4", "node_ip": "192.168.46.185", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 20, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 5000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 500, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "rware", "env_args": {"n_agents": 4, "column_height": 1, "max_inactivity_steps": null, "max_steps": 500, "fast_obs": true, "msg_bits": 0, "sensor_range": 1, "shelf_rows": 1, "shelf_columns": 3, "request_queue_size": 4, "reward_type": "RewardType.INDIVIDUAL", "map_name": "customized_map", "map_size": "tiny", "difficulty": "medium"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": true, "force_coop": false, "local_mode": true, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 4, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 100, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64}, "algorithm": "maa2c", "space_obs": "Dict(obs:Box([-100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100.], [100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.], (112,), float32))", "space_act": "Discrete(5)", "num_agents": 4, "episode_limit": 500, "policy_mapping_info": {"all_scenario": {"description": "rware all scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2", "agent_3"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "rware_customized_map", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 10, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.policy_template.MAA2CTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x7f7c1d906550>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "grad_clip": 40.0, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "microbatch_size": null}, "time_since_restore": 118.58723330497742, "timesteps_since_restore": 0, "iterations_since_restore": 12, "perf": {"cpu_util_percent": 4.066666666666666, "ram_util_percent": 29.59333333333333}}
{"episode_reward_max": 5.0, "episode_reward_min": 0.0, "episode_reward_mean": 1.35, "episode_len_mean": 500.0, "episode_media": {}, "episodes_this_iter": 24, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [4.0, 2.0, 1.0, 0.0, 1.0, 1.0, 2.0, 2.0, 2.0, 2.0, 3.0, 0.0, 3.0, 2.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 2.0, 0.0, 3.0, 2.0, 2.0, 0.0, 1.0, 0.0, 2.0, 0.0, 0.0, 0.0, 1.0, 0.0, 2.0, 2.0, 2.0, 0.0, 1.0, 1.0, 1.0, 2.0, 2.0, 0.0, 4.0, 3.0, 0.0, 1.0, 2.0, 0.0, 0.0, 0.0, 1.0, 4.0, 2.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 3.0, 0.0, 3.0, 2.0, 1.0, 0.0, 0.0, 2.0, 2.0, 3.0, 5.0, 1.0, 0.0, 3.0, 2.0, 2.0, 2.0, 1.0, 2.0, 2.0, 1.0, 1.0, 1.0, 1.0, 1.0, 2.0, 1.0, 1.0, 2.0, 1.0, 3.0, 2.0, 0.0, 1.0, 1.0, 2.0, 1.0], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.14616935452041113, "mean_inference_ms": 0.3881658481496141, "mean_action_processing_ms": 0.028677689361144537, "mean_env_wait_ms": 0.39593358747113955, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 496640, "timesteps_this_iter": 0, "agent_timesteps_total": 496640, "timers": {"sample_time_ms": 1336.84, "sample_throughput": 3829.926, "load_time_ms": 0.109, "load_throughput": 46816735.295, "learn_time_ms": 65.519, "learn_throughput": 78145.386, "update_time_ms": 2.839}, "info": {"learner": {"default_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 63.08654022216797, "policy_entropy": 7969.341796875, "policy_loss": -21.53170394897461, "vf_loss": 21.476566314697266}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 496640, "num_agent_steps_sampled": 496640, "num_steps_trained": 496640, "num_agent_steps_trained": 496640, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 248, "training_iteration": 13, "trial_id": "65be9_00000", "experiment_id": "b9e963105bdc4382843b68ace23a11d3", "date": "2024-06-17_16-10-38", "timestamp": 1718608238, "time_this_iter_s": 10.67828917503357, "time_total_s": 129.265522480011, "pid": 4998, "hostname": "DESKTOP-LQ219J4", "node_ip": "192.168.46.185", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 20, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 5000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 500, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "rware", "env_args": {"n_agents": 4, "column_height": 1, "max_inactivity_steps": null, "max_steps": 500, "fast_obs": true, "msg_bits": 0, "sensor_range": 1, "shelf_rows": 1, "shelf_columns": 3, "request_queue_size": 4, "reward_type": "RewardType.INDIVIDUAL", "map_name": "customized_map", "map_size": "tiny", "difficulty": "medium"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": true, "force_coop": false, "local_mode": true, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 4, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 100, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64}, "algorithm": "maa2c", "space_obs": "Dict(obs:Box([-100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100.], [100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.], (112,), float32))", "space_act": "Discrete(5)", "num_agents": 4, "episode_limit": 500, "policy_mapping_info": {"all_scenario": {"description": "rware all scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2", "agent_3"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "rware_customized_map", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 10, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.policy_template.MAA2CTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x7f7c1cdf6670>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "grad_clip": 40.0, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "microbatch_size": null}, "time_since_restore": 129.265522480011, "timesteps_since_restore": 0, "iterations_since_restore": 13, "perf": {"cpu_util_percent": 4.1866666666666665, "ram_util_percent": 30.246666666666663}}
{"episode_reward_max": 5.0, "episode_reward_min": 0.0, "episode_reward_mean": 1.38, "episode_len_mean": 500.0, "episode_media": {}, "episodes_this_iter": 20, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [2.0, 0.0, 3.0, 2.0, 2.0, 0.0, 1.0, 0.0, 2.0, 0.0, 0.0, 0.0, 1.0, 0.0, 2.0, 2.0, 2.0, 0.0, 1.0, 1.0, 1.0, 2.0, 2.0, 0.0, 4.0, 3.0, 0.0, 1.0, 2.0, 0.0, 0.0, 0.0, 1.0, 4.0, 2.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 3.0, 0.0, 3.0, 2.0, 1.0, 0.0, 0.0, 2.0, 2.0, 3.0, 5.0, 1.0, 0.0, 3.0, 2.0, 2.0, 2.0, 1.0, 2.0, 2.0, 1.0, 1.0, 1.0, 1.0, 1.0, 2.0, 1.0, 1.0, 2.0, 1.0, 3.0, 2.0, 0.0, 1.0, 1.0, 2.0, 1.0, 2.0, 5.0, 1.0, 0.0, 0.0, 2.0, 2.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0, 1.0, 2.0, 1.0, 2.0, 1.0, 2.0, 3.0], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.14624831000374328, "mean_inference_ms": 0.38828113308944134, "mean_action_processing_ms": 0.028676353782209646, "mean_env_wait_ms": 0.39578524530400416, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 537600, "timesteps_this_iter": 0, "agent_timesteps_total": 537600, "timers": {"sample_time_ms": 1346.15, "sample_throughput": 3803.44, "load_time_ms": 0.115, "load_throughput": 44655513.579, "learn_time_ms": 66.06, "learn_throughput": 77505.724, "update_time_ms": 2.775}, "info": {"learner": {"default_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 37.35832595825195, "policy_entropy": 7959.0400390625, "policy_loss": -9.22955322265625, "vf_loss": 16.31997299194336}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 537600, "num_agent_steps_sampled": 537600, "num_steps_trained": 537600, "num_agent_steps_trained": 537600, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 268, "training_iteration": 14, "trial_id": "65be9_00000", "experiment_id": "b9e963105bdc4382843b68ace23a11d3", "date": "2024-06-17_16-10-49", "timestamp": 1718608249, "time_this_iter_s": 10.774975538253784, "time_total_s": 140.04049801826477, "pid": 4998, "hostname": "DESKTOP-LQ219J4", "node_ip": "192.168.46.185", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 20, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 5000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 500, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "rware", "env_args": {"n_agents": 4, "column_height": 1, "max_inactivity_steps": null, "max_steps": 500, "fast_obs": true, "msg_bits": 0, "sensor_range": 1, "shelf_rows": 1, "shelf_columns": 3, "request_queue_size": 4, "reward_type": "RewardType.INDIVIDUAL", "map_name": "customized_map", "map_size": "tiny", "difficulty": "medium"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": true, "force_coop": false, "local_mode": true, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 4, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 100, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64}, "algorithm": "maa2c", "space_obs": "Dict(obs:Box([-100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100.], [100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.], (112,), float32))", "space_act": "Discrete(5)", "num_agents": 4, "episode_limit": 500, "policy_mapping_info": {"all_scenario": {"description": "rware all scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2", "agent_3"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "rware_customized_map", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 10, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.policy_template.MAA2CTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x7f7c1af19280>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "grad_clip": 40.0, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "microbatch_size": null}, "time_since_restore": 140.04049801826477, "timesteps_since_restore": 0, "iterations_since_restore": 14, "perf": {"cpu_util_percent": 4.093333333333335, "ram_util_percent": 30.873333333333335}}
{"episode_reward_max": 5.0, "episode_reward_min": 0.0, "episode_reward_mean": 1.44, "episode_len_mean": 500.0, "episode_media": {}, "episodes_this_iter": 20, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [1.0, 2.0, 2.0, 0.0, 4.0, 3.0, 0.0, 1.0, 2.0, 0.0, 0.0, 0.0, 1.0, 4.0, 2.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 3.0, 0.0, 3.0, 2.0, 1.0, 0.0, 0.0, 2.0, 2.0, 3.0, 5.0, 1.0, 0.0, 3.0, 2.0, 2.0, 2.0, 1.0, 2.0, 2.0, 1.0, 1.0, 1.0, 1.0, 1.0, 2.0, 1.0, 1.0, 2.0, 1.0, 3.0, 2.0, 0.0, 1.0, 1.0, 2.0, 1.0, 2.0, 5.0, 1.0, 0.0, 0.0, 2.0, 2.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0, 1.0, 2.0, 1.0, 2.0, 1.0, 2.0, 3.0, 0.0, 2.0, 1.0, 2.0, 3.0, 1.0, 1.0, 0.0, 2.0, 1.0, 1.0, 0.0, 2.0, 1.0, 2.0, 1.0, 3.0, 0.0, 3.0, 1.0], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.14630950051475725, "mean_inference_ms": 0.38838338428553354, "mean_action_processing_ms": 0.028673583773396807, "mean_env_wait_ms": 0.39564212039271607, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 578560, "timesteps_this_iter": 0, "agent_timesteps_total": 578560, "timers": {"sample_time_ms": 1340.632, "sample_throughput": 3819.094, "load_time_ms": 0.113, "load_throughput": 45219702.0, "learn_time_ms": 65.806, "learn_throughput": 77804.644, "update_time_ms": 2.765}, "info": {"learner": {"default_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 50.81511306762695, "policy_entropy": 7990.16845703125, "policy_loss": -23.13127899169922, "vf_loss": 13.588397979736328}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 578560, "num_agent_steps_sampled": 578560, "num_steps_trained": 578560, "num_agent_steps_trained": 578560, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 288, "training_iteration": 15, "trial_id": "65be9_00000", "experiment_id": "b9e963105bdc4382843b68ace23a11d3", "date": "2024-06-17_16-11-00", "timestamp": 1718608260, "time_this_iter_s": 10.700226068496704, "time_total_s": 150.74072408676147, "pid": 4998, "hostname": "DESKTOP-LQ219J4", "node_ip": "192.168.46.185", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 20, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 5000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 500, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "rware", "env_args": {"n_agents": 4, "column_height": 1, "max_inactivity_steps": null, "max_steps": 500, "fast_obs": true, "msg_bits": 0, "sensor_range": 1, "shelf_rows": 1, "shelf_columns": 3, "request_queue_size": 4, "reward_type": "RewardType.INDIVIDUAL", "map_name": "customized_map", "map_size": "tiny", "difficulty": "medium"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": true, "force_coop": false, "local_mode": true, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 4, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 100, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64}, "algorithm": "maa2c", "space_obs": "Dict(obs:Box([-100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100.], [100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.], (112,), float32))", "space_act": "Discrete(5)", "num_agents": 4, "episode_limit": 500, "policy_mapping_info": {"all_scenario": {"description": "rware all scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2", "agent_3"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "rware_customized_map", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 10, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.policy_template.MAA2CTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x7f7c1d450d30>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "grad_clip": 40.0, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "microbatch_size": null}, "time_since_restore": 150.74072408676147, "timesteps_since_restore": 0, "iterations_since_restore": 15, "perf": {"cpu_util_percent": 4.09375, "ram_util_percent": 31.55625}}
{"episode_reward_max": 5.0, "episode_reward_min": 0.0, "episode_reward_mean": 1.47, "episode_len_mean": 500.0, "episode_media": {}, "episodes_this_iter": 20, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [1.0, 0.0, 0.0, 3.0, 0.0, 3.0, 2.0, 1.0, 0.0, 0.0, 2.0, 2.0, 3.0, 5.0, 1.0, 0.0, 3.0, 2.0, 2.0, 2.0, 1.0, 2.0, 2.0, 1.0, 1.0, 1.0, 1.0, 1.0, 2.0, 1.0, 1.0, 2.0, 1.0, 3.0, 2.0, 0.0, 1.0, 1.0, 2.0, 1.0, 2.0, 5.0, 1.0, 0.0, 0.0, 2.0, 2.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0, 1.0, 2.0, 1.0, 2.0, 1.0, 2.0, 3.0, 0.0, 2.0, 1.0, 2.0, 3.0, 1.0, 1.0, 0.0, 2.0, 1.0, 1.0, 0.0, 2.0, 1.0, 2.0, 1.0, 3.0, 0.0, 3.0, 1.0, 3.0, 2.0, 0.0, 2.0, 2.0, 3.0, 1.0, 3.0, 0.0, 1.0, 1.0, 2.0, 0.0, 1.0, 0.0, 1.0, 3.0, 1.0, 2.0, 2.0], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.1463640795406563, "mean_inference_ms": 0.3884768154620287, "mean_action_processing_ms": 0.02866997027291393, "mean_env_wait_ms": 0.3955312459203594, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 619520, "timesteps_this_iter": 0, "agent_timesteps_total": 619520, "timers": {"sample_time_ms": 1331.615, "sample_throughput": 3844.954, "load_time_ms": 0.125, "load_throughput": 40927837.774, "learn_time_ms": 65.746, "learn_throughput": 77875.661, "update_time_ms": 2.774}, "info": {"learner": {"default_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 44.91322326660156, "policy_entropy": 8001.9873046875, "policy_loss": -16.399538040161133, "vf_loss": 13.944003105163574}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 619520, "num_agent_steps_sampled": 619520, "num_steps_trained": 619520, "num_agent_steps_trained": 619520, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 308, "training_iteration": 16, "trial_id": "65be9_00000", "experiment_id": "b9e963105bdc4382843b68ace23a11d3", "date": "2024-06-17_16-11-10", "timestamp": 1718608270, "time_this_iter_s": 10.592478036880493, "time_total_s": 161.33320212364197, "pid": 4998, "hostname": "DESKTOP-LQ219J4", "node_ip": "192.168.46.185", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 20, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 5000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 500, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "rware", "env_args": {"n_agents": 4, "column_height": 1, "max_inactivity_steps": null, "max_steps": 500, "fast_obs": true, "msg_bits": 0, "sensor_range": 1, "shelf_rows": 1, "shelf_columns": 3, "request_queue_size": 4, "reward_type": "RewardType.INDIVIDUAL", "map_name": "customized_map", "map_size": "tiny", "difficulty": "medium"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": true, "force_coop": false, "local_mode": true, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 4, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 100, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64}, "algorithm": "maa2c", "space_obs": "Dict(obs:Box([-100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100.], [100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.], (112,), float32))", "space_act": "Discrete(5)", "num_agents": 4, "episode_limit": 500, "policy_mapping_info": {"all_scenario": {"description": "rware all scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2", "agent_3"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "rware_customized_map", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 10, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.policy_template.MAA2CTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x7f7c1afbce50>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "grad_clip": 40.0, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "microbatch_size": null}, "time_since_restore": 161.33320212364197, "timesteps_since_restore": 0, "iterations_since_restore": 16, "perf": {"cpu_util_percent": 4.126666666666667, "ram_util_percent": 32.22}}
{"episode_reward_max": 5.0, "episode_reward_min": 0.0, "episode_reward_mean": 1.47, "episode_len_mean": 500.0, "episode_media": {}, "episodes_this_iter": 20, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [1.0, 2.0, 2.0, 1.0, 1.0, 1.0, 1.0, 1.0, 2.0, 1.0, 1.0, 2.0, 1.0, 3.0, 2.0, 0.0, 1.0, 1.0, 2.0, 1.0, 2.0, 5.0, 1.0, 0.0, 0.0, 2.0, 2.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0, 1.0, 2.0, 1.0, 2.0, 1.0, 2.0, 3.0, 0.0, 2.0, 1.0, 2.0, 3.0, 1.0, 1.0, 0.0, 2.0, 1.0, 1.0, 0.0, 2.0, 1.0, 2.0, 1.0, 3.0, 0.0, 3.0, 1.0, 3.0, 2.0, 0.0, 2.0, 2.0, 3.0, 1.0, 3.0, 0.0, 1.0, 1.0, 2.0, 0.0, 1.0, 0.0, 1.0, 3.0, 1.0, 2.0, 2.0, 0.0, 3.0, 3.0, 3.0, 0.0, 1.0, 1.0, 2.0, 3.0, 3.0, 1.0, 2.0, 2.0, 0.0, 1.0, 4.0, 3.0, 0.0, 0.0, 0.0], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.14641132445584465, "mean_inference_ms": 0.3885773452009331, "mean_action_processing_ms": 0.02866591021444089, "mean_env_wait_ms": 0.3954726193210461, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 660480, "timesteps_this_iter": 0, "agent_timesteps_total": 660480, "timers": {"sample_time_ms": 1339.559, "sample_throughput": 3822.153, "load_time_ms": 0.128, "load_throughput": 39893807.319, "learn_time_ms": 66.222, "learn_throughput": 77316.03, "update_time_ms": 2.81}, "info": {"learner": {"default_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 49.786373138427734, "policy_entropy": 7982.92138671875, "policy_loss": 6.187625885009766, "vf_loss": 22.992948532104492}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 660480, "num_agent_steps_sampled": 660480, "num_steps_trained": 660480, "num_agent_steps_trained": 660480, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 328, "training_iteration": 17, "trial_id": "65be9_00000", "experiment_id": "b9e963105bdc4382843b68ace23a11d3", "date": "2024-06-17_16-11-21", "timestamp": 1718608281, "time_this_iter_s": 10.724932670593262, "time_total_s": 172.05813479423523, "pid": 4998, "hostname": "DESKTOP-LQ219J4", "node_ip": "192.168.46.185", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 20, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 5000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 500, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "rware", "env_args": {"n_agents": 4, "column_height": 1, "max_inactivity_steps": null, "max_steps": 500, "fast_obs": true, "msg_bits": 0, "sensor_range": 1, "shelf_rows": 1, "shelf_columns": 3, "request_queue_size": 4, "reward_type": "RewardType.INDIVIDUAL", "map_name": "customized_map", "map_size": "tiny", "difficulty": "medium"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": true, "force_coop": false, "local_mode": true, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 4, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 100, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64}, "algorithm": "maa2c", "space_obs": "Dict(obs:Box([-100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100.], [100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.], (112,), float32))", "space_act": "Discrete(5)", "num_agents": 4, "episode_limit": 500, "policy_mapping_info": {"all_scenario": {"description": "rware all scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2", "agent_3"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "rware_customized_map", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 10, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.policy_template.MAA2CTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x7f7c1cdf63a0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "grad_clip": 40.0, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "microbatch_size": null}, "time_since_restore": 172.05813479423523, "timesteps_since_restore": 0, "iterations_since_restore": 17, "perf": {"cpu_util_percent": 4.173333333333334, "ram_util_percent": 32.88}}
{"episode_reward_max": 5.0, "episode_reward_min": 0.0, "episode_reward_mean": 1.6, "episode_len_mean": 500.0, "episode_media": {}, "episodes_this_iter": 20, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [2.0, 5.0, 1.0, 0.0, 0.0, 2.0, 2.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0, 1.0, 2.0, 1.0, 2.0, 1.0, 2.0, 3.0, 0.0, 2.0, 1.0, 2.0, 3.0, 1.0, 1.0, 0.0, 2.0, 1.0, 1.0, 0.0, 2.0, 1.0, 2.0, 1.0, 3.0, 0.0, 3.0, 1.0, 3.0, 2.0, 0.0, 2.0, 2.0, 3.0, 1.0, 3.0, 0.0, 1.0, 1.0, 2.0, 0.0, 1.0, 0.0, 1.0, 3.0, 1.0, 2.0, 2.0, 0.0, 3.0, 3.0, 3.0, 0.0, 1.0, 1.0, 2.0, 3.0, 3.0, 1.0, 2.0, 2.0, 0.0, 1.0, 4.0, 3.0, 0.0, 0.0, 0.0, 3.0, 3.0, 1.0, 1.0, 2.0, 0.0, 2.0, 2.0, 1.0, 4.0, 2.0, 2.0, 1.0, 2.0, 2.0, 3.0, 0.0, 4.0, 1.0, 4.0], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.14646406151921149, "mean_inference_ms": 0.3886809185402058, "mean_action_processing_ms": 0.028660867737216614, "mean_env_wait_ms": 0.395616840169002, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 701440, "timesteps_this_iter": 0, "agent_timesteps_total": 701440, "timers": {"sample_time_ms": 1329.746, "sample_throughput": 3850.36, "load_time_ms": 0.111, "load_throughput": 46281975.172, "learn_time_ms": 65.993, "learn_throughput": 77583.987, "update_time_ms": 2.777}, "info": {"learner": {"default_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 97.99186706542969, "policy_entropy": 7968.55908203125, "policy_loss": 29.531047821044922, "vf_loss": 27.245914459228516}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 701440, "num_agent_steps_sampled": 701440, "num_steps_trained": 701440, "num_agent_steps_trained": 701440, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 348, "training_iteration": 18, "trial_id": "65be9_00000", "experiment_id": "b9e963105bdc4382843b68ace23a11d3", "date": "2024-06-17_16-11-32", "timestamp": 1718608292, "time_this_iter_s": 10.644319534301758, "time_total_s": 182.702454328537, "pid": 4998, "hostname": "DESKTOP-LQ219J4", "node_ip": "192.168.46.185", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 20, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 5000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 500, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "rware", "env_args": {"n_agents": 4, "column_height": 1, "max_inactivity_steps": null, "max_steps": 500, "fast_obs": true, "msg_bits": 0, "sensor_range": 1, "shelf_rows": 1, "shelf_columns": 3, "request_queue_size": 4, "reward_type": "RewardType.INDIVIDUAL", "map_name": "customized_map", "map_size": "tiny", "difficulty": "medium"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": true, "force_coop": false, "local_mode": true, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 4, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 100, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64}, "algorithm": "maa2c", "space_obs": "Dict(obs:Box([-100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100.], [100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.], (112,), float32))", "space_act": "Discrete(5)", "num_agents": 4, "episode_limit": 500, "policy_mapping_info": {"all_scenario": {"description": "rware all scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2", "agent_3"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "rware_customized_map", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 10, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.policy_template.MAA2CTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x7f7c1cdf6f70>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "grad_clip": 40.0, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "microbatch_size": null}, "time_since_restore": 182.702454328537, "timesteps_since_restore": 0, "iterations_since_restore": 18, "perf": {"cpu_util_percent": 4.146666666666666, "ram_util_percent": 33.52}}
{"episode_reward_max": 8.0, "episode_reward_min": 0.0, "episode_reward_mean": 1.65, "episode_len_mean": 500.0, "episode_media": {}, "episodes_this_iter": 20, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 2.0, 1.0, 2.0, 3.0, 1.0, 1.0, 0.0, 2.0, 1.0, 1.0, 0.0, 2.0, 1.0, 2.0, 1.0, 3.0, 0.0, 3.0, 1.0, 3.0, 2.0, 0.0, 2.0, 2.0, 3.0, 1.0, 3.0, 0.0, 1.0, 1.0, 2.0, 0.0, 1.0, 0.0, 1.0, 3.0, 1.0, 2.0, 2.0, 0.0, 3.0, 3.0, 3.0, 0.0, 1.0, 1.0, 2.0, 3.0, 3.0, 1.0, 2.0, 2.0, 0.0, 1.0, 4.0, 3.0, 0.0, 0.0, 0.0, 3.0, 3.0, 1.0, 1.0, 2.0, 0.0, 2.0, 2.0, 1.0, 4.0, 2.0, 2.0, 1.0, 2.0, 2.0, 3.0, 0.0, 4.0, 1.0, 4.0, 4.0, 1.0, 8.0, 0.0, 2.0, 3.0, 0.0, 2.0, 1.0, 2.0, 4.0, 3.0, 0.0, 0.0, 3.0, 0.0, 1.0, 1.0, 0.0, 1.0], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.146470737563365, "mean_inference_ms": 0.38870515449374166, "mean_action_processing_ms": 0.028654656172617463, "mean_env_wait_ms": 0.3955089036800954, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 742400, "timesteps_this_iter": 0, "agent_timesteps_total": 742400, "timers": {"sample_time_ms": 1327.66, "sample_throughput": 3856.41, "load_time_ms": 0.116, "load_throughput": 44296279.868, "learn_time_ms": 66.542, "learn_throughput": 76943.493, "update_time_ms": 2.871}, "info": {"learner": {"default_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 83.90061950683594, "policy_entropy": 7921.4677734375, "policy_loss": 35.16899871826172, "vf_loss": 21.69842529296875}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 742400, "num_agent_steps_sampled": 742400, "num_steps_trained": 742400, "num_agent_steps_trained": 742400, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 368, "training_iteration": 19, "trial_id": "65be9_00000", "experiment_id": "b9e963105bdc4382843b68ace23a11d3", "date": "2024-06-17_16-11-42", "timestamp": 1718608302, "time_this_iter_s": 10.642861604690552, "time_total_s": 193.34531593322754, "pid": 4998, "hostname": "DESKTOP-LQ219J4", "node_ip": "192.168.46.185", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 20, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 5000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 500, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "rware", "env_args": {"n_agents": 4, "column_height": 1, "max_inactivity_steps": null, "max_steps": 500, "fast_obs": true, "msg_bits": 0, "sensor_range": 1, "shelf_rows": 1, "shelf_columns": 3, "request_queue_size": 4, "reward_type": "RewardType.INDIVIDUAL", "map_name": "customized_map", "map_size": "tiny", "difficulty": "medium"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": true, "force_coop": false, "local_mode": true, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 4, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 100, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64}, "algorithm": "maa2c", "space_obs": "Dict(obs:Box([-100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100.], [100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.], (112,), float32))", "space_act": "Discrete(5)", "num_agents": 4, "episode_limit": 500, "policy_mapping_info": {"all_scenario": {"description": "rware all scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2", "agent_3"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "rware_customized_map", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 10, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.policy_template.MAA2CTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x7f7c1d4509d0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "grad_clip": 40.0, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "microbatch_size": null}, "time_since_restore": 193.34531593322754, "timesteps_since_restore": 0, "iterations_since_restore": 19, "perf": {"cpu_util_percent": 4.02, "ram_util_percent": 34.166666666666664}}
{"episode_reward_max": 8.0, "episode_reward_min": 0.0, "episode_reward_mean": 1.72, "episode_len_mean": 500.0, "episode_media": {}, "episodes_this_iter": 20, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [3.0, 2.0, 0.0, 2.0, 2.0, 3.0, 1.0, 3.0, 0.0, 1.0, 1.0, 2.0, 0.0, 1.0, 0.0, 1.0, 3.0, 1.0, 2.0, 2.0, 0.0, 3.0, 3.0, 3.0, 0.0, 1.0, 1.0, 2.0, 3.0, 3.0, 1.0, 2.0, 2.0, 0.0, 1.0, 4.0, 3.0, 0.0, 0.0, 0.0, 3.0, 3.0, 1.0, 1.0, 2.0, 0.0, 2.0, 2.0, 1.0, 4.0, 2.0, 2.0, 1.0, 2.0, 2.0, 3.0, 0.0, 4.0, 1.0, 4.0, 4.0, 1.0, 8.0, 0.0, 2.0, 3.0, 0.0, 2.0, 1.0, 2.0, 4.0, 3.0, 0.0, 0.0, 3.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 2.0, 1.0, 3.0, 0.0, 1.0, 2.0, 4.0, 2.0, 0.0, 1.0, 1.0, 6.0, 1.0, 0.0, 1.0, 1.0, 2.0, 4.0, 1.0], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.14647798572421855, "mean_inference_ms": 0.38871798118075546, "mean_action_processing_ms": 0.028648140561430245, "mean_env_wait_ms": 0.39542758426238755, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 783360, "timesteps_this_iter": 0, "agent_timesteps_total": 783360, "timers": {"sample_time_ms": 1341.535, "sample_throughput": 3816.523, "load_time_ms": 0.136, "load_throughput": 37589421.46, "learn_time_ms": 66.082, "learn_throughput": 77479.914, "update_time_ms": 2.903}, "info": {"learner": {"default_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 91.15347290039062, "policy_entropy": 7978.3740234375, "policy_loss": 38.3065185546875, "vf_loss": 17.036663055419922}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 783360, "num_agent_steps_sampled": 783360, "num_steps_trained": 783360, "num_agent_steps_trained": 783360, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 388, "training_iteration": 20, "trial_id": "65be9_00000", "experiment_id": "b9e963105bdc4382843b68ace23a11d3", "date": "2024-06-17_16-11-53", "timestamp": 1718608313, "time_this_iter_s": 10.722191333770752, "time_total_s": 204.0675072669983, "pid": 4998, "hostname": "DESKTOP-LQ219J4", "node_ip": "192.168.46.185", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 20, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 5000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 500, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "rware", "env_args": {"n_agents": 4, "column_height": 1, "max_inactivity_steps": null, "max_steps": 500, "fast_obs": true, "msg_bits": 0, "sensor_range": 1, "shelf_rows": 1, "shelf_columns": 3, "request_queue_size": 4, "reward_type": "RewardType.INDIVIDUAL", "map_name": "customized_map", "map_size": "tiny", "difficulty": "medium"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": true, "force_coop": false, "local_mode": true, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 4, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 100, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64}, "algorithm": "maa2c", "space_obs": "Dict(obs:Box([-100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100.], [100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.], (112,), float32))", "space_act": "Discrete(5)", "num_agents": 4, "episode_limit": 500, "policy_mapping_info": {"all_scenario": {"description": "rware all scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2", "agent_3"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "rware_customized_map", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 10, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.policy_template.MAA2CTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x7f7c1cdf68b0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "grad_clip": 40.0, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "microbatch_size": null}, "time_since_restore": 204.0675072669983, "timesteps_since_restore": 0, "iterations_since_restore": 20, "perf": {"cpu_util_percent": 4.175, "ram_util_percent": 34.84375}}
{"episode_reward_max": 8.0, "episode_reward_min": 0.0, "episode_reward_mean": 1.78, "episode_len_mean": 500.0, "episode_media": {}, "episodes_this_iter": 24, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 1.0, 1.0, 2.0, 3.0, 3.0, 1.0, 2.0, 2.0, 0.0, 1.0, 4.0, 3.0, 0.0, 0.0, 0.0, 3.0, 3.0, 1.0, 1.0, 2.0, 0.0, 2.0, 2.0, 1.0, 4.0, 2.0, 2.0, 1.0, 2.0, 2.0, 3.0, 0.0, 4.0, 1.0, 4.0, 4.0, 1.0, 8.0, 0.0, 2.0, 3.0, 0.0, 2.0, 1.0, 2.0, 4.0, 3.0, 0.0, 0.0, 3.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 2.0, 1.0, 3.0, 0.0, 1.0, 2.0, 4.0, 2.0, 0.0, 1.0, 1.0, 6.0, 1.0, 0.0, 1.0, 1.0, 2.0, 4.0, 1.0, 2.0, 1.0, 4.0, 1.0, 3.0, 2.0, 2.0, 0.0, 3.0, 2.0, 1.0, 1.0, 2.0, 3.0, 2.0, 2.0, 3.0, 2.0, 1.0, 1.0, 4.0, 1.0, 1.0, 1.0], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.1464789469533506, "mean_inference_ms": 0.3886941217278577, "mean_action_processing_ms": 0.028639846403254093, "mean_env_wait_ms": 0.3953685352902669, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 824320, "timesteps_this_iter": 0, "agent_timesteps_total": 824320, "timers": {"sample_time_ms": 1336.027, "sample_throughput": 3832.258, "load_time_ms": 0.119, "load_throughput": 42898195.126, "learn_time_ms": 65.578, "learn_throughput": 78074.813, "update_time_ms": 2.846}, "info": {"learner": {"default_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 65.74117279052734, "policy_entropy": 7975.5458984375, "policy_loss": -16.316484451293945, "vf_loss": 30.117273330688477}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 824320, "num_agent_steps_sampled": 824320, "num_steps_trained": 824320, "num_agent_steps_trained": 824320, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 412, "training_iteration": 21, "trial_id": "65be9_00000", "experiment_id": "b9e963105bdc4382843b68ace23a11d3", "date": "2024-06-17_16-12-04", "timestamp": 1718608324, "time_this_iter_s": 10.713950872421265, "time_total_s": 214.78145813941956, "pid": 4998, "hostname": "DESKTOP-LQ219J4", "node_ip": "192.168.46.185", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 20, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 5000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 500, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "rware", "env_args": {"n_agents": 4, "column_height": 1, "max_inactivity_steps": null, "max_steps": 500, "fast_obs": true, "msg_bits": 0, "sensor_range": 1, "shelf_rows": 1, "shelf_columns": 3, "request_queue_size": 4, "reward_type": "RewardType.INDIVIDUAL", "map_name": "customized_map", "map_size": "tiny", "difficulty": "medium"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": true, "force_coop": false, "local_mode": true, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 4, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 100, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64}, "algorithm": "maa2c", "space_obs": "Dict(obs:Box([-100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100.], [100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.], (112,), float32))", "space_act": "Discrete(5)", "num_agents": 4, "episode_limit": 500, "policy_mapping_info": {"all_scenario": {"description": "rware all scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2", "agent_3"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "rware_customized_map", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 10, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.policy_template.MAA2CTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x7f7c1d4504c0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "grad_clip": 40.0, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "microbatch_size": null}, "time_since_restore": 214.78145813941956, "timesteps_since_restore": 0, "iterations_since_restore": 21, "perf": {"cpu_util_percent": 4.3533333333333335, "ram_util_percent": 35.53333333333333}}
{"episode_reward_max": 8.0, "episode_reward_min": 0.0, "episode_reward_mean": 1.74, "episode_len_mean": 500.0, "episode_media": {}, "episodes_this_iter": 20, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [2.0, 0.0, 2.0, 2.0, 1.0, 4.0, 2.0, 2.0, 1.0, 2.0, 2.0, 3.0, 0.0, 4.0, 1.0, 4.0, 4.0, 1.0, 8.0, 0.0, 2.0, 3.0, 0.0, 2.0, 1.0, 2.0, 4.0, 3.0, 0.0, 0.0, 3.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 2.0, 1.0, 3.0, 0.0, 1.0, 2.0, 4.0, 2.0, 0.0, 1.0, 1.0, 6.0, 1.0, 0.0, 1.0, 1.0, 2.0, 4.0, 1.0, 2.0, 1.0, 4.0, 1.0, 3.0, 2.0, 2.0, 0.0, 3.0, 2.0, 1.0, 1.0, 2.0, 3.0, 2.0, 2.0, 3.0, 2.0, 1.0, 1.0, 4.0, 1.0, 1.0, 1.0, 1.0, 2.0, 1.0, 2.0, 1.0, 1.0, 3.0, 2.0, 2.0, 1.0, 1.0, 0.0, 3.0, 2.0, 2.0, 0.0, 1.0, 0.0, 2.0, 0.0], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.1464903379247577, "mean_inference_ms": 0.3886623349521318, "mean_action_processing_ms": 0.028632830811314295, "mean_env_wait_ms": 0.3954239956749037, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 865280, "timesteps_this_iter": 0, "agent_timesteps_total": 865280, "timers": {"sample_time_ms": 1329.736, "sample_throughput": 3850.388, "load_time_ms": 0.121, "load_throughput": 42365035.471, "learn_time_ms": 66.567, "learn_throughput": 76914.749, "update_time_ms": 2.886}, "info": {"learner": {"default_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 67.85907745361328, "policy_entropy": 7905.52783203125, "policy_loss": -36.398197174072266, "vf_loss": 18.36382293701172}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 865280, "num_agent_steps_sampled": 865280, "num_steps_trained": 865280, "num_agent_steps_trained": 865280, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 432, "training_iteration": 22, "trial_id": "65be9_00000", "experiment_id": "b9e963105bdc4382843b68ace23a11d3", "date": "2024-06-17_16-12-15", "timestamp": 1718608335, "time_this_iter_s": 10.664169549942017, "time_total_s": 225.44562768936157, "pid": 4998, "hostname": "DESKTOP-LQ219J4", "node_ip": "192.168.46.185", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 20, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 5000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 500, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "rware", "env_args": {"n_agents": 4, "column_height": 1, "max_inactivity_steps": null, "max_steps": 500, "fast_obs": true, "msg_bits": 0, "sensor_range": 1, "shelf_rows": 1, "shelf_columns": 3, "request_queue_size": 4, "reward_type": "RewardType.INDIVIDUAL", "map_name": "customized_map", "map_size": "tiny", "difficulty": "medium"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": true, "force_coop": false, "local_mode": true, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 4, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 100, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64}, "algorithm": "maa2c", "space_obs": "Dict(obs:Box([-100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100.], [100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.], (112,), float32))", "space_act": "Discrete(5)", "num_agents": 4, "episode_limit": 500, "policy_mapping_info": {"all_scenario": {"description": "rware all scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2", "agent_3"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "rware_customized_map", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 10, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.policy_template.MAA2CTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x7f7c1afbca60>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "grad_clip": 40.0, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "microbatch_size": null}, "time_since_restore": 225.44562768936157, "timesteps_since_restore": 0, "iterations_since_restore": 22, "perf": {"cpu_util_percent": 4.199999999999999, "ram_util_percent": 36.18666666666666}}
{"episode_reward_max": 6.0, "episode_reward_min": 0.0, "episode_reward_mean": 1.77, "episode_len_mean": 500.0, "episode_media": {}, "episodes_this_iter": 20, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [2.0, 3.0, 0.0, 2.0, 1.0, 2.0, 4.0, 3.0, 0.0, 0.0, 3.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 2.0, 1.0, 3.0, 0.0, 1.0, 2.0, 4.0, 2.0, 0.0, 1.0, 1.0, 6.0, 1.0, 0.0, 1.0, 1.0, 2.0, 4.0, 1.0, 2.0, 1.0, 4.0, 1.0, 3.0, 2.0, 2.0, 0.0, 3.0, 2.0, 1.0, 1.0, 2.0, 3.0, 2.0, 2.0, 3.0, 2.0, 1.0, 1.0, 4.0, 1.0, 1.0, 1.0, 1.0, 2.0, 1.0, 2.0, 1.0, 1.0, 3.0, 2.0, 2.0, 1.0, 1.0, 0.0, 3.0, 2.0, 2.0, 0.0, 1.0, 0.0, 2.0, 0.0, 3.0, 2.0, 1.0, 3.0, 3.0, 3.0, 2.0, 1.0, 2.0, 4.0, 0.0, 2.0, 3.0, 2.0, 5.0, 3.0, 2.0, 4.0, 1.0, 2.0], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.14650915011734902, "mean_inference_ms": 0.3886432907041714, "mean_action_processing_ms": 0.02862741097492273, "mean_env_wait_ms": 0.39541949034103324, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 906240, "timesteps_this_iter": 0, "agent_timesteps_total": 906240, "timers": {"sample_time_ms": 1338.555, "sample_throughput": 3825.021, "load_time_ms": 0.121, "load_throughput": 42314948.729, "learn_time_ms": 66.446, "learn_throughput": 77055.391, "update_time_ms": 2.837}, "info": {"learner": {"default_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 40.23284912109375, "policy_entropy": 7934.0908203125, "policy_loss": -11.079597473144531, "vf_loss": 18.100139617919922}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 906240, "num_agent_steps_sampled": 906240, "num_steps_trained": 906240, "num_agent_steps_trained": 906240, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 452, "training_iteration": 23, "trial_id": "65be9_00000", "experiment_id": "b9e963105bdc4382843b68ace23a11d3", "date": "2024-06-17_16-12-25", "timestamp": 1718608345, "time_this_iter_s": 10.629492044448853, "time_total_s": 236.07511973381042, "pid": 4998, "hostname": "DESKTOP-LQ219J4", "node_ip": "192.168.46.185", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 20, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 5000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 500, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "rware", "env_args": {"n_agents": 4, "column_height": 1, "max_inactivity_steps": null, "max_steps": 500, "fast_obs": true, "msg_bits": 0, "sensor_range": 1, "shelf_rows": 1, "shelf_columns": 3, "request_queue_size": 4, "reward_type": "RewardType.INDIVIDUAL", "map_name": "customized_map", "map_size": "tiny", "difficulty": "medium"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": true, "force_coop": false, "local_mode": true, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 4, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 100, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64}, "algorithm": "maa2c", "space_obs": "Dict(obs:Box([-100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100.], [100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.], (112,), float32))", "space_act": "Discrete(5)", "num_agents": 4, "episode_limit": 500, "policy_mapping_info": {"all_scenario": {"description": "rware all scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2", "agent_3"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "rware_customized_map", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 10, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.policy_template.MAA2CTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x7f7c1cdde0d0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "grad_clip": 40.0, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "microbatch_size": null}, "time_since_restore": 236.07511973381042, "timesteps_since_restore": 0, "iterations_since_restore": 23, "perf": {"cpu_util_percent": 4.159999999999999, "ram_util_percent": 36.82}}
{"episode_reward_max": 6.0, "episode_reward_min": 0.0, "episode_reward_mean": 1.71, "episode_len_mean": 500.0, "episode_media": {}, "episodes_this_iter": 20, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 1.0, 2.0, 4.0, 2.0, 0.0, 1.0, 1.0, 6.0, 1.0, 0.0, 1.0, 1.0, 2.0, 4.0, 1.0, 2.0, 1.0, 4.0, 1.0, 3.0, 2.0, 2.0, 0.0, 3.0, 2.0, 1.0, 1.0, 2.0, 3.0, 2.0, 2.0, 3.0, 2.0, 1.0, 1.0, 4.0, 1.0, 1.0, 1.0, 1.0, 2.0, 1.0, 2.0, 1.0, 1.0, 3.0, 2.0, 2.0, 1.0, 1.0, 0.0, 3.0, 2.0, 2.0, 0.0, 1.0, 0.0, 2.0, 0.0, 3.0, 2.0, 1.0, 3.0, 3.0, 3.0, 2.0, 1.0, 2.0, 4.0, 0.0, 2.0, 3.0, 2.0, 5.0, 3.0, 2.0, 4.0, 1.0, 2.0, 2.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 2.0, 2.0, 0.0, 4.0, 1.0, 2.0, 1.0, 1.0, 1.0, 0.0, 2.0, 1.0, 2.0], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.14654003636076637, "mean_inference_ms": 0.38864789776562847, "mean_action_processing_ms": 0.02862225762019861, "mean_env_wait_ms": 0.39547902241104865, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 947200, "timesteps_this_iter": 0, "agent_timesteps_total": 947200, "timers": {"sample_time_ms": 1342.744, "sample_throughput": 3813.086, "load_time_ms": 0.124, "load_throughput": 41441212.814, "learn_time_ms": 66.733, "learn_throughput": 76723.739, "update_time_ms": 2.831}, "info": {"learner": {"default_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 35.70284652709961, "policy_entropy": 7963.17919921875, "policy_loss": -17.853113174438477, "vf_loss": 11.727020263671875}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 947200, "num_agent_steps_sampled": 947200, "num_steps_trained": 947200, "num_agent_steps_trained": 947200, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 472, "training_iteration": 24, "trial_id": "65be9_00000", "experiment_id": "b9e963105bdc4382843b68ace23a11d3", "date": "2024-06-17_16-12-36", "timestamp": 1718608356, "time_this_iter_s": 10.755139350891113, "time_total_s": 246.83025908470154, "pid": 4998, "hostname": "DESKTOP-LQ219J4", "node_ip": "192.168.46.185", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 20, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 5000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 500, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "rware", "env_args": {"n_agents": 4, "column_height": 1, "max_inactivity_steps": null, "max_steps": 500, "fast_obs": true, "msg_bits": 0, "sensor_range": 1, "shelf_rows": 1, "shelf_columns": 3, "request_queue_size": 4, "reward_type": "RewardType.INDIVIDUAL", "map_name": "customized_map", "map_size": "tiny", "difficulty": "medium"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": true, "force_coop": false, "local_mode": true, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 4, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 100, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64}, "algorithm": "maa2c", "space_obs": "Dict(obs:Box([-100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100.], [100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.], (112,), float32))", "space_act": "Discrete(5)", "num_agents": 4, "episode_limit": 500, "policy_mapping_info": {"all_scenario": {"description": "rware all scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2", "agent_3"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "rware_customized_map", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 10, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.policy_template.MAA2CTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x7f7c1afbb040>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "grad_clip": 40.0, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "microbatch_size": null}, "time_since_restore": 246.83025908470154, "timesteps_since_restore": 0, "iterations_since_restore": 24, "perf": {"cpu_util_percent": 4.29375, "ram_util_percent": 37.5}}
{"episode_reward_max": 5.0, "episode_reward_min": 0.0, "episode_reward_mean": 1.69, "episode_len_mean": 500.0, "episode_media": {}, "episodes_this_iter": 20, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [3.0, 2.0, 2.0, 0.0, 3.0, 2.0, 1.0, 1.0, 2.0, 3.0, 2.0, 2.0, 3.0, 2.0, 1.0, 1.0, 4.0, 1.0, 1.0, 1.0, 1.0, 2.0, 1.0, 2.0, 1.0, 1.0, 3.0, 2.0, 2.0, 1.0, 1.0, 0.0, 3.0, 2.0, 2.0, 0.0, 1.0, 0.0, 2.0, 0.0, 3.0, 2.0, 1.0, 3.0, 3.0, 3.0, 2.0, 1.0, 2.0, 4.0, 0.0, 2.0, 3.0, 2.0, 5.0, 3.0, 2.0, 4.0, 1.0, 2.0, 2.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 2.0, 2.0, 0.0, 4.0, 1.0, 2.0, 1.0, 1.0, 1.0, 0.0, 2.0, 1.0, 2.0, 2.0, 2.0, 1.0, 3.0, 0.0, 3.0, 2.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 3.0, 1.0, 5.0, 2.0, 1.0, 3.0, 1.0], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.14655389065394686, "mean_inference_ms": 0.38861040027806465, "mean_action_processing_ms": 0.028614297978373705, "mean_env_wait_ms": 0.39544424036491976, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 988160, "timesteps_this_iter": 0, "agent_timesteps_total": 988160, "timers": {"sample_time_ms": 1322.45, "sample_throughput": 3871.601, "load_time_ms": 0.121, "load_throughput": 42390123.332, "learn_time_ms": 65.493, "learn_throughput": 78176.422, "update_time_ms": 2.867}, "info": {"learner": {"default_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 57.19911575317383, "policy_entropy": 7959.875, "policy_loss": -9.332025527954102, "vf_loss": 16.330541610717773}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 988160, "num_agent_steps_sampled": 988160, "num_steps_trained": 988160, "num_agent_steps_trained": 988160, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 492, "training_iteration": 25, "trial_id": "65be9_00000", "experiment_id": "b9e963105bdc4382843b68ace23a11d3", "date": "2024-06-17_16-12-46", "timestamp": 1718608366, "time_this_iter_s": 10.528645515441895, "time_total_s": 257.35890460014343, "pid": 4998, "hostname": "DESKTOP-LQ219J4", "node_ip": "192.168.46.185", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 20, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 5000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 500, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "rware", "env_args": {"n_agents": 4, "column_height": 1, "max_inactivity_steps": null, "max_steps": 500, "fast_obs": true, "msg_bits": 0, "sensor_range": 1, "shelf_rows": 1, "shelf_columns": 3, "request_queue_size": 4, "reward_type": "RewardType.INDIVIDUAL", "map_name": "customized_map", "map_size": "tiny", "difficulty": "medium"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": true, "force_coop": false, "local_mode": true, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 4, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 100, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64}, "algorithm": "maa2c", "space_obs": "Dict(obs:Box([-100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100.], [100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.], (112,), float32))", "space_act": "Discrete(5)", "num_agents": 4, "episode_limit": 500, "policy_mapping_info": {"all_scenario": {"description": "rware all scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2", "agent_3"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "rware_customized_map", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 10, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.policy_template.MAA2CTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x7f7c1d170a60>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "grad_clip": 40.0, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "microbatch_size": null}, "time_since_restore": 257.35890460014343, "timesteps_since_restore": 0, "iterations_since_restore": 25, "perf": {"cpu_util_percent": 4.126666666666667, "ram_util_percent": 38.2}}
{"episode_reward_max": 5.0, "episode_reward_min": 0.0, "episode_reward_mean": 1.69, "episode_len_mean": 500.0, "episode_media": {}, "episodes_this_iter": 20, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [1.0, 2.0, 1.0, 2.0, 1.0, 1.0, 3.0, 2.0, 2.0, 1.0, 1.0, 0.0, 3.0, 2.0, 2.0, 0.0, 1.0, 0.0, 2.0, 0.0, 3.0, 2.0, 1.0, 3.0, 3.0, 3.0, 2.0, 1.0, 2.0, 4.0, 0.0, 2.0, 3.0, 2.0, 5.0, 3.0, 2.0, 4.0, 1.0, 2.0, 2.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 2.0, 2.0, 0.0, 4.0, 1.0, 2.0, 1.0, 1.0, 1.0, 0.0, 2.0, 1.0, 2.0, 2.0, 2.0, 1.0, 3.0, 0.0, 3.0, 2.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 3.0, 1.0, 5.0, 2.0, 1.0, 3.0, 1.0, 0.0, 2.0, 2.0, 1.0, 2.0, 3.0, 2.0, 2.0, 1.0, 4.0, 1.0, 1.0, 4.0, 1.0, 3.0, 3.0, 2.0, 1.0, 0.0, 2.0], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.14657882657526206, "mean_inference_ms": 0.38861073195576457, "mean_action_processing_ms": 0.028608687808969156, "mean_env_wait_ms": 0.3953646028562091, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 1029120, "timesteps_this_iter": 0, "agent_timesteps_total": 1029120, "timers": {"sample_time_ms": 1327.343, "sample_throughput": 3857.331, "load_time_ms": 0.125, "load_throughput": 40834448.526, "learn_time_ms": 68.072, "learn_throughput": 75214.232, "update_time_ms": 2.99}, "info": {"learner": {"default_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 84.29656219482422, "policy_entropy": 7959.19140625, "policy_loss": 13.152649879455566, "vf_loss": 24.380895614624023}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 1029120, "num_agent_steps_sampled": 1029120, "num_steps_trained": 1029120, "num_agent_steps_trained": 1029120, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 512, "training_iteration": 26, "trial_id": "65be9_00000", "experiment_id": "b9e963105bdc4382843b68ace23a11d3", "date": "2024-06-17_16-12-57", "timestamp": 1718608377, "time_this_iter_s": 10.638135433197021, "time_total_s": 267.99704003334045, "pid": 4998, "hostname": "DESKTOP-LQ219J4", "node_ip": "192.168.46.185", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 20, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 5000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 500, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "rware", "env_args": {"n_agents": 4, "column_height": 1, "max_inactivity_steps": null, "max_steps": 500, "fast_obs": true, "msg_bits": 0, "sensor_range": 1, "shelf_rows": 1, "shelf_columns": 3, "request_queue_size": 4, "reward_type": "RewardType.INDIVIDUAL", "map_name": "customized_map", "map_size": "tiny", "difficulty": "medium"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": true, "force_coop": false, "local_mode": true, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 4, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 100, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64}, "algorithm": "maa2c", "space_obs": "Dict(obs:Box([-100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100.], [100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.], (112,), float32))", "space_act": "Discrete(5)", "num_agents": 4, "episode_limit": 500, "policy_mapping_info": {"all_scenario": {"description": "rware all scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2", "agent_3"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "rware_customized_map", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 10, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.policy_template.MAA2CTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x7f7c1cdb81f0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "grad_clip": 40.0, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "microbatch_size": null}, "time_since_restore": 267.99704003334045, "timesteps_since_restore": 0, "iterations_since_restore": 26, "perf": {"cpu_util_percent": 4.159999999999999, "ram_util_percent": 38.82}}
{"episode_reward_max": 5.0, "episode_reward_min": 0.0, "episode_reward_mean": 1.8, "episode_len_mean": 500.0, "episode_media": {}, "episodes_this_iter": 20, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [3.0, 2.0, 1.0, 3.0, 3.0, 3.0, 2.0, 1.0, 2.0, 4.0, 0.0, 2.0, 3.0, 2.0, 5.0, 3.0, 2.0, 4.0, 1.0, 2.0, 2.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 2.0, 2.0, 0.0, 4.0, 1.0, 2.0, 1.0, 1.0, 1.0, 0.0, 2.0, 1.0, 2.0, 2.0, 2.0, 1.0, 3.0, 0.0, 3.0, 2.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 3.0, 1.0, 5.0, 2.0, 1.0, 3.0, 1.0, 0.0, 2.0, 2.0, 1.0, 2.0, 3.0, 2.0, 2.0, 1.0, 4.0, 1.0, 1.0, 4.0, 1.0, 3.0, 3.0, 2.0, 1.0, 0.0, 2.0, 0.0, 2.0, 2.0, 2.0, 4.0, 0.0, 0.0, 2.0, 4.0, 2.0, 2.0, 0.0, 4.0, 2.0, 2.0, 4.0, 2.0, 2.0, 1.0, 1.0], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.1466022368508075, "mean_inference_ms": 0.38861140685429973, "mean_action_processing_ms": 0.028605519896031648, "mean_env_wait_ms": 0.39524279160009373, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 1070080, "timesteps_this_iter": 0, "agent_timesteps_total": 1070080, "timers": {"sample_time_ms": 1348.847, "sample_throughput": 3795.834, "load_time_ms": 0.137, "load_throughput": 37360536.674, "learn_time_ms": 73.212, "learn_throughput": 69933.796, "update_time_ms": 2.954}, "info": {"learner": {"default_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 120.59907531738281, "policy_entropy": 7927.1171875, "policy_loss": 37.11105728149414, "vf_loss": 32.702728271484375}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 1070080, "num_agent_steps_sampled": 1070080, "num_steps_trained": 1070080, "num_agent_steps_trained": 1070080, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 532, "training_iteration": 27, "trial_id": "65be9_00000", "experiment_id": "b9e963105bdc4382843b68ace23a11d3", "date": "2024-06-17_16-13-08", "timestamp": 1718608388, "time_this_iter_s": 10.801284074783325, "time_total_s": 278.7983241081238, "pid": 4998, "hostname": "DESKTOP-LQ219J4", "node_ip": "192.168.46.185", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 20, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 5000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 500, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "rware", "env_args": {"n_agents": 4, "column_height": 1, "max_inactivity_steps": null, "max_steps": 500, "fast_obs": true, "msg_bits": 0, "sensor_range": 1, "shelf_rows": 1, "shelf_columns": 3, "request_queue_size": 4, "reward_type": "RewardType.INDIVIDUAL", "map_name": "customized_map", "map_size": "tiny", "difficulty": "medium"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": true, "force_coop": false, "local_mode": true, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 4, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 100, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64}, "algorithm": "maa2c", "space_obs": "Dict(obs:Box([-100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100.], [100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.], (112,), float32))", "space_act": "Discrete(5)", "num_agents": 4, "episode_limit": 500, "policy_mapping_info": {"all_scenario": {"description": "rware all scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2", "agent_3"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "rware_customized_map", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 10, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.policy_template.MAA2CTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x7f7c1d450dc0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "grad_clip": 40.0, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "microbatch_size": null}, "time_since_restore": 278.7983241081238, "timesteps_since_restore": 0, "iterations_since_restore": 27, "perf": {"cpu_util_percent": 4.253333333333332, "ram_util_percent": 39.486666666666665}}
{"episode_reward_max": 5.0, "episode_reward_min": 0.0, "episode_reward_mean": 1.73, "episode_len_mean": 500.0, "episode_media": {}, "episodes_this_iter": 20, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [2.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 2.0, 2.0, 0.0, 4.0, 1.0, 2.0, 1.0, 1.0, 1.0, 0.0, 2.0, 1.0, 2.0, 2.0, 2.0, 1.0, 3.0, 0.0, 3.0, 2.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 3.0, 1.0, 5.0, 2.0, 1.0, 3.0, 1.0, 0.0, 2.0, 2.0, 1.0, 2.0, 3.0, 2.0, 2.0, 1.0, 4.0, 1.0, 1.0, 4.0, 1.0, 3.0, 3.0, 2.0, 1.0, 0.0, 2.0, 0.0, 2.0, 2.0, 2.0, 4.0, 0.0, 0.0, 2.0, 4.0, 2.0, 2.0, 0.0, 4.0, 2.0, 2.0, 4.0, 2.0, 2.0, 1.0, 1.0, 1.0, 3.0, 0.0, 1.0, 2.0, 1.0, 0.0, 3.0, 2.0, 4.0, 5.0, 2.0, 2.0, 2.0, 0.0, 2.0, 3.0, 2.0, 1.0, 5.0], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.14664224923529443, "mean_inference_ms": 0.3886824749596378, "mean_action_processing_ms": 0.028605501733380726, "mean_env_wait_ms": 0.3952381555814351, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 1111040, "timesteps_this_iter": 0, "agent_timesteps_total": 1111040, "timers": {"sample_time_ms": 1379.039, "sample_throughput": 3712.731, "load_time_ms": 0.127, "load_throughput": 40313190.313, "learn_time_ms": 88.125, "learn_throughput": 58099.47, "update_time_ms": 2.892}, "info": {"learner": {"default_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 125.6183853149414, "policy_entropy": 7918.2763671875, "policy_loss": 34.729061126708984, "vf_loss": 27.57021141052246}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 1111040, "num_agent_steps_sampled": 1111040, "num_steps_trained": 1111040, "num_agent_steps_trained": 1111040, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 552, "training_iteration": 28, "trial_id": "65be9_00000", "experiment_id": "b9e963105bdc4382843b68ace23a11d3", "date": "2024-06-17_16-13-19", "timestamp": 1718608399, "time_this_iter_s": 11.12619686126709, "time_total_s": 289.92452096939087, "pid": 4998, "hostname": "DESKTOP-LQ219J4", "node_ip": "192.168.46.185", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 20, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 5000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 500, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "rware", "env_args": {"n_agents": 4, "column_height": 1, "max_inactivity_steps": null, "max_steps": 500, "fast_obs": true, "msg_bits": 0, "sensor_range": 1, "shelf_rows": 1, "shelf_columns": 3, "request_queue_size": 4, "reward_type": "RewardType.INDIVIDUAL", "map_name": "customized_map", "map_size": "tiny", "difficulty": "medium"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": true, "force_coop": false, "local_mode": true, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 4, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 100, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64}, "algorithm": "maa2c", "space_obs": "Dict(obs:Box([-100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100.], [100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.], (112,), float32))", "space_act": "Discrete(5)", "num_agents": 4, "episode_limit": 500, "policy_mapping_info": {"all_scenario": {"description": "rware all scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2", "agent_3"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "rware_customized_map", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 10, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.policy_template.MAA2CTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x7f7c1d906550>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "grad_clip": 40.0, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "microbatch_size": null}, "time_since_restore": 289.92452096939087, "timesteps_since_restore": 0, "iterations_since_restore": 28, "perf": {"cpu_util_percent": 4.0625, "ram_util_percent": 40.162499999999994}}
{"episode_reward_max": 6.0, "episode_reward_min": 0.0, "episode_reward_mean": 1.89, "episode_len_mean": 500.0, "episode_media": {}, "episodes_this_iter": 24, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 3.0, 2.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 3.0, 1.0, 5.0, 2.0, 1.0, 3.0, 1.0, 0.0, 2.0, 2.0, 1.0, 2.0, 3.0, 2.0, 2.0, 1.0, 4.0, 1.0, 1.0, 4.0, 1.0, 3.0, 3.0, 2.0, 1.0, 0.0, 2.0, 0.0, 2.0, 2.0, 2.0, 4.0, 0.0, 0.0, 2.0, 4.0, 2.0, 2.0, 0.0, 4.0, 2.0, 2.0, 4.0, 2.0, 2.0, 1.0, 1.0, 1.0, 3.0, 0.0, 1.0, 2.0, 1.0, 0.0, 3.0, 2.0, 4.0, 5.0, 2.0, 2.0, 2.0, 0.0, 2.0, 3.0, 2.0, 1.0, 5.0, 2.0, 6.0, 2.0, 2.0, 0.0, 2.0, 3.0, 2.0, 2.0, 2.0, 3.0, 5.0, 0.0, 0.0, 3.0, 4.0, 1.0, 0.0, 2.0, 1.0, 1.0, 2.0, 3.0, 0.0], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.1466715557054859, "mean_inference_ms": 0.38875463222495893, "mean_action_processing_ms": 0.02860797516383533, "mean_env_wait_ms": 0.39515022264844574, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 1152000, "timesteps_this_iter": 0, "agent_timesteps_total": 1152000, "timers": {"sample_time_ms": 1357.321, "sample_throughput": 3772.137, "load_time_ms": 0.132, "load_throughput": 38798259.223, "learn_time_ms": 73.363, "learn_throughput": 69789.954, "update_time_ms": 2.882}, "info": {"learner": {"default_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 61.443214416503906, "policy_entropy": 7929.9365234375, "policy_loss": -19.75107765197754, "vf_loss": 23.415281295776367}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 1152000, "num_agent_steps_sampled": 1152000, "num_steps_trained": 1152000, "num_agent_steps_trained": 1152000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 576, "training_iteration": 29, "trial_id": "65be9_00000", "experiment_id": "b9e963105bdc4382843b68ace23a11d3", "date": "2024-06-17_16-13-30", "timestamp": 1718608410, "time_this_iter_s": 10.905668020248413, "time_total_s": 300.8301889896393, "pid": 4998, "hostname": "DESKTOP-LQ219J4", "node_ip": "192.168.46.185", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 20, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 5000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 500, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "rware", "env_args": {"n_agents": 4, "column_height": 1, "max_inactivity_steps": null, "max_steps": 500, "fast_obs": true, "msg_bits": 0, "sensor_range": 1, "shelf_rows": 1, "shelf_columns": 3, "request_queue_size": 4, "reward_type": "RewardType.INDIVIDUAL", "map_name": "customized_map", "map_size": "tiny", "difficulty": "medium"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": true, "force_coop": false, "local_mode": true, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 4, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 100, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64}, "algorithm": "maa2c", "space_obs": "Dict(obs:Box([-100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100.], [100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.], (112,), float32))", "space_act": "Discrete(5)", "num_agents": 4, "episode_limit": 500, "policy_mapping_info": {"all_scenario": {"description": "rware all scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2", "agent_3"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "rware_customized_map", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 10, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.policy_template.MAA2CTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x7f7c1d450ca0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "grad_clip": 40.0, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "microbatch_size": null}, "time_since_restore": 300.8301889896393, "timesteps_since_restore": 0, "iterations_since_restore": 29, "perf": {"cpu_util_percent": 4.24375, "ram_util_percent": 40.875}}
{"episode_reward_max": 6.0, "episode_reward_min": 0.0, "episode_reward_mean": 1.91, "episode_len_mean": 500.0, "episode_media": {}, "episodes_this_iter": 20, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [2.0, 3.0, 2.0, 2.0, 1.0, 4.0, 1.0, 1.0, 4.0, 1.0, 3.0, 3.0, 2.0, 1.0, 0.0, 2.0, 0.0, 2.0, 2.0, 2.0, 4.0, 0.0, 0.0, 2.0, 4.0, 2.0, 2.0, 0.0, 4.0, 2.0, 2.0, 4.0, 2.0, 2.0, 1.0, 1.0, 1.0, 3.0, 0.0, 1.0, 2.0, 1.0, 0.0, 3.0, 2.0, 4.0, 5.0, 2.0, 2.0, 2.0, 0.0, 2.0, 3.0, 2.0, 1.0, 5.0, 2.0, 6.0, 2.0, 2.0, 0.0, 2.0, 3.0, 2.0, 2.0, 2.0, 3.0, 5.0, 0.0, 0.0, 3.0, 4.0, 1.0, 0.0, 2.0, 1.0, 1.0, 2.0, 3.0, 0.0, 2.0, 3.0, 2.0, 3.0, 1.0, 2.0, 3.0, 3.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 3.0, 1.0, 1.0, 0.0, 4.0, 0.0], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.14672595229024524, "mean_inference_ms": 0.3888836679673025, "mean_action_processing_ms": 0.028615059068944914, "mean_env_wait_ms": 0.3951630778754812, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 1192960, "timesteps_this_iter": 0, "agent_timesteps_total": 1192960, "timers": {"sample_time_ms": 1339.697, "sample_throughput": 3821.761, "load_time_ms": 0.126, "load_throughput": 40510915.827, "learn_time_ms": 69.179, "learn_throughput": 74010.939, "update_time_ms": 2.874}, "info": {"learner": {"default_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 36.84458923339844, "policy_entropy": 7969.1806640625, "policy_loss": -9.938265800476074, "vf_loss": 18.347043991088867}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 1192960, "num_agent_steps_sampled": 1192960, "num_steps_trained": 1192960, "num_agent_steps_trained": 1192960, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 596, "training_iteration": 30, "trial_id": "65be9_00000", "experiment_id": "b9e963105bdc4382843b68ace23a11d3", "date": "2024-06-17_16-13-41", "timestamp": 1718608421, "time_this_iter_s": 10.601195573806763, "time_total_s": 311.43138456344604, "pid": 4998, "hostname": "DESKTOP-LQ219J4", "node_ip": "192.168.46.185", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 20, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 5000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 500, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "rware", "env_args": {"n_agents": 4, "column_height": 1, "max_inactivity_steps": null, "max_steps": 500, "fast_obs": true, "msg_bits": 0, "sensor_range": 1, "shelf_rows": 1, "shelf_columns": 3, "request_queue_size": 4, "reward_type": "RewardType.INDIVIDUAL", "map_name": "customized_map", "map_size": "tiny", "difficulty": "medium"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": true, "force_coop": false, "local_mode": true, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 4, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 100, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64}, "algorithm": "maa2c", "space_obs": "Dict(obs:Box([-100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100.], [100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.], (112,), float32))", "space_act": "Discrete(5)", "num_agents": 4, "episode_limit": 500, "policy_mapping_info": {"all_scenario": {"description": "rware all scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2", "agent_3"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "rware_customized_map", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 10, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.policy_template.MAA2CTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x7f7c1d450dc0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "grad_clip": 40.0, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "microbatch_size": null}, "time_since_restore": 311.43138456344604, "timesteps_since_restore": 0, "iterations_since_restore": 30, "perf": {"cpu_util_percent": 4.159999999999999, "ram_util_percent": 41.519999999999996}}
{"episode_reward_max": 7.0, "episode_reward_min": 0.0, "episode_reward_mean": 1.9, "episode_len_mean": 500.0, "episode_media": {}, "episodes_this_iter": 20, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [4.0, 0.0, 0.0, 2.0, 4.0, 2.0, 2.0, 0.0, 4.0, 2.0, 2.0, 4.0, 2.0, 2.0, 1.0, 1.0, 1.0, 3.0, 0.0, 1.0, 2.0, 1.0, 0.0, 3.0, 2.0, 4.0, 5.0, 2.0, 2.0, 2.0, 0.0, 2.0, 3.0, 2.0, 1.0, 5.0, 2.0, 6.0, 2.0, 2.0, 0.0, 2.0, 3.0, 2.0, 2.0, 2.0, 3.0, 5.0, 0.0, 0.0, 3.0, 4.0, 1.0, 0.0, 2.0, 1.0, 1.0, 2.0, 3.0, 0.0, 2.0, 3.0, 2.0, 3.0, 1.0, 2.0, 3.0, 3.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 3.0, 1.0, 1.0, 0.0, 4.0, 0.0, 0.0, 2.0, 1.0, 2.0, 6.0, 1.0, 1.0, 1.0, 0.0, 7.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 2.0, 4.0, 1.0, 4.0], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.14678220164765107, "mean_inference_ms": 0.3890229842874803, "mean_action_processing_ms": 0.028621936928255168, "mean_env_wait_ms": 0.39524099663981715, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 1233920, "timesteps_this_iter": 0, "agent_timesteps_total": 1233920, "timers": {"sample_time_ms": 1339.872, "sample_throughput": 3821.259, "load_time_ms": 0.125, "load_throughput": 40857755.86, "learn_time_ms": 66.13, "learn_throughput": 77423.738, "update_time_ms": 2.893}, "info": {"learner": {"default_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 202.65220642089844, "policy_entropy": 7970.79833984375, "policy_loss": 98.14848327636719, "vf_loss": 56.91438293457031}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 1233920, "num_agent_steps_sampled": 1233920, "num_steps_trained": 1233920, "num_agent_steps_trained": 1233920, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 616, "training_iteration": 31, "trial_id": "65be9_00000", "experiment_id": "b9e963105bdc4382843b68ace23a11d3", "date": "2024-06-17_16-13-51", "timestamp": 1718608431, "time_this_iter_s": 10.746417760848999, "time_total_s": 322.17780232429504, "pid": 4998, "hostname": "DESKTOP-LQ219J4", "node_ip": "192.168.46.185", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 20, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 5000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 500, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "rware", "env_args": {"n_agents": 4, "column_height": 1, "max_inactivity_steps": null, "max_steps": 500, "fast_obs": true, "msg_bits": 0, "sensor_range": 1, "shelf_rows": 1, "shelf_columns": 3, "request_queue_size": 4, "reward_type": "RewardType.INDIVIDUAL", "map_name": "customized_map", "map_size": "tiny", "difficulty": "medium"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": true, "force_coop": false, "local_mode": true, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 4, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 100, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64}, "algorithm": "maa2c", "space_obs": "Dict(obs:Box([-100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100.], [100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.], (112,), float32))", "space_act": "Discrete(5)", "num_agents": 4, "episode_limit": 500, "policy_mapping_info": {"all_scenario": {"description": "rware all scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2", "agent_3"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "rware_customized_map", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 10, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.policy_template.MAA2CTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x7f7c1cdf6790>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "grad_clip": 40.0, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "microbatch_size": null}, "time_since_restore": 322.17780232429504, "timesteps_since_restore": 0, "iterations_since_restore": 31, "perf": {"cpu_util_percent": 4.1466666666666665, "ram_util_percent": 42.193333333333335}}
{"episode_reward_max": 7.0, "episode_reward_min": 0.0, "episode_reward_mean": 1.96, "episode_len_mean": 500.0, "episode_media": {}, "episodes_this_iter": 20, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [2.0, 1.0, 0.0, 3.0, 2.0, 4.0, 5.0, 2.0, 2.0, 2.0, 0.0, 2.0, 3.0, 2.0, 1.0, 5.0, 2.0, 6.0, 2.0, 2.0, 0.0, 2.0, 3.0, 2.0, 2.0, 2.0, 3.0, 5.0, 0.0, 0.0, 3.0, 4.0, 1.0, 0.0, 2.0, 1.0, 1.0, 2.0, 3.0, 0.0, 2.0, 3.0, 2.0, 3.0, 1.0, 2.0, 3.0, 3.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 3.0, 1.0, 1.0, 0.0, 4.0, 0.0, 0.0, 2.0, 1.0, 2.0, 6.0, 1.0, 1.0, 1.0, 0.0, 7.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 2.0, 4.0, 1.0, 4.0, 2.0, 4.0, 3.0, 2.0, 1.0, 1.0, 2.0, 2.0, 0.0, 1.0, 2.0, 2.0, 3.0, 2.0, 2.0, 3.0, 2.0, 6.0, 3.0, 0.0], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.1468273037587515, "mean_inference_ms": 0.3891584247122467, "mean_action_processing_ms": 0.028629703069934224, "mean_env_wait_ms": 0.3953019501185456, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 1274880, "timesteps_this_iter": 0, "agent_timesteps_total": 1274880, "timers": {"sample_time_ms": 1344.953, "sample_throughput": 3806.823, "load_time_ms": 0.127, "load_throughput": 40389009.742, "learn_time_ms": 68.051, "learn_throughput": 75237.895, "update_time_ms": 2.894}, "info": {"learner": {"default_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 163.7164306640625, "policy_entropy": 7976.859375, "policy_loss": -85.89520263671875, "vf_loss": 21.803428649902344}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 1274880, "num_agent_steps_sampled": 1274880, "num_steps_trained": 1274880, "num_agent_steps_trained": 1274880, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 636, "training_iteration": 32, "trial_id": "65be9_00000", "experiment_id": "b9e963105bdc4382843b68ace23a11d3", "date": "2024-06-17_16-14-02", "timestamp": 1718608442, "time_this_iter_s": 10.778484344482422, "time_total_s": 332.95628666877747, "pid": 4998, "hostname": "DESKTOP-LQ219J4", "node_ip": "192.168.46.185", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 20, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 5000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 500, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "rware", "env_args": {"n_agents": 4, "column_height": 1, "max_inactivity_steps": null, "max_steps": 500, "fast_obs": true, "msg_bits": 0, "sensor_range": 1, "shelf_rows": 1, "shelf_columns": 3, "request_queue_size": 4, "reward_type": "RewardType.INDIVIDUAL", "map_name": "customized_map", "map_size": "tiny", "difficulty": "medium"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": true, "force_coop": false, "local_mode": true, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 4, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 100, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64}, "algorithm": "maa2c", "space_obs": "Dict(obs:Box([-100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100.], [100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.], (112,), float32))", "space_act": "Discrete(5)", "num_agents": 4, "episode_limit": 500, "policy_mapping_info": {"all_scenario": {"description": "rware all scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2", "agent_3"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "rware_customized_map", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 10, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.policy_template.MAA2CTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x7f7c1d450ca0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "grad_clip": 40.0, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "microbatch_size": null}, "time_since_restore": 332.95628666877747, "timesteps_since_restore": 0, "iterations_since_restore": 32, "perf": {"cpu_util_percent": 4.1866666666666665, "ram_util_percent": 42.86000000000001}}
{"episode_reward_max": 7.0, "episode_reward_min": 0.0, "episode_reward_mean": 1.93, "episode_len_mean": 500.0, "episode_media": {}, "episodes_this_iter": 20, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 2.0, 3.0, 2.0, 2.0, 2.0, 3.0, 5.0, 0.0, 0.0, 3.0, 4.0, 1.0, 0.0, 2.0, 1.0, 1.0, 2.0, 3.0, 0.0, 2.0, 3.0, 2.0, 3.0, 1.0, 2.0, 3.0, 3.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 3.0, 1.0, 1.0, 0.0, 4.0, 0.0, 0.0, 2.0, 1.0, 2.0, 6.0, 1.0, 1.0, 1.0, 0.0, 7.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 2.0, 4.0, 1.0, 4.0, 2.0, 4.0, 3.0, 2.0, 1.0, 1.0, 2.0, 2.0, 0.0, 1.0, 2.0, 2.0, 3.0, 2.0, 2.0, 3.0, 2.0, 6.0, 3.0, 0.0, 0.0, 3.0, 2.0, 4.0, 3.0, 3.0, 3.0, 1.0, 1.0, 3.0, 2.0, 4.0, 2.0, 2.0, 3.0, 4.0, 2.0, 1.0, 1.0, 1.0], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.1468621470248658, "mean_inference_ms": 0.3892533584650225, "mean_action_processing_ms": 0.02863619326019997, "mean_env_wait_ms": 0.39527089394153125, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 1315840, "timesteps_this_iter": 0, "agent_timesteps_total": 1315840, "timers": {"sample_time_ms": 1340.77, "sample_throughput": 3818.7, "load_time_ms": 0.141, "load_throughput": 36262810.672, "learn_time_ms": 66.707, "learn_throughput": 76753.026, "update_time_ms": 2.912}, "info": {"learner": {"default_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 41.25218200683594, "policy_entropy": 7909.083984375, "policy_loss": -11.430462837219238, "vf_loss": 19.677461624145508}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 1315840, "num_agent_steps_sampled": 1315840, "num_steps_trained": 1315840, "num_agent_steps_trained": 1315840, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 656, "training_iteration": 33, "trial_id": "65be9_00000", "experiment_id": "b9e963105bdc4382843b68ace23a11d3", "date": "2024-06-17_16-14-13", "timestamp": 1718608453, "time_this_iter_s": 10.716205358505249, "time_total_s": 343.6724920272827, "pid": 4998, "hostname": "DESKTOP-LQ219J4", "node_ip": "192.168.46.185", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 20, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 5000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 500, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "rware", "env_args": {"n_agents": 4, "column_height": 1, "max_inactivity_steps": null, "max_steps": 500, "fast_obs": true, "msg_bits": 0, "sensor_range": 1, "shelf_rows": 1, "shelf_columns": 3, "request_queue_size": 4, "reward_type": "RewardType.INDIVIDUAL", "map_name": "customized_map", "map_size": "tiny", "difficulty": "medium"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": true, "force_coop": false, "local_mode": true, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 4, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 100, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64}, "algorithm": "maa2c", "space_obs": "Dict(obs:Box([-100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100.], [100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.], (112,), float32))", "space_act": "Discrete(5)", "num_agents": 4, "episode_limit": 500, "policy_mapping_info": {"all_scenario": {"description": "rware all scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2", "agent_3"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "rware_customized_map", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 10, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.policy_template.MAA2CTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x7f7c1d450040>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "grad_clip": 40.0, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "microbatch_size": null}, "time_since_restore": 343.6724920272827, "timesteps_since_restore": 0, "iterations_since_restore": 33, "perf": {"cpu_util_percent": 4.15, "ram_util_percent": 43.55}}
{"episode_reward_max": 7.0, "episode_reward_min": 0.0, "episode_reward_mean": 1.84, "episode_len_mean": 500.0, "episode_media": {}, "episodes_this_iter": 20, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [2.0, 3.0, 2.0, 3.0, 1.0, 2.0, 3.0, 3.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 3.0, 1.0, 1.0, 0.0, 4.0, 0.0, 0.0, 2.0, 1.0, 2.0, 6.0, 1.0, 1.0, 1.0, 0.0, 7.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 2.0, 4.0, 1.0, 4.0, 2.0, 4.0, 3.0, 2.0, 1.0, 1.0, 2.0, 2.0, 0.0, 1.0, 2.0, 2.0, 3.0, 2.0, 2.0, 3.0, 2.0, 6.0, 3.0, 0.0, 0.0, 3.0, 2.0, 4.0, 3.0, 3.0, 3.0, 1.0, 1.0, 3.0, 2.0, 4.0, 2.0, 2.0, 3.0, 4.0, 2.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 3.0, 2.0, 0.0, 1.0, 2.0, 5.0, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 3.0, 2.0, 1.0, 2.0, 1.0], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.1469030625118082, "mean_inference_ms": 0.389351612346601, "mean_action_processing_ms": 0.028641265601500817, "mean_env_wait_ms": 0.3952662704066303, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 1356800, "timesteps_this_iter": 0, "agent_timesteps_total": 1356800, "timers": {"sample_time_ms": 1336.759, "sample_throughput": 3830.159, "load_time_ms": 0.136, "load_throughput": 37648731.557, "learn_time_ms": 66.524, "learn_throughput": 76965.25, "update_time_ms": 2.918}, "info": {"learner": {"default_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 123.4401626586914, "policy_entropy": 7927.27685546875, "policy_loss": 55.74161911010742, "vf_loss": 25.222633361816406}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 1356800, "num_agent_steps_sampled": 1356800, "num_steps_trained": 1356800, "num_agent_steps_trained": 1356800, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 676, "training_iteration": 34, "trial_id": "65be9_00000", "experiment_id": "b9e963105bdc4382843b68ace23a11d3", "date": "2024-06-17_16-14-24", "timestamp": 1718608464, "time_this_iter_s": 10.654003381729126, "time_total_s": 354.32649540901184, "pid": 4998, "hostname": "DESKTOP-LQ219J4", "node_ip": "192.168.46.185", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 20, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 5000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 500, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "rware", "env_args": {"n_agents": 4, "column_height": 1, "max_inactivity_steps": null, "max_steps": 500, "fast_obs": true, "msg_bits": 0, "sensor_range": 1, "shelf_rows": 1, "shelf_columns": 3, "request_queue_size": 4, "reward_type": "RewardType.INDIVIDUAL", "map_name": "customized_map", "map_size": "tiny", "difficulty": "medium"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": true, "force_coop": false, "local_mode": true, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 4, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 100, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64}, "algorithm": "maa2c", "space_obs": "Dict(obs:Box([-100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100.], [100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.], (112,), float32))", "space_act": "Discrete(5)", "num_agents": 4, "episode_limit": 500, "policy_mapping_info": {"all_scenario": {"description": "rware all scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2", "agent_3"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "rware_customized_map", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 10, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.policy_template.MAA2CTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x7f7c1d450d30>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "grad_clip": 40.0, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "microbatch_size": null}, "time_since_restore": 354.32649540901184, "timesteps_since_restore": 0, "iterations_since_restore": 34, "perf": {"cpu_util_percent": 4.166666666666667, "ram_util_percent": 44.2}}
{"episode_reward_max": 7.0, "episode_reward_min": 0.0, "episode_reward_mean": 1.75, "episode_len_mean": 500.0, "episode_media": {}, "episodes_this_iter": 20, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 2.0, 1.0, 2.0, 6.0, 1.0, 1.0, 1.0, 0.0, 7.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 2.0, 4.0, 1.0, 4.0, 2.0, 4.0, 3.0, 2.0, 1.0, 1.0, 2.0, 2.0, 0.0, 1.0, 2.0, 2.0, 3.0, 2.0, 2.0, 3.0, 2.0, 6.0, 3.0, 0.0, 0.0, 3.0, 2.0, 4.0, 3.0, 3.0, 3.0, 1.0, 1.0, 3.0, 2.0, 4.0, 2.0, 2.0, 3.0, 4.0, 2.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 3.0, 2.0, 0.0, 1.0, 2.0, 5.0, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 3.0, 2.0, 1.0, 2.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 2.0, 2.0, 0.0, 1.0, 3.0, 2.0, 1.0, 0.0, 0.0, 1.0, 3.0, 3.0, 1.0, 2.0, 0.0], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.14693255019976378, "mean_inference_ms": 0.3894221132856955, "mean_action_processing_ms": 0.02864629549776042, "mean_env_wait_ms": 0.39528889686699314, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 1397760, "timesteps_this_iter": 0, "agent_timesteps_total": 1397760, "timers": {"sample_time_ms": 1346.74, "sample_throughput": 3801.774, "load_time_ms": 0.135, "load_throughput": 37814468.181, "learn_time_ms": 67.505, "learn_throughput": 75845.776, "update_time_ms": 3.029}, "info": {"learner": {"default_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 76.66160583496094, "policy_entropy": 7921.79248046875, "policy_loss": 29.28040313720703, "vf_loss": 22.807832717895508}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 1397760, "num_agent_steps_sampled": 1397760, "num_steps_trained": 1397760, "num_agent_steps_trained": 1397760, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 696, "training_iteration": 35, "trial_id": "65be9_00000", "experiment_id": "b9e963105bdc4382843b68ace23a11d3", "date": "2024-06-17_16-14-34", "timestamp": 1718608474, "time_this_iter_s": 10.829625844955444, "time_total_s": 365.1561212539673, "pid": 4998, "hostname": "DESKTOP-LQ219J4", "node_ip": "192.168.46.185", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 20, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 5000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 500, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "rware", "env_args": {"n_agents": 4, "column_height": 1, "max_inactivity_steps": null, "max_steps": 500, "fast_obs": true, "msg_bits": 0, "sensor_range": 1, "shelf_rows": 1, "shelf_columns": 3, "request_queue_size": 4, "reward_type": "RewardType.INDIVIDUAL", "map_name": "customized_map", "map_size": "tiny", "difficulty": "medium"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": true, "force_coop": false, "local_mode": true, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 4, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 100, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64}, "algorithm": "maa2c", "space_obs": "Dict(obs:Box([-100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100.], [100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.], (112,), float32))", "space_act": "Discrete(5)", "num_agents": 4, "episode_limit": 500, "policy_mapping_info": {"all_scenario": {"description": "rware all scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2", "agent_3"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "rware_customized_map", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 10, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.policy_template.MAA2CTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x7f7c1aff2790>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "grad_clip": 40.0, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "microbatch_size": null}, "time_since_restore": 365.1561212539673, "timesteps_since_restore": 0, "iterations_since_restore": 35, "perf": {"cpu_util_percent": 4.333333333333333, "ram_util_percent": 44.84666666666667}}
{"episode_reward_max": 6.0, "episode_reward_min": 0.0, "episode_reward_mean": 1.78, "episode_len_mean": 500.0, "episode_media": {}, "episodes_this_iter": 20, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [2.0, 4.0, 3.0, 2.0, 1.0, 1.0, 2.0, 2.0, 0.0, 1.0, 2.0, 2.0, 3.0, 2.0, 2.0, 3.0, 2.0, 6.0, 3.0, 0.0, 0.0, 3.0, 2.0, 4.0, 3.0, 3.0, 3.0, 1.0, 1.0, 3.0, 2.0, 4.0, 2.0, 2.0, 3.0, 4.0, 2.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 3.0, 2.0, 0.0, 1.0, 2.0, 5.0, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 3.0, 2.0, 1.0, 2.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 2.0, 2.0, 0.0, 1.0, 3.0, 2.0, 1.0, 0.0, 0.0, 1.0, 3.0, 3.0, 1.0, 2.0, 0.0, 2.0, 1.0, 5.0, 2.0, 1.0, 2.0, 2.0, 2.0, 2.0, 1.0, 4.0, 1.0, 1.0, 2.0, 2.0, 2.0, 2.0, 1.0, 3.0, 2.0], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.1469486540163722, "mean_inference_ms": 0.38943946597041834, "mean_action_processing_ms": 0.028647811452031616, "mean_env_wait_ms": 0.3952824126383081, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 1438720, "timesteps_this_iter": 0, "agent_timesteps_total": 1438720, "timers": {"sample_time_ms": 1337.97, "sample_throughput": 3826.693, "load_time_ms": 0.137, "load_throughput": 37263294.256, "learn_time_ms": 66.467, "learn_throughput": 77031.04, "update_time_ms": 2.982}, "info": {"learner": {"default_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 50.39636993408203, "policy_entropy": 7948.1748046875, "policy_loss": -31.955974578857422, "vf_loss": 10.982864379882812}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 1438720, "num_agent_steps_sampled": 1438720, "num_steps_trained": 1438720, "num_agent_steps_trained": 1438720, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 716, "training_iteration": 36, "trial_id": "65be9_00000", "experiment_id": "b9e963105bdc4382843b68ace23a11d3", "date": "2024-06-17_16-14-45", "timestamp": 1718608485, "time_this_iter_s": 10.58333945274353, "time_total_s": 375.7394607067108, "pid": 4998, "hostname": "DESKTOP-LQ219J4", "node_ip": "192.168.46.185", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 20, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 5000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 500, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "rware", "env_args": {"n_agents": 4, "column_height": 1, "max_inactivity_steps": null, "max_steps": 500, "fast_obs": true, "msg_bits": 0, "sensor_range": 1, "shelf_rows": 1, "shelf_columns": 3, "request_queue_size": 4, "reward_type": "RewardType.INDIVIDUAL", "map_name": "customized_map", "map_size": "tiny", "difficulty": "medium"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": true, "force_coop": false, "local_mode": true, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 4, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 100, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64}, "algorithm": "maa2c", "space_obs": "Dict(obs:Box([-100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100.], [100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.], (112,), float32))", "space_act": "Discrete(5)", "num_agents": 4, "episode_limit": 500, "policy_mapping_info": {"all_scenario": {"description": "rware all scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2", "agent_3"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "rware_customized_map", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 10, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.policy_template.MAA2CTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x7f7c1cdf6f70>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "grad_clip": 40.0, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "microbatch_size": null}, "time_since_restore": 375.7394607067108, "timesteps_since_restore": 0, "iterations_since_restore": 36, "perf": {"cpu_util_percent": 4.168749999999999, "ram_util_percent": 45.49375}}
{"episode_reward_max": 6.0, "episode_reward_min": 0.0, "episode_reward_mean": 1.69, "episode_len_mean": 500.0, "episode_media": {}, "episodes_this_iter": 20, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 3.0, 2.0, 4.0, 3.0, 3.0, 3.0, 1.0, 1.0, 3.0, 2.0, 4.0, 2.0, 2.0, 3.0, 4.0, 2.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 3.0, 2.0, 0.0, 1.0, 2.0, 5.0, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 3.0, 2.0, 1.0, 2.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 2.0, 2.0, 0.0, 1.0, 3.0, 2.0, 1.0, 0.0, 0.0, 1.0, 3.0, 3.0, 1.0, 2.0, 0.0, 2.0, 1.0, 5.0, 2.0, 1.0, 2.0, 2.0, 2.0, 2.0, 1.0, 4.0, 1.0, 1.0, 2.0, 2.0, 2.0, 2.0, 1.0, 3.0, 2.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 3.0, 1.0, 0.0, 3.0, 6.0, 2.0, 4.0, 3.0, 0.0, 0.0, 5.0], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.14696769638123056, "mean_inference_ms": 0.38944058839991996, "mean_action_processing_ms": 0.02864724691949496, "mean_env_wait_ms": 0.3952454168012599, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 1479680, "timesteps_this_iter": 0, "agent_timesteps_total": 1479680, "timers": {"sample_time_ms": 1341.362, "sample_throughput": 3817.016, "load_time_ms": 0.14, "load_throughput": 36497002.855, "learn_time_ms": 66.457, "learn_throughput": 77042.536, "update_time_ms": 3.014}, "info": {"learner": {"default_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 44.73494338989258, "policy_entropy": 7901.8486328125, "policy_loss": 5.316071510314941, "vf_loss": 15.104259490966797}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 1479680, "num_agent_steps_sampled": 1479680, "num_steps_trained": 1479680, "num_agent_steps_trained": 1479680, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 736, "training_iteration": 37, "trial_id": "65be9_00000", "experiment_id": "b9e963105bdc4382843b68ace23a11d3", "date": "2024-06-17_16-14-56", "timestamp": 1718608496, "time_this_iter_s": 10.700639724731445, "time_total_s": 386.44010043144226, "pid": 4998, "hostname": "DESKTOP-LQ219J4", "node_ip": "192.168.46.185", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 20, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 5000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 500, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "rware", "env_args": {"n_agents": 4, "column_height": 1, "max_inactivity_steps": null, "max_steps": 500, "fast_obs": true, "msg_bits": 0, "sensor_range": 1, "shelf_rows": 1, "shelf_columns": 3, "request_queue_size": 4, "reward_type": "RewardType.INDIVIDUAL", "map_name": "customized_map", "map_size": "tiny", "difficulty": "medium"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": true, "force_coop": false, "local_mode": true, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 4, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 100, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64}, "algorithm": "maa2c", "space_obs": "Dict(obs:Box([-100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100.], [100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.], (112,), float32))", "space_act": "Discrete(5)", "num_agents": 4, "episode_limit": 500, "policy_mapping_info": {"all_scenario": {"description": "rware all scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2", "agent_3"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "rware_customized_map", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 10, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.policy_template.MAA2CTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x7f7c1aff2430>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "grad_clip": 40.0, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "microbatch_size": null}, "time_since_restore": 386.44010043144226, "timesteps_since_restore": 0, "iterations_since_restore": 37, "perf": {"cpu_util_percent": 4.320000000000001, "ram_util_percent": 46.18}}
{"episode_reward_max": 6.0, "episode_reward_min": 0.0, "episode_reward_mean": 1.58, "episode_len_mean": 500.0, "episode_media": {}, "episodes_this_iter": 24, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [2.0, 0.0, 1.0, 2.0, 5.0, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 3.0, 2.0, 1.0, 2.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 2.0, 2.0, 0.0, 1.0, 3.0, 2.0, 1.0, 0.0, 0.0, 1.0, 3.0, 3.0, 1.0, 2.0, 0.0, 2.0, 1.0, 5.0, 2.0, 1.0, 2.0, 2.0, 2.0, 2.0, 1.0, 4.0, 1.0, 1.0, 2.0, 2.0, 2.0, 2.0, 1.0, 3.0, 2.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 3.0, 1.0, 0.0, 3.0, 6.0, 2.0, 4.0, 3.0, 0.0, 0.0, 5.0, 1.0, 1.0, 1.0, 2.0, 6.0, 2.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 2.0, 5.0, 0.0, 0.0, 2.0, 2.0, 1.0, 2.0, 2.0, 3.0, 0.0], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.14696199135850063, "mean_inference_ms": 0.3893785257865201, "mean_action_processing_ms": 0.02864174301685222, "mean_env_wait_ms": 0.39518433156263727, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 1520640, "timesteps_this_iter": 0, "agent_timesteps_total": 1520640, "timers": {"sample_time_ms": 1338.123, "sample_throughput": 3826.255, "load_time_ms": 0.142, "load_throughput": 36043700.034, "learn_time_ms": 68.334, "learn_throughput": 74926.404, "update_time_ms": 2.939}, "info": {"learner": {"default_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 31.32319450378418, "policy_entropy": 7966.8876953125, "policy_loss": -11.952178955078125, "vf_loss": 9.435515403747559}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 1520640, "num_agent_steps_sampled": 1520640, "num_steps_trained": 1520640, "num_agent_steps_trained": 1520640, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 760, "training_iteration": 38, "trial_id": "65be9_00000", "experiment_id": "b9e963105bdc4382843b68ace23a11d3", "date": "2024-06-17_16-15-06", "timestamp": 1718608506, "time_this_iter_s": 10.724660158157349, "time_total_s": 397.1647605895996, "pid": 4998, "hostname": "DESKTOP-LQ219J4", "node_ip": "192.168.46.185", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 20, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 5000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 500, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "rware", "env_args": {"n_agents": 4, "column_height": 1, "max_inactivity_steps": null, "max_steps": 500, "fast_obs": true, "msg_bits": 0, "sensor_range": 1, "shelf_rows": 1, "shelf_columns": 3, "request_queue_size": 4, "reward_type": "RewardType.INDIVIDUAL", "map_name": "customized_map", "map_size": "tiny", "difficulty": "medium"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": true, "force_coop": false, "local_mode": true, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 4, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 100, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64}, "algorithm": "maa2c", "space_obs": "Dict(obs:Box([-100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100.], [100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.], (112,), float32))", "space_act": "Discrete(5)", "num_agents": 4, "episode_limit": 500, "policy_mapping_info": {"all_scenario": {"description": "rware all scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2", "agent_3"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "rware_customized_map", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 10, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.policy_template.MAA2CTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x7f7c1cdf6c10>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "grad_clip": 40.0, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "microbatch_size": null}, "time_since_restore": 397.1647605895996, "timesteps_since_restore": 0, "iterations_since_restore": 38, "perf": {"cpu_util_percent": 3.926666666666667, "ram_util_percent": 46.85333333333334}}
{"episode_reward_max": 6.0, "episode_reward_min": 0.0, "episode_reward_mean": 1.64, "episode_len_mean": 500.0, "episode_media": {}, "episodes_this_iter": 20, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [1.0, 2.0, 2.0, 0.0, 1.0, 3.0, 2.0, 1.0, 0.0, 0.0, 1.0, 3.0, 3.0, 1.0, 2.0, 0.0, 2.0, 1.0, 5.0, 2.0, 1.0, 2.0, 2.0, 2.0, 2.0, 1.0, 4.0, 1.0, 1.0, 2.0, 2.0, 2.0, 2.0, 1.0, 3.0, 2.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 3.0, 1.0, 0.0, 3.0, 6.0, 2.0, 4.0, 3.0, 0.0, 0.0, 5.0, 1.0, 1.0, 1.0, 2.0, 6.0, 2.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 2.0, 5.0, 0.0, 0.0, 2.0, 2.0, 1.0, 2.0, 2.0, 3.0, 0.0, 2.0, 0.0, 2.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 5.0, 0.0, 0.0, 1.0, 0.0], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.14698054510025724, "mean_inference_ms": 0.3893551044743076, "mean_action_processing_ms": 0.02863879273275222, "mean_env_wait_ms": 0.39515786680737847, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 1561600, "timesteps_this_iter": 0, "agent_timesteps_total": 1561600, "timers": {"sample_time_ms": 1330.611, "sample_throughput": 3847.857, "load_time_ms": 0.139, "load_throughput": 36721676.607, "learn_time_ms": 66.335, "learn_throughput": 77183.701, "update_time_ms": 2.873}, "info": {"learner": {"default_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 54.515846252441406, "policy_entropy": 7961.5029296875, "policy_loss": -35.84283447265625, "vf_loss": 13.541975975036621}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 1561600, "num_agent_steps_sampled": 1561600, "num_steps_trained": 1561600, "num_agent_steps_trained": 1561600, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 780, "training_iteration": 39, "trial_id": "65be9_00000", "experiment_id": "b9e963105bdc4382843b68ace23a11d3", "date": "2024-06-17_16-15-17", "timestamp": 1718608517, "time_this_iter_s": 10.649075508117676, "time_total_s": 407.8138360977173, "pid": 4998, "hostname": "DESKTOP-LQ219J4", "node_ip": "192.168.46.185", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 20, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 5000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 500, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "rware", "env_args": {"n_agents": 4, "column_height": 1, "max_inactivity_steps": null, "max_steps": 500, "fast_obs": true, "msg_bits": 0, "sensor_range": 1, "shelf_rows": 1, "shelf_columns": 3, "request_queue_size": 4, "reward_type": "RewardType.INDIVIDUAL", "map_name": "customized_map", "map_size": "tiny", "difficulty": "medium"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": true, "force_coop": false, "local_mode": true, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 4, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 100, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64}, "algorithm": "maa2c", "space_obs": "Dict(obs:Box([-100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100.], [100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.], (112,), float32))", "space_act": "Discrete(5)", "num_agents": 4, "episode_limit": 500, "policy_mapping_info": {"all_scenario": {"description": "rware all scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2", "agent_3"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "rware_customized_map", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 10, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.policy_template.MAA2CTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x7f7c1aff2c10>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "grad_clip": 40.0, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "microbatch_size": null}, "time_since_restore": 407.8138360977173, "timesteps_since_restore": 0, "iterations_since_restore": 39, "perf": {"cpu_util_percent": 4.180000000000001, "ram_util_percent": 47.49333333333334}}
{"episode_reward_max": 6.0, "episode_reward_min": 0.0, "episode_reward_mean": 1.63, "episode_len_mean": 500.0, "episode_media": {}, "episodes_this_iter": 20, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [1.0, 2.0, 2.0, 2.0, 2.0, 1.0, 4.0, 1.0, 1.0, 2.0, 2.0, 2.0, 2.0, 1.0, 3.0, 2.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 3.0, 1.0, 0.0, 3.0, 6.0, 2.0, 4.0, 3.0, 0.0, 0.0, 5.0, 1.0, 1.0, 1.0, 2.0, 6.0, 2.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 2.0, 5.0, 0.0, 0.0, 2.0, 2.0, 1.0, 2.0, 2.0, 3.0, 0.0, 2.0, 0.0, 2.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 5.0, 0.0, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 5.0, 0.0, 0.0, 3.0, 2.0, 2.0, 0.0, 1.0, 2.0, 0.0, 1.0, 2.0, 1.0, 1.0, 3.0, 5.0, 1.0], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.14698453388479302, "mean_inference_ms": 0.38929891092064395, "mean_action_processing_ms": 0.0286326173476863, "mean_env_wait_ms": 0.3950527402734587, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 1602560, "timesteps_this_iter": 0, "agent_timesteps_total": 1602560, "timers": {"sample_time_ms": 1314.138, "sample_throughput": 3896.091, "load_time_ms": 0.136, "load_throughput": 37530297.938, "learn_time_ms": 66.393, "learn_throughput": 77116.737, "update_time_ms": 2.934}, "info": {"learner": {"default_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 58.29666519165039, "policy_entropy": 7953.3896484375, "policy_loss": 14.726509094238281, "vf_loss": 13.749115943908691}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 1602560, "num_agent_steps_sampled": 1602560, "num_steps_trained": 1602560, "num_agent_steps_trained": 1602560, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 800, "training_iteration": 40, "trial_id": "65be9_00000", "experiment_id": "b9e963105bdc4382843b68ace23a11d3", "date": "2024-06-17_16-15-28", "timestamp": 1718608528, "time_this_iter_s": 10.517306089401245, "time_total_s": 418.33114218711853, "pid": 4998, "hostname": "DESKTOP-LQ219J4", "node_ip": "192.168.46.185", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 20, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 5000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 500, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "rware", "env_args": {"n_agents": 4, "column_height": 1, "max_inactivity_steps": null, "max_steps": 500, "fast_obs": true, "msg_bits": 0, "sensor_range": 1, "shelf_rows": 1, "shelf_columns": 3, "request_queue_size": 4, "reward_type": "RewardType.INDIVIDUAL", "map_name": "customized_map", "map_size": "tiny", "difficulty": "medium"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": true, "force_coop": false, "local_mode": true, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 4, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 100, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64}, "algorithm": "maa2c", "space_obs": "Dict(obs:Box([-100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100.], [100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.], (112,), float32))", "space_act": "Discrete(5)", "num_agents": 4, "episode_limit": 500, "policy_mapping_info": {"all_scenario": {"description": "rware all scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2", "agent_3"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "rware_customized_map", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 10, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.policy_template.MAA2CTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x7f7c1aff2670>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "grad_clip": 40.0, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "microbatch_size": null}, "time_since_restore": 418.33114218711853, "timesteps_since_restore": 0, "iterations_since_restore": 40, "perf": {"cpu_util_percent": 4.039999999999999, "ram_util_percent": 48.139999999999986}}
{"episode_reward_max": 6.0, "episode_reward_min": 0.0, "episode_reward_mean": 1.71, "episode_len_mean": 500.0, "episode_media": {}, "episodes_this_iter": 20, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [1.0, 1.0, 1.0, 1.0, 1.0, 3.0, 1.0, 0.0, 3.0, 6.0, 2.0, 4.0, 3.0, 0.0, 0.0, 5.0, 1.0, 1.0, 1.0, 2.0, 6.0, 2.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 2.0, 5.0, 0.0, 0.0, 2.0, 2.0, 1.0, 2.0, 2.0, 3.0, 0.0, 2.0, 0.0, 2.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 5.0, 0.0, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 5.0, 0.0, 0.0, 3.0, 2.0, 2.0, 0.0, 1.0, 2.0, 0.0, 1.0, 2.0, 1.0, 1.0, 3.0, 5.0, 1.0, 1.0, 4.0, 1.0, 1.0, 1.0, 1.0, 1.0, 2.0, 1.0, 3.0, 2.0, 5.0, 2.0, 3.0, 1.0, 3.0, 1.0, 3.0, 3.0, 1.0], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.146982327681722, "mean_inference_ms": 0.38923860664578114, "mean_action_processing_ms": 0.028626899471155393, "mean_env_wait_ms": 0.3949306829354795, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 1643520, "timesteps_this_iter": 0, "agent_timesteps_total": 1643520, "timers": {"sample_time_ms": 1319.546, "sample_throughput": 3880.123, "load_time_ms": 0.131, "load_throughput": 38967222.791, "learn_time_ms": 67.693, "learn_throughput": 75635.755, "update_time_ms": 2.823}, "info": {"learner": {"default_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 124.91726684570312, "policy_entropy": 7954.11962890625, "policy_loss": 22.542997360229492, "vf_loss": 38.59300994873047}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 1643520, "num_agent_steps_sampled": 1643520, "num_steps_trained": 1643520, "num_agent_steps_trained": 1643520, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 820, "training_iteration": 41, "trial_id": "65be9_00000", "experiment_id": "b9e963105bdc4382843b68ace23a11d3", "date": "2024-06-17_16-15-38", "timestamp": 1718608538, "time_this_iter_s": 10.553240776062012, "time_total_s": 428.88438296318054, "pid": 4998, "hostname": "DESKTOP-LQ219J4", "node_ip": "192.168.46.185", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 20, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 5000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 500, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "rware", "env_args": {"n_agents": 4, "column_height": 1, "max_inactivity_steps": null, "max_steps": 500, "fast_obs": true, "msg_bits": 0, "sensor_range": 1, "shelf_rows": 1, "shelf_columns": 3, "request_queue_size": 4, "reward_type": "RewardType.INDIVIDUAL", "map_name": "customized_map", "map_size": "tiny", "difficulty": "medium"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": true, "force_coop": false, "local_mode": true, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 4, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 100, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64}, "algorithm": "maa2c", "space_obs": "Dict(obs:Box([-100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100.], [100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.], (112,), float32))", "space_act": "Discrete(5)", "num_agents": 4, "episode_limit": 500, "policy_mapping_info": {"all_scenario": {"description": "rware all scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2", "agent_3"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "rware_customized_map", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 10, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.policy_template.MAA2CTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x7f7c1aff2ca0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "grad_clip": 40.0, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "microbatch_size": null}, "time_since_restore": 428.88438296318054, "timesteps_since_restore": 0, "iterations_since_restore": 41, "perf": {"cpu_util_percent": 4.06, "ram_util_percent": 48.77333333333333}}
{"episode_reward_max": 6.0, "episode_reward_min": 0.0, "episode_reward_mean": 1.77, "episode_len_mean": 500.0, "episode_media": {}, "episodes_this_iter": 20, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [6.0, 2.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 2.0, 5.0, 0.0, 0.0, 2.0, 2.0, 1.0, 2.0, 2.0, 3.0, 0.0, 2.0, 0.0, 2.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 5.0, 0.0, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 5.0, 0.0, 0.0, 3.0, 2.0, 2.0, 0.0, 1.0, 2.0, 0.0, 1.0, 2.0, 1.0, 1.0, 3.0, 5.0, 1.0, 1.0, 4.0, 1.0, 1.0, 1.0, 1.0, 1.0, 2.0, 1.0, 3.0, 2.0, 5.0, 2.0, 3.0, 1.0, 3.0, 1.0, 3.0, 3.0, 1.0, 4.0, 2.0, 2.0, 1.0, 1.0, 5.0, 1.0, 2.0, 2.0, 0.0, 3.0, 1.0, 2.0, 0.0, 3.0, 2.0, 2.0, 3.0, 3.0, 4.0], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.1469697024621889, "mean_inference_ms": 0.3891548357676986, "mean_action_processing_ms": 0.028620067771240123, "mean_env_wait_ms": 0.39478982948479086, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 1684480, "timesteps_this_iter": 0, "agent_timesteps_total": 1684480, "timers": {"sample_time_ms": 1325.212, "sample_throughput": 3863.534, "load_time_ms": 0.13, "load_throughput": 39454044.608, "learn_time_ms": 65.063, "learn_throughput": 78692.642, "update_time_ms": 2.842}, "info": {"learner": {"default_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 57.822750091552734, "policy_entropy": 7970.85302734375, "policy_loss": 22.347896575927734, "vf_loss": 23.194368362426758}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 1684480, "num_agent_steps_sampled": 1684480, "num_steps_trained": 1684480, "num_agent_steps_trained": 1684480, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 840, "training_iteration": 42, "trial_id": "65be9_00000", "experiment_id": "b9e963105bdc4382843b68ace23a11d3", "date": "2024-06-17_16-15-49", "timestamp": 1718608549, "time_this_iter_s": 10.619046449661255, "time_total_s": 439.5034294128418, "pid": 4998, "hostname": "DESKTOP-LQ219J4", "node_ip": "192.168.46.185", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 20, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 5000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 500, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "rware", "env_args": {"n_agents": 4, "column_height": 1, "max_inactivity_steps": null, "max_steps": 500, "fast_obs": true, "msg_bits": 0, "sensor_range": 1, "shelf_rows": 1, "shelf_columns": 3, "request_queue_size": 4, "reward_type": "RewardType.INDIVIDUAL", "map_name": "customized_map", "map_size": "tiny", "difficulty": "medium"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": true, "force_coop": false, "local_mode": true, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 4, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 100, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64}, "algorithm": "maa2c", "space_obs": "Dict(obs:Box([-100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100.], [100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.], (112,), float32))", "space_act": "Discrete(5)", "num_agents": 4, "episode_limit": 500, "policy_mapping_info": {"all_scenario": {"description": "rware all scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2", "agent_3"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "rware_customized_map", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 10, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.policy_template.MAA2CTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x7f7c1afbca60>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "grad_clip": 40.0, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "microbatch_size": null}, "time_since_restore": 439.5034294128418, "timesteps_since_restore": 0, "iterations_since_restore": 42, "perf": {"cpu_util_percent": 4.11875, "ram_util_percent": 49.48125}}
{"episode_reward_max": 5.0, "episode_reward_min": 0.0, "episode_reward_mean": 1.7, "episode_len_mean": 500.0, "episode_media": {}, "episodes_this_iter": 20, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [2.0, 0.0, 2.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 5.0, 0.0, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 5.0, 0.0, 0.0, 3.0, 2.0, 2.0, 0.0, 1.0, 2.0, 0.0, 1.0, 2.0, 1.0, 1.0, 3.0, 5.0, 1.0, 1.0, 4.0, 1.0, 1.0, 1.0, 1.0, 1.0, 2.0, 1.0, 3.0, 2.0, 5.0, 2.0, 3.0, 1.0, 3.0, 1.0, 3.0, 3.0, 1.0, 4.0, 2.0, 2.0, 1.0, 1.0, 5.0, 1.0, 2.0, 2.0, 0.0, 3.0, 1.0, 2.0, 0.0, 3.0, 2.0, 2.0, 3.0, 3.0, 4.0, 1.0, 1.0, 1.0, 1.0, 2.0, 2.0, 0.0, 3.0, 1.0, 2.0, 1.0, 0.0, 3.0, 4.0, 0.0, 2.0, 1.0, 0.0, 1.0, 1.0], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.14696967852299925, "mean_inference_ms": 0.3890982295165664, "mean_action_processing_ms": 0.028613949765895395, "mean_env_wait_ms": 0.39472354466844656, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 1725440, "timesteps_this_iter": 0, "agent_timesteps_total": 1725440, "timers": {"sample_time_ms": 1326.95, "sample_throughput": 3858.473, "load_time_ms": 0.139, "load_throughput": 36866672.069, "learn_time_ms": 65.695, "learn_throughput": 77936.114, "update_time_ms": 2.834}, "info": {"learner": {"default_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 51.78108596801758, "policy_entropy": 7984.8916015625, "policy_loss": 17.13031768798828, "vf_loss": 15.008905410766602}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 1725440, "num_agent_steps_sampled": 1725440, "num_steps_trained": 1725440, "num_agent_steps_trained": 1725440, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 860, "training_iteration": 43, "trial_id": "65be9_00000", "experiment_id": "b9e963105bdc4382843b68ace23a11d3", "date": "2024-06-17_16-15-59", "timestamp": 1718608559, "time_this_iter_s": 10.618540048599243, "time_total_s": 450.12196946144104, "pid": 4998, "hostname": "DESKTOP-LQ219J4", "node_ip": "192.168.46.185", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 20, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 5000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 500, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "rware", "env_args": {"n_agents": 4, "column_height": 1, "max_inactivity_steps": null, "max_steps": 500, "fast_obs": true, "msg_bits": 0, "sensor_range": 1, "shelf_rows": 1, "shelf_columns": 3, "request_queue_size": 4, "reward_type": "RewardType.INDIVIDUAL", "map_name": "customized_map", "map_size": "tiny", "difficulty": "medium"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": true, "force_coop": false, "local_mode": true, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 4, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 100, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64}, "algorithm": "maa2c", "space_obs": "Dict(obs:Box([-100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100.], [100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.], (112,), float32))", "space_act": "Discrete(5)", "num_agents": 4, "episode_limit": 500, "policy_mapping_info": {"all_scenario": {"description": "rware all scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2", "agent_3"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "rware_customized_map", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 10, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.policy_template.MAA2CTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x7f7c1afbcdc0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "grad_clip": 40.0, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "microbatch_size": null}, "time_since_restore": 450.12196946144104, "timesteps_since_restore": 0, "iterations_since_restore": 43, "perf": {"cpu_util_percent": 4.126666666666666, "ram_util_percent": 50.11999999999999}}
{"episode_reward_max": 6.0, "episode_reward_min": 0.0, "episode_reward_mean": 1.81, "episode_len_mean": 500.0, "episode_media": {}, "episodes_this_iter": 20, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 2.0, 0.0, 5.0, 0.0, 0.0, 3.0, 2.0, 2.0, 0.0, 1.0, 2.0, 0.0, 1.0, 2.0, 1.0, 1.0, 3.0, 5.0, 1.0, 1.0, 4.0, 1.0, 1.0, 1.0, 1.0, 1.0, 2.0, 1.0, 3.0, 2.0, 5.0, 2.0, 3.0, 1.0, 3.0, 1.0, 3.0, 3.0, 1.0, 4.0, 2.0, 2.0, 1.0, 1.0, 5.0, 1.0, 2.0, 2.0, 0.0, 3.0, 1.0, 2.0, 0.0, 3.0, 2.0, 2.0, 3.0, 3.0, 4.0, 1.0, 1.0, 1.0, 1.0, 2.0, 2.0, 0.0, 3.0, 1.0, 2.0, 1.0, 0.0, 3.0, 4.0, 0.0, 2.0, 1.0, 0.0, 1.0, 1.0, 0.0, 4.0, 4.0, 2.0, 0.0, 2.0, 1.0, 2.0, 5.0, 1.0, 1.0, 2.0, 1.0, 4.0, 6.0, 1.0, 0.0, 4.0, 0.0, 0.0], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.14694190780421823, "mean_inference_ms": 0.38899549403171507, "mean_action_processing_ms": 0.028606099208146253, "mean_env_wait_ms": 0.3945745342399789, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 1766400, "timesteps_this_iter": 0, "agent_timesteps_total": 1766400, "timers": {"sample_time_ms": 1324.514, "sample_throughput": 3865.57, "load_time_ms": 0.134, "load_throughput": 38191066.121, "learn_time_ms": 66.927, "learn_throughput": 76501.013, "update_time_ms": 2.767}, "info": {"learner": {"default_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 76.75228118896484, "policy_entropy": 7971.623046875, "policy_loss": 16.890071868896484, "vf_loss": 31.39517593383789}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 1766400, "num_agent_steps_sampled": 1766400, "num_steps_trained": 1766400, "num_agent_steps_trained": 1766400, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 880, "training_iteration": 44, "trial_id": "65be9_00000", "experiment_id": "b9e963105bdc4382843b68ace23a11d3", "date": "2024-06-17_16-16-10", "timestamp": 1718608570, "time_this_iter_s": 10.518865823745728, "time_total_s": 460.64083528518677, "pid": 4998, "hostname": "DESKTOP-LQ219J4", "node_ip": "192.168.46.185", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 20, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 5000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 500, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "rware", "env_args": {"n_agents": 4, "column_height": 1, "max_inactivity_steps": null, "max_steps": 500, "fast_obs": true, "msg_bits": 0, "sensor_range": 1, "shelf_rows": 1, "shelf_columns": 3, "request_queue_size": 4, "reward_type": "RewardType.INDIVIDUAL", "map_name": "customized_map", "map_size": "tiny", "difficulty": "medium"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": true, "force_coop": false, "local_mode": true, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 4, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 100, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64}, "algorithm": "maa2c", "space_obs": "Dict(obs:Box([-100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100.], [100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.], (112,), float32))", "space_act": "Discrete(5)", "num_agents": 4, "episode_limit": 500, "policy_mapping_info": {"all_scenario": {"description": "rware all scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2", "agent_3"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "rware_customized_map", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 10, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.policy_template.MAA2CTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x7f7c1aff2160>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "grad_clip": 40.0, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "microbatch_size": null}, "time_since_restore": 460.64083528518677, "timesteps_since_restore": 0, "iterations_since_restore": 44, "perf": {"cpu_util_percent": 4.233333333333333, "ram_util_percent": 50.78666666666667}}
{"episode_reward_max": 6.0, "episode_reward_min": 0.0, "episode_reward_mean": 1.9, "episode_len_mean": 500.0, "episode_media": {}, "episodes_this_iter": 20, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [1.0, 4.0, 1.0, 1.0, 1.0, 1.0, 1.0, 2.0, 1.0, 3.0, 2.0, 5.0, 2.0, 3.0, 1.0, 3.0, 1.0, 3.0, 3.0, 1.0, 4.0, 2.0, 2.0, 1.0, 1.0, 5.0, 1.0, 2.0, 2.0, 0.0, 3.0, 1.0, 2.0, 0.0, 3.0, 2.0, 2.0, 3.0, 3.0, 4.0, 1.0, 1.0, 1.0, 1.0, 2.0, 2.0, 0.0, 3.0, 1.0, 2.0, 1.0, 0.0, 3.0, 4.0, 0.0, 2.0, 1.0, 0.0, 1.0, 1.0, 0.0, 4.0, 4.0, 2.0, 0.0, 2.0, 1.0, 2.0, 5.0, 1.0, 1.0, 2.0, 1.0, 4.0, 6.0, 1.0, 0.0, 4.0, 0.0, 0.0, 4.0, 0.0, 5.0, 2.0, 0.0, 1.0, 0.0, 2.0, 2.0, 2.0, 0.0, 4.0, 3.0, 3.0, 5.0, 2.0, 1.0, 1.0, 2.0, 1.0], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.14692370085065506, "mean_inference_ms": 0.38891450678965145, "mean_action_processing_ms": 0.028599115545037853, "mean_env_wait_ms": 0.3944793003655741, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 1807360, "timesteps_this_iter": 0, "agent_timesteps_total": 1807360, "timers": {"sample_time_ms": 1333.559, "sample_throughput": 3839.35, "load_time_ms": 0.143, "load_throughput": 35881096.876, "learn_time_ms": 66.385, "learn_throughput": 77126.292, "update_time_ms": 2.823}, "info": {"learner": {"default_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 46.58979034423828, "policy_entropy": 7964.18359375, "policy_loss": 0.5029309988021851, "vf_loss": 19.646728515625}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 1807360, "num_agent_steps_sampled": 1807360, "num_steps_trained": 1807360, "num_agent_steps_trained": 1807360, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 900, "training_iteration": 45, "trial_id": "65be9_00000", "experiment_id": "b9e963105bdc4382843b68ace23a11d3", "date": "2024-06-17_16-16-21", "timestamp": 1718608581, "time_this_iter_s": 10.680446863174438, "time_total_s": 471.3212821483612, "pid": 4998, "hostname": "DESKTOP-LQ219J4", "node_ip": "192.168.46.185", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 20, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 5000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 500, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "rware", "env_args": {"n_agents": 4, "column_height": 1, "max_inactivity_steps": null, "max_steps": 500, "fast_obs": true, "msg_bits": 0, "sensor_range": 1, "shelf_rows": 1, "shelf_columns": 3, "request_queue_size": 4, "reward_type": "RewardType.INDIVIDUAL", "map_name": "customized_map", "map_size": "tiny", "difficulty": "medium"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": true, "force_coop": false, "local_mode": true, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 4, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 100, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64}, "algorithm": "maa2c", "space_obs": "Dict(obs:Box([-100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100.], [100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.], (112,), float32))", "space_act": "Discrete(5)", "num_agents": 4, "episode_limit": 500, "policy_mapping_info": {"all_scenario": {"description": "rware all scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2", "agent_3"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "rware_customized_map", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 10, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.policy_template.MAA2CTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x7f7c1afbcaf0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "grad_clip": 40.0, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "microbatch_size": null}, "time_since_restore": 471.3212821483612, "timesteps_since_restore": 0, "iterations_since_restore": 45, "perf": {"cpu_util_percent": 4.58, "ram_util_percent": 51.44666666666668}}
{"episode_reward_max": 7.0, "episode_reward_min": 0.0, "episode_reward_mean": 1.97, "episode_len_mean": 500.0, "episode_media": {}, "episodes_this_iter": 24, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [1.0, 5.0, 1.0, 2.0, 2.0, 0.0, 3.0, 1.0, 2.0, 0.0, 3.0, 2.0, 2.0, 3.0, 3.0, 4.0, 1.0, 1.0, 1.0, 1.0, 2.0, 2.0, 0.0, 3.0, 1.0, 2.0, 1.0, 0.0, 3.0, 4.0, 0.0, 2.0, 1.0, 0.0, 1.0, 1.0, 0.0, 4.0, 4.0, 2.0, 0.0, 2.0, 1.0, 2.0, 5.0, 1.0, 1.0, 2.0, 1.0, 4.0, 6.0, 1.0, 0.0, 4.0, 0.0, 0.0, 4.0, 0.0, 5.0, 2.0, 0.0, 1.0, 0.0, 2.0, 2.0, 2.0, 0.0, 4.0, 3.0, 3.0, 5.0, 2.0, 1.0, 1.0, 2.0, 1.0, 1.0, 3.0, 4.0, 2.0, 1.0, 0.0, 2.0, 1.0, 1.0, 2.0, 1.0, 2.0, 1.0, 4.0, 2.0, 3.0, 3.0, 7.0, 3.0, 1.0, 0.0, 1.0, 6.0, 5.0], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.1469105135591496, "mean_inference_ms": 0.3888338086624319, "mean_action_processing_ms": 0.028592159218607815, "mean_env_wait_ms": 0.39432988084251663, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 1848320, "timesteps_this_iter": 0, "agent_timesteps_total": 1848320, "timers": {"sample_time_ms": 1346.827, "sample_throughput": 3801.529, "load_time_ms": 0.148, "load_throughput": 34525460.579, "learn_time_ms": 68.344, "learn_throughput": 74914.851, "update_time_ms": 2.901}, "info": {"learner": {"default_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 241.79278564453125, "policy_entropy": 7869.0654296875, "policy_loss": 85.97698974609375, "vf_loss": 100.91719055175781}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 1848320, "num_agent_steps_sampled": 1848320, "num_steps_trained": 1848320, "num_agent_steps_trained": 1848320, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 924, "training_iteration": 46, "trial_id": "65be9_00000", "experiment_id": "b9e963105bdc4382843b68ace23a11d3", "date": "2024-06-17_16-16-32", "timestamp": 1718608592, "time_this_iter_s": 10.818314552307129, "time_total_s": 482.13959670066833, "pid": 4998, "hostname": "DESKTOP-LQ219J4", "node_ip": "192.168.46.185", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 20, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 5000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 500, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "rware", "env_args": {"n_agents": 4, "column_height": 1, "max_inactivity_steps": null, "max_steps": 500, "fast_obs": true, "msg_bits": 0, "sensor_range": 1, "shelf_rows": 1, "shelf_columns": 3, "request_queue_size": 4, "reward_type": "RewardType.INDIVIDUAL", "map_name": "customized_map", "map_size": "tiny", "difficulty": "medium"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": true, "force_coop": false, "local_mode": true, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 4, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 100, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64}, "algorithm": "maa2c", "space_obs": "Dict(obs:Box([-100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100.], [100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.], (112,), float32))", "space_act": "Discrete(5)", "num_agents": 4, "episode_limit": 500, "policy_mapping_info": {"all_scenario": {"description": "rware all scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2", "agent_3"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "rware_customized_map", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 10, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.policy_template.MAA2CTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x7f7c1d450c10>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "grad_clip": 40.0, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "microbatch_size": null}, "time_since_restore": 482.13959670066833, "timesteps_since_restore": 0, "iterations_since_restore": 46, "perf": {"cpu_util_percent": 4.493333333333334, "ram_util_percent": 52.099999999999994}}
{"episode_reward_max": 7.0, "episode_reward_min": 0.0, "episode_reward_mean": 2.02, "episode_len_mean": 500.0, "episode_media": {}, "episodes_this_iter": 20, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [2.0, 2.0, 0.0, 3.0, 1.0, 2.0, 1.0, 0.0, 3.0, 4.0, 0.0, 2.0, 1.0, 0.0, 1.0, 1.0, 0.0, 4.0, 4.0, 2.0, 0.0, 2.0, 1.0, 2.0, 5.0, 1.0, 1.0, 2.0, 1.0, 4.0, 6.0, 1.0, 0.0, 4.0, 0.0, 0.0, 4.0, 0.0, 5.0, 2.0, 0.0, 1.0, 0.0, 2.0, 2.0, 2.0, 0.0, 4.0, 3.0, 3.0, 5.0, 2.0, 1.0, 1.0, 2.0, 1.0, 1.0, 3.0, 4.0, 2.0, 1.0, 0.0, 2.0, 1.0, 1.0, 2.0, 1.0, 2.0, 1.0, 4.0, 2.0, 3.0, 3.0, 7.0, 3.0, 1.0, 0.0, 1.0, 6.0, 5.0, 1.0, 3.0, 3.0, 1.0, 3.0, 0.0, 1.0, 6.0, 2.0, 0.0, 4.0, 4.0, 1.0, 3.0, 3.0, 3.0, 1.0, 1.0, 1.0, 2.0], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.14691683241608638, "mean_inference_ms": 0.38879819335767907, "mean_action_processing_ms": 0.02858763058581193, "mean_env_wait_ms": 0.39426861834058796, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 1889280, "timesteps_this_iter": 0, "agent_timesteps_total": 1889280, "timers": {"sample_time_ms": 1326.47, "sample_throughput": 3859.868, "load_time_ms": 0.142, "load_throughput": 36080034.409, "learn_time_ms": 65.958, "learn_throughput": 77625.156, "update_time_ms": 2.814}, "info": {"learner": {"default_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 136.05413818359375, "policy_entropy": 7869.02197265625, "policy_loss": -97.45773315429688, "vf_loss": 22.23553466796875}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 1889280, "num_agent_steps_sampled": 1889280, "num_steps_trained": 1889280, "num_agent_steps_trained": 1889280, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 944, "training_iteration": 47, "trial_id": "65be9_00000", "experiment_id": "b9e963105bdc4382843b68ace23a11d3", "date": "2024-06-17_16-16-42", "timestamp": 1718608602, "time_this_iter_s": 10.550709247589111, "time_total_s": 492.69030594825745, "pid": 4998, "hostname": "DESKTOP-LQ219J4", "node_ip": "192.168.46.185", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 20, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 5000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 500, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "rware", "env_args": {"n_agents": 4, "column_height": 1, "max_inactivity_steps": null, "max_steps": 500, "fast_obs": true, "msg_bits": 0, "sensor_range": 1, "shelf_rows": 1, "shelf_columns": 3, "request_queue_size": 4, "reward_type": "RewardType.INDIVIDUAL", "map_name": "customized_map", "map_size": "tiny", "difficulty": "medium"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": true, "force_coop": false, "local_mode": true, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 4, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 100, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64}, "algorithm": "maa2c", "space_obs": "Dict(obs:Box([-100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100.], [100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.], (112,), float32))", "space_act": "Discrete(5)", "num_agents": 4, "episode_limit": 500, "policy_mapping_info": {"all_scenario": {"description": "rware all scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2", "agent_3"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "rware_customized_map", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 10, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.policy_template.MAA2CTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x7f7c1aff2ca0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "grad_clip": 40.0, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "microbatch_size": null}, "time_since_restore": 492.69030594825745, "timesteps_since_restore": 0, "iterations_since_restore": 47, "perf": {"cpu_util_percent": 4.373333333333334, "ram_util_percent": 52.71333333333333}}
{"episode_reward_max": 7.0, "episode_reward_min": 0.0, "episode_reward_mean": 1.99, "episode_len_mean": 500.0, "episode_media": {}, "episodes_this_iter": 20, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 2.0, 1.0, 2.0, 5.0, 1.0, 1.0, 2.0, 1.0, 4.0, 6.0, 1.0, 0.0, 4.0, 0.0, 0.0, 4.0, 0.0, 5.0, 2.0, 0.0, 1.0, 0.0, 2.0, 2.0, 2.0, 0.0, 4.0, 3.0, 3.0, 5.0, 2.0, 1.0, 1.0, 2.0, 1.0, 1.0, 3.0, 4.0, 2.0, 1.0, 0.0, 2.0, 1.0, 1.0, 2.0, 1.0, 2.0, 1.0, 4.0, 2.0, 3.0, 3.0, 7.0, 3.0, 1.0, 0.0, 1.0, 6.0, 5.0, 1.0, 3.0, 3.0, 1.0, 3.0, 0.0, 1.0, 6.0, 2.0, 0.0, 4.0, 4.0, 1.0, 3.0, 3.0, 3.0, 1.0, 1.0, 1.0, 2.0, 2.0, 1.0, 3.0, 0.0, 1.0, 2.0, 2.0, 2.0, 2.0, 1.0, 0.0, 0.0, 2.0, 0.0, 3.0, 0.0, 2.0, 3.0, 4.0, 0.0], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.14692474062860217, "mean_inference_ms": 0.38875301523637645, "mean_action_processing_ms": 0.02858310730714581, "mean_env_wait_ms": 0.3942052057625821, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 1930240, "timesteps_this_iter": 0, "agent_timesteps_total": 1930240, "timers": {"sample_time_ms": 1323.007, "sample_throughput": 3869.973, "load_time_ms": 0.137, "load_throughput": 37490985.475, "learn_time_ms": 65.784, "learn_throughput": 77830.559, "update_time_ms": 2.855}, "info": {"learner": {"default_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 50.16674041748047, "policy_entropy": 7954.341796875, "policy_loss": -12.315788269042969, "vf_loss": 4.847312927246094}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 1930240, "num_agent_steps_sampled": 1930240, "num_steps_trained": 1930240, "num_agent_steps_trained": 1930240, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 964, "training_iteration": 48, "trial_id": "65be9_00000", "experiment_id": "b9e963105bdc4382843b68ace23a11d3", "date": "2024-06-17_16-16-53", "timestamp": 1718608613, "time_this_iter_s": 10.596033096313477, "time_total_s": 503.2863390445709, "pid": 4998, "hostname": "DESKTOP-LQ219J4", "node_ip": "192.168.46.185", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 20, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 5000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 500, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "rware", "env_args": {"n_agents": 4, "column_height": 1, "max_inactivity_steps": null, "max_steps": 500, "fast_obs": true, "msg_bits": 0, "sensor_range": 1, "shelf_rows": 1, "shelf_columns": 3, "request_queue_size": 4, "reward_type": "RewardType.INDIVIDUAL", "map_name": "customized_map", "map_size": "tiny", "difficulty": "medium"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": true, "force_coop": false, "local_mode": true, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 4, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 100, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64}, "algorithm": "maa2c", "space_obs": "Dict(obs:Box([-100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100.], [100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.], (112,), float32))", "space_act": "Discrete(5)", "num_agents": 4, "episode_limit": 500, "policy_mapping_info": {"all_scenario": {"description": "rware all scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2", "agent_3"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "rware_customized_map", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 10, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.policy_template.MAA2CTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x7f7c1cdf6820>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "grad_clip": 40.0, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "microbatch_size": null}, "time_since_restore": 503.2863390445709, "timesteps_since_restore": 0, "iterations_since_restore": 48, "perf": {"cpu_util_percent": 4.2124999999999995, "ram_util_percent": 53.40625}}
{"episode_reward_max": 7.0, "episode_reward_min": 0.0, "episode_reward_mean": 1.87, "episode_len_mean": 500.0, "episode_media": {}, "episodes_this_iter": 20, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 1.0, 0.0, 2.0, 2.0, 2.0, 0.0, 4.0, 3.0, 3.0, 5.0, 2.0, 1.0, 1.0, 2.0, 1.0, 1.0, 3.0, 4.0, 2.0, 1.0, 0.0, 2.0, 1.0, 1.0, 2.0, 1.0, 2.0, 1.0, 4.0, 2.0, 3.0, 3.0, 7.0, 3.0, 1.0, 0.0, 1.0, 6.0, 5.0, 1.0, 3.0, 3.0, 1.0, 3.0, 0.0, 1.0, 6.0, 2.0, 0.0, 4.0, 4.0, 1.0, 3.0, 3.0, 3.0, 1.0, 1.0, 1.0, 2.0, 2.0, 1.0, 3.0, 0.0, 1.0, 2.0, 2.0, 2.0, 2.0, 1.0, 0.0, 0.0, 2.0, 0.0, 3.0, 0.0, 2.0, 3.0, 4.0, 0.0, 1.0, 2.0, 0.0, 0.0, 3.0, 0.0, 1.0, 4.0, 1.0, 3.0, 0.0, 4.0, 1.0, 0.0, 2.0, 3.0, 0.0, 2.0, 1.0, 1.0], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.14693459473264892, "mean_inference_ms": 0.38871476268620336, "mean_action_processing_ms": 0.028579301299260087, "mean_env_wait_ms": 0.3941841446223656, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 1971200, "timesteps_this_iter": 0, "agent_timesteps_total": 1971200, "timers": {"sample_time_ms": 1325.731, "sample_throughput": 3862.02, "load_time_ms": 0.142, "load_throughput": 36116442.112, "learn_time_ms": 65.923, "learn_throughput": 77666.032, "update_time_ms": 2.846}, "info": {"learner": {"default_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 108.84786987304688, "policy_entropy": 7958.70849609375, "policy_loss": 54.653053283691406, "vf_loss": 38.44466018676758}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 1971200, "num_agent_steps_sampled": 1971200, "num_steps_trained": 1971200, "num_agent_steps_trained": 1971200, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 984, "training_iteration": 49, "trial_id": "65be9_00000", "experiment_id": "b9e963105bdc4382843b68ace23a11d3", "date": "2024-06-17_16-17-03", "timestamp": 1718608623, "time_this_iter_s": 10.63561725616455, "time_total_s": 513.9219563007355, "pid": 4998, "hostname": "DESKTOP-LQ219J4", "node_ip": "192.168.46.185", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 20, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 5000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 500, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "rware", "env_args": {"n_agents": 4, "column_height": 1, "max_inactivity_steps": null, "max_steps": 500, "fast_obs": true, "msg_bits": 0, "sensor_range": 1, "shelf_rows": 1, "shelf_columns": 3, "request_queue_size": 4, "reward_type": "RewardType.INDIVIDUAL", "map_name": "customized_map", "map_size": "tiny", "difficulty": "medium"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": true, "force_coop": false, "local_mode": true, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 4, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 100, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64}, "algorithm": "maa2c", "space_obs": "Dict(obs:Box([-100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100.], [100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.], (112,), float32))", "space_act": "Discrete(5)", "num_agents": 4, "episode_limit": 500, "policy_mapping_info": {"all_scenario": {"description": "rware all scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2", "agent_3"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "rware_customized_map", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 10, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.policy_template.MAA2CTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x7f7c1aff25e0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "grad_clip": 40.0, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "microbatch_size": null}, "time_since_restore": 513.9219563007355, "timesteps_since_restore": 0, "iterations_since_restore": 49, "perf": {"cpu_util_percent": 4.213333333333333, "ram_util_percent": 54.093333333333334}}
{"episode_reward_max": 7.0, "episode_reward_min": 0.0, "episode_reward_mean": 1.88, "episode_len_mean": 500.0, "episode_media": {}, "episodes_this_iter": 20, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [1.0, 0.0, 2.0, 1.0, 1.0, 2.0, 1.0, 2.0, 1.0, 4.0, 2.0, 3.0, 3.0, 7.0, 3.0, 1.0, 0.0, 1.0, 6.0, 5.0, 1.0, 3.0, 3.0, 1.0, 3.0, 0.0, 1.0, 6.0, 2.0, 0.0, 4.0, 4.0, 1.0, 3.0, 3.0, 3.0, 1.0, 1.0, 1.0, 2.0, 2.0, 1.0, 3.0, 0.0, 1.0, 2.0, 2.0, 2.0, 2.0, 1.0, 0.0, 0.0, 2.0, 0.0, 3.0, 0.0, 2.0, 3.0, 4.0, 0.0, 1.0, 2.0, 0.0, 0.0, 3.0, 0.0, 1.0, 4.0, 1.0, 3.0, 0.0, 4.0, 1.0, 0.0, 2.0, 3.0, 0.0, 2.0, 1.0, 1.0, 1.0, 4.0, 3.0, 3.0, 1.0, 4.0, 3.0, 1.0, 0.0, 5.0, 2.0, 1.0, 3.0, 1.0, 1.0, 4.0, 1.0, 1.0, 1.0, 0.0], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.14693392800327096, "mean_inference_ms": 0.3886570052218392, "mean_action_processing_ms": 0.028575572516977895, "mean_env_wait_ms": 0.39414277322663466, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 2012160, "timesteps_this_iter": 0, "agent_timesteps_total": 2012160, "timers": {"sample_time_ms": 1323.843, "sample_throughput": 3867.529, "load_time_ms": 0.143, "load_throughput": 35833199.533, "learn_time_ms": 65.722, "learn_throughput": 77904.223, "update_time_ms": 2.875}, "info": {"learner": {"default_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 54.589202880859375, "policy_entropy": 7978.6044921875, "policy_loss": -4.708169937133789, "vf_loss": 23.821596145629883}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 2012160, "num_agent_steps_sampled": 2012160, "num_steps_trained": 2012160, "num_agent_steps_trained": 2012160, "num_steps_trained_this_iter": 0}, "evaluation": {"episode_reward_max": 6.0, "episode_reward_min": 0.0, "episode_reward_mean": 2.2, "episode_len_mean": 500.0, "episode_media": {}, "episodes_this_iter": 10, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [1.0, 4.0, 2.0, 3.0, 1.0, 1.0, 6.0, 1.0, 3.0, 0.0], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.0897627119015894, "mean_inference_ms": 0.3948932503538355, "mean_action_processing_ms": 0.02745980383085981, "mean_env_wait_ms": 0.3742610566784349, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}}, "done": false, "episodes_total": 1004, "training_iteration": 50, "trial_id": "65be9_00000", "experiment_id": "b9e963105bdc4382843b68ace23a11d3", "date": "2024-06-17_16-17-18", "timestamp": 1718608638, "time_this_iter_s": 15.014108657836914, "time_total_s": 528.9360649585724, "pid": 4998, "hostname": "DESKTOP-LQ219J4", "node_ip": "192.168.46.185", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 20, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 5000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 500, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "rware", "env_args": {"n_agents": 4, "column_height": 1, "max_inactivity_steps": null, "max_steps": 500, "fast_obs": true, "msg_bits": 0, "sensor_range": 1, "shelf_rows": 1, "shelf_columns": 3, "request_queue_size": 4, "reward_type": "RewardType.INDIVIDUAL", "map_name": "customized_map", "map_size": "tiny", "difficulty": "medium"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": true, "force_coop": false, "local_mode": true, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 4, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 100, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64}, "algorithm": "maa2c", "space_obs": "Dict(obs:Box([-100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100.], [100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.], (112,), float32))", "space_act": "Discrete(5)", "num_agents": 4, "episode_limit": 500, "policy_mapping_info": {"all_scenario": {"description": "rware all scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2", "agent_3"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "rware_customized_map", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 10, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.policy_template.MAA2CTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x7f7c1cdf6820>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "grad_clip": 40.0, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "microbatch_size": null}, "time_since_restore": 528.9360649585724, "timesteps_since_restore": 0, "iterations_since_restore": 50, "perf": {"cpu_util_percent": 4.147619047619049, "ram_util_percent": 54.82857142857142}}
{"episode_reward_max": 7.0, "episode_reward_min": 0.0, "episode_reward_mean": 1.89, "episode_len_mean": 500.0, "episode_media": {}, "episodes_this_iter": 12, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [3.0, 7.0, 3.0, 1.0, 0.0, 1.0, 6.0, 5.0, 1.0, 3.0, 3.0, 1.0, 3.0, 0.0, 1.0, 6.0, 2.0, 0.0, 4.0, 4.0, 1.0, 3.0, 3.0, 3.0, 1.0, 1.0, 1.0, 2.0, 2.0, 1.0, 3.0, 0.0, 1.0, 2.0, 2.0, 2.0, 2.0, 1.0, 0.0, 0.0, 2.0, 0.0, 3.0, 0.0, 2.0, 3.0, 4.0, 0.0, 1.0, 2.0, 0.0, 0.0, 3.0, 0.0, 1.0, 4.0, 1.0, 3.0, 0.0, 4.0, 1.0, 0.0, 2.0, 3.0, 0.0, 2.0, 1.0, 1.0, 1.0, 4.0, 3.0, 3.0, 1.0, 4.0, 3.0, 1.0, 0.0, 5.0, 2.0, 1.0, 3.0, 1.0, 1.0, 4.0, 1.0, 1.0, 1.0, 0.0, 4.0, 1.0, 2.0, 2.0, 1.0, 1.0, 1.0, 2.0, 4.0, 1.0, 2.0, 0.0], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.1469309332204727, "mean_inference_ms": 0.3886105110673762, "mean_action_processing_ms": 0.028572738084337034, "mean_env_wait_ms": 0.39422878134789036, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 2037760, "timesteps_this_iter": 0, "agent_timesteps_total": 2037760, "timers": {"sample_time_ms": 1762.609, "sample_throughput": 2904.785, "load_time_ms": 0.152, "load_throughput": 33596427.534, "learn_time_ms": 66.214, "learn_throughput": 77324.66, "update_time_ms": 2.802}, "info": {"learner": {"default_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 83.94670867919922, "policy_entropy": 7944.99169921875, "policy_loss": 38.586463928222656, "vf_loss": 26.80137825012207}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 2037760, "num_agent_steps_sampled": 2037760, "num_steps_trained": 2037760, "num_agent_steps_trained": 2037760, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 1016, "training_iteration": 51, "trial_id": "65be9_00000", "experiment_id": "b9e963105bdc4382843b68ace23a11d3", "date": "2024-06-17_16-17-25", "timestamp": 1718608645, "time_this_iter_s": 6.512174606323242, "time_total_s": 535.4482395648956, "pid": 4998, "hostname": "DESKTOP-LQ219J4", "node_ip": "192.168.46.185", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 20, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 5000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 500, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "rware", "env_args": {"n_agents": 4, "column_height": 1, "max_inactivity_steps": null, "max_steps": 500, "fast_obs": true, "msg_bits": 0, "sensor_range": 1, "shelf_rows": 1, "shelf_columns": 3, "request_queue_size": 4, "reward_type": "RewardType.INDIVIDUAL", "map_name": "customized_map", "map_size": "tiny", "difficulty": "medium"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": true, "force_coop": false, "local_mode": true, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 4, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 100, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64}, "algorithm": "maa2c", "space_obs": "Dict(obs:Box([-100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100.], [100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.], (112,), float32))", "space_act": "Discrete(5)", "num_agents": 4, "episode_limit": 500, "policy_mapping_info": {"all_scenario": {"description": "rware all scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2", "agent_3"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "rware_customized_map", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 10, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.policy_template.MAA2CTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x7f7c1aff2e50>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "grad_clip": 40.0, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "microbatch_size": null}, "time_since_restore": 535.4482395648956, "timesteps_since_restore": 0, "iterations_since_restore": 51, "perf": {"cpu_util_percent": 3.9888888888888894, "ram_util_percent": 55.27777777777778}}
{"episode_reward_max": 6.0, "episode_reward_min": 0.0, "episode_reward_mean": 1.87, "episode_len_mean": 500.0, "episode_media": {}, "episodes_this_iter": 20, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [1.0, 3.0, 3.0, 3.0, 1.0, 1.0, 1.0, 2.0, 2.0, 1.0, 3.0, 0.0, 1.0, 2.0, 2.0, 2.0, 2.0, 1.0, 0.0, 0.0, 2.0, 0.0, 3.0, 0.0, 2.0, 3.0, 4.0, 0.0, 1.0, 2.0, 0.0, 0.0, 3.0, 0.0, 1.0, 4.0, 1.0, 3.0, 0.0, 4.0, 1.0, 0.0, 2.0, 3.0, 0.0, 2.0, 1.0, 1.0, 1.0, 4.0, 3.0, 3.0, 1.0, 4.0, 3.0, 1.0, 0.0, 5.0, 2.0, 1.0, 3.0, 1.0, 1.0, 4.0, 1.0, 1.0, 1.0, 0.0, 4.0, 1.0, 2.0, 2.0, 1.0, 1.0, 1.0, 2.0, 4.0, 1.0, 2.0, 0.0, 6.0, 1.0, 2.0, 1.0, 0.0, 3.0, 6.0, 2.0, 4.0, 4.0, 0.0, 4.0, 3.0, 1.0, 2.0, 2.0, 1.0, 4.0, 1.0, 5.0], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.1469125336475946, "mean_inference_ms": 0.38852014517433103, "mean_action_processing_ms": 0.02856699795339054, "mean_env_wait_ms": 0.39410559805687906, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 2078720, "timesteps_this_iter": 0, "agent_timesteps_total": 2078720, "timers": {"sample_time_ms": 1320.819, "sample_throughput": 3876.384, "load_time_ms": 0.14, "load_throughput": 36627727.239, "learn_time_ms": 66.265, "learn_throughput": 77265.012, "update_time_ms": 2.857}, "info": {"learner": {"default_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 80.96839904785156, "policy_entropy": 7890.61865234375, "policy_loss": -48.426658630371094, "vf_loss": 14.960744857788086}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 2078720, "num_agent_steps_sampled": 2078720, "num_steps_trained": 2078720, "num_agent_steps_trained": 2078720, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 1036, "training_iteration": 52, "trial_id": "65be9_00000", "experiment_id": "b9e963105bdc4382843b68ace23a11d3", "date": "2024-06-17_16-17-35", "timestamp": 1718608655, "time_this_iter_s": 10.592848300933838, "time_total_s": 546.0410878658295, "pid": 4998, "hostname": "DESKTOP-LQ219J4", "node_ip": "192.168.46.185", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 20, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 5000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 500, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "rware", "env_args": {"n_agents": 4, "column_height": 1, "max_inactivity_steps": null, "max_steps": 500, "fast_obs": true, "msg_bits": 0, "sensor_range": 1, "shelf_rows": 1, "shelf_columns": 3, "request_queue_size": 4, "reward_type": "RewardType.INDIVIDUAL", "map_name": "customized_map", "map_size": "tiny", "difficulty": "medium"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": true, "force_coop": false, "local_mode": true, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 4, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 100, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64}, "algorithm": "maa2c", "space_obs": "Dict(obs:Box([-100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100.], [100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.], (112,), float32))", "space_act": "Discrete(5)", "num_agents": 4, "episode_limit": 500, "policy_mapping_info": {"all_scenario": {"description": "rware all scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2", "agent_3"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "rware_customized_map", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 10, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.policy_template.MAA2CTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x7f7c1d4500d0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "grad_clip": 40.0, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "microbatch_size": null}, "time_since_restore": 546.0410878658295, "timesteps_since_restore": 0, "iterations_since_restore": 52, "perf": {"cpu_util_percent": 4.15625, "ram_util_percent": 55.8625}}
{"episode_reward_max": 6.0, "episode_reward_min": 0.0, "episode_reward_mean": 1.92, "episode_len_mean": 500.0, "episode_media": {}, "episodes_this_iter": 20, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [2.0, 0.0, 3.0, 0.0, 2.0, 3.0, 4.0, 0.0, 1.0, 2.0, 0.0, 0.0, 3.0, 0.0, 1.0, 4.0, 1.0, 3.0, 0.0, 4.0, 1.0, 0.0, 2.0, 3.0, 0.0, 2.0, 1.0, 1.0, 1.0, 4.0, 3.0, 3.0, 1.0, 4.0, 3.0, 1.0, 0.0, 5.0, 2.0, 1.0, 3.0, 1.0, 1.0, 4.0, 1.0, 1.0, 1.0, 0.0, 4.0, 1.0, 2.0, 2.0, 1.0, 1.0, 1.0, 2.0, 4.0, 1.0, 2.0, 0.0, 6.0, 1.0, 2.0, 1.0, 0.0, 3.0, 6.0, 2.0, 4.0, 4.0, 0.0, 4.0, 3.0, 1.0, 2.0, 2.0, 1.0, 4.0, 1.0, 5.0, 3.0, 1.0, 2.0, 2.0, 1.0, 2.0, 2.0, 5.0, 3.0, 0.0, 1.0, 4.0, 2.0, 2.0, 3.0, 0.0, 1.0, 0.0, 1.0, 1.0], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.14689232277209366, "mean_inference_ms": 0.3884241536716431, "mean_action_processing_ms": 0.028561180608567244, "mean_env_wait_ms": 0.3940047332848506, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 2119680, "timesteps_this_iter": 0, "agent_timesteps_total": 2119680, "timers": {"sample_time_ms": 1320.856, "sample_throughput": 3876.275, "load_time_ms": 0.139, "load_throughput": 36715398.324, "learn_time_ms": 66.215, "learn_throughput": 77323.713, "update_time_ms": 2.778}, "info": {"learner": {"default_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 90.95350646972656, "policy_entropy": 7982.4404296875, "policy_loss": 47.94780349731445, "vf_loss": 19.45842742919922}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 2119680, "num_agent_steps_sampled": 2119680, "num_steps_trained": 2119680, "num_agent_steps_trained": 2119680, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 1056, "training_iteration": 53, "trial_id": "65be9_00000", "experiment_id": "b9e963105bdc4382843b68ace23a11d3", "date": "2024-06-17_16-17-46", "timestamp": 1718608666, "time_this_iter_s": 10.569918870925903, "time_total_s": 556.6110067367554, "pid": 4998, "hostname": "DESKTOP-LQ219J4", "node_ip": "192.168.46.185", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 20, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 5000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 500, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "rware", "env_args": {"n_agents": 4, "column_height": 1, "max_inactivity_steps": null, "max_steps": 500, "fast_obs": true, "msg_bits": 0, "sensor_range": 1, "shelf_rows": 1, "shelf_columns": 3, "request_queue_size": 4, "reward_type": "RewardType.INDIVIDUAL", "map_name": "customized_map", "map_size": "tiny", "difficulty": "medium"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": true, "force_coop": false, "local_mode": true, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 4, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 100, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64}, "algorithm": "maa2c", "space_obs": "Dict(obs:Box([-100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100.], [100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.], (112,), float32))", "space_act": "Discrete(5)", "num_agents": 4, "episode_limit": 500, "policy_mapping_info": {"all_scenario": {"description": "rware all scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2", "agent_3"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "rware_customized_map", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 10, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.policy_template.MAA2CTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x7f7c1aff2b80>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "grad_clip": 40.0, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "microbatch_size": null}, "time_since_restore": 556.6110067367554, "timesteps_since_restore": 0, "iterations_since_restore": 53, "perf": {"cpu_util_percent": 4.373333333333333, "ram_util_percent": 56.53333333333334}}
{"episode_reward_max": 6.0, "episode_reward_min": 0.0, "episode_reward_mean": 2.0, "episode_len_mean": 500.0, "episode_media": {}, "episodes_this_iter": 24, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 2.0, 1.0, 1.0, 1.0, 4.0, 3.0, 3.0, 1.0, 4.0, 3.0, 1.0, 0.0, 5.0, 2.0, 1.0, 3.0, 1.0, 1.0, 4.0, 1.0, 1.0, 1.0, 0.0, 4.0, 1.0, 2.0, 2.0, 1.0, 1.0, 1.0, 2.0, 4.0, 1.0, 2.0, 0.0, 6.0, 1.0, 2.0, 1.0, 0.0, 3.0, 6.0, 2.0, 4.0, 4.0, 0.0, 4.0, 3.0, 1.0, 2.0, 2.0, 1.0, 4.0, 1.0, 5.0, 3.0, 1.0, 2.0, 2.0, 1.0, 2.0, 2.0, 5.0, 3.0, 0.0, 1.0, 4.0, 2.0, 2.0, 3.0, 0.0, 1.0, 0.0, 1.0, 1.0, 2.0, 2.0, 2.0, 2.0, 0.0, 2.0, 3.0, 3.0, 2.0, 1.0, 3.0, 3.0, 3.0, 2.0, 2.0, 2.0, 2.0, 2.0, 1.0, 2.0, 1.0, 3.0, 2.0, 0.0], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.14686828083084225, "mean_inference_ms": 0.3883005168841426, "mean_action_processing_ms": 0.028553937375121824, "mean_env_wait_ms": 0.39387044166695373, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 2160640, "timesteps_this_iter": 0, "agent_timesteps_total": 2160640, "timers": {"sample_time_ms": 1313.979, "sample_throughput": 3896.563, "load_time_ms": 0.149, "load_throughput": 34431355.588, "learn_time_ms": 66.484, "learn_throughput": 77010.929, "update_time_ms": 2.88}, "info": {"learner": {"default_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 106.99837493896484, "policy_entropy": 7982.78271484375, "policy_loss": -58.663047790527344, "vf_loss": 12.622186660766602}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 2160640, "num_agent_steps_sampled": 2160640, "num_steps_trained": 2160640, "num_agent_steps_trained": 2160640, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 1080, "training_iteration": 54, "trial_id": "65be9_00000", "experiment_id": "b9e963105bdc4382843b68ace23a11d3", "date": "2024-06-17_16-17-56", "timestamp": 1718608676, "time_this_iter_s": 10.404295444488525, "time_total_s": 567.0153021812439, "pid": 4998, "hostname": "DESKTOP-LQ219J4", "node_ip": "192.168.46.185", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 20, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 5000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 500, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "rware", "env_args": {"n_agents": 4, "column_height": 1, "max_inactivity_steps": null, "max_steps": 500, "fast_obs": true, "msg_bits": 0, "sensor_range": 1, "shelf_rows": 1, "shelf_columns": 3, "request_queue_size": 4, "reward_type": "RewardType.INDIVIDUAL", "map_name": "customized_map", "map_size": "tiny", "difficulty": "medium"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": true, "force_coop": false, "local_mode": true, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 4, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 100, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64}, "algorithm": "maa2c", "space_obs": "Dict(obs:Box([-100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100.], [100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.], (112,), float32))", "space_act": "Discrete(5)", "num_agents": 4, "episode_limit": 500, "policy_mapping_info": {"all_scenario": {"description": "rware all scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2", "agent_3"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "rware_customized_map", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 10, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.policy_template.MAA2CTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x7f7c1afbcb80>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "grad_clip": 40.0, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "microbatch_size": null}, "time_since_restore": 567.0153021812439, "timesteps_since_restore": 0, "iterations_since_restore": 54, "perf": {"cpu_util_percent": 4.180000000000001, "ram_util_percent": 57.173333333333325}}
{"episode_reward_max": 6.0, "episode_reward_min": 0.0, "episode_reward_mean": 1.96, "episode_len_mean": 500.0, "episode_media": {}, "episodes_this_iter": 20, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [1.0, 1.0, 1.0, 0.0, 4.0, 1.0, 2.0, 2.0, 1.0, 1.0, 1.0, 2.0, 4.0, 1.0, 2.0, 0.0, 6.0, 1.0, 2.0, 1.0, 0.0, 3.0, 6.0, 2.0, 4.0, 4.0, 0.0, 4.0, 3.0, 1.0, 2.0, 2.0, 1.0, 4.0, 1.0, 5.0, 3.0, 1.0, 2.0, 2.0, 1.0, 2.0, 2.0, 5.0, 3.0, 0.0, 1.0, 4.0, 2.0, 2.0, 3.0, 0.0, 1.0, 0.0, 1.0, 1.0, 2.0, 2.0, 2.0, 2.0, 0.0, 2.0, 3.0, 3.0, 2.0, 1.0, 3.0, 3.0, 3.0, 2.0, 2.0, 2.0, 2.0, 2.0, 1.0, 2.0, 1.0, 3.0, 2.0, 0.0, 1.0, 2.0, 1.0, 1.0, 2.0, 4.0, 3.0, 1.0, 1.0, 4.0, 1.0, 2.0, 2.0, 2.0, 2.0, 2.0, 0.0, 1.0, 2.0, 3.0], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.14683933654093229, "mean_inference_ms": 0.3881891445269288, "mean_action_processing_ms": 0.028546558328836583, "mean_env_wait_ms": 0.393726810243797, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 2201600, "timesteps_this_iter": 0, "agent_timesteps_total": 2201600, "timers": {"sample_time_ms": 1314.408, "sample_throughput": 3895.289, "load_time_ms": 0.143, "load_throughput": 35917103.997, "learn_time_ms": 66.274, "learn_throughput": 77254.7, "update_time_ms": 2.867}, "info": {"learner": {"default_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 46.576072692871094, "policy_entropy": 7928.51611328125, "policy_loss": -17.975570678710938, "vf_loss": 23.303207397460938}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 2201600, "num_agent_steps_sampled": 2201600, "num_steps_trained": 2201600, "num_agent_steps_trained": 2201600, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 1100, "training_iteration": 55, "trial_id": "65be9_00000", "experiment_id": "b9e963105bdc4382843b68ace23a11d3", "date": "2024-06-17_16-18-07", "timestamp": 1718608687, "time_this_iter_s": 10.533907890319824, "time_total_s": 577.5492100715637, "pid": 4998, "hostname": "DESKTOP-LQ219J4", "node_ip": "192.168.46.185", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 20, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 5000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 500, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "rware", "env_args": {"n_agents": 4, "column_height": 1, "max_inactivity_steps": null, "max_steps": 500, "fast_obs": true, "msg_bits": 0, "sensor_range": 1, "shelf_rows": 1, "shelf_columns": 3, "request_queue_size": 4, "reward_type": "RewardType.INDIVIDUAL", "map_name": "customized_map", "map_size": "tiny", "difficulty": "medium"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": true, "force_coop": false, "local_mode": true, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 4, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 100, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64}, "algorithm": "maa2c", "space_obs": "Dict(obs:Box([-100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100.], [100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.], (112,), float32))", "space_act": "Discrete(5)", "num_agents": 4, "episode_limit": 500, "policy_mapping_info": {"all_scenario": {"description": "rware all scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2", "agent_3"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "rware_customized_map", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 10, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.policy_template.MAA2CTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x7f7c1afbc8b0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "grad_clip": 40.0, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "microbatch_size": null}, "time_since_restore": 577.5492100715637, "timesteps_since_restore": 0, "iterations_since_restore": 55, "perf": {"cpu_util_percent": 4.086666666666666, "ram_util_percent": 57.82666666666667}}
{"episode_reward_max": 6.0, "episode_reward_min": 0.0, "episode_reward_mean": 2.02, "episode_len_mean": 500.0, "episode_media": {}, "episodes_this_iter": 20, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 3.0, 6.0, 2.0, 4.0, 4.0, 0.0, 4.0, 3.0, 1.0, 2.0, 2.0, 1.0, 4.0, 1.0, 5.0, 3.0, 1.0, 2.0, 2.0, 1.0, 2.0, 2.0, 5.0, 3.0, 0.0, 1.0, 4.0, 2.0, 2.0, 3.0, 0.0, 1.0, 0.0, 1.0, 1.0, 2.0, 2.0, 2.0, 2.0, 0.0, 2.0, 3.0, 3.0, 2.0, 1.0, 3.0, 3.0, 3.0, 2.0, 2.0, 2.0, 2.0, 2.0, 1.0, 2.0, 1.0, 3.0, 2.0, 0.0, 1.0, 2.0, 1.0, 1.0, 2.0, 4.0, 3.0, 1.0, 1.0, 4.0, 1.0, 2.0, 2.0, 2.0, 2.0, 2.0, 0.0, 1.0, 2.0, 3.0, 2.0, 3.0, 1.0, 0.0, 3.0, 1.0, 2.0, 4.0, 1.0, 1.0, 5.0, 2.0, 0.0, 3.0, 0.0, 5.0, 2.0, 1.0, 2.0, 2.0], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.1467946836355447, "mean_inference_ms": 0.38805250045935785, "mean_action_processing_ms": 0.02853676707132859, "mean_env_wait_ms": 0.39351223569070426, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 2242560, "timesteps_this_iter": 0, "agent_timesteps_total": 2242560, "timers": {"sample_time_ms": 1311.357, "sample_throughput": 3904.353, "load_time_ms": 0.143, "load_throughput": 35905093.596, "learn_time_ms": 66.019, "learn_throughput": 77553.475, "update_time_ms": 2.808}, "info": {"learner": {"default_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 107.9261245727539, "policy_entropy": 7952.5947265625, "policy_loss": 10.429231643676758, "vf_loss": 36.35009002685547}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 2242560, "num_agent_steps_sampled": 2242560, "num_steps_trained": 2242560, "num_agent_steps_trained": 2242560, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 1120, "training_iteration": 56, "trial_id": "65be9_00000", "experiment_id": "b9e963105bdc4382843b68ace23a11d3", "date": "2024-06-17_16-18-18", "timestamp": 1718608698, "time_this_iter_s": 10.476116180419922, "time_total_s": 588.0253262519836, "pid": 4998, "hostname": "DESKTOP-LQ219J4", "node_ip": "192.168.46.185", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 20, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 5000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 500, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "rware", "env_args": {"n_agents": 4, "column_height": 1, "max_inactivity_steps": null, "max_steps": 500, "fast_obs": true, "msg_bits": 0, "sensor_range": 1, "shelf_rows": 1, "shelf_columns": 3, "request_queue_size": 4, "reward_type": "RewardType.INDIVIDUAL", "map_name": "customized_map", "map_size": "tiny", "difficulty": "medium"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": true, "force_coop": false, "local_mode": true, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 4, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 100, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64}, "algorithm": "maa2c", "space_obs": "Dict(obs:Box([-100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100.], [100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.], (112,), float32))", "space_act": "Discrete(5)", "num_agents": 4, "episode_limit": 500, "policy_mapping_info": {"all_scenario": {"description": "rware all scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2", "agent_3"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "rware_customized_map", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 10, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.policy_template.MAA2CTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x7f7c1afbcc10>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "grad_clip": 40.0, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "microbatch_size": null}, "time_since_restore": 588.0253262519836, "timesteps_since_restore": 0, "iterations_since_restore": 56, "perf": {"cpu_util_percent": 3.913333333333333, "ram_util_percent": 58.48666666666667}}
{"episode_reward_max": 5.0, "episode_reward_min": 0.0, "episode_reward_mean": 1.89, "episode_len_mean": 500.0, "episode_media": {}, "episodes_this_iter": 20, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [1.0, 2.0, 2.0, 5.0, 3.0, 0.0, 1.0, 4.0, 2.0, 2.0, 3.0, 0.0, 1.0, 0.0, 1.0, 1.0, 2.0, 2.0, 2.0, 2.0, 0.0, 2.0, 3.0, 3.0, 2.0, 1.0, 3.0, 3.0, 3.0, 2.0, 2.0, 2.0, 2.0, 2.0, 1.0, 2.0, 1.0, 3.0, 2.0, 0.0, 1.0, 2.0, 1.0, 1.0, 2.0, 4.0, 3.0, 1.0, 1.0, 4.0, 1.0, 2.0, 2.0, 2.0, 2.0, 2.0, 0.0, 1.0, 2.0, 3.0, 2.0, 3.0, 1.0, 0.0, 3.0, 1.0, 2.0, 4.0, 1.0, 1.0, 5.0, 2.0, 0.0, 3.0, 0.0, 5.0, 2.0, 1.0, 2.0, 2.0, 2.0, 2.0, 2.0, 4.0, 0.0, 1.0, 4.0, 2.0, 3.0, 1.0, 2.0, 2.0, 1.0, 1.0, 0.0, 2.0, 0.0, 3.0, 3.0, 2.0], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.14676201871322472, "mean_inference_ms": 0.3879735166299336, "mean_action_processing_ms": 0.028528021743276063, "mean_env_wait_ms": 0.39337040852282795, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 2283520, "timesteps_this_iter": 0, "agent_timesteps_total": 2283520, "timers": {"sample_time_ms": 1316.837, "sample_throughput": 3888.105, "load_time_ms": 0.141, "load_throughput": 36268935.112, "learn_time_ms": 66.47, "learn_throughput": 77027.116, "update_time_ms": 2.783}, "info": {"learner": {"default_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 63.32752227783203, "policy_entropy": 7932.94140625, "policy_loss": -45.73720169067383, "vf_loss": 11.43188762664795}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 2283520, "num_agent_steps_sampled": 2283520, "num_steps_trained": 2283520, "num_agent_steps_trained": 2283520, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 1140, "training_iteration": 57, "trial_id": "65be9_00000", "experiment_id": "b9e963105bdc4382843b68ace23a11d3", "date": "2024-06-17_16-18-28", "timestamp": 1718608708, "time_this_iter_s": 10.568706512451172, "time_total_s": 598.5940327644348, "pid": 4998, "hostname": "DESKTOP-LQ219J4", "node_ip": "192.168.46.185", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 20, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 5000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 500, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "rware", "env_args": {"n_agents": 4, "column_height": 1, "max_inactivity_steps": null, "max_steps": 500, "fast_obs": true, "msg_bits": 0, "sensor_range": 1, "shelf_rows": 1, "shelf_columns": 3, "request_queue_size": 4, "reward_type": "RewardType.INDIVIDUAL", "map_name": "customized_map", "map_size": "tiny", "difficulty": "medium"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": true, "force_coop": false, "local_mode": true, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 4, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 100, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64}, "algorithm": "maa2c", "space_obs": "Dict(obs:Box([-100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100.], [100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.], (112,), float32))", "space_act": "Discrete(5)", "num_agents": 4, "episode_limit": 500, "policy_mapping_info": {"all_scenario": {"description": "rware all scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2", "agent_3"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "rware_customized_map", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 10, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.policy_template.MAA2CTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x7f7c1aff2310>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "grad_clip": 40.0, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "microbatch_size": null}, "time_since_restore": 598.5940327644348, "timesteps_since_restore": 0, "iterations_since_restore": 57, "perf": {"cpu_util_percent": 4.3533333333333335, "ram_util_percent": 59.17999999999999}}
{"episode_reward_max": 5.0, "episode_reward_min": 0.0, "episode_reward_mean": 1.95, "episode_len_mean": 500.0, "episode_media": {}, "episodes_this_iter": 20, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 2.0, 3.0, 3.0, 2.0, 1.0, 3.0, 3.0, 3.0, 2.0, 2.0, 2.0, 2.0, 2.0, 1.0, 2.0, 1.0, 3.0, 2.0, 0.0, 1.0, 2.0, 1.0, 1.0, 2.0, 4.0, 3.0, 1.0, 1.0, 4.0, 1.0, 2.0, 2.0, 2.0, 2.0, 2.0, 0.0, 1.0, 2.0, 3.0, 2.0, 3.0, 1.0, 0.0, 3.0, 1.0, 2.0, 4.0, 1.0, 1.0, 5.0, 2.0, 0.0, 3.0, 0.0, 5.0, 2.0, 1.0, 2.0, 2.0, 2.0, 2.0, 2.0, 4.0, 0.0, 1.0, 4.0, 2.0, 3.0, 1.0, 2.0, 2.0, 1.0, 1.0, 0.0, 2.0, 0.0, 3.0, 3.0, 2.0, 1.0, 2.0, 2.0, 4.0, 5.0, 2.0, 2.0, 0.0, 2.0, 1.0, 1.0, 5.0, 4.0, 2.0, 1.0, 0.0, 2.0, 3.0, 1.0, 2.0], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.14673116144538764, "mean_inference_ms": 0.387899361083944, "mean_action_processing_ms": 0.02851943640387347, "mean_env_wait_ms": 0.393210499450679, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 2324480, "timesteps_this_iter": 0, "agent_timesteps_total": 2324480, "timers": {"sample_time_ms": 1325.362, "sample_throughput": 3863.095, "load_time_ms": 0.154, "load_throughput": 33325320.422, "learn_time_ms": 66.722, "learn_throughput": 76736.021, "update_time_ms": 2.859}, "info": {"learner": {"default_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 73.2714614868164, "policy_entropy": 7945.24267578125, "policy_loss": -26.090085983276367, "vf_loss": 13.3243408203125}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 2324480, "num_agent_steps_sampled": 2324480, "num_steps_trained": 2324480, "num_agent_steps_trained": 2324480, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 1160, "training_iteration": 58, "trial_id": "65be9_00000", "experiment_id": "b9e963105bdc4382843b68ace23a11d3", "date": "2024-06-17_16-18-39", "timestamp": 1718608719, "time_this_iter_s": 10.51677393913269, "time_total_s": 609.1108067035675, "pid": 4998, "hostname": "DESKTOP-LQ219J4", "node_ip": "192.168.46.185", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 20, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 5000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 500, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "rware", "env_args": {"n_agents": 4, "column_height": 1, "max_inactivity_steps": null, "max_steps": 500, "fast_obs": true, "msg_bits": 0, "sensor_range": 1, "shelf_rows": 1, "shelf_columns": 3, "request_queue_size": 4, "reward_type": "RewardType.INDIVIDUAL", "map_name": "customized_map", "map_size": "tiny", "difficulty": "medium"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": true, "force_coop": false, "local_mode": true, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 4, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 100, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64}, "algorithm": "maa2c", "space_obs": "Dict(obs:Box([-100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100.], [100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.], (112,), float32))", "space_act": "Discrete(5)", "num_agents": 4, "episode_limit": 500, "policy_mapping_info": {"all_scenario": {"description": "rware all scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2", "agent_3"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "rware_customized_map", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 10, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.policy_template.MAA2CTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x7f7c1afbc940>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "grad_clip": 40.0, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "microbatch_size": null}, "time_since_restore": 609.1108067035675, "timesteps_since_restore": 0, "iterations_since_restore": 58, "perf": {"cpu_util_percent": 3.9733333333333336, "ram_util_percent": 59.86000000000001}}
{"episode_reward_max": 5.0, "episode_reward_min": 0.0, "episode_reward_mean": 1.98, "episode_len_mean": 500.0, "episode_media": {}, "episodes_this_iter": 20, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [1.0, 2.0, 1.0, 1.0, 2.0, 4.0, 3.0, 1.0, 1.0, 4.0, 1.0, 2.0, 2.0, 2.0, 2.0, 2.0, 0.0, 1.0, 2.0, 3.0, 2.0, 3.0, 1.0, 0.0, 3.0, 1.0, 2.0, 4.0, 1.0, 1.0, 5.0, 2.0, 0.0, 3.0, 0.0, 5.0, 2.0, 1.0, 2.0, 2.0, 2.0, 2.0, 2.0, 4.0, 0.0, 1.0, 4.0, 2.0, 3.0, 1.0, 2.0, 2.0, 1.0, 1.0, 0.0, 2.0, 0.0, 3.0, 3.0, 2.0, 1.0, 2.0, 2.0, 4.0, 5.0, 2.0, 2.0, 0.0, 2.0, 1.0, 1.0, 5.0, 4.0, 2.0, 1.0, 0.0, 2.0, 3.0, 1.0, 2.0, 0.0, 0.0, 4.0, 4.0, 2.0, 2.0, 0.0, 3.0, 2.0, 5.0, 2.0, 1.0, 3.0, 0.0, 2.0, 1.0, 2.0, 3.0, 3.0, 3.0], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.14672303874481862, "mean_inference_ms": 0.3878702352479634, "mean_action_processing_ms": 0.028513862951047124, "mean_env_wait_ms": 0.39312944523997456, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 2365440, "timesteps_this_iter": 0, "agent_timesteps_total": 2365440, "timers": {"sample_time_ms": 1320.382, "sample_throughput": 3877.665, "load_time_ms": 0.151, "load_throughput": 34000691.07, "learn_time_ms": 67.047, "learn_throughput": 76363.798, "update_time_ms": 2.839}, "info": {"learner": {"default_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 66.95660400390625, "policy_entropy": 7944.7783203125, "policy_loss": -26.917415618896484, "vf_loss": 15.749088287353516}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 2365440, "num_agent_steps_sampled": 2365440, "num_steps_trained": 2365440, "num_agent_steps_trained": 2365440, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 1180, "training_iteration": 59, "trial_id": "65be9_00000", "experiment_id": "b9e963105bdc4382843b68ace23a11d3", "date": "2024-06-17_16-18-49", "timestamp": 1718608729, "time_this_iter_s": 10.574066638946533, "time_total_s": 619.684873342514, "pid": 4998, "hostname": "DESKTOP-LQ219J4", "node_ip": "192.168.46.185", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 20, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 5000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 500, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "rware", "env_args": {"n_agents": 4, "column_height": 1, "max_inactivity_steps": null, "max_steps": 500, "fast_obs": true, "msg_bits": 0, "sensor_range": 1, "shelf_rows": 1, "shelf_columns": 3, "request_queue_size": 4, "reward_type": "RewardType.INDIVIDUAL", "map_name": "customized_map", "map_size": "tiny", "difficulty": "medium"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": true, "force_coop": false, "local_mode": true, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 4, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 100, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64}, "algorithm": "maa2c", "space_obs": "Dict(obs:Box([-100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100.], [100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.], (112,), float32))", "space_act": "Discrete(5)", "num_agents": 4, "episode_limit": 500, "policy_mapping_info": {"all_scenario": {"description": "rware all scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2", "agent_3"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "rware_customized_map", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 10, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.policy_template.MAA2CTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x7f7c1d170a60>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "grad_clip": 40.0, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "microbatch_size": null}, "time_since_restore": 619.684873342514, "timesteps_since_restore": 0, "iterations_since_restore": 59, "perf": {"cpu_util_percent": 4.006666666666667, "ram_util_percent": 60.50666666666667}}
{"episode_reward_max": 7.0, "episode_reward_min": 0.0, "episode_reward_mean": 2.0, "episode_len_mean": 500.0, "episode_media": {}, "episodes_this_iter": 20, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [2.0, 3.0, 1.0, 0.0, 3.0, 1.0, 2.0, 4.0, 1.0, 1.0, 5.0, 2.0, 0.0, 3.0, 0.0, 5.0, 2.0, 1.0, 2.0, 2.0, 2.0, 2.0, 2.0, 4.0, 0.0, 1.0, 4.0, 2.0, 3.0, 1.0, 2.0, 2.0, 1.0, 1.0, 0.0, 2.0, 0.0, 3.0, 3.0, 2.0, 1.0, 2.0, 2.0, 4.0, 5.0, 2.0, 2.0, 0.0, 2.0, 1.0, 1.0, 5.0, 4.0, 2.0, 1.0, 0.0, 2.0, 3.0, 1.0, 2.0, 0.0, 0.0, 4.0, 4.0, 2.0, 2.0, 0.0, 3.0, 2.0, 5.0, 2.0, 1.0, 3.0, 0.0, 2.0, 1.0, 2.0, 3.0, 3.0, 3.0, 3.0, 1.0, 0.0, 2.0, 2.0, 0.0, 1.0, 2.0, 1.0, 2.0, 0.0, 5.0, 1.0, 1.0, 1.0, 2.0, 3.0, 1.0, 7.0, 4.0], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.14669669463746207, "mean_inference_ms": 0.387803122450281, "mean_action_processing_ms": 0.028505507688868805, "mean_env_wait_ms": 0.39300827830673923, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 2406400, "timesteps_this_iter": 0, "agent_timesteps_total": 2406400, "timers": {"sample_time_ms": 1311.359, "sample_throughput": 3904.347, "load_time_ms": 0.144, "load_throughput": 35460430.119, "learn_time_ms": 66.084, "learn_throughput": 77477.006, "update_time_ms": 2.87}, "info": {"learner": {"default_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 56.52599334716797, "policy_entropy": 7944.6103515625, "policy_loss": -26.603683471679688, "vf_loss": 13.532922744750977}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 2406400, "num_agent_steps_sampled": 2406400, "num_steps_trained": 2406400, "num_agent_steps_trained": 2406400, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 1200, "training_iteration": 60, "trial_id": "65be9_00000", "experiment_id": "b9e963105bdc4382843b68ace23a11d3", "date": "2024-06-17_16-19-00", "timestamp": 1718608740, "time_this_iter_s": 10.504220724105835, "time_total_s": 630.1890940666199, "pid": 4998, "hostname": "DESKTOP-LQ219J4", "node_ip": "192.168.46.185", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 20, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 5000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 500, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "rware", "env_args": {"n_agents": 4, "column_height": 1, "max_inactivity_steps": null, "max_steps": 500, "fast_obs": true, "msg_bits": 0, "sensor_range": 1, "shelf_rows": 1, "shelf_columns": 3, "request_queue_size": 4, "reward_type": "RewardType.INDIVIDUAL", "map_name": "customized_map", "map_size": "tiny", "difficulty": "medium"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": true, "force_coop": false, "local_mode": true, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 4, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 100, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64}, "algorithm": "maa2c", "space_obs": "Dict(obs:Box([-100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100.], [100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.], (112,), float32))", "space_act": "Discrete(5)", "num_agents": 4, "episode_limit": 500, "policy_mapping_info": {"all_scenario": {"description": "rware all scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2", "agent_3"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "rware_customized_map", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 10, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.policy_template.MAA2CTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x7f7c1aff2430>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "grad_clip": 40.0, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "microbatch_size": null}, "time_since_restore": 630.1890940666199, "timesteps_since_restore": 0, "iterations_since_restore": 60, "perf": {"cpu_util_percent": 3.993333333333333, "ram_util_percent": 61.15999999999999}}
{"episode_reward_max": 7.0, "episode_reward_min": 0.0, "episode_reward_mean": 1.96, "episode_len_mean": 500.0, "episode_media": {}, "episodes_this_iter": 20, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [2.0, 2.0, 2.0, 4.0, 0.0, 1.0, 4.0, 2.0, 3.0, 1.0, 2.0, 2.0, 1.0, 1.0, 0.0, 2.0, 0.0, 3.0, 3.0, 2.0, 1.0, 2.0, 2.0, 4.0, 5.0, 2.0, 2.0, 0.0, 2.0, 1.0, 1.0, 5.0, 4.0, 2.0, 1.0, 0.0, 2.0, 3.0, 1.0, 2.0, 0.0, 0.0, 4.0, 4.0, 2.0, 2.0, 0.0, 3.0, 2.0, 5.0, 2.0, 1.0, 3.0, 0.0, 2.0, 1.0, 2.0, 3.0, 3.0, 3.0, 3.0, 1.0, 0.0, 2.0, 2.0, 0.0, 1.0, 2.0, 1.0, 2.0, 0.0, 5.0, 1.0, 1.0, 1.0, 2.0, 3.0, 1.0, 7.0, 4.0, 1.0, 2.0, 1.0, 1.0, 1.0, 2.0, 2.0, 2.0, 5.0, 0.0, 1.0, 1.0, 0.0, 3.0, 6.0, 2.0, 0.0, 1.0, 2.0, 3.0], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.14667291540286084, "mean_inference_ms": 0.3877466667579337, "mean_action_processing_ms": 0.028498114198285792, "mean_env_wait_ms": 0.39285920066959995, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 2447360, "timesteps_this_iter": 0, "agent_timesteps_total": 2447360, "timers": {"sample_time_ms": 1302.539, "sample_throughput": 3930.785, "load_time_ms": 0.148, "load_throughput": 34586626.639, "learn_time_ms": 65.805, "learn_throughput": 77805.518, "update_time_ms": 2.856}, "info": {"learner": {"default_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 44.010643005371094, "policy_entropy": 7978.4599609375, "policy_loss": 9.693023681640625, "vf_loss": 5.99724006652832}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 2447360, "num_agent_steps_sampled": 2447360, "num_steps_trained": 2447360, "num_agent_steps_trained": 2447360, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 1220, "training_iteration": 61, "trial_id": "65be9_00000", "experiment_id": "b9e963105bdc4382843b68ace23a11d3", "date": "2024-06-17_16-19-10", "timestamp": 1718608750, "time_this_iter_s": 10.406889200210571, "time_total_s": 640.5959832668304, "pid": 4998, "hostname": "DESKTOP-LQ219J4", "node_ip": "192.168.46.185", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 20, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 5000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 500, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "rware", "env_args": {"n_agents": 4, "column_height": 1, "max_inactivity_steps": null, "max_steps": 500, "fast_obs": true, "msg_bits": 0, "sensor_range": 1, "shelf_rows": 1, "shelf_columns": 3, "request_queue_size": 4, "reward_type": "RewardType.INDIVIDUAL", "map_name": "customized_map", "map_size": "tiny", "difficulty": "medium"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": true, "force_coop": false, "local_mode": true, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 4, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 100, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64}, "algorithm": "maa2c", "space_obs": "Dict(obs:Box([-100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100.], [100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.], (112,), float32))", "space_act": "Discrete(5)", "num_agents": 4, "episode_limit": 500, "policy_mapping_info": {"all_scenario": {"description": "rware all scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2", "agent_3"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "rware_customized_map", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 10, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.policy_template.MAA2CTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x7f7c1d450a60>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "grad_clip": 40.0, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "microbatch_size": null}, "time_since_restore": 640.5959832668304, "timesteps_since_restore": 0, "iterations_since_restore": 61, "perf": {"cpu_util_percent": 4.042857142857143, "ram_util_percent": 61.771428571428565}}
{"episode_reward_max": 7.0, "episode_reward_min": 0.0, "episode_reward_mean": 1.94, "episode_len_mean": 500.0, "episode_media": {}, "episodes_this_iter": 24, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [5.0, 2.0, 2.0, 0.0, 2.0, 1.0, 1.0, 5.0, 4.0, 2.0, 1.0, 0.0, 2.0, 3.0, 1.0, 2.0, 0.0, 0.0, 4.0, 4.0, 2.0, 2.0, 0.0, 3.0, 2.0, 5.0, 2.0, 1.0, 3.0, 0.0, 2.0, 1.0, 2.0, 3.0, 3.0, 3.0, 3.0, 1.0, 0.0, 2.0, 2.0, 0.0, 1.0, 2.0, 1.0, 2.0, 0.0, 5.0, 1.0, 1.0, 1.0, 2.0, 3.0, 1.0, 7.0, 4.0, 1.0, 2.0, 1.0, 1.0, 1.0, 2.0, 2.0, 2.0, 5.0, 0.0, 1.0, 1.0, 0.0, 3.0, 6.0, 2.0, 0.0, 1.0, 2.0, 3.0, 1.0, 1.0, 2.0, 3.0, 1.0, 1.0, 0.0, 5.0, 3.0, 1.0, 3.0, 2.0, 1.0, 1.0, 3.0, 1.0, 1.0, 2.0, 2.0, 1.0, 3.0, 1.0, 3.0, 2.0], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.1466307852762775, "mean_inference_ms": 0.3876128178487393, "mean_action_processing_ms": 0.02848805247441203, "mean_env_wait_ms": 0.39269596247682725, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 2488320, "timesteps_this_iter": 0, "agent_timesteps_total": 2488320, "timers": {"sample_time_ms": 1317.191, "sample_throughput": 3887.061, "load_time_ms": 0.147, "load_throughput": 34720835.053, "learn_time_ms": 65.477, "learn_throughput": 78195.495, "update_time_ms": 2.875}, "info": {"learner": {"default_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 119.69229125976562, "policy_entropy": 7936.83642578125, "policy_loss": -77.31446075439453, "vf_loss": 18.418596267700195}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 2488320, "num_agent_steps_sampled": 2488320, "num_steps_trained": 2488320, "num_agent_steps_trained": 2488320, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 1244, "training_iteration": 62, "trial_id": "65be9_00000", "experiment_id": "b9e963105bdc4382843b68ace23a11d3", "date": "2024-06-17_16-19-21", "timestamp": 1718608761, "time_this_iter_s": 10.56607460975647, "time_total_s": 651.1620578765869, "pid": 4998, "hostname": "DESKTOP-LQ219J4", "node_ip": "192.168.46.185", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 20, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 5000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 500, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "rware", "env_args": {"n_agents": 4, "column_height": 1, "max_inactivity_steps": null, "max_steps": 500, "fast_obs": true, "msg_bits": 0, "sensor_range": 1, "shelf_rows": 1, "shelf_columns": 3, "request_queue_size": 4, "reward_type": "RewardType.INDIVIDUAL", "map_name": "customized_map", "map_size": "tiny", "difficulty": "medium"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": true, "force_coop": false, "local_mode": true, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 4, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 100, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64}, "algorithm": "maa2c", "space_obs": "Dict(obs:Box([-100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100.], [100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.], (112,), float32))", "space_act": "Discrete(5)", "num_agents": 4, "episode_limit": 500, "policy_mapping_info": {"all_scenario": {"description": "rware all scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2", "agent_3"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "rware_customized_map", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 10, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.policy_template.MAA2CTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x7f7c1d170f70>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "grad_clip": 40.0, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "microbatch_size": null}, "time_since_restore": 651.1620578765869, "timesteps_since_restore": 0, "iterations_since_restore": 62, "perf": {"cpu_util_percent": 4.418749999999999, "ram_util_percent": 62.443749999999994}}
{"episode_reward_max": 7.0, "episode_reward_min": 0.0, "episode_reward_mean": 1.93, "episode_len_mean": 500.0, "episode_media": {}, "episodes_this_iter": 20, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [2.0, 2.0, 0.0, 3.0, 2.0, 5.0, 2.0, 1.0, 3.0, 0.0, 2.0, 1.0, 2.0, 3.0, 3.0, 3.0, 3.0, 1.0, 0.0, 2.0, 2.0, 0.0, 1.0, 2.0, 1.0, 2.0, 0.0, 5.0, 1.0, 1.0, 1.0, 2.0, 3.0, 1.0, 7.0, 4.0, 1.0, 2.0, 1.0, 1.0, 1.0, 2.0, 2.0, 2.0, 5.0, 0.0, 1.0, 1.0, 0.0, 3.0, 6.0, 2.0, 0.0, 1.0, 2.0, 3.0, 1.0, 1.0, 2.0, 3.0, 1.0, 1.0, 0.0, 5.0, 3.0, 1.0, 3.0, 2.0, 1.0, 1.0, 3.0, 1.0, 1.0, 2.0, 2.0, 1.0, 3.0, 1.0, 3.0, 2.0, 1.0, 1.0, 6.0, 0.0, 0.0, 5.0, 2.0, 2.0, 2.0, 3.0, 1.0, 0.0, 6.0, 0.0, 2.0, 2.0, 2.0, 3.0, 1.0, 1.0], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.14661304347865614, "mean_inference_ms": 0.3875296849974755, "mean_action_processing_ms": 0.028482861373992415, "mean_env_wait_ms": 0.39260707725790467, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 2529280, "timesteps_this_iter": 0, "agent_timesteps_total": 2529280, "timers": {"sample_time_ms": 1323.397, "sample_throughput": 3868.832, "load_time_ms": 0.147, "load_throughput": 34884399.74, "learn_time_ms": 65.522, "learn_throughput": 78142.144, "update_time_ms": 2.908}, "info": {"learner": {"default_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 49.568572998046875, "policy_entropy": 7955.6708984375, "policy_loss": -21.56914520263672, "vf_loss": 26.381223678588867}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 2529280, "num_agent_steps_sampled": 2529280, "num_steps_trained": 2529280, "num_agent_steps_trained": 2529280, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 1264, "training_iteration": 63, "trial_id": "65be9_00000", "experiment_id": "b9e963105bdc4382843b68ace23a11d3", "date": "2024-06-17_16-19-31", "timestamp": 1718608771, "time_this_iter_s": 10.566021203994751, "time_total_s": 661.7280790805817, "pid": 4998, "hostname": "DESKTOP-LQ219J4", "node_ip": "192.168.46.185", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 20, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 5000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 500, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "rware", "env_args": {"n_agents": 4, "column_height": 1, "max_inactivity_steps": null, "max_steps": 500, "fast_obs": true, "msg_bits": 0, "sensor_range": 1, "shelf_rows": 1, "shelf_columns": 3, "request_queue_size": 4, "reward_type": "RewardType.INDIVIDUAL", "map_name": "customized_map", "map_size": "tiny", "difficulty": "medium"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": true, "force_coop": false, "local_mode": true, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 4, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 100, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64}, "algorithm": "maa2c", "space_obs": "Dict(obs:Box([-100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100.], [100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.], (112,), float32))", "space_act": "Discrete(5)", "num_agents": 4, "episode_limit": 500, "policy_mapping_info": {"all_scenario": {"description": "rware all scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2", "agent_3"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "rware_customized_map", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 10, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.policy_template.MAA2CTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x7f7c1afbcdc0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "grad_clip": 40.0, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "microbatch_size": null}, "time_since_restore": 661.7280790805817, "timesteps_since_restore": 0, "iterations_since_restore": 63, "perf": {"cpu_util_percent": 4.126666666666666, "ram_util_percent": 63.126666666666665}}
{"episode_reward_max": 7.0, "episode_reward_min": 0.0, "episode_reward_mean": 1.89, "episode_len_mean": 500.0, "episode_media": {}, "episodes_this_iter": 20, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [2.0, 0.0, 1.0, 2.0, 1.0, 2.0, 0.0, 5.0, 1.0, 1.0, 1.0, 2.0, 3.0, 1.0, 7.0, 4.0, 1.0, 2.0, 1.0, 1.0, 1.0, 2.0, 2.0, 2.0, 5.0, 0.0, 1.0, 1.0, 0.0, 3.0, 6.0, 2.0, 0.0, 1.0, 2.0, 3.0, 1.0, 1.0, 2.0, 3.0, 1.0, 1.0, 0.0, 5.0, 3.0, 1.0, 3.0, 2.0, 1.0, 1.0, 3.0, 1.0, 1.0, 2.0, 2.0, 1.0, 3.0, 1.0, 3.0, 2.0, 1.0, 1.0, 6.0, 0.0, 0.0, 5.0, 2.0, 2.0, 2.0, 3.0, 1.0, 0.0, 6.0, 0.0, 2.0, 2.0, 2.0, 3.0, 1.0, 1.0, 4.0, 0.0, 3.0, 4.0, 1.0, 1.0, 4.0, 1.0, 2.0, 1.0, 1.0, 0.0, 1.0, 1.0, 3.0, 1.0, 2.0, 3.0, 2.0, 1.0], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.14659414271445315, "mean_inference_ms": 0.3874464260907415, "mean_action_processing_ms": 0.028477354527450826, "mean_env_wait_ms": 0.3924866019446901, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 2570240, "timesteps_this_iter": 0, "agent_timesteps_total": 2570240, "timers": {"sample_time_ms": 1313.384, "sample_throughput": 3898.326, "load_time_ms": 0.157, "load_throughput": 32621656.509, "learn_time_ms": 66.35, "learn_throughput": 77166.034, "update_time_ms": 2.885}, "info": {"learner": {"default_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 123.1040267944336, "policy_entropy": 7994.5771484375, "policy_loss": -79.94657897949219, "vf_loss": 11.137201309204102}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 2570240, "num_agent_steps_sampled": 2570240, "num_steps_trained": 2570240, "num_agent_steps_trained": 2570240, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 1284, "training_iteration": 64, "trial_id": "65be9_00000", "experiment_id": "b9e963105bdc4382843b68ace23a11d3", "date": "2024-06-17_16-19-42", "timestamp": 1718608782, "time_this_iter_s": 10.514256477355957, "time_total_s": 672.2423355579376, "pid": 4998, "hostname": "DESKTOP-LQ219J4", "node_ip": "192.168.46.185", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 20, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 5000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 500, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "rware", "env_args": {"n_agents": 4, "column_height": 1, "max_inactivity_steps": null, "max_steps": 500, "fast_obs": true, "msg_bits": 0, "sensor_range": 1, "shelf_rows": 1, "shelf_columns": 3, "request_queue_size": 4, "reward_type": "RewardType.INDIVIDUAL", "map_name": "customized_map", "map_size": "tiny", "difficulty": "medium"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": true, "force_coop": false, "local_mode": true, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 4, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 100, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64}, "algorithm": "maa2c", "space_obs": "Dict(obs:Box([-100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100.], [100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.], (112,), float32))", "space_act": "Discrete(5)", "num_agents": 4, "episode_limit": 500, "policy_mapping_info": {"all_scenario": {"description": "rware all scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2", "agent_3"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "rware_customized_map", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 10, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.policy_template.MAA2CTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x7f7c1cdf65e0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "grad_clip": 40.0, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "microbatch_size": null}, "time_since_restore": 672.2423355579376, "timesteps_since_restore": 0, "iterations_since_restore": 64, "perf": {"cpu_util_percent": 3.9666666666666672, "ram_util_percent": 63.779999999999994}}
{"episode_reward_max": 9.0, "episode_reward_min": 0.0, "episode_reward_mean": 1.91, "episode_len_mean": 500.0, "episode_media": {}, "episodes_this_iter": 20, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [1.0, 2.0, 2.0, 2.0, 5.0, 0.0, 1.0, 1.0, 0.0, 3.0, 6.0, 2.0, 0.0, 1.0, 2.0, 3.0, 1.0, 1.0, 2.0, 3.0, 1.0, 1.0, 0.0, 5.0, 3.0, 1.0, 3.0, 2.0, 1.0, 1.0, 3.0, 1.0, 1.0, 2.0, 2.0, 1.0, 3.0, 1.0, 3.0, 2.0, 1.0, 1.0, 6.0, 0.0, 0.0, 5.0, 2.0, 2.0, 2.0, 3.0, 1.0, 0.0, 6.0, 0.0, 2.0, 2.0, 2.0, 3.0, 1.0, 1.0, 4.0, 0.0, 3.0, 4.0, 1.0, 1.0, 4.0, 1.0, 2.0, 1.0, 1.0, 0.0, 1.0, 1.0, 3.0, 1.0, 2.0, 3.0, 2.0, 1.0, 0.0, 0.0, 0.0, 9.0, 2.0, 0.0, 2.0, 3.0, 6.0, 3.0, 1.0, 1.0, 1.0, 1.0, 3.0, 1.0, 0.0, 0.0, 2.0, 5.0], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.14657668164891338, "mean_inference_ms": 0.38736730097130073, "mean_action_processing_ms": 0.028472067200211896, "mean_env_wait_ms": 0.39236874014925605, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 2611200, "timesteps_this_iter": 0, "agent_timesteps_total": 2611200, "timers": {"sample_time_ms": 1314.3, "sample_throughput": 3895.61, "load_time_ms": 0.15, "load_throughput": 34195599.49, "learn_time_ms": 66.251, "learn_throughput": 77281.667, "update_time_ms": 2.883}, "info": {"learner": {"default_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 132.63584899902344, "policy_entropy": 7937.14013671875, "policy_loss": 42.3111686706543, "vf_loss": 41.19927978515625}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 2611200, "num_agent_steps_sampled": 2611200, "num_steps_trained": 2611200, "num_agent_steps_trained": 2611200, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 1304, "training_iteration": 65, "trial_id": "65be9_00000", "experiment_id": "b9e963105bdc4382843b68ace23a11d3", "date": "2024-06-17_16-19-52", "timestamp": 1718608792, "time_this_iter_s": 10.432348251342773, "time_total_s": 682.6746838092804, "pid": 4998, "hostname": "DESKTOP-LQ219J4", "node_ip": "192.168.46.185", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 20, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 5000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 500, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "rware", "env_args": {"n_agents": 4, "column_height": 1, "max_inactivity_steps": null, "max_steps": 500, "fast_obs": true, "msg_bits": 0, "sensor_range": 1, "shelf_rows": 1, "shelf_columns": 3, "request_queue_size": 4, "reward_type": "RewardType.INDIVIDUAL", "map_name": "customized_map", "map_size": "tiny", "difficulty": "medium"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": true, "force_coop": false, "local_mode": true, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 4, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 100, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64}, "algorithm": "maa2c", "space_obs": "Dict(obs:Box([-100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100.], [100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.], (112,), float32))", "space_act": "Discrete(5)", "num_agents": 4, "episode_limit": 500, "policy_mapping_info": {"all_scenario": {"description": "rware all scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2", "agent_3"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "rware_customized_map", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 10, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.policy_template.MAA2CTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x7f7c1d450040>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "grad_clip": 40.0, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "microbatch_size": null}, "time_since_restore": 682.6746838092804, "timesteps_since_restore": 0, "iterations_since_restore": 65, "perf": {"cpu_util_percent": 4.153333333333333, "ram_util_percent": 64.43333333333334}}
{"episode_reward_max": 9.0, "episode_reward_min": 0.0, "episode_reward_mean": 2.1, "episode_len_mean": 500.0, "episode_media": {}, "episodes_this_iter": 20, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [1.0, 1.0, 0.0, 5.0, 3.0, 1.0, 3.0, 2.0, 1.0, 1.0, 3.0, 1.0, 1.0, 2.0, 2.0, 1.0, 3.0, 1.0, 3.0, 2.0, 1.0, 1.0, 6.0, 0.0, 0.0, 5.0, 2.0, 2.0, 2.0, 3.0, 1.0, 0.0, 6.0, 0.0, 2.0, 2.0, 2.0, 3.0, 1.0, 1.0, 4.0, 0.0, 3.0, 4.0, 1.0, 1.0, 4.0, 1.0, 2.0, 1.0, 1.0, 0.0, 1.0, 1.0, 3.0, 1.0, 2.0, 3.0, 2.0, 1.0, 0.0, 0.0, 0.0, 9.0, 2.0, 0.0, 2.0, 3.0, 6.0, 3.0, 1.0, 1.0, 1.0, 1.0, 3.0, 1.0, 0.0, 0.0, 2.0, 5.0, 4.0, 1.0, 4.0, 5.0, 3.0, 3.0, 1.0, 2.0, 1.0, 4.0, 1.0, 3.0, 5.0, 4.0, 3.0, 3.0, 1.0, 3.0, 2.0, 4.0], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.14656196107967773, "mean_inference_ms": 0.38729258283160595, "mean_action_processing_ms": 0.02846685046692752, "mean_env_wait_ms": 0.392286484119242, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 2652160, "timesteps_this_iter": 0, "agent_timesteps_total": 2652160, "timers": {"sample_time_ms": 1317.667, "sample_throughput": 3885.655, "load_time_ms": 0.156, "load_throughput": 32751008.815, "learn_time_ms": 66.714, "learn_throughput": 76745.236, "update_time_ms": 2.842}, "info": {"learner": {"default_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 110.19699096679688, "policy_entropy": 7926.09765625, "policy_loss": -68.19052124023438, "vf_loss": 25.963516235351562}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 2652160, "num_agent_steps_sampled": 2652160, "num_steps_trained": 2652160, "num_agent_steps_trained": 2652160, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 1324, "training_iteration": 66, "trial_id": "65be9_00000", "experiment_id": "b9e963105bdc4382843b68ace23a11d3", "date": "2024-06-17_16-20-03", "timestamp": 1718608803, "time_this_iter_s": 10.545541524887085, "time_total_s": 693.2202253341675, "pid": 4998, "hostname": "DESKTOP-LQ219J4", "node_ip": "192.168.46.185", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 20, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 5000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 500, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "rware", "env_args": {"n_agents": 4, "column_height": 1, "max_inactivity_steps": null, "max_steps": 500, "fast_obs": true, "msg_bits": 0, "sensor_range": 1, "shelf_rows": 1, "shelf_columns": 3, "request_queue_size": 4, "reward_type": "RewardType.INDIVIDUAL", "map_name": "customized_map", "map_size": "tiny", "difficulty": "medium"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": true, "force_coop": false, "local_mode": true, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 4, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 100, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64}, "algorithm": "maa2c", "space_obs": "Dict(obs:Box([-100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100.], [100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.], (112,), float32))", "space_act": "Discrete(5)", "num_agents": 4, "episode_limit": 500, "policy_mapping_info": {"all_scenario": {"description": "rware all scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2", "agent_3"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "rware_customized_map", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 10, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.policy_template.MAA2CTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x7f7c1afbca60>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "grad_clip": 40.0, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "microbatch_size": null}, "time_since_restore": 693.2202253341675, "timesteps_since_restore": 0, "iterations_since_restore": 66, "perf": {"cpu_util_percent": 4.086666666666668, "ram_util_percent": 65.08666666666666}}
{"episode_reward_max": 9.0, "episode_reward_min": 0.0, "episode_reward_mean": 2.27, "episode_len_mean": 500.0, "episode_media": {}, "episodes_this_iter": 20, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [1.0, 1.0, 6.0, 0.0, 0.0, 5.0, 2.0, 2.0, 2.0, 3.0, 1.0, 0.0, 6.0, 0.0, 2.0, 2.0, 2.0, 3.0, 1.0, 1.0, 4.0, 0.0, 3.0, 4.0, 1.0, 1.0, 4.0, 1.0, 2.0, 1.0, 1.0, 0.0, 1.0, 1.0, 3.0, 1.0, 2.0, 3.0, 2.0, 1.0, 0.0, 0.0, 0.0, 9.0, 2.0, 0.0, 2.0, 3.0, 6.0, 3.0, 1.0, 1.0, 1.0, 1.0, 3.0, 1.0, 0.0, 0.0, 2.0, 5.0, 4.0, 1.0, 4.0, 5.0, 3.0, 3.0, 1.0, 2.0, 1.0, 4.0, 1.0, 3.0, 5.0, 4.0, 3.0, 3.0, 1.0, 3.0, 2.0, 4.0, 4.0, 0.0, 3.0, 5.0, 0.0, 2.0, 7.0, 5.0, 2.0, 6.0, 5.0, 1.0, 1.0, 4.0, 1.0, 2.0, 2.0, 2.0, 1.0, 1.0], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.14656569164408878, "mean_inference_ms": 0.3872528969194933, "mean_action_processing_ms": 0.028464275969284754, "mean_env_wait_ms": 0.39224594155671866, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 2693120, "timesteps_this_iter": 0, "agent_timesteps_total": 2693120, "timers": {"sample_time_ms": 1324.731, "sample_throughput": 3864.937, "load_time_ms": 0.154, "load_throughput": 33258225.925, "learn_time_ms": 66.468, "learn_throughput": 77029.852, "update_time_ms": 2.874}, "info": {"learner": {"default_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 63.88246536254883, "policy_entropy": 7892.2158203125, "policy_loss": -38.55930709838867, "vf_loss": 18.600223541259766}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 2693120, "num_agent_steps_sampled": 2693120, "num_steps_trained": 2693120, "num_agent_steps_trained": 2693120, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 1344, "training_iteration": 67, "trial_id": "65be9_00000", "experiment_id": "b9e963105bdc4382843b68ace23a11d3", "date": "2024-06-17_16-20-13", "timestamp": 1718608813, "time_this_iter_s": 10.6172034740448, "time_total_s": 703.8374288082123, "pid": 4998, "hostname": "DESKTOP-LQ219J4", "node_ip": "192.168.46.185", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 20, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 5000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 500, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "rware", "env_args": {"n_agents": 4, "column_height": 1, "max_inactivity_steps": null, "max_steps": 500, "fast_obs": true, "msg_bits": 0, "sensor_range": 1, "shelf_rows": 1, "shelf_columns": 3, "request_queue_size": 4, "reward_type": "RewardType.INDIVIDUAL", "map_name": "customized_map", "map_size": "tiny", "difficulty": "medium"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": true, "force_coop": false, "local_mode": true, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 4, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 100, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64}, "algorithm": "maa2c", "space_obs": "Dict(obs:Box([-100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100.], [100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.], (112,), float32))", "space_act": "Discrete(5)", "num_agents": 4, "episode_limit": 500, "policy_mapping_info": {"all_scenario": {"description": "rware all scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2", "agent_3"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "rware_customized_map", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 10, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.policy_template.MAA2CTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x7f7c1d4500d0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "grad_clip": 40.0, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "microbatch_size": null}, "time_since_restore": 703.8374288082123, "timesteps_since_restore": 0, "iterations_since_restore": 67, "perf": {"cpu_util_percent": 4.173333333333334, "ram_util_percent": 65.75333333333333}}
{"episode_reward_max": 9.0, "episode_reward_min": 0.0, "episode_reward_mean": 2.24, "episode_len_mean": 500.0, "episode_media": {}, "episodes_this_iter": 20, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [4.0, 0.0, 3.0, 4.0, 1.0, 1.0, 4.0, 1.0, 2.0, 1.0, 1.0, 0.0, 1.0, 1.0, 3.0, 1.0, 2.0, 3.0, 2.0, 1.0, 0.0, 0.0, 0.0, 9.0, 2.0, 0.0, 2.0, 3.0, 6.0, 3.0, 1.0, 1.0, 1.0, 1.0, 3.0, 1.0, 0.0, 0.0, 2.0, 5.0, 4.0, 1.0, 4.0, 5.0, 3.0, 3.0, 1.0, 2.0, 1.0, 4.0, 1.0, 3.0, 5.0, 4.0, 3.0, 3.0, 1.0, 3.0, 2.0, 4.0, 4.0, 0.0, 3.0, 5.0, 0.0, 2.0, 7.0, 5.0, 2.0, 6.0, 5.0, 1.0, 1.0, 4.0, 1.0, 2.0, 2.0, 2.0, 1.0, 1.0, 1.0, 2.0, 3.0, 3.0, 0.0, 1.0, 1.0, 1.0, 1.0, 3.0, 3.0, 2.0, 2.0, 1.0, 1.0, 3.0, 1.0, 2.0, 4.0, 2.0], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.14655080710777058, "mean_inference_ms": 0.38717989307310935, "mean_action_processing_ms": 0.028458389648326796, "mean_env_wait_ms": 0.39214941958909405, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 2734080, "timesteps_this_iter": 0, "agent_timesteps_total": 2734080, "timers": {"sample_time_ms": 1318.993, "sample_throughput": 3881.748, "load_time_ms": 0.147, "load_throughput": 34856089.076, "learn_time_ms": 66.482, "learn_throughput": 77013.36, "update_time_ms": 2.916}, "info": {"learner": {"default_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 129.11224365234375, "policy_entropy": 7922.892578125, "policy_loss": 62.60496520996094, "vf_loss": 23.52625846862793}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 2734080, "num_agent_steps_sampled": 2734080, "num_steps_trained": 2734080, "num_agent_steps_trained": 2734080, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 1364, "training_iteration": 68, "trial_id": "65be9_00000", "experiment_id": "b9e963105bdc4382843b68ace23a11d3", "date": "2024-06-17_16-20-24", "timestamp": 1718608824, "time_this_iter_s": 10.474989175796509, "time_total_s": 714.3124179840088, "pid": 4998, "hostname": "DESKTOP-LQ219J4", "node_ip": "192.168.46.185", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 20, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 5000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 500, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "rware", "env_args": {"n_agents": 4, "column_height": 1, "max_inactivity_steps": null, "max_steps": 500, "fast_obs": true, "msg_bits": 0, "sensor_range": 1, "shelf_rows": 1, "shelf_columns": 3, "request_queue_size": 4, "reward_type": "RewardType.INDIVIDUAL", "map_name": "customized_map", "map_size": "tiny", "difficulty": "medium"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": true, "force_coop": false, "local_mode": true, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 4, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 100, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64}, "algorithm": "maa2c", "space_obs": "Dict(obs:Box([-100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100.], [100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.], (112,), float32))", "space_act": "Discrete(5)", "num_agents": 4, "episode_limit": 500, "policy_mapping_info": {"all_scenario": {"description": "rware all scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2", "agent_3"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "rware_customized_map", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 10, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.policy_template.MAA2CTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x7f7c1cdf6c10>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "grad_clip": 40.0, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "microbatch_size": null}, "time_since_restore": 714.3124179840088, "timesteps_since_restore": 0, "iterations_since_restore": 68, "perf": {"cpu_util_percent": 4.2733333333333325, "ram_util_percent": 66.41333333333334}}
{"episode_reward_max": 9.0, "episode_reward_min": 0.0, "episode_reward_mean": 2.36, "episode_len_mean": 500.0, "episode_media": {}, "episodes_this_iter": 20, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 9.0, 2.0, 0.0, 2.0, 3.0, 6.0, 3.0, 1.0, 1.0, 1.0, 1.0, 3.0, 1.0, 0.0, 0.0, 2.0, 5.0, 4.0, 1.0, 4.0, 5.0, 3.0, 3.0, 1.0, 2.0, 1.0, 4.0, 1.0, 3.0, 5.0, 4.0, 3.0, 3.0, 1.0, 3.0, 2.0, 4.0, 4.0, 0.0, 3.0, 5.0, 0.0, 2.0, 7.0, 5.0, 2.0, 6.0, 5.0, 1.0, 1.0, 4.0, 1.0, 2.0, 2.0, 2.0, 1.0, 1.0, 1.0, 2.0, 3.0, 3.0, 0.0, 1.0, 1.0, 1.0, 1.0, 3.0, 3.0, 2.0, 2.0, 1.0, 1.0, 3.0, 1.0, 2.0, 4.0, 2.0, 2.0, 2.0, 3.0, 0.0, 3.0, 5.0, 1.0, 1.0, 0.0, 4.0, 1.0, 1.0, 2.0, 3.0, 6.0, 1.0, 2.0, 2.0, 5.0, 4.0], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.14653960370405797, "mean_inference_ms": 0.3871125514932085, "mean_action_processing_ms": 0.028453172877349005, "mean_env_wait_ms": 0.39206338603244745, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 2775040, "timesteps_this_iter": 0, "agent_timesteps_total": 2775040, "timers": {"sample_time_ms": 1318.962, "sample_throughput": 3881.84, "load_time_ms": 0.146, "load_throughput": 35072409.734, "learn_time_ms": 66.356, "learn_throughput": 77159.934, "update_time_ms": 2.884}, "info": {"learner": {"default_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 129.36074829101562, "policy_entropy": 7912.13623046875, "policy_loss": 40.65436553955078, "vf_loss": 47.986446380615234}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 2775040, "num_agent_steps_sampled": 2775040, "num_steps_trained": 2775040, "num_agent_steps_trained": 2775040, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 1384, "training_iteration": 69, "trial_id": "65be9_00000", "experiment_id": "b9e963105bdc4382843b68ace23a11d3", "date": "2024-06-17_16-20-35", "timestamp": 1718608835, "time_this_iter_s": 10.570772647857666, "time_total_s": 724.8831906318665, "pid": 4998, "hostname": "DESKTOP-LQ219J4", "node_ip": "192.168.46.185", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 20, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 5000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 500, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "rware", "env_args": {"n_agents": 4, "column_height": 1, "max_inactivity_steps": null, "max_steps": 500, "fast_obs": true, "msg_bits": 0, "sensor_range": 1, "shelf_rows": 1, "shelf_columns": 3, "request_queue_size": 4, "reward_type": "RewardType.INDIVIDUAL", "map_name": "customized_map", "map_size": "tiny", "difficulty": "medium"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": true, "force_coop": false, "local_mode": true, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 4, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 100, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64}, "algorithm": "maa2c", "space_obs": "Dict(obs:Box([-100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100.], [100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.], (112,), float32))", "space_act": "Discrete(5)", "num_agents": 4, "episode_limit": 500, "policy_mapping_info": {"all_scenario": {"description": "rware all scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2", "agent_3"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "rware_customized_map", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 10, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.policy_template.MAA2CTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x7f7c1afbcca0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "grad_clip": 40.0, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "microbatch_size": null}, "time_since_restore": 724.8831906318665, "timesteps_since_restore": 0, "iterations_since_restore": 69, "perf": {"cpu_util_percent": 4.28, "ram_util_percent": 67.02666666666667}}
{"episode_reward_max": 7.0, "episode_reward_min": 0.0, "episode_reward_mean": 2.41, "episode_len_mean": 500.0, "episode_media": {}, "episodes_this_iter": 24, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [3.0, 3.0, 1.0, 2.0, 1.0, 4.0, 1.0, 3.0, 5.0, 4.0, 3.0, 3.0, 1.0, 3.0, 2.0, 4.0, 4.0, 0.0, 3.0, 5.0, 0.0, 2.0, 7.0, 5.0, 2.0, 6.0, 5.0, 1.0, 1.0, 4.0, 1.0, 2.0, 2.0, 2.0, 1.0, 1.0, 1.0, 2.0, 3.0, 3.0, 0.0, 1.0, 1.0, 1.0, 1.0, 3.0, 3.0, 2.0, 2.0, 1.0, 1.0, 3.0, 1.0, 2.0, 4.0, 2.0, 2.0, 2.0, 3.0, 0.0, 3.0, 5.0, 1.0, 1.0, 0.0, 4.0, 1.0, 1.0, 2.0, 3.0, 6.0, 1.0, 2.0, 2.0, 5.0, 4.0, 1.0, 6.0, 0.0, 2.0, 0.0, 5.0, 3.0, 2.0, 3.0, 1.0, 3.0, 3.0, 1.0, 1.0, 4.0, 2.0, 0.0, 3.0, 7.0, 3.0, 2.0, 1.0, 1.0, 5.0], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.1465157354559905, "mean_inference_ms": 0.38700605856295417, "mean_action_processing_ms": 0.02844524120752661, "mean_env_wait_ms": 0.3919620389693689, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 2816000, "timesteps_this_iter": 0, "agent_timesteps_total": 2816000, "timers": {"sample_time_ms": 1322.192, "sample_throughput": 3872.357, "load_time_ms": 0.145, "load_throughput": 35355344.88, "learn_time_ms": 66.55, "learn_throughput": 76934.865, "update_time_ms": 2.845}, "info": {"learner": {"default_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 225.25442504882812, "policy_entropy": 7903.71923828125, "policy_loss": 77.99241638183594, "vf_loss": 56.976539611816406}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 2816000, "num_agent_steps_sampled": 2816000, "num_steps_trained": 2816000, "num_agent_steps_trained": 2816000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 1408, "training_iteration": 70, "trial_id": "65be9_00000", "experiment_id": "b9e963105bdc4382843b68ace23a11d3", "date": "2024-06-17_16-20-45", "timestamp": 1718608845, "time_this_iter_s": 10.57334280014038, "time_total_s": 735.4565334320068, "pid": 4998, "hostname": "DESKTOP-LQ219J4", "node_ip": "192.168.46.185", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 20, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 5000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 500, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "rware", "env_args": {"n_agents": 4, "column_height": 1, "max_inactivity_steps": null, "max_steps": 500, "fast_obs": true, "msg_bits": 0, "sensor_range": 1, "shelf_rows": 1, "shelf_columns": 3, "request_queue_size": 4, "reward_type": "RewardType.INDIVIDUAL", "map_name": "customized_map", "map_size": "tiny", "difficulty": "medium"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": true, "force_coop": false, "local_mode": true, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 4, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 100, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64}, "algorithm": "maa2c", "space_obs": "Dict(obs:Box([-100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100.], [100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.], (112,), float32))", "space_act": "Discrete(5)", "num_agents": 4, "episode_limit": 500, "policy_mapping_info": {"all_scenario": {"description": "rware all scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2", "agent_3"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "rware_customized_map", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 10, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.policy_template.MAA2CTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x7f7c1cdf6430>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "grad_clip": 40.0, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "microbatch_size": null}, "time_since_restore": 735.4565334320068, "timesteps_since_restore": 0, "iterations_since_restore": 70, "perf": {"cpu_util_percent": 4.126666666666667, "ram_util_percent": 67.70666666666666}}
{"episode_reward_max": 7.0, "episode_reward_min": 0.0, "episode_reward_mean": 2.43, "episode_len_mean": 500.0, "episode_media": {}, "episodes_this_iter": 20, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 2.0, 7.0, 5.0, 2.0, 6.0, 5.0, 1.0, 1.0, 4.0, 1.0, 2.0, 2.0, 2.0, 1.0, 1.0, 1.0, 2.0, 3.0, 3.0, 0.0, 1.0, 1.0, 1.0, 1.0, 3.0, 3.0, 2.0, 2.0, 1.0, 1.0, 3.0, 1.0, 2.0, 4.0, 2.0, 2.0, 2.0, 3.0, 0.0, 3.0, 5.0, 1.0, 1.0, 0.0, 4.0, 1.0, 1.0, 2.0, 3.0, 6.0, 1.0, 2.0, 2.0, 5.0, 4.0, 1.0, 6.0, 0.0, 2.0, 0.0, 5.0, 3.0, 2.0, 3.0, 1.0, 3.0, 3.0, 1.0, 1.0, 4.0, 2.0, 0.0, 3.0, 7.0, 3.0, 2.0, 1.0, 1.0, 5.0, 5.0, 2.0, 3.0, 2.0, 2.0, 4.0, 1.0, 3.0, 2.0, 6.0, 2.0, 2.0, 1.0, 5.0, 6.0, 2.0, 2.0, 2.0, 1.0, 4.0], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.146509479039767, "mean_inference_ms": 0.3869442118504797, "mean_action_processing_ms": 0.028440970040172632, "mean_env_wait_ms": 0.3918982859349141, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 2856960, "timesteps_this_iter": 0, "agent_timesteps_total": 2856960, "timers": {"sample_time_ms": 1308.767, "sample_throughput": 3912.08, "load_time_ms": 0.146, "load_throughput": 35135530.89, "learn_time_ms": 67.24, "learn_throughput": 76145.584, "update_time_ms": 2.813}, "info": {"learner": {"default_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 69.79151916503906, "policy_entropy": 7929.32421875, "policy_loss": 18.68240737915039, "vf_loss": 32.18084716796875}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 2856960, "num_agent_steps_sampled": 2856960, "num_steps_trained": 2856960, "num_agent_steps_trained": 2856960, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 1428, "training_iteration": 71, "trial_id": "65be9_00000", "experiment_id": "b9e963105bdc4382843b68ace23a11d3", "date": "2024-06-17_16-20-56", "timestamp": 1718608856, "time_this_iter_s": 10.463482141494751, "time_total_s": 745.9200155735016, "pid": 4998, "hostname": "DESKTOP-LQ219J4", "node_ip": "192.168.46.185", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 20, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 5000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 500, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "rware", "env_args": {"n_agents": 4, "column_height": 1, "max_inactivity_steps": null, "max_steps": 500, "fast_obs": true, "msg_bits": 0, "sensor_range": 1, "shelf_rows": 1, "shelf_columns": 3, "request_queue_size": 4, "reward_type": "RewardType.INDIVIDUAL", "map_name": "customized_map", "map_size": "tiny", "difficulty": "medium"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": true, "force_coop": false, "local_mode": true, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 4, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 100, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64}, "algorithm": "maa2c", "space_obs": "Dict(obs:Box([-100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100.], [100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.], (112,), float32))", "space_act": "Discrete(5)", "num_agents": 4, "episode_limit": 500, "policy_mapping_info": {"all_scenario": {"description": "rware all scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2", "agent_3"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "rware_customized_map", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 10, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.policy_template.MAA2CTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x7f7c1aff20d0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "grad_clip": 40.0, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "microbatch_size": null}, "time_since_restore": 745.9200155735016, "timesteps_since_restore": 0, "iterations_since_restore": 71, "perf": {"cpu_util_percent": 4.086666666666667, "ram_util_percent": 68.37333333333332}}
{"episode_reward_max": 7.0, "episode_reward_min": 0.0, "episode_reward_mean": 2.45, "episode_len_mean": 500.0, "episode_media": {}, "episodes_this_iter": 20, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 1.0, 1.0, 1.0, 1.0, 3.0, 3.0, 2.0, 2.0, 1.0, 1.0, 3.0, 1.0, 2.0, 4.0, 2.0, 2.0, 2.0, 3.0, 0.0, 3.0, 5.0, 1.0, 1.0, 0.0, 4.0, 1.0, 1.0, 2.0, 3.0, 6.0, 1.0, 2.0, 2.0, 5.0, 4.0, 1.0, 6.0, 0.0, 2.0, 0.0, 5.0, 3.0, 2.0, 3.0, 1.0, 3.0, 3.0, 1.0, 1.0, 4.0, 2.0, 0.0, 3.0, 7.0, 3.0, 2.0, 1.0, 1.0, 5.0, 5.0, 2.0, 3.0, 2.0, 2.0, 4.0, 1.0, 3.0, 2.0, 6.0, 2.0, 2.0, 1.0, 5.0, 6.0, 2.0, 2.0, 2.0, 1.0, 4.0, 1.0, 4.0, 2.0, 1.0, 0.0, 4.0, 2.0, 3.0, 3.0, 3.0, 1.0, 5.0, 4.0, 3.0, 0.0, 3.0, 3.0, 3.0, 1.0, 7.0], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.14650093431674083, "mean_inference_ms": 0.3868784746926772, "mean_action_processing_ms": 0.02843654072665596, "mean_env_wait_ms": 0.39182130092123346, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 2897920, "timesteps_this_iter": 0, "agent_timesteps_total": 2897920, "timers": {"sample_time_ms": 1316.972, "sample_throughput": 3887.707, "load_time_ms": 0.153, "load_throughput": 33449901.059, "learn_time_ms": 67.108, "learn_throughput": 76295.186, "update_time_ms": 2.87}, "info": {"learner": {"default_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 124.3595199584961, "policy_entropy": 7949.4736328125, "policy_loss": -15.659862518310547, "vf_loss": 60.970706939697266}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 2897920, "num_agent_steps_sampled": 2897920, "num_steps_trained": 2897920, "num_agent_steps_trained": 2897920, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 1448, "training_iteration": 72, "trial_id": "65be9_00000", "experiment_id": "b9e963105bdc4382843b68ace23a11d3", "date": "2024-06-17_16-21-06", "timestamp": 1718608866, "time_this_iter_s": 10.533172130584717, "time_total_s": 756.4531877040863, "pid": 4998, "hostname": "DESKTOP-LQ219J4", "node_ip": "192.168.46.185", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 20, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 5000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 500, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "rware", "env_args": {"n_agents": 4, "column_height": 1, "max_inactivity_steps": null, "max_steps": 500, "fast_obs": true, "msg_bits": 0, "sensor_range": 1, "shelf_rows": 1, "shelf_columns": 3, "request_queue_size": 4, "reward_type": "RewardType.INDIVIDUAL", "map_name": "customized_map", "map_size": "tiny", "difficulty": "medium"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": true, "force_coop": false, "local_mode": true, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 4, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 100, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64}, "algorithm": "maa2c", "space_obs": "Dict(obs:Box([-100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100.], [100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.], (112,), float32))", "space_act": "Discrete(5)", "num_agents": 4, "episode_limit": 500, "policy_mapping_info": {"all_scenario": {"description": "rware all scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2", "agent_3"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "rware_customized_map", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 10, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.policy_template.MAA2CTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x7f7c1cdf6040>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "grad_clip": 40.0, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "microbatch_size": null}, "time_since_restore": 756.4531877040863, "timesteps_since_restore": 0, "iterations_since_restore": 72, "perf": {"cpu_util_percent": 4.1466666666666665, "ram_util_percent": 69.09333333333333}}
{"episode_reward_max": 7.0, "episode_reward_min": 0.0, "episode_reward_mean": 2.69, "episode_len_mean": 500.0, "episode_media": {}, "episodes_this_iter": 20, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [3.0, 5.0, 1.0, 1.0, 0.0, 4.0, 1.0, 1.0, 2.0, 3.0, 6.0, 1.0, 2.0, 2.0, 5.0, 4.0, 1.0, 6.0, 0.0, 2.0, 0.0, 5.0, 3.0, 2.0, 3.0, 1.0, 3.0, 3.0, 1.0, 1.0, 4.0, 2.0, 0.0, 3.0, 7.0, 3.0, 2.0, 1.0, 1.0, 5.0, 5.0, 2.0, 3.0, 2.0, 2.0, 4.0, 1.0, 3.0, 2.0, 6.0, 2.0, 2.0, 1.0, 5.0, 6.0, 2.0, 2.0, 2.0, 1.0, 4.0, 1.0, 4.0, 2.0, 1.0, 0.0, 4.0, 2.0, 3.0, 3.0, 3.0, 1.0, 5.0, 4.0, 3.0, 0.0, 3.0, 3.0, 3.0, 1.0, 7.0, 0.0, 4.0, 2.0, 3.0, 3.0, 2.0, 7.0, 1.0, 2.0, 3.0, 2.0, 2.0, 1.0, 6.0, 6.0, 3.0, 3.0, 5.0, 2.0, 2.0], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.146493370756769, "mean_inference_ms": 0.3868185087563243, "mean_action_processing_ms": 0.028432425863710357, "mean_env_wait_ms": 0.391765692583662, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 2938880, "timesteps_this_iter": 0, "agent_timesteps_total": 2938880, "timers": {"sample_time_ms": 1317.759, "sample_throughput": 3885.384, "load_time_ms": 0.151, "load_throughput": 33882670.369, "learn_time_ms": 65.941, "learn_throughput": 77645.42, "update_time_ms": 2.835}, "info": {"learner": {"default_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 53.25926971435547, "policy_entropy": 7943.69775390625, "policy_loss": -17.805150985717773, "vf_loss": 33.18841552734375}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 2938880, "num_agent_steps_sampled": 2938880, "num_steps_trained": 2938880, "num_agent_steps_trained": 2938880, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 1468, "training_iteration": 73, "trial_id": "65be9_00000", "experiment_id": "b9e963105bdc4382843b68ace23a11d3", "date": "2024-06-17_16-21-17", "timestamp": 1718608877, "time_this_iter_s": 10.55389404296875, "time_total_s": 767.007081747055, "pid": 4998, "hostname": "DESKTOP-LQ219J4", "node_ip": "192.168.46.185", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 20, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 5000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 500, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "rware", "env_args": {"n_agents": 4, "column_height": 1, "max_inactivity_steps": null, "max_steps": 500, "fast_obs": true, "msg_bits": 0, "sensor_range": 1, "shelf_rows": 1, "shelf_columns": 3, "request_queue_size": 4, "reward_type": "RewardType.INDIVIDUAL", "map_name": "customized_map", "map_size": "tiny", "difficulty": "medium"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": true, "force_coop": false, "local_mode": true, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 4, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 100, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64}, "algorithm": "maa2c", "space_obs": "Dict(obs:Box([-100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100.], [100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.], (112,), float32))", "space_act": "Discrete(5)", "num_agents": 4, "episode_limit": 500, "policy_mapping_info": {"all_scenario": {"description": "rware all scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2", "agent_3"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "rware_customized_map", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 10, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.policy_template.MAA2CTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x7f7c1cdf6820>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "grad_clip": 40.0, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "microbatch_size": null}, "time_since_restore": 767.007081747055, "timesteps_since_restore": 0, "iterations_since_restore": 73, "perf": {"cpu_util_percent": 4.279999999999999, "ram_util_percent": 69.80666666666666}}
{"episode_reward_max": 8.0, "episode_reward_min": 0.0, "episode_reward_mean": 2.56, "episode_len_mean": 500.0, "episode_media": {}, "episodes_this_iter": 20, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 5.0, 3.0, 2.0, 3.0, 1.0, 3.0, 3.0, 1.0, 1.0, 4.0, 2.0, 0.0, 3.0, 7.0, 3.0, 2.0, 1.0, 1.0, 5.0, 5.0, 2.0, 3.0, 2.0, 2.0, 4.0, 1.0, 3.0, 2.0, 6.0, 2.0, 2.0, 1.0, 5.0, 6.0, 2.0, 2.0, 2.0, 1.0, 4.0, 1.0, 4.0, 2.0, 1.0, 0.0, 4.0, 2.0, 3.0, 3.0, 3.0, 1.0, 5.0, 4.0, 3.0, 0.0, 3.0, 3.0, 3.0, 1.0, 7.0, 0.0, 4.0, 2.0, 3.0, 3.0, 2.0, 7.0, 1.0, 2.0, 3.0, 2.0, 2.0, 1.0, 6.0, 6.0, 3.0, 3.0, 5.0, 2.0, 2.0, 2.0, 2.0, 2.0, 0.0, 8.0, 1.0, 2.0, 1.0, 3.0, 3.0, 2.0, 3.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 3.0], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.14648437870017675, "mean_inference_ms": 0.38675681753137126, "mean_action_processing_ms": 0.028427972758529402, "mean_env_wait_ms": 0.39170839870183644, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 2979840, "timesteps_this_iter": 0, "agent_timesteps_total": 2979840, "timers": {"sample_time_ms": 1315.684, "sample_throughput": 3891.511, "load_time_ms": 0.15, "load_throughput": 34070817.833, "learn_time_ms": 66.819, "learn_throughput": 76624.775, "update_time_ms": 2.859}, "info": {"learner": {"default_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 165.03785705566406, "policy_entropy": 7886.916015625, "policy_loss": 81.76007080078125, "vf_loss": 39.7081184387207}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 2979840, "num_agent_steps_sampled": 2979840, "num_steps_trained": 2979840, "num_agent_steps_trained": 2979840, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 1488, "training_iteration": 74, "trial_id": "65be9_00000", "experiment_id": "b9e963105bdc4382843b68ace23a11d3", "date": "2024-06-17_16-21-27", "timestamp": 1718608887, "time_this_iter_s": 10.549698829650879, "time_total_s": 777.5567805767059, "pid": 4998, "hostname": "DESKTOP-LQ219J4", "node_ip": "192.168.46.185", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 20, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 5000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 500, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "rware", "env_args": {"n_agents": 4, "column_height": 1, "max_inactivity_steps": null, "max_steps": 500, "fast_obs": true, "msg_bits": 0, "sensor_range": 1, "shelf_rows": 1, "shelf_columns": 3, "request_queue_size": 4, "reward_type": "RewardType.INDIVIDUAL", "map_name": "customized_map", "map_size": "tiny", "difficulty": "medium"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": true, "force_coop": false, "local_mode": true, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 4, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 100, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64}, "algorithm": "maa2c", "space_obs": "Dict(obs:Box([-100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100.], [100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.], (112,), float32))", "space_act": "Discrete(5)", "num_agents": 4, "episode_limit": 500, "policy_mapping_info": {"all_scenario": {"description": "rware all scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2", "agent_3"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "rware_customized_map", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 10, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.policy_template.MAA2CTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x7f7c1aff2310>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "grad_clip": 40.0, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "microbatch_size": null}, "time_since_restore": 777.5567805767059, "timesteps_since_restore": 0, "iterations_since_restore": 74, "perf": {"cpu_util_percent": 4.080000000000001, "ram_util_percent": 70.46000000000002}}
{"episode_reward_max": 11.0, "episode_reward_min": 0.0, "episode_reward_mean": 2.62, "episode_len_mean": 500.0, "episode_media": {}, "episodes_this_iter": 20, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [5.0, 2.0, 3.0, 2.0, 2.0, 4.0, 1.0, 3.0, 2.0, 6.0, 2.0, 2.0, 1.0, 5.0, 6.0, 2.0, 2.0, 2.0, 1.0, 4.0, 1.0, 4.0, 2.0, 1.0, 0.0, 4.0, 2.0, 3.0, 3.0, 3.0, 1.0, 5.0, 4.0, 3.0, 0.0, 3.0, 3.0, 3.0, 1.0, 7.0, 0.0, 4.0, 2.0, 3.0, 3.0, 2.0, 7.0, 1.0, 2.0, 3.0, 2.0, 2.0, 1.0, 6.0, 6.0, 3.0, 3.0, 5.0, 2.0, 2.0, 2.0, 2.0, 2.0, 0.0, 8.0, 1.0, 2.0, 1.0, 3.0, 3.0, 2.0, 3.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 3.0, 1.0, 2.0, 0.0, 4.0, 3.0, 1.0, 1.0, 0.0, 5.0, 2.0, 6.0, 3.0, 0.0, 1.0, 11.0, 2.0, 4.0, 4.0, 5.0, 1.0], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.1464900395129064, "mean_inference_ms": 0.3867300069104992, "mean_action_processing_ms": 0.028425854204928956, "mean_env_wait_ms": 0.3916620579692114, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 3020800, "timesteps_this_iter": 0, "agent_timesteps_total": 3020800, "timers": {"sample_time_ms": 1322.033, "sample_throughput": 3872.822, "load_time_ms": 0.148, "load_throughput": 34670385.018, "learn_time_ms": 67.661, "learn_throughput": 75671.362, "update_time_ms": 2.851}, "info": {"learner": {"default_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 153.93130493164062, "policy_entropy": 7888.29931640625, "policy_loss": -102.82698822021484, "vf_loss": 12.717143058776855}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 3020800, "num_agent_steps_sampled": 3020800, "num_steps_trained": 3020800, "num_agent_steps_trained": 3020800, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 1508, "training_iteration": 75, "trial_id": "65be9_00000", "experiment_id": "b9e963105bdc4382843b68ace23a11d3", "date": "2024-06-17_16-21-38", "timestamp": 1718608898, "time_this_iter_s": 10.493412733078003, "time_total_s": 788.0501933097839, "pid": 4998, "hostname": "DESKTOP-LQ219J4", "node_ip": "192.168.46.185", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 20, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 5000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 500, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "rware", "env_args": {"n_agents": 4, "column_height": 1, "max_inactivity_steps": null, "max_steps": 500, "fast_obs": true, "msg_bits": 0, "sensor_range": 1, "shelf_rows": 1, "shelf_columns": 3, "request_queue_size": 4, "reward_type": "RewardType.INDIVIDUAL", "map_name": "customized_map", "map_size": "tiny", "difficulty": "medium"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": true, "force_coop": false, "local_mode": true, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 4, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 100, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64}, "algorithm": "maa2c", "space_obs": "Dict(obs:Box([-100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100.], [100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.], (112,), float32))", "space_act": "Discrete(5)", "num_agents": 4, "episode_limit": 500, "policy_mapping_info": {"all_scenario": {"description": "rware all scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2", "agent_3"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "rware_customized_map", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 10, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.policy_template.MAA2CTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x7f7c1aff2dc0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "grad_clip": 40.0, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "microbatch_size": null}, "time_since_restore": 788.0501933097839, "timesteps_since_restore": 0, "iterations_since_restore": 75, "perf": {"cpu_util_percent": 4.12, "ram_util_percent": 71.09333333333333}}
{"episode_reward_max": 11.0, "episode_reward_min": 0.0, "episode_reward_mean": 2.6, "episode_len_mean": 500.0, "episode_media": {}, "episodes_this_iter": 20, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [1.0, 4.0, 2.0, 1.0, 0.0, 4.0, 2.0, 3.0, 3.0, 3.0, 1.0, 5.0, 4.0, 3.0, 0.0, 3.0, 3.0, 3.0, 1.0, 7.0, 0.0, 4.0, 2.0, 3.0, 3.0, 2.0, 7.0, 1.0, 2.0, 3.0, 2.0, 2.0, 1.0, 6.0, 6.0, 3.0, 3.0, 5.0, 2.0, 2.0, 2.0, 2.0, 2.0, 0.0, 8.0, 1.0, 2.0, 1.0, 3.0, 3.0, 2.0, 3.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 3.0, 1.0, 2.0, 0.0, 4.0, 3.0, 1.0, 1.0, 0.0, 5.0, 2.0, 6.0, 3.0, 0.0, 1.0, 11.0, 2.0, 4.0, 4.0, 5.0, 1.0, 2.0, 3.0, 1.0, 2.0, 3.0, 0.0, 4.0, 2.0, 3.0, 2.0, 2.0, 7.0, 2.0, 3.0, 3.0, 1.0, 5.0, 5.0, 3.0, 2.0], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.14647776053855188, "mean_inference_ms": 0.38666684084404634, "mean_action_processing_ms": 0.02842111916185586, "mean_env_wait_ms": 0.3916118826905457, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 3061760, "timesteps_this_iter": 0, "agent_timesteps_total": 3061760, "timers": {"sample_time_ms": 1318.107, "sample_throughput": 3884.358, "load_time_ms": 0.154, "load_throughput": 33181144.129, "learn_time_ms": 66.069, "learn_throughput": 77495.208, "update_time_ms": 2.8}, "info": {"learner": {"default_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 139.79774475097656, "policy_entropy": 7877.37109375, "policy_loss": 45.232093811035156, "vf_loss": 42.790645599365234}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 3061760, "num_agent_steps_sampled": 3061760, "num_steps_trained": 3061760, "num_agent_steps_trained": 3061760, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 1528, "training_iteration": 76, "trial_id": "65be9_00000", "experiment_id": "b9e963105bdc4382843b68ace23a11d3", "date": "2024-06-17_16-21-48", "timestamp": 1718608908, "time_this_iter_s": 10.541737794876099, "time_total_s": 798.59193110466, "pid": 4998, "hostname": "DESKTOP-LQ219J4", "node_ip": "192.168.46.185", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 20, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 5000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 500, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "rware", "env_args": {"n_agents": 4, "column_height": 1, "max_inactivity_steps": null, "max_steps": 500, "fast_obs": true, "msg_bits": 0, "sensor_range": 1, "shelf_rows": 1, "shelf_columns": 3, "request_queue_size": 4, "reward_type": "RewardType.INDIVIDUAL", "map_name": "customized_map", "map_size": "tiny", "difficulty": "medium"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": true, "force_coop": false, "local_mode": true, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 4, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 100, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64}, "algorithm": "maa2c", "space_obs": "Dict(obs:Box([-100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100.], [100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.], (112,), float32))", "space_act": "Discrete(5)", "num_agents": 4, "episode_limit": 500, "policy_mapping_info": {"all_scenario": {"description": "rware all scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2", "agent_3"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "rware_customized_map", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 10, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.policy_template.MAA2CTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x7f7c1cdf6940>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "grad_clip": 40.0, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "microbatch_size": null}, "time_since_restore": 798.59193110466, "timesteps_since_restore": 0, "iterations_since_restore": 76, "perf": {"cpu_util_percent": 4.153333333333333, "ram_util_percent": 71.77333333333333}}
{"episode_reward_max": 11.0, "episode_reward_min": 0.0, "episode_reward_mean": 2.64, "episode_len_mean": 500.0, "episode_media": {}, "episodes_this_iter": 20, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 4.0, 2.0, 3.0, 3.0, 2.0, 7.0, 1.0, 2.0, 3.0, 2.0, 2.0, 1.0, 6.0, 6.0, 3.0, 3.0, 5.0, 2.0, 2.0, 2.0, 2.0, 2.0, 0.0, 8.0, 1.0, 2.0, 1.0, 3.0, 3.0, 2.0, 3.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 3.0, 1.0, 2.0, 0.0, 4.0, 3.0, 1.0, 1.0, 0.0, 5.0, 2.0, 6.0, 3.0, 0.0, 1.0, 11.0, 2.0, 4.0, 4.0, 5.0, 1.0, 2.0, 3.0, 1.0, 2.0, 3.0, 0.0, 4.0, 2.0, 3.0, 2.0, 2.0, 7.0, 2.0, 3.0, 3.0, 1.0, 5.0, 5.0, 3.0, 2.0, 6.0, 0.0, 4.0, 2.0, 0.0, 1.0, 1.0, 0.0, 3.0, 4.0, 3.0, 1.0, 3.0, 8.0, 0.0, 7.0, 5.0, 3.0, 5.0, 1.0], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.1464673691310954, "mean_inference_ms": 0.3866060687473872, "mean_action_processing_ms": 0.02841633779836795, "mean_env_wait_ms": 0.39157059392385074, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 3102720, "timesteps_this_iter": 0, "agent_timesteps_total": 3102720, "timers": {"sample_time_ms": 1322.477, "sample_throughput": 3871.523, "load_time_ms": 0.155, "load_throughput": 33033127.95, "learn_time_ms": 68.058, "learn_throughput": 75230.252, "update_time_ms": 2.802}, "info": {"learner": {"default_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 248.46978759765625, "policy_entropy": 7803.7060546875, "policy_loss": 101.3556900024414, "vf_loss": 56.08522033691406}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 3102720, "num_agent_steps_sampled": 3102720, "num_steps_trained": 3102720, "num_agent_steps_trained": 3102720, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 1548, "training_iteration": 77, "trial_id": "65be9_00000", "experiment_id": "b9e963105bdc4382843b68ace23a11d3", "date": "2024-06-17_16-21-59", "timestamp": 1718608919, "time_this_iter_s": 10.585132598876953, "time_total_s": 809.177063703537, "pid": 4998, "hostname": "DESKTOP-LQ219J4", "node_ip": "192.168.46.185", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 20, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 5000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 500, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "rware", "env_args": {"n_agents": 4, "column_height": 1, "max_inactivity_steps": null, "max_steps": 500, "fast_obs": true, "msg_bits": 0, "sensor_range": 1, "shelf_rows": 1, "shelf_columns": 3, "request_queue_size": 4, "reward_type": "RewardType.INDIVIDUAL", "map_name": "customized_map", "map_size": "tiny", "difficulty": "medium"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": true, "force_coop": false, "local_mode": true, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 4, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 100, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64}, "algorithm": "maa2c", "space_obs": "Dict(obs:Box([-100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100.], [100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.], (112,), float32))", "space_act": "Discrete(5)", "num_agents": 4, "episode_limit": 500, "policy_mapping_info": {"all_scenario": {"description": "rware all scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2", "agent_3"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "rware_customized_map", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 10, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.policy_template.MAA2CTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x7f7c1aff2700>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "grad_clip": 40.0, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "microbatch_size": null}, "time_since_restore": 809.177063703537, "timesteps_since_restore": 0, "iterations_since_restore": 77, "perf": {"cpu_util_percent": 4.066666666666666, "ram_util_percent": 72.46000000000001}}
{"episode_reward_max": 11.0, "episode_reward_min": 0.0, "episode_reward_mean": 2.5, "episode_len_mean": 500.0, "episode_media": {}, "episodes_this_iter": 20, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [2.0, 2.0, 2.0, 0.0, 8.0, 1.0, 2.0, 1.0, 3.0, 3.0, 2.0, 3.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 3.0, 1.0, 2.0, 0.0, 4.0, 3.0, 1.0, 1.0, 0.0, 5.0, 2.0, 6.0, 3.0, 0.0, 1.0, 11.0, 2.0, 4.0, 4.0, 5.0, 1.0, 2.0, 3.0, 1.0, 2.0, 3.0, 0.0, 4.0, 2.0, 3.0, 2.0, 2.0, 7.0, 2.0, 3.0, 3.0, 1.0, 5.0, 5.0, 3.0, 2.0, 6.0, 0.0, 4.0, 2.0, 0.0, 1.0, 1.0, 0.0, 3.0, 4.0, 3.0, 1.0, 3.0, 8.0, 0.0, 7.0, 5.0, 3.0, 5.0, 1.0, 5.0, 1.0, 1.0, 4.0, 0.0, 2.0, 0.0, 0.0, 4.0, 4.0, 10.0, 0.0, 1.0, 3.0, 0.0, 1.0, 1.0, 2.0, 5.0, 1.0], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.14645588824163633, "mean_inference_ms": 0.3865435228075845, "mean_action_processing_ms": 0.028411499478765537, "mean_env_wait_ms": 0.39151117829925086, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 3143680, "timesteps_this_iter": 0, "agent_timesteps_total": 3143680, "timers": {"sample_time_ms": 1309.137, "sample_throughput": 3910.973, "load_time_ms": 0.146, "load_throughput": 35101073.03, "learn_time_ms": 67.467, "learn_throughput": 75889.063, "update_time_ms": 2.832}, "info": {"learner": {"default_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 131.9750213623047, "policy_entropy": 7907.6904296875, "policy_loss": 61.38276672363281, "vf_loss": 32.96584701538086}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 3143680, "num_agent_steps_sampled": 3143680, "num_steps_trained": 3143680, "num_agent_steps_trained": 3143680, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 1568, "training_iteration": 78, "trial_id": "65be9_00000", "experiment_id": "b9e963105bdc4382843b68ace23a11d3", "date": "2024-06-17_16-22-09", "timestamp": 1718608929, "time_this_iter_s": 10.472417116165161, "time_total_s": 819.6494808197021, "pid": 4998, "hostname": "DESKTOP-LQ219J4", "node_ip": "192.168.46.185", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 20, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 5000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 500, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "rware", "env_args": {"n_agents": 4, "column_height": 1, "max_inactivity_steps": null, "max_steps": 500, "fast_obs": true, "msg_bits": 0, "sensor_range": 1, "shelf_rows": 1, "shelf_columns": 3, "request_queue_size": 4, "reward_type": "RewardType.INDIVIDUAL", "map_name": "customized_map", "map_size": "tiny", "difficulty": "medium"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": true, "force_coop": false, "local_mode": true, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 4, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 100, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64}, "algorithm": "maa2c", "space_obs": "Dict(obs:Box([-100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100.], [100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.], (112,), float32))", "space_act": "Discrete(5)", "num_agents": 4, "episode_limit": 500, "policy_mapping_info": {"all_scenario": {"description": "rware all scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2", "agent_3"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "rware_customized_map", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 10, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.policy_template.MAA2CTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x7f7c1afbb040>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "grad_clip": 40.0, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "microbatch_size": null}, "time_since_restore": 819.6494808197021, "timesteps_since_restore": 0, "iterations_since_restore": 78, "perf": {"cpu_util_percent": 4.253333333333334, "ram_util_percent": 73.13333333333331}}
{"episode_reward_max": 11.0, "episode_reward_min": 0.0, "episode_reward_mean": 2.66, "episode_len_mean": 500.0, "episode_media": {}, "episodes_this_iter": 24, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [3.0, 1.0, 1.0, 0.0, 5.0, 2.0, 6.0, 3.0, 0.0, 1.0, 11.0, 2.0, 4.0, 4.0, 5.0, 1.0, 2.0, 3.0, 1.0, 2.0, 3.0, 0.0, 4.0, 2.0, 3.0, 2.0, 2.0, 7.0, 2.0, 3.0, 3.0, 1.0, 5.0, 5.0, 3.0, 2.0, 6.0, 0.0, 4.0, 2.0, 0.0, 1.0, 1.0, 0.0, 3.0, 4.0, 3.0, 1.0, 3.0, 8.0, 0.0, 7.0, 5.0, 3.0, 5.0, 1.0, 5.0, 1.0, 1.0, 4.0, 0.0, 2.0, 0.0, 0.0, 4.0, 4.0, 10.0, 0.0, 1.0, 3.0, 0.0, 1.0, 1.0, 2.0, 5.0, 1.0, 3.0, 5.0, 3.0, 0.0, 0.0, 2.0, 2.0, 3.0, 2.0, 2.0, 5.0, 5.0, 4.0, 1.0, 2.0, 3.0, 1.0, 4.0, 2.0, 2.0, 3.0, 3.0, 1.0, 2.0], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.1464287516606736, "mean_inference_ms": 0.3864499590735134, "mean_action_processing_ms": 0.02840381231216754, "mean_env_wait_ms": 0.3914188248068495, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 3184640, "timesteps_this_iter": 0, "agent_timesteps_total": 3184640, "timers": {"sample_time_ms": 1327.845, "sample_throughput": 3855.873, "load_time_ms": 0.155, "load_throughput": 33084018.61, "learn_time_ms": 67.503, "learn_throughput": 75848.723, "update_time_ms": 2.938}, "info": {"learner": {"default_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 146.3950653076172, "policy_entropy": 7938.38525390625, "policy_loss": -92.78801727294922, "vf_loss": 13.21793270111084}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 3184640, "num_agent_steps_sampled": 3184640, "num_steps_trained": 3184640, "num_agent_steps_trained": 3184640, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 1592, "training_iteration": 79, "trial_id": "65be9_00000", "experiment_id": "b9e963105bdc4382843b68ace23a11d3", "date": "2024-06-17_16-22-20", "timestamp": 1718608940, "time_this_iter_s": 10.630680561065674, "time_total_s": 830.2801613807678, "pid": 4998, "hostname": "DESKTOP-LQ219J4", "node_ip": "192.168.46.185", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 20, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 5000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 500, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "rware", "env_args": {"n_agents": 4, "column_height": 1, "max_inactivity_steps": null, "max_steps": 500, "fast_obs": true, "msg_bits": 0, "sensor_range": 1, "shelf_rows": 1, "shelf_columns": 3, "request_queue_size": 4, "reward_type": "RewardType.INDIVIDUAL", "map_name": "customized_map", "map_size": "tiny", "difficulty": "medium"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": true, "force_coop": false, "local_mode": true, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 4, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 100, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64}, "algorithm": "maa2c", "space_obs": "Dict(obs:Box([-100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100.], [100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.], (112,), float32))", "space_act": "Discrete(5)", "num_agents": 4, "episode_limit": 500, "policy_mapping_info": {"all_scenario": {"description": "rware all scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2", "agent_3"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "rware_customized_map", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 10, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.policy_template.MAA2CTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x7f7c1afbcdc0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "grad_clip": 40.0, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "microbatch_size": null}, "time_since_restore": 830.2801613807678, "timesteps_since_restore": 0, "iterations_since_restore": 79, "perf": {"cpu_util_percent": 4.220000000000001, "ram_util_percent": 73.78666666666665}}
{"episode_reward_max": 10.0, "episode_reward_min": 0.0, "episode_reward_mean": 2.64, "episode_len_mean": 500.0, "episode_media": {}, "episodes_this_iter": 20, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [3.0, 0.0, 4.0, 2.0, 3.0, 2.0, 2.0, 7.0, 2.0, 3.0, 3.0, 1.0, 5.0, 5.0, 3.0, 2.0, 6.0, 0.0, 4.0, 2.0, 0.0, 1.0, 1.0, 0.0, 3.0, 4.0, 3.0, 1.0, 3.0, 8.0, 0.0, 7.0, 5.0, 3.0, 5.0, 1.0, 5.0, 1.0, 1.0, 4.0, 0.0, 2.0, 0.0, 0.0, 4.0, 4.0, 10.0, 0.0, 1.0, 3.0, 0.0, 1.0, 1.0, 2.0, 5.0, 1.0, 3.0, 5.0, 3.0, 0.0, 0.0, 2.0, 2.0, 3.0, 2.0, 2.0, 5.0, 5.0, 4.0, 1.0, 2.0, 3.0, 1.0, 4.0, 2.0, 2.0, 3.0, 3.0, 1.0, 2.0, 1.0, 2.0, 2.0, 5.0, 4.0, 4.0, 5.0, 7.0, 4.0, 0.0, 3.0, 3.0, 0.0, 0.0, 5.0, 1.0, 3.0, 1.0, 2.0, 3.0], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.146425868484002, "mean_inference_ms": 0.38641353308499743, "mean_action_processing_ms": 0.028400210509170073, "mean_env_wait_ms": 0.3913903519490852, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 3225600, "timesteps_this_iter": 0, "agent_timesteps_total": 3225600, "timers": {"sample_time_ms": 1324.18, "sample_throughput": 3866.545, "load_time_ms": 0.154, "load_throughput": 33330492.752, "learn_time_ms": 66.462, "learn_throughput": 77036.87, "update_time_ms": 2.837}, "info": {"learner": {"default_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 60.432395935058594, "policy_entropy": 7922.33154296875, "policy_loss": -21.5794734954834, "vf_loss": 33.41883087158203}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 3225600, "num_agent_steps_sampled": 3225600, "num_steps_trained": 3225600, "num_agent_steps_trained": 3225600, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 1612, "training_iteration": 80, "trial_id": "65be9_00000", "experiment_id": "b9e963105bdc4382843b68ace23a11d3", "date": "2024-06-17_16-22-31", "timestamp": 1718608951, "time_this_iter_s": 10.602988719940186, "time_total_s": 840.883150100708, "pid": 4998, "hostname": "DESKTOP-LQ219J4", "node_ip": "192.168.46.185", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 20, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 5000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 500, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "rware", "env_args": {"n_agents": 4, "column_height": 1, "max_inactivity_steps": null, "max_steps": 500, "fast_obs": true, "msg_bits": 0, "sensor_range": 1, "shelf_rows": 1, "shelf_columns": 3, "request_queue_size": 4, "reward_type": "RewardType.INDIVIDUAL", "map_name": "customized_map", "map_size": "tiny", "difficulty": "medium"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": true, "force_coop": false, "local_mode": true, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 4, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 100, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64}, "algorithm": "maa2c", "space_obs": "Dict(obs:Box([-100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100.], [100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.], (112,), float32))", "space_act": "Discrete(5)", "num_agents": 4, "episode_limit": 500, "policy_mapping_info": {"all_scenario": {"description": "rware all scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2", "agent_3"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "rware_customized_map", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 10, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.policy_template.MAA2CTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x7f7c1aff2550>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "grad_clip": 40.0, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "microbatch_size": null}, "time_since_restore": 840.883150100708, "timesteps_since_restore": 0, "iterations_since_restore": 80, "perf": {"cpu_util_percent": 4.126666666666667, "ram_util_percent": 74.43333333333335}}
{"episode_reward_max": 10.0, "episode_reward_min": 0.0, "episode_reward_mean": 2.6, "episode_len_mean": 500.0, "episode_media": {}, "episodes_this_iter": 20, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 1.0, 1.0, 0.0, 3.0, 4.0, 3.0, 1.0, 3.0, 8.0, 0.0, 7.0, 5.0, 3.0, 5.0, 1.0, 5.0, 1.0, 1.0, 4.0, 0.0, 2.0, 0.0, 0.0, 4.0, 4.0, 10.0, 0.0, 1.0, 3.0, 0.0, 1.0, 1.0, 2.0, 5.0, 1.0, 3.0, 5.0, 3.0, 0.0, 0.0, 2.0, 2.0, 3.0, 2.0, 2.0, 5.0, 5.0, 4.0, 1.0, 2.0, 3.0, 1.0, 4.0, 2.0, 2.0, 3.0, 3.0, 1.0, 2.0, 1.0, 2.0, 2.0, 5.0, 4.0, 4.0, 5.0, 7.0, 4.0, 0.0, 3.0, 3.0, 0.0, 0.0, 5.0, 1.0, 3.0, 1.0, 2.0, 3.0, 0.0, 2.0, 4.0, 3.0, 0.0, 1.0, 5.0, 1.0, 3.0, 5.0, 4.0, 3.0, 4.0, 9.0, 2.0, 2.0, 2.0, 1.0, 1.0, 3.0], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.1464258702173171, "mean_inference_ms": 0.3863878387137384, "mean_action_processing_ms": 0.028397056463679383, "mean_env_wait_ms": 0.3913597157638983, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 3266560, "timesteps_this_iter": 0, "agent_timesteps_total": 3266560, "timers": {"sample_time_ms": 1325.195, "sample_throughput": 3863.583, "load_time_ms": 0.156, "load_throughput": 32761001.495, "learn_time_ms": 66.611, "learn_throughput": 76863.847, "update_time_ms": 2.832}, "info": {"learner": {"default_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 183.47752380371094, "policy_entropy": 7967.91455078125, "policy_loss": -96.12661743164062, "vf_loss": 7.2262115478515625}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 3266560, "num_agent_steps_sampled": 3266560, "num_steps_trained": 3266560, "num_agent_steps_trained": 3266560, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 1632, "training_iteration": 81, "trial_id": "65be9_00000", "experiment_id": "b9e963105bdc4382843b68ace23a11d3", "date": "2024-06-17_16-22-41", "timestamp": 1718608961, "time_this_iter_s": 10.607770681381226, "time_total_s": 851.4909207820892, "pid": 4998, "hostname": "DESKTOP-LQ219J4", "node_ip": "192.168.46.185", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 20, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 5000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 500, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "rware", "env_args": {"n_agents": 4, "column_height": 1, "max_inactivity_steps": null, "max_steps": 500, "fast_obs": true, "msg_bits": 0, "sensor_range": 1, "shelf_rows": 1, "shelf_columns": 3, "request_queue_size": 4, "reward_type": "RewardType.INDIVIDUAL", "map_name": "customized_map", "map_size": "tiny", "difficulty": "medium"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": true, "force_coop": false, "local_mode": true, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 4, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 100, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64}, "algorithm": "maa2c", "space_obs": "Dict(obs:Box([-100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100.], [100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.], (112,), float32))", "space_act": "Discrete(5)", "num_agents": 4, "episode_limit": 500, "policy_mapping_info": {"all_scenario": {"description": "rware all scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2", "agent_3"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "rware_customized_map", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 10, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.policy_template.MAA2CTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x7f7c1cdf6b80>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "grad_clip": 40.0, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "microbatch_size": null}, "time_since_restore": 851.4909207820892, "timesteps_since_restore": 0, "iterations_since_restore": 81, "perf": {"cpu_util_percent": 4.173333333333334, "ram_util_percent": 75.09333333333333}}
{"episode_reward_max": 10.0, "episode_reward_min": 0.0, "episode_reward_mean": 2.64, "episode_len_mean": 500.0, "episode_media": {}, "episodes_this_iter": 20, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 2.0, 0.0, 0.0, 4.0, 4.0, 10.0, 0.0, 1.0, 3.0, 0.0, 1.0, 1.0, 2.0, 5.0, 1.0, 3.0, 5.0, 3.0, 0.0, 0.0, 2.0, 2.0, 3.0, 2.0, 2.0, 5.0, 5.0, 4.0, 1.0, 2.0, 3.0, 1.0, 4.0, 2.0, 2.0, 3.0, 3.0, 1.0, 2.0, 1.0, 2.0, 2.0, 5.0, 4.0, 4.0, 5.0, 7.0, 4.0, 0.0, 3.0, 3.0, 0.0, 0.0, 5.0, 1.0, 3.0, 1.0, 2.0, 3.0, 0.0, 2.0, 4.0, 3.0, 0.0, 1.0, 5.0, 1.0, 3.0, 5.0, 4.0, 3.0, 4.0, 9.0, 2.0, 2.0, 2.0, 1.0, 1.0, 3.0, 1.0, 6.0, 1.0, 1.0, 8.0, 2.0, 0.0, 1.0, 5.0, 4.0, 3.0, 4.0, 4.0, 5.0, 1.0, 0.0, 3.0, 6.0, 3.0, 2.0], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.1464279446183593, "mean_inference_ms": 0.38637155673822754, "mean_action_processing_ms": 0.028394387529194133, "mean_env_wait_ms": 0.3913094317649548, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 3307520, "timesteps_this_iter": 0, "agent_timesteps_total": 3307520, "timers": {"sample_time_ms": 1323.187, "sample_throughput": 3869.444, "load_time_ms": 0.147, "load_throughput": 34844777.673, "learn_time_ms": 66.904, "learn_throughput": 76527.948, "update_time_ms": 2.809}, "info": {"learner": {"default_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 92.05121612548828, "policy_entropy": 7968.68603515625, "policy_loss": -52.94059753417969, "vf_loss": 18.703603744506836}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 3307520, "num_agent_steps_sampled": 3307520, "num_steps_trained": 3307520, "num_agent_steps_trained": 3307520, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 1652, "training_iteration": 82, "trial_id": "65be9_00000", "experiment_id": "b9e963105bdc4382843b68ace23a11d3", "date": "2024-06-17_16-22-52", "timestamp": 1718608972, "time_this_iter_s": 10.520752668380737, "time_total_s": 862.01167345047, "pid": 4998, "hostname": "DESKTOP-LQ219J4", "node_ip": "192.168.46.185", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 20, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 5000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 500, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "rware", "env_args": {"n_agents": 4, "column_height": 1, "max_inactivity_steps": null, "max_steps": 500, "fast_obs": true, "msg_bits": 0, "sensor_range": 1, "shelf_rows": 1, "shelf_columns": 3, "request_queue_size": 4, "reward_type": "RewardType.INDIVIDUAL", "map_name": "customized_map", "map_size": "tiny", "difficulty": "medium"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": true, "force_coop": false, "local_mode": true, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 4, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 100, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64}, "algorithm": "maa2c", "space_obs": "Dict(obs:Box([-100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100.], [100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.], (112,), float32))", "space_act": "Discrete(5)", "num_agents": 4, "episode_limit": 500, "policy_mapping_info": {"all_scenario": {"description": "rware all scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2", "agent_3"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "rware_customized_map", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 10, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.policy_template.MAA2CTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x7f7c1afbcdc0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "grad_clip": 40.0, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "microbatch_size": null}, "time_since_restore": 862.01167345047, "timesteps_since_restore": 0, "iterations_since_restore": 82, "perf": {"cpu_util_percent": 4.319999999999999, "ram_util_percent": 75.76666666666665}}
{"episode_reward_max": 9.0, "episode_reward_min": 0.0, "episode_reward_mean": 2.87, "episode_len_mean": 500.0, "episode_media": {}, "episodes_this_iter": 20, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 2.0, 2.0, 3.0, 2.0, 2.0, 5.0, 5.0, 4.0, 1.0, 2.0, 3.0, 1.0, 4.0, 2.0, 2.0, 3.0, 3.0, 1.0, 2.0, 1.0, 2.0, 2.0, 5.0, 4.0, 4.0, 5.0, 7.0, 4.0, 0.0, 3.0, 3.0, 0.0, 0.0, 5.0, 1.0, 3.0, 1.0, 2.0, 3.0, 0.0, 2.0, 4.0, 3.0, 0.0, 1.0, 5.0, 1.0, 3.0, 5.0, 4.0, 3.0, 4.0, 9.0, 2.0, 2.0, 2.0, 1.0, 1.0, 3.0, 1.0, 6.0, 1.0, 1.0, 8.0, 2.0, 0.0, 1.0, 5.0, 4.0, 3.0, 4.0, 4.0, 5.0, 1.0, 0.0, 3.0, 6.0, 3.0, 2.0, 0.0, 2.0, 8.0, 2.0, 1.0, 2.0, 0.0, 7.0, 4.0, 4.0, 3.0, 0.0, 6.0, 5.0, 3.0, 3.0, 2.0, 5.0, 6.0, 5.0], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.14643156126889992, "mean_inference_ms": 0.38636035304726407, "mean_action_processing_ms": 0.028392030250626518, "mean_env_wait_ms": 0.39127537078633173, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 3348480, "timesteps_this_iter": 0, "agent_timesteps_total": 3348480, "timers": {"sample_time_ms": 1320.632, "sample_throughput": 3876.93, "load_time_ms": 0.151, "load_throughput": 33807991.94, "learn_time_ms": 66.395, "learn_throughput": 77114.272, "update_time_ms": 2.909}, "info": {"learner": {"default_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 79.3951416015625, "policy_entropy": 7948.177734375, "policy_loss": -41.00173568725586, "vf_loss": 30.930891036987305}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 3348480, "num_agent_steps_sampled": 3348480, "num_steps_trained": 3348480, "num_agent_steps_trained": 3348480, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 1672, "training_iteration": 83, "trial_id": "65be9_00000", "experiment_id": "b9e963105bdc4382843b68ace23a11d3", "date": "2024-06-17_16-23-02", "timestamp": 1718608982, "time_this_iter_s": 10.574456691741943, "time_total_s": 872.5861301422119, "pid": 4998, "hostname": "DESKTOP-LQ219J4", "node_ip": "192.168.46.185", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 20, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 5000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 500, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "rware", "env_args": {"n_agents": 4, "column_height": 1, "max_inactivity_steps": null, "max_steps": 500, "fast_obs": true, "msg_bits": 0, "sensor_range": 1, "shelf_rows": 1, "shelf_columns": 3, "request_queue_size": 4, "reward_type": "RewardType.INDIVIDUAL", "map_name": "customized_map", "map_size": "tiny", "difficulty": "medium"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": true, "force_coop": false, "local_mode": true, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 4, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 100, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64}, "algorithm": "maa2c", "space_obs": "Dict(obs:Box([-100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100.], [100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.], (112,), float32))", "space_act": "Discrete(5)", "num_agents": 4, "episode_limit": 500, "policy_mapping_info": {"all_scenario": {"description": "rware all scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2", "agent_3"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "rware_customized_map", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 10, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.policy_template.MAA2CTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x7f7c1aff2d30>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "grad_clip": 40.0, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "microbatch_size": null}, "time_since_restore": 872.5861301422119, "timesteps_since_restore": 0, "iterations_since_restore": 83, "perf": {"cpu_util_percent": 3.973333333333333, "ram_util_percent": 76.41333333333334}}
{"episode_reward_max": 13.0, "episode_reward_min": 0.0, "episode_reward_mean": 3.18, "episode_len_mean": 500.0, "episode_media": {}, "episodes_this_iter": 20, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [1.0, 2.0, 2.0, 5.0, 4.0, 4.0, 5.0, 7.0, 4.0, 0.0, 3.0, 3.0, 0.0, 0.0, 5.0, 1.0, 3.0, 1.0, 2.0, 3.0, 0.0, 2.0, 4.0, 3.0, 0.0, 1.0, 5.0, 1.0, 3.0, 5.0, 4.0, 3.0, 4.0, 9.0, 2.0, 2.0, 2.0, 1.0, 1.0, 3.0, 1.0, 6.0, 1.0, 1.0, 8.0, 2.0, 0.0, 1.0, 5.0, 4.0, 3.0, 4.0, 4.0, 5.0, 1.0, 0.0, 3.0, 6.0, 3.0, 2.0, 0.0, 2.0, 8.0, 2.0, 1.0, 2.0, 0.0, 7.0, 4.0, 4.0, 3.0, 0.0, 6.0, 5.0, 3.0, 3.0, 2.0, 5.0, 6.0, 5.0, 2.0, 1.0, 3.0, 1.0, 1.0, 5.0, 3.0, 3.0, 11.0, 4.0, 3.0, 4.0, 6.0, 2.0, 9.0, 2.0, 13.0, 3.0, 2.0, 2.0], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.14645096505481217, "mean_inference_ms": 0.386383010724538, "mean_action_processing_ms": 0.028392642434799154, "mean_env_wait_ms": 0.39126033151570516, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 3389440, "timesteps_this_iter": 0, "agent_timesteps_total": 3389440, "timers": {"sample_time_ms": 1327.417, "sample_throughput": 3857.115, "load_time_ms": 0.155, "load_throughput": 33135066.317, "learn_time_ms": 65.664, "learn_throughput": 77973.185, "update_time_ms": 2.858}, "info": {"learner": {"default_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 219.49041748046875, "policy_entropy": 7928.921875, "policy_loss": 46.17313766479492, "vf_loss": 55.37363815307617}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 3389440, "num_agent_steps_sampled": 3389440, "num_steps_trained": 3389440, "num_agent_steps_trained": 3389440, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 1692, "training_iteration": 84, "trial_id": "65be9_00000", "experiment_id": "b9e963105bdc4382843b68ace23a11d3", "date": "2024-06-17_16-23-13", "timestamp": 1718608993, "time_this_iter_s": 10.62250804901123, "time_total_s": 883.2086381912231, "pid": 4998, "hostname": "DESKTOP-LQ219J4", "node_ip": "192.168.46.185", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 20, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 5000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 500, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "rware", "env_args": {"n_agents": 4, "column_height": 1, "max_inactivity_steps": null, "max_steps": 500, "fast_obs": true, "msg_bits": 0, "sensor_range": 1, "shelf_rows": 1, "shelf_columns": 3, "request_queue_size": 4, "reward_type": "RewardType.INDIVIDUAL", "map_name": "customized_map", "map_size": "tiny", "difficulty": "medium"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": true, "force_coop": false, "local_mode": true, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 4, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 100, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64}, "algorithm": "maa2c", "space_obs": "Dict(obs:Box([-100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100.], [100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.], (112,), float32))", "space_act": "Discrete(5)", "num_agents": 4, "episode_limit": 500, "policy_mapping_info": {"all_scenario": {"description": "rware all scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2", "agent_3"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "rware_customized_map", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 10, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.policy_template.MAA2CTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x7f7c1cdf6d30>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "grad_clip": 40.0, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "microbatch_size": null}, "time_since_restore": 883.2086381912231, "timesteps_since_restore": 0, "iterations_since_restore": 84, "perf": {"cpu_util_percent": 4.2125, "ram_util_percent": 77.07499999999999}}
{"episode_reward_max": 13.0, "episode_reward_min": 0.0, "episode_reward_mean": 3.17, "episode_len_mean": 500.0, "episode_media": {}, "episodes_this_iter": 20, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 2.0, 4.0, 3.0, 0.0, 1.0, 5.0, 1.0, 3.0, 5.0, 4.0, 3.0, 4.0, 9.0, 2.0, 2.0, 2.0, 1.0, 1.0, 3.0, 1.0, 6.0, 1.0, 1.0, 8.0, 2.0, 0.0, 1.0, 5.0, 4.0, 3.0, 4.0, 4.0, 5.0, 1.0, 0.0, 3.0, 6.0, 3.0, 2.0, 0.0, 2.0, 8.0, 2.0, 1.0, 2.0, 0.0, 7.0, 4.0, 4.0, 3.0, 0.0, 6.0, 5.0, 3.0, 3.0, 2.0, 5.0, 6.0, 5.0, 2.0, 1.0, 3.0, 1.0, 1.0, 5.0, 3.0, 3.0, 11.0, 4.0, 3.0, 4.0, 6.0, 2.0, 9.0, 2.0, 13.0, 3.0, 2.0, 2.0, 5.0, 5.0, 0.0, 3.0, 0.0, 1.0, 0.0, 4.0, 6.0, 4.0, 4.0, 1.0, 4.0, 1.0, 1.0, 1.0, 2.0, 2.0, 5.0, 5.0], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.14644892824130865, "mean_inference_ms": 0.3863634515161489, "mean_action_processing_ms": 0.02839016086087038, "mean_env_wait_ms": 0.391195011968089, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 3430400, "timesteps_this_iter": 0, "agent_timesteps_total": 3430400, "timers": {"sample_time_ms": 1308.336, "sample_throughput": 3913.366, "load_time_ms": 0.158, "load_throughput": 32463849.554, "learn_time_ms": 66.72, "learn_throughput": 76739.12, "update_time_ms": 2.88}, "info": {"learner": {"default_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 123.4288330078125, "policy_entropy": 7948.7568359375, "policy_loss": 53.9734992980957, "vf_loss": 22.235576629638672}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 3430400, "num_agent_steps_sampled": 3430400, "num_steps_trained": 3430400, "num_agent_steps_trained": 3430400, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 1712, "training_iteration": 85, "trial_id": "65be9_00000", "experiment_id": "b9e963105bdc4382843b68ace23a11d3", "date": "2024-06-17_16-23-23", "timestamp": 1718609003, "time_this_iter_s": 10.430606842041016, "time_total_s": 893.6392450332642, "pid": 4998, "hostname": "DESKTOP-LQ219J4", "node_ip": "192.168.46.185", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 20, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 5000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 500, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "rware", "env_args": {"n_agents": 4, "column_height": 1, "max_inactivity_steps": null, "max_steps": 500, "fast_obs": true, "msg_bits": 0, "sensor_range": 1, "shelf_rows": 1, "shelf_columns": 3, "request_queue_size": 4, "reward_type": "RewardType.INDIVIDUAL", "map_name": "customized_map", "map_size": "tiny", "difficulty": "medium"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": true, "force_coop": false, "local_mode": true, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 4, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 100, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64}, "algorithm": "maa2c", "space_obs": "Dict(obs:Box([-100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100.], [100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.], (112,), float32))", "space_act": "Discrete(5)", "num_agents": 4, "episode_limit": 500, "policy_mapping_info": {"all_scenario": {"description": "rware all scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2", "agent_3"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "rware_customized_map", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 10, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.policy_template.MAA2CTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x7f7c1d170a60>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "grad_clip": 40.0, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "microbatch_size": null}, "time_since_restore": 893.6392450332642, "timesteps_since_restore": 0, "iterations_since_restore": 85, "perf": {"cpu_util_percent": 3.9642857142857144, "ram_util_percent": 77.69999999999997}}
{"episode_reward_max": 13.0, "episode_reward_min": 0.0, "episode_reward_mean": 3.08, "episode_len_mean": 500.0, "episode_media": {}, "episodes_this_iter": 20, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [1.0, 6.0, 1.0, 1.0, 8.0, 2.0, 0.0, 1.0, 5.0, 4.0, 3.0, 4.0, 4.0, 5.0, 1.0, 0.0, 3.0, 6.0, 3.0, 2.0, 0.0, 2.0, 8.0, 2.0, 1.0, 2.0, 0.0, 7.0, 4.0, 4.0, 3.0, 0.0, 6.0, 5.0, 3.0, 3.0, 2.0, 5.0, 6.0, 5.0, 2.0, 1.0, 3.0, 1.0, 1.0, 5.0, 3.0, 3.0, 11.0, 4.0, 3.0, 4.0, 6.0, 2.0, 9.0, 2.0, 13.0, 3.0, 2.0, 2.0, 5.0, 5.0, 0.0, 3.0, 0.0, 1.0, 0.0, 4.0, 6.0, 4.0, 4.0, 1.0, 4.0, 1.0, 1.0, 1.0, 2.0, 2.0, 5.0, 5.0, 2.0, 2.0, 3.0, 5.0, 5.0, 2.0, 2.0, 2.0, 1.0, 3.0, 1.0, 2.0, 7.0, 2.0, 0.0, 1.0, 3.0, 0.0, 1.0, 2.0], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.14644665662823936, "mean_inference_ms": 0.386340509906087, "mean_action_processing_ms": 0.028387720952284416, "mean_env_wait_ms": 0.39112571974980376, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 3471360, "timesteps_this_iter": 0, "agent_timesteps_total": 3471360, "timers": {"sample_time_ms": 1319.051, "sample_throughput": 3881.579, "load_time_ms": 0.159, "load_throughput": 32114306.086, "learn_time_ms": 66.255, "learn_throughput": 77277.551, "update_time_ms": 2.955}, "info": {"learner": {"default_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 108.31605529785156, "policy_entropy": 7956.0732421875, "policy_loss": 40.996185302734375, "vf_loss": 36.94261932373047}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 3471360, "num_agent_steps_sampled": 3471360, "num_steps_trained": 3471360, "num_agent_steps_trained": 3471360, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 1732, "training_iteration": 86, "trial_id": "65be9_00000", "experiment_id": "b9e963105bdc4382843b68ace23a11d3", "date": "2024-06-17_16-23-34", "timestamp": 1718609014, "time_this_iter_s": 10.568209409713745, "time_total_s": 904.2074544429779, "pid": 4998, "hostname": "DESKTOP-LQ219J4", "node_ip": "192.168.46.185", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 20, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 5000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 500, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "rware", "env_args": {"n_agents": 4, "column_height": 1, "max_inactivity_steps": null, "max_steps": 500, "fast_obs": true, "msg_bits": 0, "sensor_range": 1, "shelf_rows": 1, "shelf_columns": 3, "request_queue_size": 4, "reward_type": "RewardType.INDIVIDUAL", "map_name": "customized_map", "map_size": "tiny", "difficulty": "medium"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": true, "force_coop": false, "local_mode": true, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 4, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 100, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64}, "algorithm": "maa2c", "space_obs": "Dict(obs:Box([-100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100.], [100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.], (112,), float32))", "space_act": "Discrete(5)", "num_agents": 4, "episode_limit": 500, "policy_mapping_info": {"all_scenario": {"description": "rware all scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2", "agent_3"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "rware_customized_map", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 10, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.policy_template.MAA2CTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x7f7c1afbca60>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "grad_clip": 40.0, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "microbatch_size": null}, "time_since_restore": 904.2074544429779, "timesteps_since_restore": 0, "iterations_since_restore": 86, "perf": {"cpu_util_percent": 4.1, "ram_util_percent": 78.39375}}
{"episode_reward_max": 13.0, "episode_reward_min": 0.0, "episode_reward_mean": 3.13, "episode_len_mean": 500.0, "episode_media": {}, "episodes_this_iter": 24, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [1.0, 2.0, 0.0, 7.0, 4.0, 4.0, 3.0, 0.0, 6.0, 5.0, 3.0, 3.0, 2.0, 5.0, 6.0, 5.0, 2.0, 1.0, 3.0, 1.0, 1.0, 5.0, 3.0, 3.0, 11.0, 4.0, 3.0, 4.0, 6.0, 2.0, 9.0, 2.0, 13.0, 3.0, 2.0, 2.0, 5.0, 5.0, 0.0, 3.0, 0.0, 1.0, 0.0, 4.0, 6.0, 4.0, 4.0, 1.0, 4.0, 1.0, 1.0, 1.0, 2.0, 2.0, 5.0, 5.0, 2.0, 2.0, 3.0, 5.0, 5.0, 2.0, 2.0, 2.0, 1.0, 3.0, 1.0, 2.0, 7.0, 2.0, 0.0, 1.0, 3.0, 0.0, 1.0, 2.0, 3.0, 5.0, 3.0, 2.0, 2.0, 1.0, 8.0, 3.0, 3.0, 4.0, 1.0, 3.0, 2.0, 6.0, 4.0, 2.0, 1.0, 5.0, 2.0, 4.0, 1.0, 2.0, 2.0, 8.0], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.146427973165238, "mean_inference_ms": 0.38627609650604344, "mean_action_processing_ms": 0.028382845632650887, "mean_env_wait_ms": 0.3910423198754663, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 3512320, "timesteps_this_iter": 0, "agent_timesteps_total": 3512320, "timers": {"sample_time_ms": 1323.097, "sample_throughput": 3869.71, "load_time_ms": 0.163, "load_throughput": 31350126.248, "learn_time_ms": 67.535, "learn_throughput": 75812.039, "update_time_ms": 3.036}, "info": {"learner": {"default_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 73.2547836303711, "policy_entropy": 7896.7861328125, "policy_loss": -42.41592025756836, "vf_loss": 63.268455505371094}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 3512320, "num_agent_steps_sampled": 3512320, "num_steps_trained": 3512320, "num_agent_steps_trained": 3512320, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 1756, "training_iteration": 87, "trial_id": "65be9_00000", "experiment_id": "b9e963105bdc4382843b68ace23a11d3", "date": "2024-06-17_16-23-45", "timestamp": 1718609025, "time_this_iter_s": 10.616358995437622, "time_total_s": 914.8238134384155, "pid": 4998, "hostname": "DESKTOP-LQ219J4", "node_ip": "192.168.46.185", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 20, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 5000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 500, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "rware", "env_args": {"n_agents": 4, "column_height": 1, "max_inactivity_steps": null, "max_steps": 500, "fast_obs": true, "msg_bits": 0, "sensor_range": 1, "shelf_rows": 1, "shelf_columns": 3, "request_queue_size": 4, "reward_type": "RewardType.INDIVIDUAL", "map_name": "customized_map", "map_size": "tiny", "difficulty": "medium"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": true, "force_coop": false, "local_mode": true, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 4, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 100, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64}, "algorithm": "maa2c", "space_obs": "Dict(obs:Box([-100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100.], [100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.], (112,), float32))", "space_act": "Discrete(5)", "num_agents": 4, "episode_limit": 500, "policy_mapping_info": {"all_scenario": {"description": "rware all scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2", "agent_3"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "rware_customized_map", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 10, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.policy_template.MAA2CTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x7f7c1d906550>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "grad_clip": 40.0, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "microbatch_size": null}, "time_since_restore": 914.8238134384155, "timesteps_since_restore": 0, "iterations_since_restore": 87, "perf": {"cpu_util_percent": 4.293333333333334, "ram_util_percent": 79.08000000000001}}
{"episode_reward_max": 13.0, "episode_reward_min": 0.0, "episode_reward_mean": 3.08, "episode_len_mean": 500.0, "episode_media": {}, "episodes_this_iter": 20, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [1.0, 5.0, 3.0, 3.0, 11.0, 4.0, 3.0, 4.0, 6.0, 2.0, 9.0, 2.0, 13.0, 3.0, 2.0, 2.0, 5.0, 5.0, 0.0, 3.0, 0.0, 1.0, 0.0, 4.0, 6.0, 4.0, 4.0, 1.0, 4.0, 1.0, 1.0, 1.0, 2.0, 2.0, 5.0, 5.0, 2.0, 2.0, 3.0, 5.0, 5.0, 2.0, 2.0, 2.0, 1.0, 3.0, 1.0, 2.0, 7.0, 2.0, 0.0, 1.0, 3.0, 0.0, 1.0, 2.0, 3.0, 5.0, 3.0, 2.0, 2.0, 1.0, 8.0, 3.0, 3.0, 4.0, 1.0, 3.0, 2.0, 6.0, 4.0, 2.0, 1.0, 5.0, 2.0, 4.0, 1.0, 2.0, 2.0, 8.0, 4.0, 5.0, 7.0, 5.0, 4.0, 4.0, 1.0, 2.0, 2.0, 0.0, 0.0, 4.0, 3.0, 1.0, 1.0, 5.0, 6.0, 1.0, 2.0, 1.0], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.1464254468878451, "mean_inference_ms": 0.3862515897288453, "mean_action_processing_ms": 0.028381053938961356, "mean_env_wait_ms": 0.3910093849951711, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 3553280, "timesteps_this_iter": 0, "agent_timesteps_total": 3553280, "timers": {"sample_time_ms": 1330.019, "sample_throughput": 3849.57, "load_time_ms": 0.163, "load_throughput": 31340975.598, "learn_time_ms": 67.882, "learn_throughput": 75425.305, "update_time_ms": 2.96}, "info": {"learner": {"default_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 245.16676330566406, "policy_entropy": 7953.68212890625, "policy_loss": -125.78707885742188, "vf_loss": 4.013001441955566}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 3553280, "num_agent_steps_sampled": 3553280, "num_steps_trained": 3553280, "num_agent_steps_trained": 3553280, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 1776, "training_iteration": 88, "trial_id": "65be9_00000", "experiment_id": "b9e963105bdc4382843b68ace23a11d3", "date": "2024-06-17_16-23-55", "timestamp": 1718609035, "time_this_iter_s": 10.616305112838745, "time_total_s": 925.4401185512543, "pid": 4998, "hostname": "DESKTOP-LQ219J4", "node_ip": "192.168.46.185", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 20, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 5000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 500, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "rware", "env_args": {"n_agents": 4, "column_height": 1, "max_inactivity_steps": null, "max_steps": 500, "fast_obs": true, "msg_bits": 0, "sensor_range": 1, "shelf_rows": 1, "shelf_columns": 3, "request_queue_size": 4, "reward_type": "RewardType.INDIVIDUAL", "map_name": "customized_map", "map_size": "tiny", "difficulty": "medium"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": true, "force_coop": false, "local_mode": true, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 4, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 100, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64}, "algorithm": "maa2c", "space_obs": "Dict(obs:Box([-100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100.], [100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.], (112,), float32))", "space_act": "Discrete(5)", "num_agents": 4, "episode_limit": 500, "policy_mapping_info": {"all_scenario": {"description": "rware all scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2", "agent_3"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "rware_customized_map", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 10, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.policy_template.MAA2CTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x7f7c1aff21f0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "grad_clip": 40.0, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "microbatch_size": null}, "time_since_restore": 925.4401185512543, "timesteps_since_restore": 0, "iterations_since_restore": 88, "perf": {"cpu_util_percent": 4.446666666666666, "ram_util_percent": 79.72666666666666}}
{"episode_reward_max": 9.0, "episode_reward_min": 0.0, "episode_reward_mean": 2.78, "episode_len_mean": 500.0, "episode_media": {}, "episodes_this_iter": 20, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 1.0, 0.0, 4.0, 6.0, 4.0, 4.0, 1.0, 4.0, 1.0, 1.0, 1.0, 2.0, 2.0, 5.0, 5.0, 2.0, 2.0, 3.0, 5.0, 5.0, 2.0, 2.0, 2.0, 1.0, 3.0, 1.0, 2.0, 7.0, 2.0, 0.0, 1.0, 3.0, 0.0, 1.0, 2.0, 3.0, 5.0, 3.0, 2.0, 2.0, 1.0, 8.0, 3.0, 3.0, 4.0, 1.0, 3.0, 2.0, 6.0, 4.0, 2.0, 1.0, 5.0, 2.0, 4.0, 1.0, 2.0, 2.0, 8.0, 4.0, 5.0, 7.0, 5.0, 4.0, 4.0, 1.0, 2.0, 2.0, 0.0, 0.0, 4.0, 3.0, 1.0, 1.0, 5.0, 6.0, 1.0, 2.0, 1.0, 3.0, 5.0, 5.0, 4.0, 0.0, 9.0, 3.0, 3.0, 6.0, 0.0, 3.0, 3.0, 2.0, 0.0, 3.0, 0.0, 4.0, 0.0, 2.0, 1.0], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.14642189933819794, "mean_inference_ms": 0.38622542359635753, "mean_action_processing_ms": 0.02837994546683409, "mean_env_wait_ms": 0.39095993688172626, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 3594240, "timesteps_this_iter": 0, "agent_timesteps_total": 3594240, "timers": {"sample_time_ms": 1326.239, "sample_throughput": 3860.542, "load_time_ms": 0.164, "load_throughput": 31277070.318, "learn_time_ms": 67.83, "learn_throughput": 75483.286, "update_time_ms": 2.948}, "info": {"learner": {"default_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 81.00360870361328, "policy_entropy": 7919.583984375, "policy_loss": -18.64447021484375, "vf_loss": 35.43891143798828}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 3594240, "num_agent_steps_sampled": 3594240, "num_steps_trained": 3594240, "num_agent_steps_trained": 3594240, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 1796, "training_iteration": 89, "trial_id": "65be9_00000", "experiment_id": "b9e963105bdc4382843b68ace23a11d3", "date": "2024-06-17_16-24-06", "timestamp": 1718609046, "time_this_iter_s": 10.531676054000854, "time_total_s": 935.9717946052551, "pid": 4998, "hostname": "DESKTOP-LQ219J4", "node_ip": "192.168.46.185", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 20, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 5000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 500, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "rware", "env_args": {"n_agents": 4, "column_height": 1, "max_inactivity_steps": null, "max_steps": 500, "fast_obs": true, "msg_bits": 0, "sensor_range": 1, "shelf_rows": 1, "shelf_columns": 3, "request_queue_size": 4, "reward_type": "RewardType.INDIVIDUAL", "map_name": "customized_map", "map_size": "tiny", "difficulty": "medium"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": true, "force_coop": false, "local_mode": true, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 4, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 100, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64}, "algorithm": "maa2c", "space_obs": "Dict(obs:Box([-100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100.], [100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.], (112,), float32))", "space_act": "Discrete(5)", "num_agents": 4, "episode_limit": 500, "policy_mapping_info": {"all_scenario": {"description": "rware all scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2", "agent_3"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "rware_customized_map", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 10, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.policy_template.MAA2CTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x7f7c1afbca60>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "grad_clip": 40.0, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "microbatch_size": null}, "time_since_restore": 935.9717946052551, "timesteps_since_restore": 0, "iterations_since_restore": 89, "perf": {"cpu_util_percent": 4.260000000000001, "ram_util_percent": 80.4}}
{"episode_reward_max": 9.0, "episode_reward_min": 0.0, "episode_reward_mean": 3.0, "episode_len_mean": 500.0, "episode_media": {}, "episodes_this_iter": 20, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [5.0, 2.0, 2.0, 2.0, 1.0, 3.0, 1.0, 2.0, 7.0, 2.0, 0.0, 1.0, 3.0, 0.0, 1.0, 2.0, 3.0, 5.0, 3.0, 2.0, 2.0, 1.0, 8.0, 3.0, 3.0, 4.0, 1.0, 3.0, 2.0, 6.0, 4.0, 2.0, 1.0, 5.0, 2.0, 4.0, 1.0, 2.0, 2.0, 8.0, 4.0, 5.0, 7.0, 5.0, 4.0, 4.0, 1.0, 2.0, 2.0, 0.0, 0.0, 4.0, 3.0, 1.0, 1.0, 5.0, 6.0, 1.0, 2.0, 1.0, 3.0, 5.0, 5.0, 4.0, 0.0, 9.0, 3.0, 3.0, 6.0, 0.0, 3.0, 3.0, 2.0, 0.0, 3.0, 0.0, 4.0, 0.0, 2.0, 1.0, 2.0, 7.0, 5.0, 5.0, 7.0, 2.0, 2.0, 2.0, 5.0, 4.0, 6.0, 3.0, 4.0, 3.0, 3.0, 4.0, 5.0, 2.0, 2.0, 2.0], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.1464189554808417, "mean_inference_ms": 0.3861997114703688, "mean_action_processing_ms": 0.028378775796063474, "mean_env_wait_ms": 0.3909360115390572, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 3635200, "timesteps_this_iter": 0, "agent_timesteps_total": 3635200, "timers": {"sample_time_ms": 1318.697, "sample_throughput": 3882.62, "load_time_ms": 0.154, "load_throughput": 33176018.044, "learn_time_ms": 66.632, "learn_throughput": 76840.139, "update_time_ms": 2.892}, "info": {"learner": {"default_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 148.72598266601562, "policy_entropy": 7916.802734375, "policy_loss": -91.4507827758789, "vf_loss": 43.43226623535156}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 3635200, "num_agent_steps_sampled": 3635200, "num_steps_trained": 3635200, "num_agent_steps_trained": 3635200, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 1816, "training_iteration": 90, "trial_id": "65be9_00000", "experiment_id": "b9e963105bdc4382843b68ace23a11d3", "date": "2024-06-17_16-24-16", "timestamp": 1718609056, "time_this_iter_s": 10.536181211471558, "time_total_s": 946.5079758167267, "pid": 4998, "hostname": "DESKTOP-LQ219J4", "node_ip": "192.168.46.185", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 20, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 5000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 500, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "rware", "env_args": {"n_agents": 4, "column_height": 1, "max_inactivity_steps": null, "max_steps": 500, "fast_obs": true, "msg_bits": 0, "sensor_range": 1, "shelf_rows": 1, "shelf_columns": 3, "request_queue_size": 4, "reward_type": "RewardType.INDIVIDUAL", "map_name": "customized_map", "map_size": "tiny", "difficulty": "medium"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": true, "force_coop": false, "local_mode": true, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 4, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 100, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64}, "algorithm": "maa2c", "space_obs": "Dict(obs:Box([-100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100.], [100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.], (112,), float32))", "space_act": "Discrete(5)", "num_agents": 4, "episode_limit": 500, "policy_mapping_info": {"all_scenario": {"description": "rware all scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2", "agent_3"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "rware_customized_map", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 10, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.policy_template.MAA2CTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x7f7c1aff2160>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "grad_clip": 40.0, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "microbatch_size": null}, "time_since_restore": 946.5079758167267, "timesteps_since_restore": 0, "iterations_since_restore": 90, "perf": {"cpu_util_percent": 4.193333333333333, "ram_util_percent": 81.08000000000001}}
{"episode_reward_max": 12.0, "episode_reward_min": 0.0, "episode_reward_mean": 3.26, "episode_len_mean": 500.0, "episode_media": {}, "episodes_this_iter": 20, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [2.0, 1.0, 8.0, 3.0, 3.0, 4.0, 1.0, 3.0, 2.0, 6.0, 4.0, 2.0, 1.0, 5.0, 2.0, 4.0, 1.0, 2.0, 2.0, 8.0, 4.0, 5.0, 7.0, 5.0, 4.0, 4.0, 1.0, 2.0, 2.0, 0.0, 0.0, 4.0, 3.0, 1.0, 1.0, 5.0, 6.0, 1.0, 2.0, 1.0, 3.0, 5.0, 5.0, 4.0, 0.0, 9.0, 3.0, 3.0, 6.0, 0.0, 3.0, 3.0, 2.0, 0.0, 3.0, 0.0, 4.0, 0.0, 2.0, 1.0, 2.0, 7.0, 5.0, 5.0, 7.0, 2.0, 2.0, 2.0, 5.0, 4.0, 6.0, 3.0, 4.0, 3.0, 3.0, 4.0, 5.0, 2.0, 2.0, 2.0, 4.0, 0.0, 2.0, 3.0, 2.0, 2.0, 1.0, 12.0, 4.0, 2.0, 4.0, 3.0, 6.0, 6.0, 2.0, 3.0, 4.0, 1.0, 2.0, 10.0], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.1464154775030958, "mean_inference_ms": 0.3861717384649985, "mean_action_processing_ms": 0.028377270736413048, "mean_env_wait_ms": 0.39091359696355765, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 3676160, "timesteps_this_iter": 0, "agent_timesteps_total": 3676160, "timers": {"sample_time_ms": 1318.284, "sample_throughput": 3883.838, "load_time_ms": 0.167, "load_throughput": 30652064.63, "learn_time_ms": 66.506, "learn_throughput": 76985.806, "update_time_ms": 2.914}, "info": {"learner": {"default_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 74.56369018554688, "policy_entropy": 7930.5361328125, "policy_loss": -33.55927276611328, "vf_loss": 23.092939376831055}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 3676160, "num_agent_steps_sampled": 3676160, "num_steps_trained": 3676160, "num_agent_steps_trained": 3676160, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 1836, "training_iteration": 91, "trial_id": "65be9_00000", "experiment_id": "b9e963105bdc4382843b68ace23a11d3", "date": "2024-06-17_16-24-27", "timestamp": 1718609067, "time_this_iter_s": 10.565159797668457, "time_total_s": 957.0731356143951, "pid": 4998, "hostname": "DESKTOP-LQ219J4", "node_ip": "192.168.46.185", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 20, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 5000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 500, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "rware", "env_args": {"n_agents": 4, "column_height": 1, "max_inactivity_steps": null, "max_steps": 500, "fast_obs": true, "msg_bits": 0, "sensor_range": 1, "shelf_rows": 1, "shelf_columns": 3, "request_queue_size": 4, "reward_type": "RewardType.INDIVIDUAL", "map_name": "customized_map", "map_size": "tiny", "difficulty": "medium"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": true, "force_coop": false, "local_mode": true, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 4, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 100, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64}, "algorithm": "maa2c", "space_obs": "Dict(obs:Box([-100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100.], [100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.], (112,), float32))", "space_act": "Discrete(5)", "num_agents": 4, "episode_limit": 500, "policy_mapping_info": {"all_scenario": {"description": "rware all scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2", "agent_3"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "rware_customized_map", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 10, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.policy_template.MAA2CTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x7f7c1aff2700>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "grad_clip": 40.0, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "microbatch_size": null}, "time_since_restore": 957.0731356143951, "timesteps_since_restore": 0, "iterations_since_restore": 91, "perf": {"cpu_util_percent": 4.133333333333334, "ram_util_percent": 81.7}}
{"episode_reward_max": 12.0, "episode_reward_min": 0.0, "episode_reward_mean": 3.18, "episode_len_mean": 500.0, "episode_media": {}, "episodes_this_iter": 20, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [4.0, 5.0, 7.0, 5.0, 4.0, 4.0, 1.0, 2.0, 2.0, 0.0, 0.0, 4.0, 3.0, 1.0, 1.0, 5.0, 6.0, 1.0, 2.0, 1.0, 3.0, 5.0, 5.0, 4.0, 0.0, 9.0, 3.0, 3.0, 6.0, 0.0, 3.0, 3.0, 2.0, 0.0, 3.0, 0.0, 4.0, 0.0, 2.0, 1.0, 2.0, 7.0, 5.0, 5.0, 7.0, 2.0, 2.0, 2.0, 5.0, 4.0, 6.0, 3.0, 4.0, 3.0, 3.0, 4.0, 5.0, 2.0, 2.0, 2.0, 4.0, 0.0, 2.0, 3.0, 2.0, 2.0, 1.0, 12.0, 4.0, 2.0, 4.0, 3.0, 6.0, 6.0, 2.0, 3.0, 4.0, 1.0, 2.0, 10.0, 1.0, 7.0, 1.0, 3.0, 2.0, 3.0, 4.0, 3.0, 4.0, 6.0, 2.0, 0.0, 2.0, 1.0, 2.0, 5.0, 2.0, 4.0, 2.0, 2.0], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.14642945723942616, "mean_inference_ms": 0.38617995160466834, "mean_action_processing_ms": 0.02837804979425531, "mean_env_wait_ms": 0.39089239786971386, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 3717120, "timesteps_this_iter": 0, "agent_timesteps_total": 3717120, "timers": {"sample_time_ms": 1319.844, "sample_throughput": 3879.245, "load_time_ms": 0.155, "load_throughput": 33073827.938, "learn_time_ms": 67.248, "learn_throughput": 76135.811, "update_time_ms": 2.85}, "info": {"learner": {"default_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 202.09681701660156, "policy_entropy": 7768.88232421875, "policy_loss": 59.48145294189453, "vf_loss": 62.169403076171875}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 3717120, "num_agent_steps_sampled": 3717120, "num_steps_trained": 3717120, "num_agent_steps_trained": 3717120, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 1856, "training_iteration": 92, "trial_id": "65be9_00000", "experiment_id": "b9e963105bdc4382843b68ace23a11d3", "date": "2024-06-17_16-24-38", "timestamp": 1718609078, "time_this_iter_s": 10.565536737442017, "time_total_s": 967.6386723518372, "pid": 4998, "hostname": "DESKTOP-LQ219J4", "node_ip": "192.168.46.185", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 20, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 5000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 500, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "rware", "env_args": {"n_agents": 4, "column_height": 1, "max_inactivity_steps": null, "max_steps": 500, "fast_obs": true, "msg_bits": 0, "sensor_range": 1, "shelf_rows": 1, "shelf_columns": 3, "request_queue_size": 4, "reward_type": "RewardType.INDIVIDUAL", "map_name": "customized_map", "map_size": "tiny", "difficulty": "medium"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": true, "force_coop": false, "local_mode": true, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 4, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 100, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64}, "algorithm": "maa2c", "space_obs": "Dict(obs:Box([-100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100.], [100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.], (112,), float32))", "space_act": "Discrete(5)", "num_agents": 4, "episode_limit": 500, "policy_mapping_info": {"all_scenario": {"description": "rware all scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2", "agent_3"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "rware_customized_map", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 10, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.policy_template.MAA2CTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x7f7c1aff2430>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "grad_clip": 40.0, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "microbatch_size": null}, "time_since_restore": 967.6386723518372, "timesteps_since_restore": 0, "iterations_since_restore": 92, "perf": {"cpu_util_percent": 4.14, "ram_util_percent": 82.37333333333332}}
{"episode_reward_max": 12.0, "episode_reward_min": 0.0, "episode_reward_mean": 3.36, "episode_len_mean": 500.0, "episode_media": {}, "episodes_this_iter": 20, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [3.0, 5.0, 5.0, 4.0, 0.0, 9.0, 3.0, 3.0, 6.0, 0.0, 3.0, 3.0, 2.0, 0.0, 3.0, 0.0, 4.0, 0.0, 2.0, 1.0, 2.0, 7.0, 5.0, 5.0, 7.0, 2.0, 2.0, 2.0, 5.0, 4.0, 6.0, 3.0, 4.0, 3.0, 3.0, 4.0, 5.0, 2.0, 2.0, 2.0, 4.0, 0.0, 2.0, 3.0, 2.0, 2.0, 1.0, 12.0, 4.0, 2.0, 4.0, 3.0, 6.0, 6.0, 2.0, 3.0, 4.0, 1.0, 2.0, 10.0, 1.0, 7.0, 1.0, 3.0, 2.0, 3.0, 4.0, 3.0, 4.0, 6.0, 2.0, 0.0, 2.0, 1.0, 2.0, 5.0, 2.0, 4.0, 2.0, 2.0, 7.0, 2.0, 1.0, 2.0, 4.0, 3.0, 4.0, 2.0, 4.0, 4.0, 1.0, 1.0, 10.0, 6.0, 8.0, 5.0, 6.0, 0.0, 3.0, 3.0], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.1464263084650465, "mean_inference_ms": 0.38615186579642186, "mean_action_processing_ms": 0.02837610595756057, "mean_env_wait_ms": 0.39085223357733, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 3758080, "timesteps_this_iter": 0, "agent_timesteps_total": 3758080, "timers": {"sample_time_ms": 1326.732, "sample_throughput": 3859.107, "load_time_ms": 0.164, "load_throughput": 31181699.55, "learn_time_ms": 67.215, "learn_throughput": 76173.35, "update_time_ms": 3.381}, "info": {"learner": {"default_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 56.665245056152344, "policy_entropy": 7889.11962890625, "policy_loss": -11.05438232421875, "vf_loss": 23.202547073364258}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 3758080, "num_agent_steps_sampled": 3758080, "num_steps_trained": 3758080, "num_agent_steps_trained": 3758080, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 1876, "training_iteration": 93, "trial_id": "65be9_00000", "experiment_id": "b9e963105bdc4382843b68ace23a11d3", "date": "2024-06-17_16-24-48", "timestamp": 1718609088, "time_this_iter_s": 10.601523160934448, "time_total_s": 978.2401955127716, "pid": 4998, "hostname": "DESKTOP-LQ219J4", "node_ip": "192.168.46.185", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 20, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 5000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 500, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "rware", "env_args": {"n_agents": 4, "column_height": 1, "max_inactivity_steps": null, "max_steps": 500, "fast_obs": true, "msg_bits": 0, "sensor_range": 1, "shelf_rows": 1, "shelf_columns": 3, "request_queue_size": 4, "reward_type": "RewardType.INDIVIDUAL", "map_name": "customized_map", "map_size": "tiny", "difficulty": "medium"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": true, "force_coop": false, "local_mode": true, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 4, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 100, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64}, "algorithm": "maa2c", "space_obs": "Dict(obs:Box([-100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100.], [100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.], (112,), float32))", "space_act": "Discrete(5)", "num_agents": 4, "episode_limit": 500, "policy_mapping_info": {"all_scenario": {"description": "rware all scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2", "agent_3"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "rware_customized_map", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 10, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.policy_template.MAA2CTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x7f7c1cdf63a0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "grad_clip": 40.0, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "microbatch_size": null}, "time_since_restore": 978.2401955127716, "timesteps_since_restore": 0, "iterations_since_restore": 93, "perf": {"cpu_util_percent": 4.1866666666666665, "ram_util_percent": 83.02}}
{"episode_reward_max": 12.0, "episode_reward_min": 0.0, "episode_reward_mean": 3.3, "episode_len_mean": 500.0, "episode_media": {}, "episodes_this_iter": 20, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [2.0, 7.0, 5.0, 5.0, 7.0, 2.0, 2.0, 2.0, 5.0, 4.0, 6.0, 3.0, 4.0, 3.0, 3.0, 4.0, 5.0, 2.0, 2.0, 2.0, 4.0, 0.0, 2.0, 3.0, 2.0, 2.0, 1.0, 12.0, 4.0, 2.0, 4.0, 3.0, 6.0, 6.0, 2.0, 3.0, 4.0, 1.0, 2.0, 10.0, 1.0, 7.0, 1.0, 3.0, 2.0, 3.0, 4.0, 3.0, 4.0, 6.0, 2.0, 0.0, 2.0, 1.0, 2.0, 5.0, 2.0, 4.0, 2.0, 2.0, 7.0, 2.0, 1.0, 2.0, 4.0, 3.0, 4.0, 2.0, 4.0, 4.0, 1.0, 1.0, 10.0, 6.0, 8.0, 5.0, 6.0, 0.0, 3.0, 3.0, 3.0, 3.0, 0.0, 4.0, 1.0, 1.0, 2.0, 1.0, 2.0, 5.0, 2.0, 1.0, 5.0, 2.0, 1.0, 2.0, 2.0, 4.0, 7.0, 2.0], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.1464248428745614, "mean_inference_ms": 0.3861255824303786, "mean_action_processing_ms": 0.028373301922628748, "mean_env_wait_ms": 0.3908288141397645, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 3799040, "timesteps_this_iter": 0, "agent_timesteps_total": 3799040, "timers": {"sample_time_ms": 1325.699, "sample_throughput": 3862.113, "load_time_ms": 0.16, "load_throughput": 32080723.753, "learn_time_ms": 66.098, "learn_throughput": 77460.77, "update_time_ms": 2.806}, "info": {"learner": {"default_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 426.6291198730469, "policy_entropy": 7866.107421875, "policy_loss": 164.187744140625, "vf_loss": 78.60039520263672}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 3799040, "num_agent_steps_sampled": 3799040, "num_steps_trained": 3799040, "num_agent_steps_trained": 3799040, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 1896, "training_iteration": 94, "trial_id": "65be9_00000", "experiment_id": "b9e963105bdc4382843b68ace23a11d3", "date": "2024-06-17_16-24-59", "timestamp": 1718609099, "time_this_iter_s": 10.60722041130066, "time_total_s": 988.8474159240723, "pid": 4998, "hostname": "DESKTOP-LQ219J4", "node_ip": "192.168.46.185", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 20, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 5000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 500, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "rware", "env_args": {"n_agents": 4, "column_height": 1, "max_inactivity_steps": null, "max_steps": 500, "fast_obs": true, "msg_bits": 0, "sensor_range": 1, "shelf_rows": 1, "shelf_columns": 3, "request_queue_size": 4, "reward_type": "RewardType.INDIVIDUAL", "map_name": "customized_map", "map_size": "tiny", "difficulty": "medium"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": true, "force_coop": false, "local_mode": true, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 4, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 100, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64}, "algorithm": "maa2c", "space_obs": "Dict(obs:Box([-100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100.], [100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.], (112,), float32))", "space_act": "Discrete(5)", "num_agents": 4, "episode_limit": 500, "policy_mapping_info": {"all_scenario": {"description": "rware all scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2", "agent_3"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "rware_customized_map", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 10, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.policy_template.MAA2CTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x7f7c1d450ca0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "grad_clip": 40.0, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "microbatch_size": null}, "time_since_restore": 988.8474159240723, "timesteps_since_restore": 0, "iterations_since_restore": 94, "perf": {"cpu_util_percent": 4.333333333333333, "ram_util_percent": 83.70666666666666}}
{"episode_reward_max": 12.0, "episode_reward_min": 0.0, "episode_reward_mean": 3.24, "episode_len_mean": 500.0, "episode_media": {}, "episodes_this_iter": 24, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [2.0, 2.0, 1.0, 12.0, 4.0, 2.0, 4.0, 3.0, 6.0, 6.0, 2.0, 3.0, 4.0, 1.0, 2.0, 10.0, 1.0, 7.0, 1.0, 3.0, 2.0, 3.0, 4.0, 3.0, 4.0, 6.0, 2.0, 0.0, 2.0, 1.0, 2.0, 5.0, 2.0, 4.0, 2.0, 2.0, 7.0, 2.0, 1.0, 2.0, 4.0, 3.0, 4.0, 2.0, 4.0, 4.0, 1.0, 1.0, 10.0, 6.0, 8.0, 5.0, 6.0, 0.0, 3.0, 3.0, 3.0, 3.0, 0.0, 4.0, 1.0, 1.0, 2.0, 1.0, 2.0, 5.0, 2.0, 1.0, 5.0, 2.0, 1.0, 2.0, 2.0, 4.0, 7.0, 2.0, 10.0, 6.0, 2.0, 1.0, 2.0, 4.0, 2.0, 4.0, 3.0, 8.0, 1.0, 1.0, 1.0, 2.0, 5.0, 1.0, 8.0, 3.0, 3.0, 0.0, 3.0, 1.0, 1.0, 6.0], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.14641045118936988, "mean_inference_ms": 0.3860682782021028, "mean_action_processing_ms": 0.028368799307010518, "mean_env_wait_ms": 0.3908011019577202, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 3840000, "timesteps_this_iter": 0, "agent_timesteps_total": 3840000, "timers": {"sample_time_ms": 1324.617, "sample_throughput": 3865.269, "load_time_ms": 0.166, "load_throughput": 30823649.318, "learn_time_ms": 67.041, "learn_throughput": 76370.615, "update_time_ms": 3.128}, "info": {"learner": {"default_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 87.64946746826172, "policy_entropy": 7918.71923828125, "policy_loss": 9.200647354125977, "vf_loss": 37.06327438354492}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 3840000, "num_agent_steps_sampled": 3840000, "num_steps_trained": 3840000, "num_agent_steps_trained": 3840000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 1920, "training_iteration": 95, "trial_id": "65be9_00000", "experiment_id": "b9e963105bdc4382843b68ace23a11d3", "date": "2024-06-17_16-25-09", "timestamp": 1718609109, "time_this_iter_s": 10.627189874649048, "time_total_s": 999.4746057987213, "pid": 4998, "hostname": "DESKTOP-LQ219J4", "node_ip": "192.168.46.185", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 20, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 5000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 500, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "rware", "env_args": {"n_agents": 4, "column_height": 1, "max_inactivity_steps": null, "max_steps": 500, "fast_obs": true, "msg_bits": 0, "sensor_range": 1, "shelf_rows": 1, "shelf_columns": 3, "request_queue_size": 4, "reward_type": "RewardType.INDIVIDUAL", "map_name": "customized_map", "map_size": "tiny", "difficulty": "medium"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": true, "force_coop": false, "local_mode": true, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 4, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 100, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64}, "algorithm": "maa2c", "space_obs": "Dict(obs:Box([-100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100.], [100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.], (112,), float32))", "space_act": "Discrete(5)", "num_agents": 4, "episode_limit": 500, "policy_mapping_info": {"all_scenario": {"description": "rware all scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2", "agent_3"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "rware_customized_map", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 10, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.policy_template.MAA2CTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x7f7c1afbb040>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "grad_clip": 40.0, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "microbatch_size": null}, "time_since_restore": 999.4746057987213, "timesteps_since_restore": 0, "iterations_since_restore": 95, "perf": {"cpu_util_percent": 4.073333333333333, "ram_util_percent": 84.33333333333331}}
{"episode_reward_max": 10.0, "episode_reward_min": 0.0, "episode_reward_mean": 3.16, "episode_len_mean": 500.0, "episode_media": {}, "episodes_this_iter": 20, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [2.0, 3.0, 4.0, 3.0, 4.0, 6.0, 2.0, 0.0, 2.0, 1.0, 2.0, 5.0, 2.0, 4.0, 2.0, 2.0, 7.0, 2.0, 1.0, 2.0, 4.0, 3.0, 4.0, 2.0, 4.0, 4.0, 1.0, 1.0, 10.0, 6.0, 8.0, 5.0, 6.0, 0.0, 3.0, 3.0, 3.0, 3.0, 0.0, 4.0, 1.0, 1.0, 2.0, 1.0, 2.0, 5.0, 2.0, 1.0, 5.0, 2.0, 1.0, 2.0, 2.0, 4.0, 7.0, 2.0, 10.0, 6.0, 2.0, 1.0, 2.0, 4.0, 2.0, 4.0, 3.0, 8.0, 1.0, 1.0, 1.0, 2.0, 5.0, 1.0, 8.0, 3.0, 3.0, 0.0, 3.0, 1.0, 1.0, 6.0, 2.0, 4.0, 6.0, 6.0, 2.0, 2.0, 2.0, 2.0, 3.0, 4.0, 4.0, 1.0, 5.0, 2.0, 7.0, 2.0, 0.0, 6.0, 3.0, 5.0], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.14641155567962139, "mean_inference_ms": 0.3860491363983467, "mean_action_processing_ms": 0.028367130509418324, "mean_env_wait_ms": 0.39076818334528923, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 3880960, "timesteps_this_iter": 0, "agent_timesteps_total": 3880960, "timers": {"sample_time_ms": 1318.664, "sample_throughput": 3882.718, "load_time_ms": 0.159, "load_throughput": 32288131.83, "learn_time_ms": 67.154, "learn_throughput": 76242.691, "update_time_ms": 2.907}, "info": {"learner": {"default_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 330.8487548828125, "policy_entropy": 7816.44189453125, "policy_loss": 114.14057922363281, "vf_loss": 76.5894775390625}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 3880960, "num_agent_steps_sampled": 3880960, "num_steps_trained": 3880960, "num_agent_steps_trained": 3880960, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 1940, "training_iteration": 96, "trial_id": "65be9_00000", "experiment_id": "b9e963105bdc4382843b68ace23a11d3", "date": "2024-06-17_16-25-20", "timestamp": 1718609120, "time_this_iter_s": 10.469962358474731, "time_total_s": 1009.944568157196, "pid": 4998, "hostname": "DESKTOP-LQ219J4", "node_ip": "192.168.46.185", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 20, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 5000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 500, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "rware", "env_args": {"n_agents": 4, "column_height": 1, "max_inactivity_steps": null, "max_steps": 500, "fast_obs": true, "msg_bits": 0, "sensor_range": 1, "shelf_rows": 1, "shelf_columns": 3, "request_queue_size": 4, "reward_type": "RewardType.INDIVIDUAL", "map_name": "customized_map", "map_size": "tiny", "difficulty": "medium"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": true, "force_coop": false, "local_mode": true, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 4, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 100, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64}, "algorithm": "maa2c", "space_obs": "Dict(obs:Box([-100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100.], [100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.], (112,), float32))", "space_act": "Discrete(5)", "num_agents": 4, "episode_limit": 500, "policy_mapping_info": {"all_scenario": {"description": "rware all scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2", "agent_3"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "rware_customized_map", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 10, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.policy_template.MAA2CTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x7f7c1d4500d0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "grad_clip": 40.0, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "microbatch_size": null}, "time_since_restore": 1009.944568157196, "timesteps_since_restore": 0, "iterations_since_restore": 96, "perf": {"cpu_util_percent": 4.1466666666666665, "ram_util_percent": 84.98666666666666}}
{"episode_reward_max": 10.0, "episode_reward_min": 0.0, "episode_reward_mean": 3.36, "episode_len_mean": 500.0, "episode_media": {}, "episodes_this_iter": 20, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [4.0, 3.0, 4.0, 2.0, 4.0, 4.0, 1.0, 1.0, 10.0, 6.0, 8.0, 5.0, 6.0, 0.0, 3.0, 3.0, 3.0, 3.0, 0.0, 4.0, 1.0, 1.0, 2.0, 1.0, 2.0, 5.0, 2.0, 1.0, 5.0, 2.0, 1.0, 2.0, 2.0, 4.0, 7.0, 2.0, 10.0, 6.0, 2.0, 1.0, 2.0, 4.0, 2.0, 4.0, 3.0, 8.0, 1.0, 1.0, 1.0, 2.0, 5.0, 1.0, 8.0, 3.0, 3.0, 0.0, 3.0, 1.0, 1.0, 6.0, 2.0, 4.0, 6.0, 6.0, 2.0, 2.0, 2.0, 2.0, 3.0, 4.0, 4.0, 1.0, 5.0, 2.0, 7.0, 2.0, 0.0, 6.0, 3.0, 5.0, 3.0, 4.0, 5.0, 3.0, 4.0, 2.0, 4.0, 1.0, 3.0, 3.0, 5.0, 6.0, 3.0, 4.0, 3.0, 6.0, 4.0, 4.0, 5.0, 4.0], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.1464107592243304, "mean_inference_ms": 0.3860263772632402, "mean_action_processing_ms": 0.02836519543033045, "mean_env_wait_ms": 0.3907365812245419, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 3921920, "timesteps_this_iter": 0, "agent_timesteps_total": 3921920, "timers": {"sample_time_ms": 1323.026, "sample_throughput": 3869.917, "load_time_ms": 0.164, "load_throughput": 31141004.176, "learn_time_ms": 66.762, "learn_throughput": 76690.723, "update_time_ms": 2.971}, "info": {"learner": {"default_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 148.7020263671875, "policy_entropy": 7912.033203125, "policy_loss": -80.84210205078125, "vf_loss": 40.20555114746094}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 3921920, "num_agent_steps_sampled": 3921920, "num_steps_trained": 3921920, "num_agent_steps_trained": 3921920, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 1960, "training_iteration": 97, "trial_id": "65be9_00000", "experiment_id": "b9e963105bdc4382843b68ace23a11d3", "date": "2024-06-17_16-25-31", "timestamp": 1718609131, "time_this_iter_s": 10.590981006622314, "time_total_s": 1020.5355491638184, "pid": 4998, "hostname": "DESKTOP-LQ219J4", "node_ip": "192.168.46.185", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 20, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 5000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 500, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "rware", "env_args": {"n_agents": 4, "column_height": 1, "max_inactivity_steps": null, "max_steps": 500, "fast_obs": true, "msg_bits": 0, "sensor_range": 1, "shelf_rows": 1, "shelf_columns": 3, "request_queue_size": 4, "reward_type": "RewardType.INDIVIDUAL", "map_name": "customized_map", "map_size": "tiny", "difficulty": "medium"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": true, "force_coop": false, "local_mode": true, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 4, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 100, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64}, "algorithm": "maa2c", "space_obs": "Dict(obs:Box([-100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100.], [100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.], (112,), float32))", "space_act": "Discrete(5)", "num_agents": 4, "episode_limit": 500, "policy_mapping_info": {"all_scenario": {"description": "rware all scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2", "agent_3"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "rware_customized_map", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 10, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.policy_template.MAA2CTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x7f7c1aff21f0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "grad_clip": 40.0, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "microbatch_size": null}, "time_since_restore": 1020.5355491638184, "timesteps_since_restore": 0, "iterations_since_restore": 97, "perf": {"cpu_util_percent": 4.20625, "ram_util_percent": 85.68125}}
{"episode_reward_max": 10.0, "episode_reward_min": 0.0, "episode_reward_mean": 3.28, "episode_len_mean": 500.0, "episode_media": {}, "episodes_this_iter": 20, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [1.0, 1.0, 2.0, 1.0, 2.0, 5.0, 2.0, 1.0, 5.0, 2.0, 1.0, 2.0, 2.0, 4.0, 7.0, 2.0, 10.0, 6.0, 2.0, 1.0, 2.0, 4.0, 2.0, 4.0, 3.0, 8.0, 1.0, 1.0, 1.0, 2.0, 5.0, 1.0, 8.0, 3.0, 3.0, 0.0, 3.0, 1.0, 1.0, 6.0, 2.0, 4.0, 6.0, 6.0, 2.0, 2.0, 2.0, 2.0, 3.0, 4.0, 4.0, 1.0, 5.0, 2.0, 7.0, 2.0, 0.0, 6.0, 3.0, 5.0, 3.0, 4.0, 5.0, 3.0, 4.0, 2.0, 4.0, 1.0, 3.0, 3.0, 5.0, 6.0, 3.0, 4.0, 3.0, 6.0, 4.0, 4.0, 5.0, 4.0, 2.0, 3.0, 3.0, 4.0, 7.0, 3.0, 2.0, 2.0, 1.0, 2.0, 2.0, 1.0, 3.0, 7.0, 2.0, 6.0, 3.0, 6.0, 4.0, 3.0], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.14641230898556193, "mean_inference_ms": 0.3860083398337892, "mean_action_processing_ms": 0.02836393956755055, "mean_env_wait_ms": 0.3907019387684809, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 3962880, "timesteps_this_iter": 0, "agent_timesteps_total": 3962880, "timers": {"sample_time_ms": 1326.823, "sample_throughput": 3858.843, "load_time_ms": 0.158, "load_throughput": 32424636.086, "learn_time_ms": 66.488, "learn_throughput": 77006.704, "update_time_ms": 3.027}, "info": {"learner": {"default_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 169.700439453125, "policy_entropy": 7938.13720703125, "policy_loss": 42.59827423095703, "vf_loss": 47.92262268066406}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 3962880, "num_agent_steps_sampled": 3962880, "num_steps_trained": 3962880, "num_agent_steps_trained": 3962880, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 1980, "training_iteration": 98, "trial_id": "65be9_00000", "experiment_id": "b9e963105bdc4382843b68ace23a11d3", "date": "2024-06-17_16-25-41", "timestamp": 1718609141, "time_this_iter_s": 10.621497631072998, "time_total_s": 1031.1570467948914, "pid": 4998, "hostname": "DESKTOP-LQ219J4", "node_ip": "192.168.46.185", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 20, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 5000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 500, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "rware", "env_args": {"n_agents": 4, "column_height": 1, "max_inactivity_steps": null, "max_steps": 500, "fast_obs": true, "msg_bits": 0, "sensor_range": 1, "shelf_rows": 1, "shelf_columns": 3, "request_queue_size": 4, "reward_type": "RewardType.INDIVIDUAL", "map_name": "customized_map", "map_size": "tiny", "difficulty": "medium"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": true, "force_coop": false, "local_mode": true, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 4, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 100, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64}, "algorithm": "maa2c", "space_obs": "Dict(obs:Box([-100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100.], [100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.], (112,), float32))", "space_act": "Discrete(5)", "num_agents": 4, "episode_limit": 500, "policy_mapping_info": {"all_scenario": {"description": "rware all scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2", "agent_3"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "rware_customized_map", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 10, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.policy_template.MAA2CTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x7f7c1afbcaf0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "grad_clip": 40.0, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "microbatch_size": null}, "time_since_restore": 1031.1570467948914, "timesteps_since_restore": 0, "iterations_since_restore": 98, "perf": {"cpu_util_percent": 4.133333333333334, "ram_util_percent": 86.36666666666665}}
{"episode_reward_max": 9.0, "episode_reward_min": 0.0, "episode_reward_mean": 3.47, "episode_len_mean": 500.0, "episode_media": {}, "episodes_this_iter": 20, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [2.0, 4.0, 2.0, 4.0, 3.0, 8.0, 1.0, 1.0, 1.0, 2.0, 5.0, 1.0, 8.0, 3.0, 3.0, 0.0, 3.0, 1.0, 1.0, 6.0, 2.0, 4.0, 6.0, 6.0, 2.0, 2.0, 2.0, 2.0, 3.0, 4.0, 4.0, 1.0, 5.0, 2.0, 7.0, 2.0, 0.0, 6.0, 3.0, 5.0, 3.0, 4.0, 5.0, 3.0, 4.0, 2.0, 4.0, 1.0, 3.0, 3.0, 5.0, 6.0, 3.0, 4.0, 3.0, 6.0, 4.0, 4.0, 5.0, 4.0, 2.0, 3.0, 3.0, 4.0, 7.0, 3.0, 2.0, 2.0, 1.0, 2.0, 2.0, 1.0, 3.0, 7.0, 2.0, 6.0, 3.0, 6.0, 4.0, 3.0, 1.0, 6.0, 3.0, 1.0, 8.0, 5.0, 5.0, 3.0, 1.0, 9.0, 2.0, 4.0, 3.0, 5.0, 4.0, 6.0, 3.0, 5.0, 2.0, 2.0], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.14641367976789696, "mean_inference_ms": 0.38598891388705586, "mean_action_processing_ms": 0.02836261325573266, "mean_env_wait_ms": 0.3906651355374261, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 4003840, "timesteps_this_iter": 0, "agent_timesteps_total": 4003840, "timers": {"sample_time_ms": 1325.459, "sample_throughput": 3862.813, "load_time_ms": 0.165, "load_throughput": 30997165.82, "learn_time_ms": 66.455, "learn_throughput": 77044.139, "update_time_ms": 2.83}, "info": {"learner": {"default_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 142.48455810546875, "policy_entropy": 7879.09814453125, "policy_loss": -65.37615966796875, "vf_loss": 31.450031280517578}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 4003840, "num_agent_steps_sampled": 4003840, "num_steps_trained": 4003840, "num_agent_steps_trained": 4003840, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 2000, "training_iteration": 99, "trial_id": "65be9_00000", "experiment_id": "b9e963105bdc4382843b68ace23a11d3", "date": "2024-06-17_16-25-52", "timestamp": 1718609152, "time_this_iter_s": 10.52107048034668, "time_total_s": 1041.678117275238, "pid": 4998, "hostname": "DESKTOP-LQ219J4", "node_ip": "192.168.46.185", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 20, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 5000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 500, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "rware", "env_args": {"n_agents": 4, "column_height": 1, "max_inactivity_steps": null, "max_steps": 500, "fast_obs": true, "msg_bits": 0, "sensor_range": 1, "shelf_rows": 1, "shelf_columns": 3, "request_queue_size": 4, "reward_type": "RewardType.INDIVIDUAL", "map_name": "customized_map", "map_size": "tiny", "difficulty": "medium"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": true, "force_coop": false, "local_mode": true, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 4, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 100, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64}, "algorithm": "maa2c", "space_obs": "Dict(obs:Box([-100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100.], [100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.], (112,), float32))", "space_act": "Discrete(5)", "num_agents": 4, "episode_limit": 500, "policy_mapping_info": {"all_scenario": {"description": "rware all scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2", "agent_3"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "rware_customized_map", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 10, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.policy_template.MAA2CTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x7f7c1d170f70>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "grad_clip": 40.0, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "microbatch_size": null}, "time_since_restore": 1041.678117275238, "timesteps_since_restore": 0, "iterations_since_restore": 99, "perf": {"cpu_util_percent": 3.986666666666667, "ram_util_percent": 87.02}}
{"episode_reward_max": 9.0, "episode_reward_min": 0.0, "episode_reward_mean": 3.75, "episode_len_mean": 500.0, "episode_media": {}, "episodes_this_iter": 20, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [2.0, 4.0, 6.0, 6.0, 2.0, 2.0, 2.0, 2.0, 3.0, 4.0, 4.0, 1.0, 5.0, 2.0, 7.0, 2.0, 0.0, 6.0, 3.0, 5.0, 3.0, 4.0, 5.0, 3.0, 4.0, 2.0, 4.0, 1.0, 3.0, 3.0, 5.0, 6.0, 3.0, 4.0, 3.0, 6.0, 4.0, 4.0, 5.0, 4.0, 2.0, 3.0, 3.0, 4.0, 7.0, 3.0, 2.0, 2.0, 1.0, 2.0, 2.0, 1.0, 3.0, 7.0, 2.0, 6.0, 3.0, 6.0, 4.0, 3.0, 1.0, 6.0, 3.0, 1.0, 8.0, 5.0, 5.0, 3.0, 1.0, 9.0, 2.0, 4.0, 3.0, 5.0, 4.0, 6.0, 3.0, 5.0, 2.0, 2.0, 3.0, 4.0, 2.0, 1.0, 7.0, 9.0, 2.0, 7.0, 5.0, 4.0, 1.0, 4.0, 7.0, 4.0, 5.0, 3.0, 8.0, 1.0, 3.0, 7.0], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.1464318649560363, "mean_inference_ms": 0.38600535970490113, "mean_action_processing_ms": 0.0283636662041822, "mean_env_wait_ms": 0.3906563371521575, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 4044800, "timesteps_this_iter": 0, "agent_timesteps_total": 4044800, "timers": {"sample_time_ms": 1329.185, "sample_throughput": 3851.985, "load_time_ms": 0.16, "load_throughput": 32075932.009, "learn_time_ms": 66.549, "learn_throughput": 76936.298, "update_time_ms": 2.967}, "info": {"learner": {"default_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 149.2393341064453, "policy_entropy": 7869.4501953125, "policy_loss": -78.70977783203125, "vf_loss": 56.244873046875}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 4044800, "num_agent_steps_sampled": 4044800, "num_steps_trained": 4044800, "num_agent_steps_trained": 4044800, "num_steps_trained_this_iter": 0}, "evaluation": {"episode_reward_max": 10.0, "episode_reward_min": 1.0, "episode_reward_mean": 2.9, "episode_len_mean": 500.0, "episode_media": {}, "episodes_this_iter": 10, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [1.0, 10.0, 1.0, 3.0, 1.0, 3.0, 3.0, 5.0, 1.0, 1.0], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.09064583310650867, "mean_inference_ms": 0.39588631468884367, "mean_action_processing_ms": 0.027264848779099137, "mean_env_wait_ms": 0.3761498764292882, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}}, "done": false, "episodes_total": 2020, "training_iteration": 100, "trial_id": "65be9_00000", "experiment_id": "b9e963105bdc4382843b68ace23a11d3", "date": "2024-06-17_16-26-07", "timestamp": 1718609167, "time_this_iter_s": 15.1080482006073, "time_total_s": 1056.7861654758453, "pid": 4998, "hostname": "DESKTOP-LQ219J4", "node_ip": "192.168.46.185", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 20, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 5000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 500, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "rware", "env_args": {"n_agents": 4, "column_height": 1, "max_inactivity_steps": null, "max_steps": 500, "fast_obs": true, "msg_bits": 0, "sensor_range": 1, "shelf_rows": 1, "shelf_columns": 3, "request_queue_size": 4, "reward_type": "RewardType.INDIVIDUAL", "map_name": "customized_map", "map_size": "tiny", "difficulty": "medium"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": true, "force_coop": false, "local_mode": true, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 4, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 100, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64}, "algorithm": "maa2c", "space_obs": "Dict(obs:Box([-100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100.], [100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.], (112,), float32))", "space_act": "Discrete(5)", "num_agents": 4, "episode_limit": 500, "policy_mapping_info": {"all_scenario": {"description": "rware all scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2", "agent_3"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "rware_customized_map", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 10, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.policy_template.MAA2CTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x7f7c1aff2790>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "grad_clip": 40.0, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "microbatch_size": null}, "time_since_restore": 1056.7861654758453, "timesteps_since_restore": 0, "iterations_since_restore": 100, "perf": {"cpu_util_percent": 3.9666666666666663, "ram_util_percent": 87.76190476190476}}
{"episode_reward_max": 9.0, "episode_reward_min": 0.0, "episode_reward_mean": 3.81, "episode_len_mean": 500.0, "episode_media": {}, "episodes_this_iter": 12, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [5.0, 2.0, 7.0, 2.0, 0.0, 6.0, 3.0, 5.0, 3.0, 4.0, 5.0, 3.0, 4.0, 2.0, 4.0, 1.0, 3.0, 3.0, 5.0, 6.0, 3.0, 4.0, 3.0, 6.0, 4.0, 4.0, 5.0, 4.0, 2.0, 3.0, 3.0, 4.0, 7.0, 3.0, 2.0, 2.0, 1.0, 2.0, 2.0, 1.0, 3.0, 7.0, 2.0, 6.0, 3.0, 6.0, 4.0, 3.0, 1.0, 6.0, 3.0, 1.0, 8.0, 5.0, 5.0, 3.0, 1.0, 9.0, 2.0, 4.0, 3.0, 5.0, 4.0, 6.0, 3.0, 5.0, 2.0, 2.0, 3.0, 4.0, 2.0, 1.0, 7.0, 9.0, 2.0, 7.0, 5.0, 4.0, 1.0, 4.0, 7.0, 4.0, 5.0, 3.0, 8.0, 1.0, 3.0, 7.0, 2.0, 1.0, 6.0, 3.0, 4.0, 5.0, 3.0, 2.0, 5.0, 6.0, 5.0, 2.0], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.14642114207967388, "mean_inference_ms": 0.38597592898086114, "mean_action_processing_ms": 0.028361044689919738, "mean_env_wait_ms": 0.39068267161008785, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 4070400, "timesteps_this_iter": 0, "agent_timesteps_total": 4070400, "timers": {"sample_time_ms": 1772.38, "sample_throughput": 2888.77, "load_time_ms": 0.157, "load_throughput": 32547493.907, "learn_time_ms": 67.124, "learn_throughput": 76276.352, "update_time_ms": 2.992}, "info": {"learner": {"default_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 72.15400695800781, "policy_entropy": 7887.9638671875, "policy_loss": -9.152803421020508, "vf_loss": 40.55243682861328}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 4070400, "num_agent_steps_sampled": 4070400, "num_steps_trained": 4070400, "num_agent_steps_trained": 4070400, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 2032, "training_iteration": 101, "trial_id": "65be9_00000", "experiment_id": "b9e963105bdc4382843b68ace23a11d3", "date": "2024-06-17_16-26-14", "timestamp": 1718609174, "time_this_iter_s": 6.666277170181274, "time_total_s": 1063.4524426460266, "pid": 4998, "hostname": "DESKTOP-LQ219J4", "node_ip": "192.168.46.185", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 20, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 5000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 500, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "rware", "env_args": {"n_agents": 4, "column_height": 1, "max_inactivity_steps": null, "max_steps": 500, "fast_obs": true, "msg_bits": 0, "sensor_range": 1, "shelf_rows": 1, "shelf_columns": 3, "request_queue_size": 4, "reward_type": "RewardType.INDIVIDUAL", "map_name": "customized_map", "map_size": "tiny", "difficulty": "medium"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": true, "force_coop": false, "local_mode": true, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 4, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 100, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64}, "algorithm": "maa2c", "space_obs": "Dict(obs:Box([-100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100.], [100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.], (112,), float32))", "space_act": "Discrete(5)", "num_agents": 4, "episode_limit": 500, "policy_mapping_info": {"all_scenario": {"description": "rware all scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2", "agent_3"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "rware_customized_map", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 10, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.policy_template.MAA2CTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x7f7c1aff2940>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "grad_clip": 40.0, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "microbatch_size": null}, "time_since_restore": 1063.4524426460266, "timesteps_since_restore": 0, "iterations_since_restore": 101, "perf": {"cpu_util_percent": 4.13, "ram_util_percent": 88.2}}
{"episode_reward_max": 9.0, "episode_reward_min": 0.0, "episode_reward_mean": 3.66, "episode_len_mean": 500.0, "episode_media": {}, "episodes_this_iter": 20, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [3.0, 4.0, 3.0, 6.0, 4.0, 4.0, 5.0, 4.0, 2.0, 3.0, 3.0, 4.0, 7.0, 3.0, 2.0, 2.0, 1.0, 2.0, 2.0, 1.0, 3.0, 7.0, 2.0, 6.0, 3.0, 6.0, 4.0, 3.0, 1.0, 6.0, 3.0, 1.0, 8.0, 5.0, 5.0, 3.0, 1.0, 9.0, 2.0, 4.0, 3.0, 5.0, 4.0, 6.0, 3.0, 5.0, 2.0, 2.0, 3.0, 4.0, 2.0, 1.0, 7.0, 9.0, 2.0, 7.0, 5.0, 4.0, 1.0, 4.0, 7.0, 4.0, 5.0, 3.0, 8.0, 1.0, 3.0, 7.0, 2.0, 1.0, 6.0, 3.0, 4.0, 5.0, 3.0, 2.0, 5.0, 6.0, 5.0, 2.0, 2.0, 3.0, 2.0, 2.0, 3.0, 1.0, 2.0, 0.0, 1.0, 3.0, 4.0, 4.0, 5.0, 4.0, 7.0, 5.0, 3.0, 3.0, 2.0, 2.0], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.1464262652103263, "mean_inference_ms": 0.3859680015196716, "mean_action_processing_ms": 0.028360568799472893, "mean_env_wait_ms": 0.39066419032344973, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 4111360, "timesteps_this_iter": 0, "agent_timesteps_total": 4111360, "timers": {"sample_time_ms": 1330.219, "sample_throughput": 3848.99, "load_time_ms": 0.156, "load_throughput": 32721067.317, "learn_time_ms": 67.241, "learn_throughput": 76143.748, "update_time_ms": 3.004}, "info": {"learner": {"default_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 435.9892578125, "policy_entropy": 7927.55029296875, "policy_loss": 167.66909790039062, "vf_loss": 121.226318359375}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 4111360, "num_agent_steps_sampled": 4111360, "num_steps_trained": 4111360, "num_agent_steps_trained": 4111360, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 2052, "training_iteration": 102, "trial_id": "65be9_00000", "experiment_id": "b9e963105bdc4382843b68ace23a11d3", "date": "2024-06-17_16-26-24", "timestamp": 1718609184, "time_this_iter_s": 10.573295593261719, "time_total_s": 1074.0257382392883, "pid": 4998, "hostname": "DESKTOP-LQ219J4", "node_ip": "192.168.46.185", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 20, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 5000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 500, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "rware", "env_args": {"n_agents": 4, "column_height": 1, "max_inactivity_steps": null, "max_steps": 500, "fast_obs": true, "msg_bits": 0, "sensor_range": 1, "shelf_rows": 1, "shelf_columns": 3, "request_queue_size": 4, "reward_type": "RewardType.INDIVIDUAL", "map_name": "customized_map", "map_size": "tiny", "difficulty": "medium"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": true, "force_coop": false, "local_mode": true, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 4, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 100, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64}, "algorithm": "maa2c", "space_obs": "Dict(obs:Box([-100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100.], [100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.], (112,), float32))", "space_act": "Discrete(5)", "num_agents": 4, "episode_limit": 500, "policy_mapping_info": {"all_scenario": {"description": "rware all scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2", "agent_3"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "rware_customized_map", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 10, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.policy_template.MAA2CTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x7f7c768b73a0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "grad_clip": 40.0, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "microbatch_size": null}, "time_since_restore": 1074.0257382392883, "timesteps_since_restore": 0, "iterations_since_restore": 102, "perf": {"cpu_util_percent": 4.24, "ram_util_percent": 88.76666666666667}}
{"episode_reward_max": 13.0, "episode_reward_min": 0.0, "episode_reward_mean": 3.84, "episode_len_mean": 500.0, "episode_media": {}, "episodes_this_iter": 24, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [3.0, 6.0, 4.0, 3.0, 1.0, 6.0, 3.0, 1.0, 8.0, 5.0, 5.0, 3.0, 1.0, 9.0, 2.0, 4.0, 3.0, 5.0, 4.0, 6.0, 3.0, 5.0, 2.0, 2.0, 3.0, 4.0, 2.0, 1.0, 7.0, 9.0, 2.0, 7.0, 5.0, 4.0, 1.0, 4.0, 7.0, 4.0, 5.0, 3.0, 8.0, 1.0, 3.0, 7.0, 2.0, 1.0, 6.0, 3.0, 4.0, 5.0, 3.0, 2.0, 5.0, 6.0, 5.0, 2.0, 2.0, 3.0, 2.0, 2.0, 3.0, 1.0, 2.0, 0.0, 1.0, 3.0, 4.0, 4.0, 5.0, 4.0, 7.0, 5.0, 3.0, 3.0, 2.0, 2.0, 9.0, 8.0, 9.0, 3.0, 3.0, 4.0, 2.0, 2.0, 4.0, 3.0, 4.0, 2.0, 3.0, 1.0, 2.0, 9.0, 2.0, 6.0, 13.0, 4.0, 3.0, 2.0, 2.0, 1.0], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.14643908074435086, "mean_inference_ms": 0.38596067784133664, "mean_action_processing_ms": 0.02836093285266956, "mean_env_wait_ms": 0.39059136512440323, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 4152320, "timesteps_this_iter": 0, "agent_timesteps_total": 4152320, "timers": {"sample_time_ms": 1330.166, "sample_throughput": 3849.143, "load_time_ms": 0.151, "load_throughput": 33861300.032, "learn_time_ms": 66.641, "learn_throughput": 76829.198, "update_time_ms": 2.855}, "info": {"learner": {"default_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 225.57659912109375, "policy_entropy": 7928.40087890625, "policy_loss": -124.61868286132812, "vf_loss": 22.794395446777344}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 4152320, "num_agent_steps_sampled": 4152320, "num_steps_trained": 4152320, "num_agent_steps_trained": 4152320, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 2076, "training_iteration": 103, "trial_id": "65be9_00000", "experiment_id": "b9e963105bdc4382843b68ace23a11d3", "date": "2024-06-17_16-26-35", "timestamp": 1718609195, "time_this_iter_s": 10.628222703933716, "time_total_s": 1084.653960943222, "pid": 4998, "hostname": "DESKTOP-LQ219J4", "node_ip": "192.168.46.185", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 20, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 5000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 500, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "rware", "env_args": {"n_agents": 4, "column_height": 1, "max_inactivity_steps": null, "max_steps": 500, "fast_obs": true, "msg_bits": 0, "sensor_range": 1, "shelf_rows": 1, "shelf_columns": 3, "request_queue_size": 4, "reward_type": "RewardType.INDIVIDUAL", "map_name": "customized_map", "map_size": "tiny", "difficulty": "medium"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": true, "force_coop": false, "local_mode": true, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 4, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 100, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64}, "algorithm": "maa2c", "space_obs": "Dict(obs:Box([-100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100.], [100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.], (112,), float32))", "space_act": "Discrete(5)", "num_agents": 4, "episode_limit": 500, "policy_mapping_info": {"all_scenario": {"description": "rware all scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2", "agent_3"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "rware_customized_map", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 10, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.policy_template.MAA2CTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x7f7c7688eee0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "grad_clip": 40.0, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "microbatch_size": null}, "time_since_restore": 1084.653960943222, "timesteps_since_restore": 0, "iterations_since_restore": 103, "perf": {"cpu_util_percent": 4.5, "ram_util_percent": 89.41333333333334}}
{"episode_reward_max": 13.0, "episode_reward_min": 0.0, "episode_reward_mean": 3.53, "episode_len_mean": 500.0, "episode_media": {}, "episodes_this_iter": 20, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [3.0, 5.0, 2.0, 2.0, 3.0, 4.0, 2.0, 1.0, 7.0, 9.0, 2.0, 7.0, 5.0, 4.0, 1.0, 4.0, 7.0, 4.0, 5.0, 3.0, 8.0, 1.0, 3.0, 7.0, 2.0, 1.0, 6.0, 3.0, 4.0, 5.0, 3.0, 2.0, 5.0, 6.0, 5.0, 2.0, 2.0, 3.0, 2.0, 2.0, 3.0, 1.0, 2.0, 0.0, 1.0, 3.0, 4.0, 4.0, 5.0, 4.0, 7.0, 5.0, 3.0, 3.0, 2.0, 2.0, 9.0, 8.0, 9.0, 3.0, 3.0, 4.0, 2.0, 2.0, 4.0, 3.0, 4.0, 2.0, 3.0, 1.0, 2.0, 9.0, 2.0, 6.0, 13.0, 4.0, 3.0, 2.0, 2.0, 1.0, 2.0, 0.0, 4.0, 1.0, 5.0, 1.0, 3.0, 6.0, 1.0, 3.0, 5.0, 1.0, 4.0, 1.0, 1.0, 1.0, 2.0, 4.0, 4.0, 2.0], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.14644584376242537, "mean_inference_ms": 0.3859546833279247, "mean_action_processing_ms": 0.028360119532043235, "mean_env_wait_ms": 0.39058278004529723, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 4193280, "timesteps_this_iter": 0, "agent_timesteps_total": 4193280, "timers": {"sample_time_ms": 1326.555, "sample_throughput": 3859.62, "load_time_ms": 0.148, "load_throughput": 34664788.507, "learn_time_ms": 66.903, "learn_throughput": 76529.175, "update_time_ms": 2.889}, "info": {"learner": {"default_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 103.64639282226562, "policy_entropy": 7887.1591796875, "policy_loss": -21.77400779724121, "vf_loss": 40.90424346923828}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 4193280, "num_agent_steps_sampled": 4193280, "num_steps_trained": 4193280, "num_agent_steps_trained": 4193280, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 2096, "training_iteration": 104, "trial_id": "65be9_00000", "experiment_id": "b9e963105bdc4382843b68ace23a11d3", "date": "2024-06-17_16-26-45", "timestamp": 1718609205, "time_this_iter_s": 10.619879007339478, "time_total_s": 1095.2738399505615, "pid": 4998, "hostname": "DESKTOP-LQ219J4", "node_ip": "192.168.46.185", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 20, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 5000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 500, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "rware", "env_args": {"n_agents": 4, "column_height": 1, "max_inactivity_steps": null, "max_steps": 500, "fast_obs": true, "msg_bits": 0, "sensor_range": 1, "shelf_rows": 1, "shelf_columns": 3, "request_queue_size": 4, "reward_type": "RewardType.INDIVIDUAL", "map_name": "customized_map", "map_size": "tiny", "difficulty": "medium"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": true, "force_coop": false, "local_mode": true, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 4, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 100, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64}, "algorithm": "maa2c", "space_obs": "Dict(obs:Box([-100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100.], [100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.], (112,), float32))", "space_act": "Discrete(5)", "num_agents": 4, "episode_limit": 500, "policy_mapping_info": {"all_scenario": {"description": "rware all scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2", "agent_3"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "rware_customized_map", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 10, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.policy_template.MAA2CTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x7f7c1d170d30>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "grad_clip": 40.0, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "microbatch_size": null}, "time_since_restore": 1095.2738399505615, "timesteps_since_restore": 0, "iterations_since_restore": 104, "perf": {"cpu_util_percent": 4.506666666666666, "ram_util_percent": 90.06}}
{"episode_reward_max": 13.0, "episode_reward_min": 0.0, "episode_reward_mean": 3.51, "episode_len_mean": 500.0, "episode_media": {}, "episodes_this_iter": 20, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [8.0, 1.0, 3.0, 7.0, 2.0, 1.0, 6.0, 3.0, 4.0, 5.0, 3.0, 2.0, 5.0, 6.0, 5.0, 2.0, 2.0, 3.0, 2.0, 2.0, 3.0, 1.0, 2.0, 0.0, 1.0, 3.0, 4.0, 4.0, 5.0, 4.0, 7.0, 5.0, 3.0, 3.0, 2.0, 2.0, 9.0, 8.0, 9.0, 3.0, 3.0, 4.0, 2.0, 2.0, 4.0, 3.0, 4.0, 2.0, 3.0, 1.0, 2.0, 9.0, 2.0, 6.0, 13.0, 4.0, 3.0, 2.0, 2.0, 1.0, 2.0, 0.0, 4.0, 1.0, 5.0, 1.0, 3.0, 6.0, 1.0, 3.0, 5.0, 1.0, 4.0, 1.0, 1.0, 1.0, 2.0, 4.0, 4.0, 2.0, 3.0, 5.0, 2.0, 5.0, 1.0, 0.0, 1.0, 5.0, 4.0, 9.0, 5.0, 5.0, 11.0, 7.0, 5.0, 2.0, 2.0, 3.0, 1.0, 2.0], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.14645544894722634, "mean_inference_ms": 0.3859518632874305, "mean_action_processing_ms": 0.028359392735420364, "mean_env_wait_ms": 0.39055927119289213, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 4234240, "timesteps_this_iter": 0, "agent_timesteps_total": 4234240, "timers": {"sample_time_ms": 1323.976, "sample_throughput": 3867.14, "load_time_ms": 0.161, "load_throughput": 31814572.563, "learn_time_ms": 66.858, "learn_throughput": 76580.591, "update_time_ms": 2.944}, "info": {"learner": {"default_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 86.99608612060547, "policy_entropy": 7870.9375, "policy_loss": -27.39474868774414, "vf_loss": 57.606876373291016}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 4234240, "num_agent_steps_sampled": 4234240, "num_steps_trained": 4234240, "num_agent_steps_trained": 4234240, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 2116, "training_iteration": 105, "trial_id": "65be9_00000", "experiment_id": "b9e963105bdc4382843b68ace23a11d3", "date": "2024-06-17_16-26-56", "timestamp": 1718609216, "time_this_iter_s": 10.593987226486206, "time_total_s": 1105.8678271770477, "pid": 4998, "hostname": "DESKTOP-LQ219J4", "node_ip": "192.168.46.185", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 20, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 5000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 500, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "rware", "env_args": {"n_agents": 4, "column_height": 1, "max_inactivity_steps": null, "max_steps": 500, "fast_obs": true, "msg_bits": 0, "sensor_range": 1, "shelf_rows": 1, "shelf_columns": 3, "request_queue_size": 4, "reward_type": "RewardType.INDIVIDUAL", "map_name": "customized_map", "map_size": "tiny", "difficulty": "medium"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": true, "force_coop": false, "local_mode": true, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 4, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 100, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64}, "algorithm": "maa2c", "space_obs": "Dict(obs:Box([-100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100.], [100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.], (112,), float32))", "space_act": "Discrete(5)", "num_agents": 4, "episode_limit": 500, "policy_mapping_info": {"all_scenario": {"description": "rware all scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2", "agent_3"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "rware_customized_map", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 10, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.policy_template.MAA2CTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x7f7c1aff2d30>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "grad_clip": 40.0, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "microbatch_size": null}, "time_since_restore": 1105.8678271770477, "timesteps_since_restore": 0, "iterations_since_restore": 105, "perf": {"cpu_util_percent": 4.379999999999999, "ram_util_percent": 90.72}}
{"episode_reward_max": 13.0, "episode_reward_min": 0.0, "episode_reward_mean": 3.49, "episode_len_mean": 500.0, "episode_media": {}, "episodes_this_iter": 20, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [3.0, 1.0, 2.0, 0.0, 1.0, 3.0, 4.0, 4.0, 5.0, 4.0, 7.0, 5.0, 3.0, 3.0, 2.0, 2.0, 9.0, 8.0, 9.0, 3.0, 3.0, 4.0, 2.0, 2.0, 4.0, 3.0, 4.0, 2.0, 3.0, 1.0, 2.0, 9.0, 2.0, 6.0, 13.0, 4.0, 3.0, 2.0, 2.0, 1.0, 2.0, 0.0, 4.0, 1.0, 5.0, 1.0, 3.0, 6.0, 1.0, 3.0, 5.0, 1.0, 4.0, 1.0, 1.0, 1.0, 2.0, 4.0, 4.0, 2.0, 3.0, 5.0, 2.0, 5.0, 1.0, 0.0, 1.0, 5.0, 4.0, 9.0, 5.0, 5.0, 11.0, 7.0, 5.0, 2.0, 2.0, 3.0, 1.0, 2.0, 4.0, 2.0, 0.0, 0.0, 1.0, 3.0, 2.0, 4.0, 9.0, 4.0, 9.0, 0.0, 1.0, 6.0, 3.0, 5.0, 7.0, 3.0, 3.0, 4.0], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.14647382362222877, "mean_inference_ms": 0.3859678243968753, "mean_action_processing_ms": 0.028359129898272918, "mean_env_wait_ms": 0.39058171429285055, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 4275200, "timesteps_this_iter": 0, "agent_timesteps_total": 4275200, "timers": {"sample_time_ms": 1387.277, "sample_throughput": 3690.683, "load_time_ms": 0.168, "load_throughput": 30495365.635, "learn_time_ms": 69.366, "learn_throughput": 73811.045, "update_time_ms": 3.194}, "info": {"learner": {"default_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 133.81964111328125, "policy_entropy": 7931.0625, "policy_loss": -68.96507263183594, "vf_loss": 28.95897102355957}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 4275200, "num_agent_steps_sampled": 4275200, "num_steps_trained": 4275200, "num_agent_steps_trained": 4275200, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 2136, "training_iteration": 106, "trial_id": "65be9_00000", "experiment_id": "b9e963105bdc4382843b68ace23a11d3", "date": "2024-06-17_16-27-07", "timestamp": 1718609227, "time_this_iter_s": 11.21378207206726, "time_total_s": 1117.081609249115, "pid": 4998, "hostname": "DESKTOP-LQ219J4", "node_ip": "192.168.46.185", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 20, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 5000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 500, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "rware", "env_args": {"n_agents": 4, "column_height": 1, "max_inactivity_steps": null, "max_steps": 500, "fast_obs": true, "msg_bits": 0, "sensor_range": 1, "shelf_rows": 1, "shelf_columns": 3, "request_queue_size": 4, "reward_type": "RewardType.INDIVIDUAL", "map_name": "customized_map", "map_size": "tiny", "difficulty": "medium"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": true, "force_coop": false, "local_mode": true, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 4, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 100, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64}, "algorithm": "maa2c", "space_obs": "Dict(obs:Box([-100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100.], [100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.], (112,), float32))", "space_act": "Discrete(5)", "num_agents": 4, "episode_limit": 500, "policy_mapping_info": {"all_scenario": {"description": "rware all scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2", "agent_3"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "rware_customized_map", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 10, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.policy_template.MAA2CTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x7f7c1d170ee0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "grad_clip": 40.0, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "microbatch_size": null}, "time_since_restore": 1117.081609249115, "timesteps_since_restore": 0, "iterations_since_restore": 106, "perf": {"cpu_util_percent": 4.362500000000001, "ram_util_percent": 91.375}}
{"episode_reward_max": 13.0, "episode_reward_min": 0.0, "episode_reward_mean": 3.33, "episode_len_mean": 500.0, "episode_media": {}, "episodes_this_iter": 20, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [3.0, 4.0, 2.0, 2.0, 4.0, 3.0, 4.0, 2.0, 3.0, 1.0, 2.0, 9.0, 2.0, 6.0, 13.0, 4.0, 3.0, 2.0, 2.0, 1.0, 2.0, 0.0, 4.0, 1.0, 5.0, 1.0, 3.0, 6.0, 1.0, 3.0, 5.0, 1.0, 4.0, 1.0, 1.0, 1.0, 2.0, 4.0, 4.0, 2.0, 3.0, 5.0, 2.0, 5.0, 1.0, 0.0, 1.0, 5.0, 4.0, 9.0, 5.0, 5.0, 11.0, 7.0, 5.0, 2.0, 2.0, 3.0, 1.0, 2.0, 4.0, 2.0, 0.0, 0.0, 1.0, 3.0, 2.0, 4.0, 9.0, 4.0, 9.0, 0.0, 1.0, 6.0, 3.0, 5.0, 7.0, 3.0, 3.0, 4.0, 7.0, 5.0, 5.0, 2.0, 1.0, 1.0, 4.0, 2.0, 3.0, 2.0, 2.0, 3.0, 4.0, 2.0, 0.0, 2.0, 4.0, 4.0, 2.0, 7.0], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.14650980821397946, "mean_inference_ms": 0.38601320864174526, "mean_action_processing_ms": 0.02836209776609363, "mean_env_wait_ms": 0.3906249911229245, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 4316160, "timesteps_this_iter": 0, "agent_timesteps_total": 4316160, "timers": {"sample_time_ms": 1360.557, "sample_throughput": 3763.164, "load_time_ms": 0.163, "load_throughput": 31363862.246, "learn_time_ms": 66.862, "learn_throughput": 76575.703, "update_time_ms": 2.933}, "info": {"learner": {"default_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 97.22604370117188, "policy_entropy": 7931.56884765625, "policy_loss": -51.556396484375, "vf_loss": 36.48423767089844}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 4316160, "num_agent_steps_sampled": 4316160, "num_steps_trained": 4316160, "num_agent_steps_trained": 4316160, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 2156, "training_iteration": 107, "trial_id": "65be9_00000", "experiment_id": "b9e963105bdc4382843b68ace23a11d3", "date": "2024-06-17_16-27-18", "timestamp": 1718609238, "time_this_iter_s": 10.847489833831787, "time_total_s": 1127.9290990829468, "pid": 4998, "hostname": "DESKTOP-LQ219J4", "node_ip": "192.168.46.185", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 20, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 5000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 500, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "rware", "env_args": {"n_agents": 4, "column_height": 1, "max_inactivity_steps": null, "max_steps": 500, "fast_obs": true, "msg_bits": 0, "sensor_range": 1, "shelf_rows": 1, "shelf_columns": 3, "request_queue_size": 4, "reward_type": "RewardType.INDIVIDUAL", "map_name": "customized_map", "map_size": "tiny", "difficulty": "medium"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": true, "force_coop": false, "local_mode": true, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 4, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 100, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64}, "algorithm": "maa2c", "space_obs": "Dict(obs:Box([-100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100.], [100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.], (112,), float32))", "space_act": "Discrete(5)", "num_agents": 4, "episode_limit": 500, "policy_mapping_info": {"all_scenario": {"description": "rware all scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2", "agent_3"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "rware_customized_map", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 10, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.policy_template.MAA2CTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x7f7c1d170d30>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "grad_clip": 40.0, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "microbatch_size": null}, "time_since_restore": 1127.9290990829468, "timesteps_since_restore": 0, "iterations_since_restore": 107, "perf": {"cpu_util_percent": 4.4750000000000005, "ram_util_percent": 92.0625}}
{"episode_reward_max": 11.0, "episode_reward_min": 0.0, "episode_reward_mean": 3.41, "episode_len_mean": 500.0, "episode_media": {}, "episodes_this_iter": 20, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [2.0, 0.0, 4.0, 1.0, 5.0, 1.0, 3.0, 6.0, 1.0, 3.0, 5.0, 1.0, 4.0, 1.0, 1.0, 1.0, 2.0, 4.0, 4.0, 2.0, 3.0, 5.0, 2.0, 5.0, 1.0, 0.0, 1.0, 5.0, 4.0, 9.0, 5.0, 5.0, 11.0, 7.0, 5.0, 2.0, 2.0, 3.0, 1.0, 2.0, 4.0, 2.0, 0.0, 0.0, 1.0, 3.0, 2.0, 4.0, 9.0, 4.0, 9.0, 0.0, 1.0, 6.0, 3.0, 5.0, 7.0, 3.0, 3.0, 4.0, 7.0, 5.0, 5.0, 2.0, 1.0, 1.0, 4.0, 2.0, 3.0, 2.0, 2.0, 3.0, 4.0, 2.0, 0.0, 2.0, 4.0, 4.0, 2.0, 7.0, 6.0, 3.0, 4.0, 3.0, 8.0, 9.0, 4.0, 2.0, 2.0, 7.0, 2.0, 1.0, 2.0, 2.0, 6.0, 1.0, 7.0, 1.0, 4.0, 6.0], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.14656566570801816, "mean_inference_ms": 0.38610094231085723, "mean_action_processing_ms": 0.02836799611773932, "mean_env_wait_ms": 0.3906827956133383, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 4357120, "timesteps_this_iter": 0, "agent_timesteps_total": 4357120, "timers": {"sample_time_ms": 1343.986, "sample_throughput": 3809.563, "load_time_ms": 0.161, "load_throughput": 31833436.822, "learn_time_ms": 66.367, "learn_throughput": 77147.294, "update_time_ms": 2.998}, "info": {"learner": {"default_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 103.88613891601562, "policy_entropy": 7902.60302734375, "policy_loss": -8.212379455566406, "vf_loss": 44.382869720458984}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 4357120, "num_agent_steps_sampled": 4357120, "num_steps_trained": 4357120, "num_agent_steps_trained": 4357120, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 2176, "training_iteration": 108, "trial_id": "65be9_00000", "experiment_id": "b9e963105bdc4382843b68ace23a11d3", "date": "2024-06-17_16-27-29", "timestamp": 1718609249, "time_this_iter_s": 10.759130001068115, "time_total_s": 1138.688229084015, "pid": 4998, "hostname": "DESKTOP-LQ219J4", "node_ip": "192.168.46.185", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 20, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 5000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 500, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "rware", "env_args": {"n_agents": 4, "column_height": 1, "max_inactivity_steps": null, "max_steps": 500, "fast_obs": true, "msg_bits": 0, "sensor_range": 1, "shelf_rows": 1, "shelf_columns": 3, "request_queue_size": 4, "reward_type": "RewardType.INDIVIDUAL", "map_name": "customized_map", "map_size": "tiny", "difficulty": "medium"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": true, "force_coop": false, "local_mode": true, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 4, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 100, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64}, "algorithm": "maa2c", "space_obs": "Dict(obs:Box([-100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100.], [100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.], (112,), float32))", "space_act": "Discrete(5)", "num_agents": 4, "episode_limit": 500, "policy_mapping_info": {"all_scenario": {"description": "rware all scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2", "agent_3"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "rware_customized_map", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 10, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.policy_template.MAA2CTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x7f7c1afbcca0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "grad_clip": 40.0, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "microbatch_size": null}, "time_since_restore": 1138.688229084015, "timesteps_since_restore": 0, "iterations_since_restore": 108, "perf": {"cpu_util_percent": 4.573333333333333, "ram_util_percent": 92.73333333333333}}
{"episode_reward_max": 11.0, "episode_reward_min": 0.0, "episode_reward_mean": 3.61, "episode_len_mean": 500.0, "episode_media": {}, "episodes_this_iter": 20, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [3.0, 5.0, 2.0, 5.0, 1.0, 0.0, 1.0, 5.0, 4.0, 9.0, 5.0, 5.0, 11.0, 7.0, 5.0, 2.0, 2.0, 3.0, 1.0, 2.0, 4.0, 2.0, 0.0, 0.0, 1.0, 3.0, 2.0, 4.0, 9.0, 4.0, 9.0, 0.0, 1.0, 6.0, 3.0, 5.0, 7.0, 3.0, 3.0, 4.0, 7.0, 5.0, 5.0, 2.0, 1.0, 1.0, 4.0, 2.0, 3.0, 2.0, 2.0, 3.0, 4.0, 2.0, 0.0, 2.0, 4.0, 4.0, 2.0, 7.0, 6.0, 3.0, 4.0, 3.0, 8.0, 9.0, 4.0, 2.0, 2.0, 7.0, 2.0, 1.0, 2.0, 2.0, 6.0, 1.0, 7.0, 1.0, 4.0, 6.0, 3.0, 8.0, 2.0, 1.0, 1.0, 1.0, 2.0, 6.0, 6.0, 1.0, 6.0, 2.0, 5.0, 3.0, 8.0, 1.0, 1.0, 4.0, 2.0, 8.0], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.14661923222137752, "mean_inference_ms": 0.38618084667118163, "mean_action_processing_ms": 0.028372863646967672, "mean_env_wait_ms": 0.39074860919664095, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 4398080, "timesteps_this_iter": 0, "agent_timesteps_total": 4398080, "timers": {"sample_time_ms": 1385.866, "sample_throughput": 3694.441, "load_time_ms": 0.182, "load_throughput": 28178502.139, "learn_time_ms": 71.801, "learn_throughput": 71308.299, "update_time_ms": 3.178}, "info": {"learner": {"default_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 86.13363647460938, "policy_entropy": 7711.25146484375, "policy_loss": 6.926078796386719, "vf_loss": 41.88345718383789}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 4398080, "num_agent_steps_sampled": 4398080, "num_steps_trained": 4398080, "num_agent_steps_trained": 4398080, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 2196, "training_iteration": 109, "trial_id": "65be9_00000", "experiment_id": "b9e963105bdc4382843b68ace23a11d3", "date": "2024-06-17_16-27-40", "timestamp": 1718609260, "time_this_iter_s": 11.05134654045105, "time_total_s": 1149.739575624466, "pid": 4998, "hostname": "DESKTOP-LQ219J4", "node_ip": "192.168.46.185", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 20, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 5000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 500, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "rware", "env_args": {"n_agents": 4, "column_height": 1, "max_inactivity_steps": null, "max_steps": 500, "fast_obs": true, "msg_bits": 0, "sensor_range": 1, "shelf_rows": 1, "shelf_columns": 3, "request_queue_size": 4, "reward_type": "RewardType.INDIVIDUAL", "map_name": "customized_map", "map_size": "tiny", "difficulty": "medium"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": true, "force_coop": false, "local_mode": true, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 4, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 100, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64}, "algorithm": "maa2c", "space_obs": "Dict(obs:Box([-100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100.], [100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.], (112,), float32))", "space_act": "Discrete(5)", "num_agents": 4, "episode_limit": 500, "policy_mapping_info": {"all_scenario": {"description": "rware all scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2", "agent_3"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "rware_customized_map", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 10, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.policy_template.MAA2CTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x7f7c1aff2e50>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "grad_clip": 40.0, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "microbatch_size": null}, "time_since_restore": 1149.739575624466, "timesteps_since_restore": 0, "iterations_since_restore": 109, "perf": {"cpu_util_percent": 4.5625, "ram_util_percent": 93.05}}
{"episode_reward_max": 10.0, "episode_reward_min": 0.0, "episode_reward_mean": 3.59, "episode_len_mean": 500.0, "episode_media": {}, "episodes_this_iter": 20, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [4.0, 2.0, 0.0, 0.0, 1.0, 3.0, 2.0, 4.0, 9.0, 4.0, 9.0, 0.0, 1.0, 6.0, 3.0, 5.0, 7.0, 3.0, 3.0, 4.0, 7.0, 5.0, 5.0, 2.0, 1.0, 1.0, 4.0, 2.0, 3.0, 2.0, 2.0, 3.0, 4.0, 2.0, 0.0, 2.0, 4.0, 4.0, 2.0, 7.0, 6.0, 3.0, 4.0, 3.0, 8.0, 9.0, 4.0, 2.0, 2.0, 7.0, 2.0, 1.0, 2.0, 2.0, 6.0, 1.0, 7.0, 1.0, 4.0, 6.0, 3.0, 8.0, 2.0, 1.0, 1.0, 1.0, 2.0, 6.0, 6.0, 1.0, 6.0, 2.0, 5.0, 3.0, 8.0, 1.0, 1.0, 4.0, 2.0, 8.0, 3.0, 4.0, 4.0, 2.0, 2.0, 6.0, 4.0, 0.0, 4.0, 6.0, 4.0, 7.0, 1.0, 2.0, 5.0, 3.0, 10.0, 3.0, 4.0, 2.0], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.1466753913395129, "mean_inference_ms": 0.3862666477057081, "mean_action_processing_ms": 0.0283781492462766, "mean_env_wait_ms": 0.3908396965633278, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 4439040, "timesteps_this_iter": 0, "agent_timesteps_total": 4439040, "timers": {"sample_time_ms": 1355.997, "sample_throughput": 3775.82, "load_time_ms": 0.172, "load_throughput": 29813739.386, "learn_time_ms": 70.985, "learn_throughput": 72127.495, "update_time_ms": 3.043}, "info": {"learner": {"default_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 189.86691284179688, "policy_entropy": 7824.19775390625, "policy_loss": 49.4179573059082, "vf_loss": 49.99991226196289}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 4439040, "num_agent_steps_sampled": 4439040, "num_steps_trained": 4439040, "num_agent_steps_trained": 4439040, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 2216, "training_iteration": 110, "trial_id": "65be9_00000", "experiment_id": "b9e963105bdc4382843b68ace23a11d3", "date": "2024-06-17_16-27-51", "timestamp": 1718609271, "time_this_iter_s": 10.84728717803955, "time_total_s": 1160.5868628025055, "pid": 4998, "hostname": "DESKTOP-LQ219J4", "node_ip": "192.168.46.185", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 20, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 5000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 500, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "rware", "env_args": {"n_agents": 4, "column_height": 1, "max_inactivity_steps": null, "max_steps": 500, "fast_obs": true, "msg_bits": 0, "sensor_range": 1, "shelf_rows": 1, "shelf_columns": 3, "request_queue_size": 4, "reward_type": "RewardType.INDIVIDUAL", "map_name": "customized_map", "map_size": "tiny", "difficulty": "medium"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": true, "force_coop": false, "local_mode": true, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 4, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 100, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64}, "algorithm": "maa2c", "space_obs": "Dict(obs:Box([-100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100.], [100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.], (112,), float32))", "space_act": "Discrete(5)", "num_agents": 4, "episode_limit": 500, "policy_mapping_info": {"all_scenario": {"description": "rware all scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2", "agent_3"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "rware_customized_map", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 10, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.policy_template.MAA2CTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x7f7c1cdf6280>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "grad_clip": 40.0, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "microbatch_size": null}, "time_since_restore": 1160.5868628025055, "timesteps_since_restore": 0, "iterations_since_restore": 110, "perf": {"cpu_util_percent": 4.48, "ram_util_percent": 93.55999999999999}}
{"episode_reward_max": 13.0, "episode_reward_min": 0.0, "episode_reward_mean": 3.8, "episode_len_mean": 500.0, "episode_media": {}, "episodes_this_iter": 24, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [1.0, 1.0, 4.0, 2.0, 3.0, 2.0, 2.0, 3.0, 4.0, 2.0, 0.0, 2.0, 4.0, 4.0, 2.0, 7.0, 6.0, 3.0, 4.0, 3.0, 8.0, 9.0, 4.0, 2.0, 2.0, 7.0, 2.0, 1.0, 2.0, 2.0, 6.0, 1.0, 7.0, 1.0, 4.0, 6.0, 3.0, 8.0, 2.0, 1.0, 1.0, 1.0, 2.0, 6.0, 6.0, 1.0, 6.0, 2.0, 5.0, 3.0, 8.0, 1.0, 1.0, 4.0, 2.0, 8.0, 3.0, 4.0, 4.0, 2.0, 2.0, 6.0, 4.0, 0.0, 4.0, 6.0, 4.0, 7.0, 1.0, 2.0, 5.0, 3.0, 10.0, 3.0, 4.0, 2.0, 1.0, 3.0, 2.0, 2.0, 4.0, 8.0, 1.0, 3.0, 2.0, 7.0, 7.0, 10.0, 11.0, 0.0, 3.0, 5.0, 3.0, 9.0, 0.0, 2.0, 6.0, 5.0, 3.0, 13.0], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.14671039685733622, "mean_inference_ms": 0.3862968669861364, "mean_action_processing_ms": 0.02837946319949341, "mean_env_wait_ms": 0.39089496412510905, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 4480000, "timesteps_this_iter": 0, "agent_timesteps_total": 4480000, "timers": {"sample_time_ms": 1355.807, "sample_throughput": 3776.348, "load_time_ms": 0.178, "load_throughput": 28794363.744, "learn_time_ms": 73.217, "learn_throughput": 69928.718, "update_time_ms": 3.537}, "info": {"learner": {"default_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 604.3870849609375, "policy_entropy": 7810.1904296875, "policy_loss": 170.8052978515625, "vf_loss": 144.88609313964844}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 4480000, "num_agent_steps_sampled": 4480000, "num_steps_trained": 4480000, "num_agent_steps_trained": 4480000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 2240, "training_iteration": 111, "trial_id": "65be9_00000", "experiment_id": "b9e963105bdc4382843b68ace23a11d3", "date": "2024-06-17_16-28-02", "timestamp": 1718609282, "time_this_iter_s": 10.874611139297485, "time_total_s": 1171.461473941803, "pid": 4998, "hostname": "DESKTOP-LQ219J4", "node_ip": "192.168.46.185", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 20, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 5000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 500, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "rware", "env_args": {"n_agents": 4, "column_height": 1, "max_inactivity_steps": null, "max_steps": 500, "fast_obs": true, "msg_bits": 0, "sensor_range": 1, "shelf_rows": 1, "shelf_columns": 3, "request_queue_size": 4, "reward_type": "RewardType.INDIVIDUAL", "map_name": "customized_map", "map_size": "tiny", "difficulty": "medium"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": true, "force_coop": false, "local_mode": true, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 4, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 100, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64}, "algorithm": "maa2c", "space_obs": "Dict(obs:Box([-100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100.], [100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.], (112,), float32))", "space_act": "Discrete(5)", "num_agents": 4, "episode_limit": 500, "policy_mapping_info": {"all_scenario": {"description": "rware all scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2", "agent_3"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "rware_customized_map", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 10, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.policy_template.MAA2CTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x7f7c1d450c10>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "grad_clip": 40.0, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "microbatch_size": null}, "time_since_restore": 1171.461473941803, "timesteps_since_restore": 0, "iterations_since_restore": 111, "perf": {"cpu_util_percent": 4.44375, "ram_util_percent": 94.1875}}
{"episode_reward_max": 13.0, "episode_reward_min": 0.0, "episode_reward_mean": 3.97, "episode_len_mean": 500.0, "episode_media": {}, "episodes_this_iter": 20, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [8.0, 9.0, 4.0, 2.0, 2.0, 7.0, 2.0, 1.0, 2.0, 2.0, 6.0, 1.0, 7.0, 1.0, 4.0, 6.0, 3.0, 8.0, 2.0, 1.0, 1.0, 1.0, 2.0, 6.0, 6.0, 1.0, 6.0, 2.0, 5.0, 3.0, 8.0, 1.0, 1.0, 4.0, 2.0, 8.0, 3.0, 4.0, 4.0, 2.0, 2.0, 6.0, 4.0, 0.0, 4.0, 6.0, 4.0, 7.0, 1.0, 2.0, 5.0, 3.0, 10.0, 3.0, 4.0, 2.0, 1.0, 3.0, 2.0, 2.0, 4.0, 8.0, 1.0, 3.0, 2.0, 7.0, 7.0, 10.0, 11.0, 0.0, 3.0, 5.0, 3.0, 9.0, 0.0, 2.0, 6.0, 5.0, 3.0, 13.0, 2.0, 2.0, 5.0, 5.0, 4.0, 1.0, 1.0, 2.0, 1.0, 8.0, 1.0, 6.0, 2.0, 5.0, 7.0, 2.0, 4.0, 6.0, 2.0, 10.0], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.14675051751599702, "mean_inference_ms": 0.3863472489788833, "mean_action_processing_ms": 0.02838158484918827, "mean_env_wait_ms": 0.39092854283576356, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 4520960, "timesteps_this_iter": 0, "agent_timesteps_total": 4520960, "timers": {"sample_time_ms": 1345.7, "sample_throughput": 3804.71, "load_time_ms": 0.169, "load_throughput": 30323124.089, "learn_time_ms": 76.001, "learn_throughput": 67367.45, "update_time_ms": 3.623}, "info": {"learner": {"default_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 212.4032440185547, "policy_entropy": 7829.8310546875, "policy_loss": -112.15626525878906, "vf_loss": 94.67568969726562}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 4520960, "num_agent_steps_sampled": 4520960, "num_steps_trained": 4520960, "num_agent_steps_trained": 4520960, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 2260, "training_iteration": 112, "trial_id": "65be9_00000", "experiment_id": "b9e963105bdc4382843b68ace23a11d3", "date": "2024-06-17_16-28-12", "timestamp": 1718609292, "time_this_iter_s": 10.699613809585571, "time_total_s": 1182.1610877513885, "pid": 4998, "hostname": "DESKTOP-LQ219J4", "node_ip": "192.168.46.185", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 20, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 5000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 500, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "rware", "env_args": {"n_agents": 4, "column_height": 1, "max_inactivity_steps": null, "max_steps": 500, "fast_obs": true, "msg_bits": 0, "sensor_range": 1, "shelf_rows": 1, "shelf_columns": 3, "request_queue_size": 4, "reward_type": "RewardType.INDIVIDUAL", "map_name": "customized_map", "map_size": "tiny", "difficulty": "medium"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": true, "force_coop": false, "local_mode": true, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 4, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 100, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64}, "algorithm": "maa2c", "space_obs": "Dict(obs:Box([-100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100.], [100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.], (112,), float32))", "space_act": "Discrete(5)", "num_agents": 4, "episode_limit": 500, "policy_mapping_info": {"all_scenario": {"description": "rware all scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2", "agent_3"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "rware_customized_map", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 10, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.policy_template.MAA2CTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x7f7c1afbc940>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "grad_clip": 40.0, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "microbatch_size": null}, "time_since_restore": 1182.1610877513885, "timesteps_since_restore": 0, "iterations_since_restore": 112, "perf": {"cpu_util_percent": 4.946666666666666, "ram_util_percent": 94.64000000000001}}
{"episode_reward_max": 13.0, "episode_reward_min": 0.0, "episode_reward_mean": 3.69, "episode_len_mean": 500.0, "episode_media": {}, "episodes_this_iter": 20, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [1.0, 1.0, 2.0, 6.0, 6.0, 1.0, 6.0, 2.0, 5.0, 3.0, 8.0, 1.0, 1.0, 4.0, 2.0, 8.0, 3.0, 4.0, 4.0, 2.0, 2.0, 6.0, 4.0, 0.0, 4.0, 6.0, 4.0, 7.0, 1.0, 2.0, 5.0, 3.0, 10.0, 3.0, 4.0, 2.0, 1.0, 3.0, 2.0, 2.0, 4.0, 8.0, 1.0, 3.0, 2.0, 7.0, 7.0, 10.0, 11.0, 0.0, 3.0, 5.0, 3.0, 9.0, 0.0, 2.0, 6.0, 5.0, 3.0, 13.0, 2.0, 2.0, 5.0, 5.0, 4.0, 1.0, 1.0, 2.0, 1.0, 8.0, 1.0, 6.0, 2.0, 5.0, 7.0, 2.0, 4.0, 6.0, 2.0, 10.0, 1.0, 1.0, 5.0, 3.0, 3.0, 0.0, 3.0, 1.0, 3.0, 2.0, 3.0, 2.0, 1.0, 6.0, 5.0, 2.0, 2.0, 5.0, 1.0, 1.0], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.14679085606339976, "mean_inference_ms": 0.38638796333511194, "mean_action_processing_ms": 0.028383988085487234, "mean_env_wait_ms": 0.39094716495623016, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 4561920, "timesteps_this_iter": 0, "agent_timesteps_total": 4561920, "timers": {"sample_time_ms": 1347.861, "sample_throughput": 3798.612, "load_time_ms": 0.175, "load_throughput": 29273223.119, "learn_time_ms": 73.896, "learn_throughput": 69286.965, "update_time_ms": 2.979}, "info": {"learner": {"default_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 93.45126342773438, "policy_entropy": 7909.24560546875, "policy_loss": 29.77120018005371, "vf_loss": 16.729219436645508}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 4561920, "num_agent_steps_sampled": 4561920, "num_steps_trained": 4561920, "num_agent_steps_trained": 4561920, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 2280, "training_iteration": 113, "trial_id": "65be9_00000", "experiment_id": "b9e963105bdc4382843b68ace23a11d3", "date": "2024-06-17_16-28-23", "timestamp": 1718609303, "time_this_iter_s": 10.78920030593872, "time_total_s": 1192.9502880573273, "pid": 4998, "hostname": "DESKTOP-LQ219J4", "node_ip": "192.168.46.185", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 20, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 5000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 500, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "rware", "env_args": {"n_agents": 4, "column_height": 1, "max_inactivity_steps": null, "max_steps": 500, "fast_obs": true, "msg_bits": 0, "sensor_range": 1, "shelf_rows": 1, "shelf_columns": 3, "request_queue_size": 4, "reward_type": "RewardType.INDIVIDUAL", "map_name": "customized_map", "map_size": "tiny", "difficulty": "medium"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": true, "force_coop": false, "local_mode": true, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 4, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 100, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64}, "algorithm": "maa2c", "space_obs": "Dict(obs:Box([-100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100.], [100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.], (112,), float32))", "space_act": "Discrete(5)", "num_agents": 4, "episode_limit": 500, "policy_mapping_info": {"all_scenario": {"description": "rware all scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2", "agent_3"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "rware_customized_map", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 10, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.policy_template.MAA2CTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x7f7c1afbcd30>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "grad_clip": 40.0, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "microbatch_size": null}, "time_since_restore": 1192.9502880573273, "timesteps_since_restore": 0, "iterations_since_restore": 113, "perf": {"cpu_util_percent": 4.418749999999999, "ram_util_percent": 95.14375000000001}}
{"episode_reward_max": 13.0, "episode_reward_min": 0.0, "episode_reward_mean": 3.76, "episode_len_mean": 500.0, "episode_media": {}, "episodes_this_iter": 20, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [2.0, 6.0, 4.0, 0.0, 4.0, 6.0, 4.0, 7.0, 1.0, 2.0, 5.0, 3.0, 10.0, 3.0, 4.0, 2.0, 1.0, 3.0, 2.0, 2.0, 4.0, 8.0, 1.0, 3.0, 2.0, 7.0, 7.0, 10.0, 11.0, 0.0, 3.0, 5.0, 3.0, 9.0, 0.0, 2.0, 6.0, 5.0, 3.0, 13.0, 2.0, 2.0, 5.0, 5.0, 4.0, 1.0, 1.0, 2.0, 1.0, 8.0, 1.0, 6.0, 2.0, 5.0, 7.0, 2.0, 4.0, 6.0, 2.0, 10.0, 1.0, 1.0, 5.0, 3.0, 3.0, 0.0, 3.0, 1.0, 3.0, 2.0, 3.0, 2.0, 1.0, 6.0, 5.0, 2.0, 2.0, 5.0, 1.0, 1.0, 3.0, 3.0, 3.0, 4.0, 5.0, 3.0, 3.0, 5.0, 6.0, 2.0, 1.0, 5.0, 7.0, 8.0, 7.0, 2.0, 1.0, 3.0, 2.0, 4.0], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.1468411083188661, "mean_inference_ms": 0.3864096654269114, "mean_action_processing_ms": 0.028385631290171524, "mean_env_wait_ms": 0.39093220199507556, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 4602880, "timesteps_this_iter": 0, "agent_timesteps_total": 4602880, "timers": {"sample_time_ms": 1351.877, "sample_throughput": 3787.326, "load_time_ms": 0.17, "load_throughput": 30186725.443, "learn_time_ms": 73.475, "learn_throughput": 69683.133, "update_time_ms": 2.947}, "info": {"learner": {"default_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 130.7980499267578, "policy_entropy": 7924.2509765625, "policy_loss": -72.63790893554688, "vf_loss": 29.521320343017578}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 4602880, "num_agent_steps_sampled": 4602880, "num_steps_trained": 4602880, "num_agent_steps_trained": 4602880, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 2300, "training_iteration": 114, "trial_id": "65be9_00000", "experiment_id": "b9e963105bdc4382843b68ace23a11d3", "date": "2024-06-17_16-28-34", "timestamp": 1718609314, "time_this_iter_s": 10.82799744606018, "time_total_s": 1203.7782855033875, "pid": 4998, "hostname": "DESKTOP-LQ219J4", "node_ip": "192.168.46.185", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 20, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 5000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 500, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "rware", "env_args": {"n_agents": 4, "column_height": 1, "max_inactivity_steps": null, "max_steps": 500, "fast_obs": true, "msg_bits": 0, "sensor_range": 1, "shelf_rows": 1, "shelf_columns": 3, "request_queue_size": 4, "reward_type": "RewardType.INDIVIDUAL", "map_name": "customized_map", "map_size": "tiny", "difficulty": "medium"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": true, "force_coop": false, "local_mode": true, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 4, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 100, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64}, "algorithm": "maa2c", "space_obs": "Dict(obs:Box([-100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100.], [100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.], (112,), float32))", "space_act": "Discrete(5)", "num_agents": 4, "episode_limit": 500, "policy_mapping_info": {"all_scenario": {"description": "rware all scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2", "agent_3"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "rware_customized_map", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 10, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.policy_template.MAA2CTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x7f7c768b70d0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "grad_clip": 40.0, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "microbatch_size": null}, "time_since_restore": 1203.7782855033875, "timesteps_since_restore": 0, "iterations_since_restore": 114, "perf": {"cpu_util_percent": 4.42, "ram_util_percent": 95.76666666666667}}
{"episode_reward_max": 13.0, "episode_reward_min": 0.0, "episode_reward_mean": 3.73, "episode_len_mean": 500.0, "episode_media": {}, "episodes_this_iter": 20, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [4.0, 8.0, 1.0, 3.0, 2.0, 7.0, 7.0, 10.0, 11.0, 0.0, 3.0, 5.0, 3.0, 9.0, 0.0, 2.0, 6.0, 5.0, 3.0, 13.0, 2.0, 2.0, 5.0, 5.0, 4.0, 1.0, 1.0, 2.0, 1.0, 8.0, 1.0, 6.0, 2.0, 5.0, 7.0, 2.0, 4.0, 6.0, 2.0, 10.0, 1.0, 1.0, 5.0, 3.0, 3.0, 0.0, 3.0, 1.0, 3.0, 2.0, 3.0, 2.0, 1.0, 6.0, 5.0, 2.0, 2.0, 5.0, 1.0, 1.0, 3.0, 3.0, 3.0, 4.0, 5.0, 3.0, 3.0, 5.0, 6.0, 2.0, 1.0, 5.0, 7.0, 8.0, 7.0, 2.0, 1.0, 3.0, 2.0, 4.0, 2.0, 4.0, 1.0, 0.0, 0.0, 0.0, 12.0, 4.0, 3.0, 1.0, 3.0, 1.0, 4.0, 4.0, 6.0, 1.0, 6.0, 4.0, 10.0, 2.0], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.14690442062472728, "mean_inference_ms": 0.38642629250470134, "mean_action_processing_ms": 0.028387056822883883, "mean_env_wait_ms": 0.39089433244424676, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 4643840, "timesteps_this_iter": 0, "agent_timesteps_total": 4643840, "timers": {"sample_time_ms": 1342.247, "sample_throughput": 3814.499, "load_time_ms": 0.166, "load_throughput": 30925743.779, "learn_time_ms": 73.91, "learn_throughput": 69273.532, "update_time_ms": 3.009}, "info": {"learner": {"default_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 152.54428100585938, "policy_entropy": 7855.9833984375, "policy_loss": -73.5848159790039, "vf_loss": 59.91132354736328}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 4643840, "num_agent_steps_sampled": 4643840, "num_steps_trained": 4643840, "num_agent_steps_trained": 4643840, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 2320, "training_iteration": 115, "trial_id": "65be9_00000", "experiment_id": "b9e963105bdc4382843b68ace23a11d3", "date": "2024-06-17_16-28-45", "timestamp": 1718609325, "time_this_iter_s": 10.793730020523071, "time_total_s": 1214.5720155239105, "pid": 4998, "hostname": "DESKTOP-LQ219J4", "node_ip": "192.168.46.185", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 20, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 5000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 500, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "rware", "env_args": {"n_agents": 4, "column_height": 1, "max_inactivity_steps": null, "max_steps": 500, "fast_obs": true, "msg_bits": 0, "sensor_range": 1, "shelf_rows": 1, "shelf_columns": 3, "request_queue_size": 4, "reward_type": "RewardType.INDIVIDUAL", "map_name": "customized_map", "map_size": "tiny", "difficulty": "medium"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": true, "force_coop": false, "local_mode": true, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 4, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 100, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64}, "algorithm": "maa2c", "space_obs": "Dict(obs:Box([-100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100.], [100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.], (112,), float32))", "space_act": "Discrete(5)", "num_agents": 4, "episode_limit": 500, "policy_mapping_info": {"all_scenario": {"description": "rware all scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2", "agent_3"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "rware_customized_map", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 10, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.policy_template.MAA2CTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x7f7c1afbce50>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "grad_clip": 40.0, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "microbatch_size": null}, "time_since_restore": 1214.5720155239105, "timesteps_since_restore": 0, "iterations_since_restore": 115, "perf": {"cpu_util_percent": 4.0600000000000005, "ram_util_percent": 96.40666666666665}}
{"episode_reward_max": 12.0, "episode_reward_min": 0.0, "episode_reward_mean": 3.31, "episode_len_mean": 500.0, "episode_media": {}, "episodes_this_iter": 20, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [2.0, 2.0, 5.0, 5.0, 4.0, 1.0, 1.0, 2.0, 1.0, 8.0, 1.0, 6.0, 2.0, 5.0, 7.0, 2.0, 4.0, 6.0, 2.0, 10.0, 1.0, 1.0, 5.0, 3.0, 3.0, 0.0, 3.0, 1.0, 3.0, 2.0, 3.0, 2.0, 1.0, 6.0, 5.0, 2.0, 2.0, 5.0, 1.0, 1.0, 3.0, 3.0, 3.0, 4.0, 5.0, 3.0, 3.0, 5.0, 6.0, 2.0, 1.0, 5.0, 7.0, 8.0, 7.0, 2.0, 1.0, 3.0, 2.0, 4.0, 2.0, 4.0, 1.0, 0.0, 0.0, 0.0, 12.0, 4.0, 3.0, 1.0, 3.0, 1.0, 4.0, 4.0, 6.0, 1.0, 6.0, 4.0, 10.0, 2.0, 2.0, 1.0, 2.0, 7.0, 8.0, 2.0, 2.0, 4.0, 1.0, 4.0, 3.0, 1.0, 5.0, 2.0, 1.0, 8.0, 1.0, 1.0, 4.0, 1.0], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.14698629980690747, "mean_inference_ms": 0.3864864722296536, "mean_action_processing_ms": 0.0283915315720147, "mean_env_wait_ms": 0.3908894716126662, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 4684800, "timesteps_this_iter": 0, "agent_timesteps_total": 4684800, "timers": {"sample_time_ms": 1372.378, "sample_throughput": 3730.751, "load_time_ms": 0.175, "load_throughput": 29265244.59, "learn_time_ms": 79.671, "learn_throughput": 64264.093, "update_time_ms": 3.212}, "info": {"learner": {"default_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 121.46965789794922, "policy_entropy": 7877.904296875, "policy_loss": 7.999581336975098, "vf_loss": 45.37298583984375}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 4684800, "num_agent_steps_sampled": 4684800, "num_steps_trained": 4684800, "num_agent_steps_trained": 4684800, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 2340, "training_iteration": 116, "trial_id": "65be9_00000", "experiment_id": "b9e963105bdc4382843b68ace23a11d3", "date": "2024-06-17_16-28-56", "timestamp": 1718609336, "time_this_iter_s": 10.942851066589355, "time_total_s": 1225.5148665904999, "pid": 4998, "hostname": "DESKTOP-LQ219J4", "node_ip": "192.168.46.185", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 20, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 5000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 500, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "rware", "env_args": {"n_agents": 4, "column_height": 1, "max_inactivity_steps": null, "max_steps": 500, "fast_obs": true, "msg_bits": 0, "sensor_range": 1, "shelf_rows": 1, "shelf_columns": 3, "request_queue_size": 4, "reward_type": "RewardType.INDIVIDUAL", "map_name": "customized_map", "map_size": "tiny", "difficulty": "medium"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": true, "force_coop": false, "local_mode": true, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 4, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 100, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64}, "algorithm": "maa2c", "space_obs": "Dict(obs:Box([-100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100.], [100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.], (112,), float32))", "space_act": "Discrete(5)", "num_agents": 4, "episode_limit": 500, "policy_mapping_info": {"all_scenario": {"description": "rware all scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2", "agent_3"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "rware_customized_map", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 10, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.policy_template.MAA2CTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x7f7c1afbcf70>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "grad_clip": 40.0, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "microbatch_size": null}, "time_since_restore": 1225.5148665904999, "timesteps_since_restore": 0, "iterations_since_restore": 116, "perf": {"cpu_util_percent": 4.275, "ram_util_percent": 97.01249999999999}}
