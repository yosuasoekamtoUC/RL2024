{"episode_reward_max": NaN, "episode_reward_min": NaN, "episode_reward_mean": NaN, "episode_len_mean": NaN, "episode_media": {}, "episodes_this_iter": 0, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [], "episode_lengths": []}, "sampler_perf": {}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 5120, "timesteps_this_iter": 0, "agent_timesteps_total": 5120, "timers": {"sample_time_ms": 1252.105, "sample_throughput": 4089.114, "load_time_ms": 0.228, "load_throughput": 22439745.538, "learn_time_ms": 72.948, "learn_throughput": 70186.544, "update_time_ms": 2.373}, "info": {"learner": {"default_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 15.923462867736816, "policy_entropy": 8047.1708984375, "policy_loss": 7.4039435386657715, "vf_loss": 1.4888436794281006}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 5120, "num_agent_steps_sampled": 5120, "num_steps_trained": 5120, "num_agent_steps_trained": 5120}, "done": false, "episodes_total": 0, "training_iteration": 1, "trial_id": "6184f_00000", "experiment_id": "f2b91da2b7784e16a8a98abdfbd268d1", "date": "2024-06-12_13-22-31", "timestamp": 1718166151, "time_this_iter_s": 1.3196165561676025, "time_total_s": 1.3196165561676025, "pid": 76400, "hostname": "DESKTOP-LQ219J4", "node_ip": "192.168.46.185", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 20, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 5000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 500, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "rware", "env_args": {"n_agents": 4, "column_height": 1, "max_inactivity_steps": null, "max_steps": 500, "fast_obs": true, "msg_bits": 0, "sensor_range": 1, "shelf_rows": 1, "shelf_columns": 3, "request_queue_size": 4, "reward_type": "RewardType.INDIVIDUAL", "map_name": "customized_map", "map_size": "tiny", "difficulty": "medium"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": true, "force_coop": false, "local_mode": true, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 4, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 100, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64}, "algorithm": "maa2c", "space_obs": "Dict(obs:Box([-100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100.], [100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.], (112,), float32))", "space_act": "Discrete(5)", "num_agents": 4, "episode_limit": 500, "policy_mapping_info": {"all_scenario": {"description": "rware all scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2", "agent_3"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "rware_customized_map", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 10, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.policy_template.MAA2CTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x7f1d70045f70>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "grad_clip": 40.0, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "microbatch_size": null}, "time_since_restore": 1.3196165561676025, "timesteps_since_restore": 0, "iterations_since_restore": 1, "perf": {"cpu_util_percent": 7.75, "ram_util_percent": 22.35}}
{"episode_reward_max": 3.0, "episode_reward_min": 0.0, "episode_reward_mean": 1.35, "episode_len_mean": 500.0, "episode_media": {}, "episodes_this_iter": 20, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 1.0, 1.0, 0.0, 2.0, 0.0, 1.0, 3.0, 1.0, 1.0, 1.0, 2.0, 3.0, 2.0, 1.0, 1.0, 3.0, 3.0, 1.0, 0.0], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.14462418458561893, "mean_inference_ms": 0.3739271632336528, "mean_action_processing_ms": 0.02715176734937557, "mean_env_wait_ms": 0.38596752905589105, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 46080, "timesteps_this_iter": 0, "agent_timesteps_total": 46080, "timers": {"sample_time_ms": 1294.839, "sample_throughput": 3954.159, "load_time_ms": 0.116, "load_throughput": 44045927.147, "learn_time_ms": 66.397, "learn_throughput": 77111.943, "update_time_ms": 2.641}, "info": {"learner": {"default_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 36.516448974609375, "policy_entropy": 8042.197265625, "policy_loss": -6.424854278564453, "vf_loss": 11.658124923706055}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 46080, "num_agent_steps_sampled": 46080, "num_steps_trained": 46080, "num_agent_steps_trained": 46080, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 20, "training_iteration": 2, "trial_id": "6184f_00000", "experiment_id": "f2b91da2b7784e16a8a98abdfbd268d1", "date": "2024-06-12_13-22-41", "timestamp": 1718166161, "time_this_iter_s": 10.383549213409424, "time_total_s": 11.703165769577026, "pid": 76400, "hostname": "DESKTOP-LQ219J4", "node_ip": "192.168.46.185", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 20, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 5000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 500, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "rware", "env_args": {"n_agents": 4, "column_height": 1, "max_inactivity_steps": null, "max_steps": 500, "fast_obs": true, "msg_bits": 0, "sensor_range": 1, "shelf_rows": 1, "shelf_columns": 3, "request_queue_size": 4, "reward_type": "RewardType.INDIVIDUAL", "map_name": "customized_map", "map_size": "tiny", "difficulty": "medium"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": true, "force_coop": false, "local_mode": true, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 4, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 100, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64}, "algorithm": "maa2c", "space_obs": "Dict(obs:Box([-100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100.], [100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.], (112,), float32))", "space_act": "Discrete(5)", "num_agents": 4, "episode_limit": 500, "policy_mapping_info": {"all_scenario": {"description": "rware all scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2", "agent_3"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "rware_customized_map", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 10, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.policy_template.MAA2CTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x7f1d704c30d0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "grad_clip": 40.0, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "microbatch_size": null}, "time_since_restore": 11.703165769577026, "timesteps_since_restore": 0, "iterations_since_restore": 2, "perf": {"cpu_util_percent": 4.226666666666666, "ram_util_percent": 23.24666666666667}}
{"episode_reward_max": 3.0, "episode_reward_min": 0.0, "episode_reward_mean": 1.2, "episode_len_mean": 500.0, "episode_media": {}, "episodes_this_iter": 20, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 1.0, 1.0, 0.0, 2.0, 0.0, 1.0, 3.0, 1.0, 1.0, 1.0, 2.0, 3.0, 2.0, 1.0, 1.0, 3.0, 3.0, 1.0, 0.0, 2.0, 2.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 2.0, 2.0, 1.0, 0.0, 1.0, 2.0, 2.0, 1.0, 1.0], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.14485132839974513, "mean_inference_ms": 0.3742652184544862, "mean_action_processing_ms": 0.027117547382118766, "mean_env_wait_ms": 0.38452182258085676, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 87040, "timesteps_this_iter": 0, "agent_timesteps_total": 87040, "timers": {"sample_time_ms": 1303.678, "sample_throughput": 3927.35, "load_time_ms": 0.095, "load_throughput": 54092787.103, "learn_time_ms": 64.072, "learn_throughput": 79909.609, "update_time_ms": 2.575}, "info": {"learner": {"default_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 84.81382751464844, "policy_entropy": 8029.98046875, "policy_loss": 33.36455535888672, "vf_loss": 15.991667747497559}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 87040, "num_agent_steps_sampled": 87040, "num_steps_trained": 87040, "num_agent_steps_trained": 87040, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 40, "training_iteration": 3, "trial_id": "6184f_00000", "experiment_id": "f2b91da2b7784e16a8a98abdfbd268d1", "date": "2024-06-12_13-22-51", "timestamp": 1718166171, "time_this_iter_s": 10.334203720092773, "time_total_s": 22.0373694896698, "pid": 76400, "hostname": "DESKTOP-LQ219J4", "node_ip": "192.168.46.185", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 20, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 5000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 500, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "rware", "env_args": {"n_agents": 4, "column_height": 1, "max_inactivity_steps": null, "max_steps": 500, "fast_obs": true, "msg_bits": 0, "sensor_range": 1, "shelf_rows": 1, "shelf_columns": 3, "request_queue_size": 4, "reward_type": "RewardType.INDIVIDUAL", "map_name": "customized_map", "map_size": "tiny", "difficulty": "medium"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": true, "force_coop": false, "local_mode": true, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 4, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 100, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64}, "algorithm": "maa2c", "space_obs": "Dict(obs:Box([-100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100.], [100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.], (112,), float32))", "space_act": "Discrete(5)", "num_agents": 4, "episode_limit": 500, "policy_mapping_info": {"all_scenario": {"description": "rware all scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2", "agent_3"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "rware_customized_map", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 10, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.policy_template.MAA2CTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x7f1c5cd1f550>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "grad_clip": 40.0, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "microbatch_size": null}, "time_since_restore": 22.0373694896698, "timesteps_since_restore": 0, "iterations_since_restore": 3, "perf": {"cpu_util_percent": 4.546666666666666, "ram_util_percent": 23.966666666666665}}
{"episode_reward_max": 3.0, "episode_reward_min": 0.0, "episode_reward_mean": 1.171875, "episode_len_mean": 500.0, "episode_media": {}, "episodes_this_iter": 24, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 1.0, 1.0, 0.0, 2.0, 0.0, 1.0, 3.0, 1.0, 1.0, 1.0, 2.0, 3.0, 2.0, 1.0, 1.0, 3.0, 3.0, 1.0, 0.0, 2.0, 2.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 2.0, 2.0, 1.0, 0.0, 1.0, 2.0, 2.0, 1.0, 1.0, 2.0, 2.0, 0.0, 1.0, 2.0, 1.0, 0.0, 1.0, 0.0, 2.0, 0.0, 2.0, 1.0, 2.0, 3.0, 1.0, 0.0, 2.0, 0.0, 0.0, 1.0, 2.0, 1.0, 1.0], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.14503659448205714, "mean_inference_ms": 0.37446944756016465, "mean_action_processing_ms": 0.027086237747464527, "mean_env_wait_ms": 0.384743195620272, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 128000, "timesteps_this_iter": 0, "agent_timesteps_total": 128000, "timers": {"sample_time_ms": 1304.688, "sample_throughput": 3924.311, "load_time_ms": 0.098, "load_throughput": 52224796.887, "learn_time_ms": 68.894, "learn_throughput": 74316.599, "update_time_ms": 2.616}, "info": {"learner": {"default_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 174.85134887695312, "policy_entropy": 8018.2060546875, "policy_loss": 72.1163101196289, "vf_loss": 32.578773498535156}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 128000, "num_agent_steps_sampled": 128000, "num_steps_trained": 128000, "num_agent_steps_trained": 128000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 64, "training_iteration": 4, "trial_id": "6184f_00000", "experiment_id": "f2b91da2b7784e16a8a98abdfbd268d1", "date": "2024-06-12_13-23-02", "timestamp": 1718166182, "time_this_iter_s": 10.489561319351196, "time_total_s": 32.526930809020996, "pid": 76400, "hostname": "DESKTOP-LQ219J4", "node_ip": "192.168.46.185", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 20, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 5000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 500, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "rware", "env_args": {"n_agents": 4, "column_height": 1, "max_inactivity_steps": null, "max_steps": 500, "fast_obs": true, "msg_bits": 0, "sensor_range": 1, "shelf_rows": 1, "shelf_columns": 3, "request_queue_size": 4, "reward_type": "RewardType.INDIVIDUAL", "map_name": "customized_map", "map_size": "tiny", "difficulty": "medium"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": true, "force_coop": false, "local_mode": true, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 4, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 100, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64}, "algorithm": "maa2c", "space_obs": "Dict(obs:Box([-100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100.], [100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.], (112,), float32))", "space_act": "Discrete(5)", "num_agents": 4, "episode_limit": 500, "policy_mapping_info": {"all_scenario": {"description": "rware all scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2", "agent_3"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "rware_customized_map", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 10, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.policy_template.MAA2CTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x7f1c4efd23a0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "grad_clip": 40.0, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "microbatch_size": null}, "time_since_restore": 32.526930809020996, "timesteps_since_restore": 0, "iterations_since_restore": 4, "perf": {"cpu_util_percent": 4.1933333333333325, "ram_util_percent": 24.633333333333333}}
{"episode_reward_max": 4.0, "episode_reward_min": 0.0, "episode_reward_mean": 1.1785714285714286, "episode_len_mean": 500.0, "episode_media": {}, "episodes_this_iter": 20, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 1.0, 1.0, 0.0, 2.0, 0.0, 1.0, 3.0, 1.0, 1.0, 1.0, 2.0, 3.0, 2.0, 1.0, 1.0, 3.0, 3.0, 1.0, 0.0, 2.0, 2.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 2.0, 2.0, 1.0, 0.0, 1.0, 2.0, 2.0, 1.0, 1.0, 2.0, 2.0, 0.0, 1.0, 2.0, 1.0, 0.0, 1.0, 0.0, 2.0, 0.0, 2.0, 1.0, 2.0, 3.0, 1.0, 0.0, 2.0, 0.0, 0.0, 1.0, 2.0, 1.0, 1.0, 2.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 2.0, 4.0, 2.0, 0.0, 1.0, 2.0, 0.0, 4.0, 0.0, 1.0, 1.0, 0.0, 0.0], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.14532951970324698, "mean_inference_ms": 0.37497940747862507, "mean_action_processing_ms": 0.027101817748744643, "mean_env_wait_ms": 0.3854640342961579, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 168960, "timesteps_this_iter": 0, "agent_timesteps_total": 168960, "timers": {"sample_time_ms": 1331.729, "sample_throughput": 3844.625, "load_time_ms": 0.099, "load_throughput": 51547855.209, "learn_time_ms": 71.925, "learn_throughput": 71184.865, "update_time_ms": 2.72}, "info": {"learner": {"default_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 36.275794982910156, "policy_entropy": 8029.1611328125, "policy_loss": -3.5042898654937744, "vf_loss": 14.617300987243652}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 168960, "num_agent_steps_sampled": 168960, "num_steps_trained": 168960, "num_agent_steps_trained": 168960, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 84, "training_iteration": 5, "trial_id": "6184f_00000", "experiment_id": "f2b91da2b7784e16a8a98abdfbd268d1", "date": "2024-06-12_13-23-13", "timestamp": 1718166193, "time_this_iter_s": 10.664206504821777, "time_total_s": 43.19113731384277, "pid": 76400, "hostname": "DESKTOP-LQ219J4", "node_ip": "192.168.46.185", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 20, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 5000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 500, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "rware", "env_args": {"n_agents": 4, "column_height": 1, "max_inactivity_steps": null, "max_steps": 500, "fast_obs": true, "msg_bits": 0, "sensor_range": 1, "shelf_rows": 1, "shelf_columns": 3, "request_queue_size": 4, "reward_type": "RewardType.INDIVIDUAL", "map_name": "customized_map", "map_size": "tiny", "difficulty": "medium"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": true, "force_coop": false, "local_mode": true, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 4, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 100, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64}, "algorithm": "maa2c", "space_obs": "Dict(obs:Box([-100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100.], [100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.], (112,), float32))", "space_act": "Discrete(5)", "num_agents": 4, "episode_limit": 500, "policy_mapping_info": {"all_scenario": {"description": "rware all scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2", "agent_3"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "rware_customized_map", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 10, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.policy_template.MAA2CTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x7f1c5cd1fa60>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "grad_clip": 40.0, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "microbatch_size": null}, "time_since_restore": 43.19113731384277, "timesteps_since_restore": 0, "iterations_since_restore": 5, "perf": {"cpu_util_percent": 4.246666666666666, "ram_util_percent": 25.32666666666667}}
{"episode_reward_max": 4.0, "episode_reward_min": 0.0, "episode_reward_mean": 1.24, "episode_len_mean": 500.0, "episode_media": {}, "episodes_this_iter": 20, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [2.0, 0.0, 1.0, 3.0, 1.0, 1.0, 1.0, 2.0, 3.0, 2.0, 1.0, 1.0, 3.0, 3.0, 1.0, 0.0, 2.0, 2.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 2.0, 2.0, 1.0, 0.0, 1.0, 2.0, 2.0, 1.0, 1.0, 2.0, 2.0, 0.0, 1.0, 2.0, 1.0, 0.0, 1.0, 0.0, 2.0, 0.0, 2.0, 1.0, 2.0, 3.0, 1.0, 0.0, 2.0, 0.0, 0.0, 1.0, 2.0, 1.0, 1.0, 2.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 2.0, 4.0, 2.0, 0.0, 1.0, 2.0, 0.0, 4.0, 0.0, 1.0, 1.0, 0.0, 0.0, 2.0, 3.0, 1.0, 0.0, 0.0, 2.0, 2.0, 3.0, 1.0, 1.0, 1.0, 2.0, 1.0, 2.0, 1.0, 0.0, 2.0, 2.0, 0.0, 1.0], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.14566125682325104, "mean_inference_ms": 0.3754453329482022, "mean_action_processing_ms": 0.027144764065194556, "mean_env_wait_ms": 0.3862707707715648, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 209920, "timesteps_this_iter": 0, "agent_timesteps_total": 209920, "timers": {"sample_time_ms": 1335.672, "sample_throughput": 3833.276, "load_time_ms": 0.1, "load_throughput": 51106226.749, "learn_time_ms": 66.343, "learn_throughput": 77174.88, "update_time_ms": 9.799}, "info": {"learner": {"default_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 172.96438598632812, "policy_entropy": 8014.94140625, "policy_loss": -79.69963073730469, "vf_loss": 0.958224892616272}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 209920, "num_agent_steps_sampled": 209920, "num_steps_trained": 209920, "num_agent_steps_trained": 209920, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 104, "training_iteration": 6, "trial_id": "6184f_00000", "experiment_id": "f2b91da2b7784e16a8a98abdfbd268d1", "date": "2024-06-12_13-23-23", "timestamp": 1718166203, "time_this_iter_s": 10.683756351470947, "time_total_s": 53.87489366531372, "pid": 76400, "hostname": "DESKTOP-LQ219J4", "node_ip": "192.168.46.185", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 20, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 5000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 500, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "rware", "env_args": {"n_agents": 4, "column_height": 1, "max_inactivity_steps": null, "max_steps": 500, "fast_obs": true, "msg_bits": 0, "sensor_range": 1, "shelf_rows": 1, "shelf_columns": 3, "request_queue_size": 4, "reward_type": "RewardType.INDIVIDUAL", "map_name": "customized_map", "map_size": "tiny", "difficulty": "medium"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": true, "force_coop": false, "local_mode": true, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 4, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 100, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64}, "algorithm": "maa2c", "space_obs": "Dict(obs:Box([-100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100.], [100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.], (112,), float32))", "space_act": "Discrete(5)", "num_agents": 4, "episode_limit": 500, "policy_mapping_info": {"all_scenario": {"description": "rware all scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2", "agent_3"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "rware_customized_map", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 10, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.policy_template.MAA2CTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x7f1c5c12d940>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "grad_clip": 40.0, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "microbatch_size": null}, "time_since_restore": 53.87489366531372, "timesteps_since_restore": 0, "iterations_since_restore": 6, "perf": {"cpu_util_percent": 4.406666666666666, "ram_util_percent": 25.953333333333333}}
{"episode_reward_max": 5.0, "episode_reward_min": 0.0, "episode_reward_mean": 1.25, "episode_len_mean": 500.0, "episode_media": {}, "episodes_this_iter": 20, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 2.0, 2.0, 1.0, 0.0, 1.0, 2.0, 2.0, 1.0, 1.0, 2.0, 2.0, 0.0, 1.0, 2.0, 1.0, 0.0, 1.0, 0.0, 2.0, 0.0, 2.0, 1.0, 2.0, 3.0, 1.0, 0.0, 2.0, 0.0, 0.0, 1.0, 2.0, 1.0, 1.0, 2.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 2.0, 4.0, 2.0, 0.0, 1.0, 2.0, 0.0, 4.0, 0.0, 1.0, 1.0, 0.0, 0.0, 2.0, 3.0, 1.0, 0.0, 0.0, 2.0, 2.0, 3.0, 1.0, 1.0, 1.0, 2.0, 1.0, 2.0, 1.0, 0.0, 2.0, 2.0, 0.0, 1.0, 1.0, 1.0, 2.0, 2.0, 1.0, 1.0, 0.0, 2.0, 1.0, 1.0, 2.0, 3.0, 2.0, 2.0, 2.0, 2.0, 5.0, 0.0, 0.0, 1.0], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.14618838022914354, "mean_inference_ms": 0.37659222991563324, "mean_action_processing_ms": 0.027192654374303883, "mean_env_wait_ms": 0.3871121589669491, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 250880, "timesteps_this_iter": 0, "agent_timesteps_total": 250880, "timers": {"sample_time_ms": 1344.478, "sample_throughput": 3808.169, "load_time_ms": 0.108, "load_throughput": 47542254.771, "learn_time_ms": 66.647, "learn_throughput": 76822.437, "update_time_ms": 2.674}, "info": {"learner": {"default_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 41.02016830444336, "policy_entropy": 7973.6728515625, "policy_loss": -18.22477149963379, "vf_loss": 15.697237968444824}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 250880, "num_agent_steps_sampled": 250880, "num_steps_trained": 250880, "num_agent_steps_trained": 250880, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 124, "training_iteration": 7, "trial_id": "6184f_00000", "experiment_id": "f2b91da2b7784e16a8a98abdfbd268d1", "date": "2024-06-12_13-23-34", "timestamp": 1718166214, "time_this_iter_s": 10.780922651290894, "time_total_s": 64.65581631660461, "pid": 76400, "hostname": "DESKTOP-LQ219J4", "node_ip": "192.168.46.185", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 20, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 5000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 500, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "rware", "env_args": {"n_agents": 4, "column_height": 1, "max_inactivity_steps": null, "max_steps": 500, "fast_obs": true, "msg_bits": 0, "sensor_range": 1, "shelf_rows": 1, "shelf_columns": 3, "request_queue_size": 4, "reward_type": "RewardType.INDIVIDUAL", "map_name": "customized_map", "map_size": "tiny", "difficulty": "medium"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": true, "force_coop": false, "local_mode": true, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 4, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 100, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64}, "algorithm": "maa2c", "space_obs": "Dict(obs:Box([-100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100.], [100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.], (112,), float32))", "space_act": "Discrete(5)", "num_agents": 4, "episode_limit": 500, "policy_mapping_info": {"all_scenario": {"description": "rware all scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2", "agent_3"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "rware_customized_map", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 10, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.policy_template.MAA2CTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x7f1c5cd1f4c0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "grad_clip": 40.0, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "microbatch_size": null}, "time_since_restore": 64.65581631660461, "timesteps_since_restore": 0, "iterations_since_restore": 7, "perf": {"cpu_util_percent": 4.375, "ram_util_percent": 26.63125}}
{"episode_reward_max": 6.0, "episode_reward_min": 0.0, "episode_reward_mean": 1.44, "episode_len_mean": 500.0, "episode_media": {}, "episodes_this_iter": 20, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [2.0, 1.0, 0.0, 1.0, 0.0, 2.0, 0.0, 2.0, 1.0, 2.0, 3.0, 1.0, 0.0, 2.0, 0.0, 0.0, 1.0, 2.0, 1.0, 1.0, 2.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 2.0, 4.0, 2.0, 0.0, 1.0, 2.0, 0.0, 4.0, 0.0, 1.0, 1.0, 0.0, 0.0, 2.0, 3.0, 1.0, 0.0, 0.0, 2.0, 2.0, 3.0, 1.0, 1.0, 1.0, 2.0, 1.0, 2.0, 1.0, 0.0, 2.0, 2.0, 0.0, 1.0, 1.0, 1.0, 2.0, 2.0, 1.0, 1.0, 0.0, 2.0, 1.0, 1.0, 2.0, 3.0, 2.0, 2.0, 2.0, 2.0, 5.0, 0.0, 0.0, 1.0, 2.0, 2.0, 2.0, 1.0, 1.0, 2.0, 1.0, 3.0, 3.0, 4.0, 1.0, 3.0, 3.0, 1.0, 1.0, 1.0, 2.0, 6.0, 0.0, 1.0], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.1467570552161673, "mean_inference_ms": 0.3778485855116736, "mean_action_processing_ms": 0.02726756134482172, "mean_env_wait_ms": 0.3888734566022735, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 291840, "timesteps_this_iter": 0, "agent_timesteps_total": 291840, "timers": {"sample_time_ms": 1351.097, "sample_throughput": 3789.514, "load_time_ms": 0.115, "load_throughput": 44572097.302, "learn_time_ms": 67.756, "learn_throughput": 75565.386, "update_time_ms": 2.766}, "info": {"learner": {"default_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 46.69939422607422, "policy_entropy": 7949.86962890625, "policy_loss": 10.652973175048828, "vf_loss": 22.160724639892578}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 291840, "num_agent_steps_sampled": 291840, "num_steps_trained": 291840, "num_agent_steps_trained": 291840, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 144, "training_iteration": 8, "trial_id": "6184f_00000", "experiment_id": "f2b91da2b7784e16a8a98abdfbd268d1", "date": "2024-06-12_13-23-45", "timestamp": 1718166225, "time_this_iter_s": 10.803087711334229, "time_total_s": 75.45890402793884, "pid": 76400, "hostname": "DESKTOP-LQ219J4", "node_ip": "192.168.46.185", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 20, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 5000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 500, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "rware", "env_args": {"n_agents": 4, "column_height": 1, "max_inactivity_steps": null, "max_steps": 500, "fast_obs": true, "msg_bits": 0, "sensor_range": 1, "shelf_rows": 1, "shelf_columns": 3, "request_queue_size": 4, "reward_type": "RewardType.INDIVIDUAL", "map_name": "customized_map", "map_size": "tiny", "difficulty": "medium"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": true, "force_coop": false, "local_mode": true, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 4, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 100, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64}, "algorithm": "maa2c", "space_obs": "Dict(obs:Box([-100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100.], [100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.], (112,), float32))", "space_act": "Discrete(5)", "num_agents": 4, "episode_limit": 500, "policy_mapping_info": {"all_scenario": {"description": "rware all scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2", "agent_3"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "rware_customized_map", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 10, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.policy_template.MAA2CTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x7f1c5c128d30>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "grad_clip": 40.0, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "microbatch_size": null}, "time_since_restore": 75.45890402793884, "timesteps_since_restore": 0, "iterations_since_restore": 8, "perf": {"cpu_util_percent": 4.1066666666666665, "ram_util_percent": 27.30666666666667}}
{"episode_reward_max": 6.0, "episode_reward_min": 0.0, "episode_reward_mean": 1.58, "episode_len_mean": 500.0, "episode_media": {}, "episodes_this_iter": 20, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [2.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 2.0, 4.0, 2.0, 0.0, 1.0, 2.0, 0.0, 4.0, 0.0, 1.0, 1.0, 0.0, 0.0, 2.0, 3.0, 1.0, 0.0, 0.0, 2.0, 2.0, 3.0, 1.0, 1.0, 1.0, 2.0, 1.0, 2.0, 1.0, 0.0, 2.0, 2.0, 0.0, 1.0, 1.0, 1.0, 2.0, 2.0, 1.0, 1.0, 0.0, 2.0, 1.0, 1.0, 2.0, 3.0, 2.0, 2.0, 2.0, 2.0, 5.0, 0.0, 0.0, 1.0, 2.0, 2.0, 2.0, 1.0, 1.0, 2.0, 1.0, 3.0, 3.0, 4.0, 1.0, 3.0, 3.0, 1.0, 1.0, 1.0, 2.0, 6.0, 0.0, 1.0, 2.0, 1.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0, 6.0, 2.0, 2.0, 0.0, 1.0, 1.0, 0.0, 3.0, 2.0, 1.0, 1.0, 1.0], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.14737782559272364, "mean_inference_ms": 0.3792887981094188, "mean_action_processing_ms": 0.027360422909850916, "mean_env_wait_ms": 0.390419027158829, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 332800, "timesteps_this_iter": 0, "agent_timesteps_total": 332800, "timers": {"sample_time_ms": 1351.055, "sample_throughput": 3789.632, "load_time_ms": 0.106, "load_throughput": 48290614.976, "learn_time_ms": 66.291, "learn_throughput": 77235.417, "update_time_ms": 2.808}, "info": {"learner": {"default_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 119.65878295898438, "policy_entropy": 7979.68359375, "policy_loss": -59.357696533203125, "vf_loss": 9.206733703613281}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 332800, "num_agent_steps_sampled": 332800, "num_steps_trained": 332800, "num_agent_steps_trained": 332800, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 164, "training_iteration": 9, "trial_id": "6184f_00000", "experiment_id": "f2b91da2b7784e16a8a98abdfbd268d1", "date": "2024-06-12_13-23-56", "timestamp": 1718166236, "time_this_iter_s": 10.811036109924316, "time_total_s": 86.26994013786316, "pid": 76400, "hostname": "DESKTOP-LQ219J4", "node_ip": "192.168.46.185", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 20, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 5000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 500, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "rware", "env_args": {"n_agents": 4, "column_height": 1, "max_inactivity_steps": null, "max_steps": 500, "fast_obs": true, "msg_bits": 0, "sensor_range": 1, "shelf_rows": 1, "shelf_columns": 3, "request_queue_size": 4, "reward_type": "RewardType.INDIVIDUAL", "map_name": "customized_map", "map_size": "tiny", "difficulty": "medium"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": true, "force_coop": false, "local_mode": true, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 4, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 100, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64}, "algorithm": "maa2c", "space_obs": "Dict(obs:Box([-100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100.], [100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.], (112,), float32))", "space_act": "Discrete(5)", "num_agents": 4, "episode_limit": 500, "policy_mapping_info": {"all_scenario": {"description": "rware all scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2", "agent_3"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "rware_customized_map", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 10, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.policy_template.MAA2CTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x7f1c5cd1f0d0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "grad_clip": 40.0, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "microbatch_size": null}, "time_since_restore": 86.26994013786316, "timesteps_since_restore": 0, "iterations_since_restore": 9, "perf": {"cpu_util_percent": 4.706250000000001, "ram_util_percent": 27.96875}}
{"episode_reward_max": 6.0, "episode_reward_min": 0.0, "episode_reward_mean": 1.59, "episode_len_mean": 500.0, "episode_media": {}, "episodes_this_iter": 20, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [2.0, 3.0, 1.0, 0.0, 0.0, 2.0, 2.0, 3.0, 1.0, 1.0, 1.0, 2.0, 1.0, 2.0, 1.0, 0.0, 2.0, 2.0, 0.0, 1.0, 1.0, 1.0, 2.0, 2.0, 1.0, 1.0, 0.0, 2.0, 1.0, 1.0, 2.0, 3.0, 2.0, 2.0, 2.0, 2.0, 5.0, 0.0, 0.0, 1.0, 2.0, 2.0, 2.0, 1.0, 1.0, 2.0, 1.0, 3.0, 3.0, 4.0, 1.0, 3.0, 3.0, 1.0, 1.0, 1.0, 2.0, 6.0, 0.0, 1.0, 2.0, 1.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0, 6.0, 2.0, 2.0, 0.0, 1.0, 1.0, 0.0, 3.0, 2.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 2.0, 1.0, 0.0, 2.0, 0.0, 1.0, 1.0, 2.0, 0.0, 3.0, 1.0, 2.0, 0.0, 2.0, 3.0, 2.0, 2.0], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.14782582391440555, "mean_inference_ms": 0.38025786927066646, "mean_action_processing_ms": 0.027426820795061636, "mean_env_wait_ms": 0.3915081413024535, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 373760, "timesteps_this_iter": 0, "agent_timesteps_total": 373760, "timers": {"sample_time_ms": 1324.037, "sample_throughput": 3866.962, "load_time_ms": 0.104, "load_throughput": 49356093.955, "learn_time_ms": 64.495, "learn_throughput": 79385.481, "update_time_ms": 2.687}, "info": {"learner": {"default_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 87.58184814453125, "policy_entropy": 7991.21630859375, "policy_loss": 26.964988708496094, "vf_loss": 17.61189079284668}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 373760, "num_agent_steps_sampled": 373760, "num_steps_trained": 373760, "num_agent_steps_trained": 373760, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 184, "training_iteration": 10, "trial_id": "6184f_00000", "experiment_id": "f2b91da2b7784e16a8a98abdfbd268d1", "date": "2024-06-12_13-24-06", "timestamp": 1718166246, "time_this_iter_s": 10.574037313461304, "time_total_s": 96.84397745132446, "pid": 76400, "hostname": "DESKTOP-LQ219J4", "node_ip": "192.168.46.185", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 20, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 5000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 500, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "rware", "env_args": {"n_agents": 4, "column_height": 1, "max_inactivity_steps": null, "max_steps": 500, "fast_obs": true, "msg_bits": 0, "sensor_range": 1, "shelf_rows": 1, "shelf_columns": 3, "request_queue_size": 4, "reward_type": "RewardType.INDIVIDUAL", "map_name": "customized_map", "map_size": "tiny", "difficulty": "medium"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": true, "force_coop": false, "local_mode": true, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 4, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 100, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64}, "algorithm": "maa2c", "space_obs": "Dict(obs:Box([-100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100.], [100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.], (112,), float32))", "space_act": "Discrete(5)", "num_agents": 4, "episode_limit": 500, "policy_mapping_info": {"all_scenario": {"description": "rware all scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2", "agent_3"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "rware_customized_map", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 10, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.policy_template.MAA2CTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x7f1c5c0fc820>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "grad_clip": 40.0, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "microbatch_size": null}, "time_since_restore": 96.84397745132446, "timesteps_since_restore": 0, "iterations_since_restore": 10, "perf": {"cpu_util_percent": 4.0200000000000005, "ram_util_percent": 28.68}}
{"episode_reward_max": 6.0, "episode_reward_min": 0.0, "episode_reward_mean": 1.56, "episode_len_mean": 500.0, "episode_media": {}, "episodes_this_iter": 20, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [1.0, 1.0, 2.0, 2.0, 1.0, 1.0, 0.0, 2.0, 1.0, 1.0, 2.0, 3.0, 2.0, 2.0, 2.0, 2.0, 5.0, 0.0, 0.0, 1.0, 2.0, 2.0, 2.0, 1.0, 1.0, 2.0, 1.0, 3.0, 3.0, 4.0, 1.0, 3.0, 3.0, 1.0, 1.0, 1.0, 2.0, 6.0, 0.0, 1.0, 2.0, 1.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0, 6.0, 2.0, 2.0, 0.0, 1.0, 1.0, 0.0, 3.0, 2.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 2.0, 1.0, 0.0, 2.0, 0.0, 1.0, 1.0, 2.0, 0.0, 3.0, 1.0, 2.0, 0.0, 2.0, 3.0, 2.0, 2.0, 0.0, 0.0, 3.0, 1.0, 1.0, 0.0, 1.0, 2.0, 2.0, 2.0, 1.0, 3.0, 1.0, 1.0, 0.0, 4.0, 0.0, 0.0, 1.0, 1.0], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.14818643743108093, "mean_inference_ms": 0.3809904599451188, "mean_action_processing_ms": 0.02745975685545445, "mean_env_wait_ms": 0.3925026751194933, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 414720, "timesteps_this_iter": 0, "agent_timesteps_total": 414720, "timers": {"sample_time_ms": 1332.285, "sample_throughput": 3843.021, "load_time_ms": 0.106, "load_throughput": 48203897.823, "learn_time_ms": 65.983, "learn_throughput": 77595.986, "update_time_ms": 2.785}, "info": {"learner": {"default_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 41.76667022705078, "policy_entropy": 8009.40869140625, "policy_loss": -24.144346237182617, "vf_loss": 0.6421929597854614}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 414720, "num_agent_steps_sampled": 414720, "num_steps_trained": 414720, "num_agent_steps_trained": 414720, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 204, "training_iteration": 11, "trial_id": "6184f_00000", "experiment_id": "f2b91da2b7784e16a8a98abdfbd268d1", "date": "2024-06-12_13-24-17", "timestamp": 1718166257, "time_this_iter_s": 10.651402473449707, "time_total_s": 107.49537992477417, "pid": 76400, "hostname": "DESKTOP-LQ219J4", "node_ip": "192.168.46.185", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 20, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 5000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 500, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "rware", "env_args": {"n_agents": 4, "column_height": 1, "max_inactivity_steps": null, "max_steps": 500, "fast_obs": true, "msg_bits": 0, "sensor_range": 1, "shelf_rows": 1, "shelf_columns": 3, "request_queue_size": 4, "reward_type": "RewardType.INDIVIDUAL", "map_name": "customized_map", "map_size": "tiny", "difficulty": "medium"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": true, "force_coop": false, "local_mode": true, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 4, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 100, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64}, "algorithm": "maa2c", "space_obs": "Dict(obs:Box([-100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100.], [100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.], (112,), float32))", "space_act": "Discrete(5)", "num_agents": 4, "episode_limit": 500, "policy_mapping_info": {"all_scenario": {"description": "rware all scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2", "agent_3"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "rware_customized_map", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 10, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.policy_template.MAA2CTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x7f1c5c0fc430>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "grad_clip": 40.0, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "microbatch_size": null}, "time_since_restore": 107.49537992477417, "timesteps_since_restore": 0, "iterations_since_restore": 11, "perf": {"cpu_util_percent": 3.953333333333333, "ram_util_percent": 29.36666666666667}}
{"episode_reward_max": 6.0, "episode_reward_min": 0.0, "episode_reward_mean": 1.46, "episode_len_mean": 500.0, "episode_media": {}, "episodes_this_iter": 20, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [2.0, 2.0, 2.0, 1.0, 1.0, 2.0, 1.0, 3.0, 3.0, 4.0, 1.0, 3.0, 3.0, 1.0, 1.0, 1.0, 2.0, 6.0, 0.0, 1.0, 2.0, 1.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0, 6.0, 2.0, 2.0, 0.0, 1.0, 1.0, 0.0, 3.0, 2.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 2.0, 1.0, 0.0, 2.0, 0.0, 1.0, 1.0, 2.0, 0.0, 3.0, 1.0, 2.0, 0.0, 2.0, 3.0, 2.0, 2.0, 0.0, 0.0, 3.0, 1.0, 1.0, 0.0, 1.0, 2.0, 2.0, 2.0, 1.0, 3.0, 1.0, 1.0, 0.0, 4.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 3.0, 1.0, 1.0, 0.0, 2.0, 1.0, 2.0, 0.0, 1.0, 0.0, 1.0, 1.0, 3.0, 1.0, 0.0, 2.0, 0.0], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.14840414630610455, "mean_inference_ms": 0.38137159523456504, "mean_action_processing_ms": 0.02747463350353656, "mean_env_wait_ms": 0.39302444817842885, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 455680, "timesteps_this_iter": 0, "agent_timesteps_total": 455680, "timers": {"sample_time_ms": 1320.287, "sample_throughput": 3877.945, "load_time_ms": 0.115, "load_throughput": 44711298.105, "learn_time_ms": 65.447, "learn_throughput": 78231.814, "update_time_ms": 2.653}, "info": {"learner": {"default_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 105.17439270019531, "policy_entropy": 8016.908203125, "policy_loss": 48.09006881713867, "vf_loss": 20.172931671142578}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 455680, "num_agent_steps_sampled": 455680, "num_steps_trained": 455680, "num_agent_steps_trained": 455680, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 224, "training_iteration": 12, "trial_id": "6184f_00000", "experiment_id": "f2b91da2b7784e16a8a98abdfbd268d1", "date": "2024-06-12_13-24-28", "timestamp": 1718166268, "time_this_iter_s": 10.536667346954346, "time_total_s": 118.03204727172852, "pid": 76400, "hostname": "DESKTOP-LQ219J4", "node_ip": "192.168.46.185", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 20, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 5000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 500, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "rware", "env_args": {"n_agents": 4, "column_height": 1, "max_inactivity_steps": null, "max_steps": 500, "fast_obs": true, "msg_bits": 0, "sensor_range": 1, "shelf_rows": 1, "shelf_columns": 3, "request_queue_size": 4, "reward_type": "RewardType.INDIVIDUAL", "map_name": "customized_map", "map_size": "tiny", "difficulty": "medium"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": true, "force_coop": false, "local_mode": true, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 4, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 100, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64}, "algorithm": "maa2c", "space_obs": "Dict(obs:Box([-100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100.], [100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.], (112,), float32))", "space_act": "Discrete(5)", "num_agents": 4, "episode_limit": 500, "policy_mapping_info": {"all_scenario": {"description": "rware all scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2", "agent_3"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "rware_customized_map", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 10, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.policy_template.MAA2CTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x7f1d70045940>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "grad_clip": 40.0, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "microbatch_size": null}, "time_since_restore": 118.03204727172852, "timesteps_since_restore": 0, "iterations_since_restore": 12, "perf": {"cpu_util_percent": 4.28, "ram_util_percent": 30.013333333333335}}
{"episode_reward_max": 6.0, "episode_reward_min": 0.0, "episode_reward_mean": 1.37, "episode_len_mean": 500.0, "episode_media": {}, "episodes_this_iter": 24, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [1.0, 3.0, 1.0, 2.0, 6.0, 2.0, 2.0, 0.0, 1.0, 1.0, 0.0, 3.0, 2.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 2.0, 1.0, 0.0, 2.0, 0.0, 1.0, 1.0, 2.0, 0.0, 3.0, 1.0, 2.0, 0.0, 2.0, 3.0, 2.0, 2.0, 0.0, 0.0, 3.0, 1.0, 1.0, 0.0, 1.0, 2.0, 2.0, 2.0, 1.0, 3.0, 1.0, 1.0, 0.0, 4.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 3.0, 1.0, 1.0, 0.0, 2.0, 1.0, 2.0, 0.0, 1.0, 0.0, 1.0, 1.0, 3.0, 1.0, 0.0, 2.0, 0.0, 2.0, 1.0, 1.0, 2.0, 0.0, 1.0, 1.0, 1.0, 2.0, 0.0, 1.0, 5.0, 3.0, 1.0, 4.0, 2.0, 3.0, 4.0, 1.0, 3.0, 0.0, 0.0, 2.0, 0.0], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.1485133133940828, "mean_inference_ms": 0.3814044227321031, "mean_action_processing_ms": 0.0274681583201456, "mean_env_wait_ms": 0.39286383111312917, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 496640, "timesteps_this_iter": 0, "agent_timesteps_total": 496640, "timers": {"sample_time_ms": 1315.544, "sample_throughput": 3891.925, "load_time_ms": 0.108, "load_throughput": 47353553.429, "learn_time_ms": 65.15, "learn_throughput": 78587.588, "update_time_ms": 2.728}, "info": {"learner": {"default_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 164.96237182617188, "policy_entropy": 7983.859375, "policy_loss": 66.80357360839844, "vf_loss": 36.494258880615234}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 496640, "num_agent_steps_sampled": 496640, "num_steps_trained": 496640, "num_agent_steps_trained": 496640, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 248, "training_iteration": 13, "trial_id": "6184f_00000", "experiment_id": "f2b91da2b7784e16a8a98abdfbd268d1", "date": "2024-06-12_13-24-38", "timestamp": 1718166278, "time_this_iter_s": 10.447271585464478, "time_total_s": 128.479318857193, "pid": 76400, "hostname": "DESKTOP-LQ219J4", "node_ip": "192.168.46.185", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 20, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 5000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 500, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "rware", "env_args": {"n_agents": 4, "column_height": 1, "max_inactivity_steps": null, "max_steps": 500, "fast_obs": true, "msg_bits": 0, "sensor_range": 1, "shelf_rows": 1, "shelf_columns": 3, "request_queue_size": 4, "reward_type": "RewardType.INDIVIDUAL", "map_name": "customized_map", "map_size": "tiny", "difficulty": "medium"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": true, "force_coop": false, "local_mode": true, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 4, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 100, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64}, "algorithm": "maa2c", "space_obs": "Dict(obs:Box([-100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100.], [100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.], (112,), float32))", "space_act": "Discrete(5)", "num_agents": 4, "episode_limit": 500, "policy_mapping_info": {"all_scenario": {"description": "rware all scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2", "agent_3"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "rware_customized_map", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 10, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.policy_template.MAA2CTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x7f1c5cd1f5e0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "grad_clip": 40.0, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "microbatch_size": null}, "time_since_restore": 128.479318857193, "timesteps_since_restore": 0, "iterations_since_restore": 13, "perf": {"cpu_util_percent": 4.459999999999999, "ram_util_percent": 30.653333333333325}}
{"episode_reward_max": 5.0, "episode_reward_min": 0.0, "episode_reward_mean": 1.43, "episode_len_mean": 500.0, "episode_media": {}, "episodes_this_iter": 20, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [1.0, 0.0, 2.0, 0.0, 1.0, 1.0, 2.0, 0.0, 3.0, 1.0, 2.0, 0.0, 2.0, 3.0, 2.0, 2.0, 0.0, 0.0, 3.0, 1.0, 1.0, 0.0, 1.0, 2.0, 2.0, 2.0, 1.0, 3.0, 1.0, 1.0, 0.0, 4.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 3.0, 1.0, 1.0, 0.0, 2.0, 1.0, 2.0, 0.0, 1.0, 0.0, 1.0, 1.0, 3.0, 1.0, 0.0, 2.0, 0.0, 2.0, 1.0, 1.0, 2.0, 0.0, 1.0, 1.0, 1.0, 2.0, 0.0, 1.0, 5.0, 3.0, 1.0, 4.0, 2.0, 3.0, 4.0, 1.0, 3.0, 0.0, 0.0, 2.0, 0.0, 2.0, 3.0, 3.0, 3.0, 0.0, 1.0, 3.0, 0.0, 3.0, 1.0, 1.0, 3.0, 1.0, 1.0, 1.0, 2.0, 2.0, 3.0, 2.0, 1.0], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.14849346370413244, "mean_inference_ms": 0.3812597507799045, "mean_action_processing_ms": 0.027454386167470746, "mean_env_wait_ms": 0.3926048998248787, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 537600, "timesteps_this_iter": 0, "agent_timesteps_total": 537600, "timers": {"sample_time_ms": 1309.722, "sample_throughput": 3909.225, "load_time_ms": 0.119, "load_throughput": 43087553.13, "learn_time_ms": 65.55, "learn_throughput": 78108.18, "update_time_ms": 2.726}, "info": {"learner": {"default_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 94.18494415283203, "policy_entropy": 7943.62353515625, "policy_loss": -38.154449462890625, "vf_loss": 13.970956802368164}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 537600, "num_agent_steps_sampled": 537600, "num_steps_trained": 537600, "num_agent_steps_trained": 537600, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 268, "training_iteration": 14, "trial_id": "6184f_00000", "experiment_id": "f2b91da2b7784e16a8a98abdfbd268d1", "date": "2024-06-12_13-24-48", "timestamp": 1718166288, "time_this_iter_s": 10.456945657730103, "time_total_s": 138.9362645149231, "pid": 76400, "hostname": "DESKTOP-LQ219J4", "node_ip": "192.168.46.185", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 20, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 5000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 500, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "rware", "env_args": {"n_agents": 4, "column_height": 1, "max_inactivity_steps": null, "max_steps": 500, "fast_obs": true, "msg_bits": 0, "sensor_range": 1, "shelf_rows": 1, "shelf_columns": 3, "request_queue_size": 4, "reward_type": "RewardType.INDIVIDUAL", "map_name": "customized_map", "map_size": "tiny", "difficulty": "medium"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": true, "force_coop": false, "local_mode": true, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 4, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 100, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64}, "algorithm": "maa2c", "space_obs": "Dict(obs:Box([-100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100.], [100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.], (112,), float32))", "space_act": "Discrete(5)", "num_agents": 4, "episode_limit": 500, "policy_mapping_info": {"all_scenario": {"description": "rware all scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2", "agent_3"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "rware_customized_map", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 10, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.policy_template.MAA2CTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x7f1d983148b0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "grad_clip": 40.0, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "microbatch_size": null}, "time_since_restore": 138.9362645149231, "timesteps_since_restore": 0, "iterations_since_restore": 14, "perf": {"cpu_util_percent": 4.293333333333334, "ram_util_percent": 31.35333333333334}}
{"episode_reward_max": 6.0, "episode_reward_min": 0.0, "episode_reward_mean": 1.54, "episode_len_mean": 500.0, "episode_media": {}, "episodes_this_iter": 20, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [1.0, 0.0, 1.0, 2.0, 2.0, 2.0, 1.0, 3.0, 1.0, 1.0, 0.0, 4.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 3.0, 1.0, 1.0, 0.0, 2.0, 1.0, 2.0, 0.0, 1.0, 0.0, 1.0, 1.0, 3.0, 1.0, 0.0, 2.0, 0.0, 2.0, 1.0, 1.0, 2.0, 0.0, 1.0, 1.0, 1.0, 2.0, 0.0, 1.0, 5.0, 3.0, 1.0, 4.0, 2.0, 3.0, 4.0, 1.0, 3.0, 0.0, 0.0, 2.0, 0.0, 2.0, 3.0, 3.0, 3.0, 0.0, 1.0, 3.0, 0.0, 3.0, 1.0, 1.0, 3.0, 1.0, 1.0, 1.0, 2.0, 2.0, 3.0, 2.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 4.0, 1.0, 1.0, 4.0, 2.0, 5.0, 6.0, 0.0, 2.0, 2.0, 3.0, 0.0, 0.0, 2.0], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.14844494695846028, "mean_inference_ms": 0.381079456544044, "mean_action_processing_ms": 0.027437518806049884, "mean_env_wait_ms": 0.392177927539932, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 578560, "timesteps_this_iter": 0, "agent_timesteps_total": 578560, "timers": {"sample_time_ms": 1309.259, "sample_throughput": 3910.61, "load_time_ms": 0.116, "load_throughput": 43960770.686, "learn_time_ms": 65.804, "learn_throughput": 77807.097, "update_time_ms": 2.744}, "info": {"learner": {"default_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 97.30238342285156, "policy_entropy": 7984.02685546875, "policy_loss": 34.24504470825195, "vf_loss": 34.344669342041016}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 578560, "num_agent_steps_sampled": 578560, "num_steps_trained": 578560, "num_agent_steps_trained": 578560, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 288, "training_iteration": 15, "trial_id": "6184f_00000", "experiment_id": "f2b91da2b7784e16a8a98abdfbd268d1", "date": "2024-06-12_13-24-59", "timestamp": 1718166299, "time_this_iter_s": 10.491535425186157, "time_total_s": 149.42779994010925, "pid": 76400, "hostname": "DESKTOP-LQ219J4", "node_ip": "192.168.46.185", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 20, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 5000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 500, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "rware", "env_args": {"n_agents": 4, "column_height": 1, "max_inactivity_steps": null, "max_steps": 500, "fast_obs": true, "msg_bits": 0, "sensor_range": 1, "shelf_rows": 1, "shelf_columns": 3, "request_queue_size": 4, "reward_type": "RewardType.INDIVIDUAL", "map_name": "customized_map", "map_size": "tiny", "difficulty": "medium"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": true, "force_coop": false, "local_mode": true, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 4, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 100, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64}, "algorithm": "maa2c", "space_obs": "Dict(obs:Box([-100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100.], [100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.], (112,), float32))", "space_act": "Discrete(5)", "num_agents": 4, "episode_limit": 500, "policy_mapping_info": {"all_scenario": {"description": "rware all scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2", "agent_3"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "rware_customized_map", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 10, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.policy_template.MAA2CTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x7f1c5c12db80>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "grad_clip": 40.0, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "microbatch_size": null}, "time_since_restore": 149.42779994010925, "timesteps_since_restore": 0, "iterations_since_restore": 15, "perf": {"cpu_util_percent": 4.206666666666668, "ram_util_percent": 32.013333333333335}}
{"episode_reward_max": 6.0, "episode_reward_min": 0.0, "episode_reward_mean": 1.69, "episode_len_mean": 500.0, "episode_media": {}, "episodes_this_iter": 20, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [1.0, 1.0, 0.0, 2.0, 1.0, 2.0, 0.0, 1.0, 0.0, 1.0, 1.0, 3.0, 1.0, 0.0, 2.0, 0.0, 2.0, 1.0, 1.0, 2.0, 0.0, 1.0, 1.0, 1.0, 2.0, 0.0, 1.0, 5.0, 3.0, 1.0, 4.0, 2.0, 3.0, 4.0, 1.0, 3.0, 0.0, 0.0, 2.0, 0.0, 2.0, 3.0, 3.0, 3.0, 0.0, 1.0, 3.0, 0.0, 3.0, 1.0, 1.0, 3.0, 1.0, 1.0, 1.0, 2.0, 2.0, 3.0, 2.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 4.0, 1.0, 1.0, 4.0, 2.0, 5.0, 6.0, 0.0, 2.0, 2.0, 3.0, 0.0, 0.0, 2.0, 4.0, 2.0, 1.0, 2.0, 1.0, 3.0, 1.0, 1.0, 2.0, 2.0, 2.0, 2.0, 1.0, 1.0, 4.0, 2.0, 1.0, 3.0, 3.0, 2.0], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.1483615566090565, "mean_inference_ms": 0.3807905484985233, "mean_action_processing_ms": 0.027418002100815294, "mean_env_wait_ms": 0.3916716319674874, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 619520, "timesteps_this_iter": 0, "agent_timesteps_total": 619520, "timers": {"sample_time_ms": 1304.728, "sample_throughput": 3924.19, "load_time_ms": 0.114, "load_throughput": 44879491.076, "learn_time_ms": 68.253, "learn_throughput": 75015.052, "update_time_ms": 2.96}, "info": {"learner": {"default_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 120.12232208251953, "policy_entropy": 7986.14453125, "policy_loss": -59.9941520690918, "vf_loss": 7.474987030029297}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 619520, "num_agent_steps_sampled": 619520, "num_steps_trained": 619520, "num_agent_steps_trained": 619520, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 308, "training_iteration": 16, "trial_id": "6184f_00000", "experiment_id": "f2b91da2b7784e16a8a98abdfbd268d1", "date": "2024-06-12_13-25-09", "timestamp": 1718166309, "time_this_iter_s": 10.468440294265747, "time_total_s": 159.896240234375, "pid": 76400, "hostname": "DESKTOP-LQ219J4", "node_ip": "192.168.46.185", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 20, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 5000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 500, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "rware", "env_args": {"n_agents": 4, "column_height": 1, "max_inactivity_steps": null, "max_steps": 500, "fast_obs": true, "msg_bits": 0, "sensor_range": 1, "shelf_rows": 1, "shelf_columns": 3, "request_queue_size": 4, "reward_type": "RewardType.INDIVIDUAL", "map_name": "customized_map", "map_size": "tiny", "difficulty": "medium"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": true, "force_coop": false, "local_mode": true, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 4, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 100, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64}, "algorithm": "maa2c", "space_obs": "Dict(obs:Box([-100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100.], [100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.], (112,), float32))", "space_act": "Discrete(5)", "num_agents": 4, "episode_limit": 500, "policy_mapping_info": {"all_scenario": {"description": "rware all scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2", "agent_3"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "rware_customized_map", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 10, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.policy_template.MAA2CTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x7f1c5c0fc1f0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "grad_clip": 40.0, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "microbatch_size": null}, "time_since_restore": 159.896240234375, "timesteps_since_restore": 0, "iterations_since_restore": 16, "perf": {"cpu_util_percent": 4.4, "ram_util_percent": 32.68}}
{"episode_reward_max": 6.0, "episode_reward_min": 0.0, "episode_reward_mean": 1.76, "episode_len_mean": 500.0, "episode_media": {}, "episodes_this_iter": 20, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 1.0, 1.0, 1.0, 2.0, 0.0, 1.0, 5.0, 3.0, 1.0, 4.0, 2.0, 3.0, 4.0, 1.0, 3.0, 0.0, 0.0, 2.0, 0.0, 2.0, 3.0, 3.0, 3.0, 0.0, 1.0, 3.0, 0.0, 3.0, 1.0, 1.0, 3.0, 1.0, 1.0, 1.0, 2.0, 2.0, 3.0, 2.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 4.0, 1.0, 1.0, 4.0, 2.0, 5.0, 6.0, 0.0, 2.0, 2.0, 3.0, 0.0, 0.0, 2.0, 4.0, 2.0, 1.0, 2.0, 1.0, 3.0, 1.0, 1.0, 2.0, 2.0, 2.0, 2.0, 1.0, 1.0, 4.0, 2.0, 1.0, 3.0, 3.0, 2.0, 2.0, 5.0, 3.0, 0.0, 1.0, 2.0, 1.0, 0.0, 2.0, 2.0, 1.0, 1.0, 3.0, 0.0, 1.0, 1.0, 2.0, 0.0, 1.0, 1.0], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.14825707535606006, "mean_inference_ms": 0.3804708716066632, "mean_action_processing_ms": 0.0273934837005676, "mean_env_wait_ms": 0.39127528511529164, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 660480, "timesteps_this_iter": 0, "agent_timesteps_total": 660480, "timers": {"sample_time_ms": 1302.189, "sample_throughput": 3931.84, "load_time_ms": 0.114, "load_throughput": 44898257.328, "learn_time_ms": 65.476, "learn_throughput": 78196.548, "update_time_ms": 2.846}, "info": {"learner": {"default_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 44.981136322021484, "policy_entropy": 7984.1640625, "policy_loss": 4.377279758453369, "vf_loss": 19.249353408813477}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 660480, "num_agent_steps_sampled": 660480, "num_steps_trained": 660480, "num_agent_steps_trained": 660480, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 328, "training_iteration": 17, "trial_id": "6184f_00000", "experiment_id": "f2b91da2b7784e16a8a98abdfbd268d1", "date": "2024-06-12_13-25-20", "timestamp": 1718166320, "time_this_iter_s": 10.399828433990479, "time_total_s": 170.29606866836548, "pid": 76400, "hostname": "DESKTOP-LQ219J4", "node_ip": "192.168.46.185", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 20, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 5000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 500, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "rware", "env_args": {"n_agents": 4, "column_height": 1, "max_inactivity_steps": null, "max_steps": 500, "fast_obs": true, "msg_bits": 0, "sensor_range": 1, "shelf_rows": 1, "shelf_columns": 3, "request_queue_size": 4, "reward_type": "RewardType.INDIVIDUAL", "map_name": "customized_map", "map_size": "tiny", "difficulty": "medium"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": true, "force_coop": false, "local_mode": true, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 4, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 100, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64}, "algorithm": "maa2c", "space_obs": "Dict(obs:Box([-100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100.], [100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.], (112,), float32))", "space_act": "Discrete(5)", "num_agents": 4, "episode_limit": 500, "policy_mapping_info": {"all_scenario": {"description": "rware all scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2", "agent_3"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "rware_customized_map", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 10, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.policy_template.MAA2CTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x7f1c5c12ddc0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "grad_clip": 40.0, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "microbatch_size": null}, "time_since_restore": 170.29606866836548, "timesteps_since_restore": 0, "iterations_since_restore": 17, "perf": {"cpu_util_percent": 4.026666666666666, "ram_util_percent": 33.35333333333333}}
{"episode_reward_max": 6.0, "episode_reward_min": 0.0, "episode_reward_mean": 1.74, "episode_len_mean": 500.0, "episode_media": {}, "episodes_this_iter": 20, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [2.0, 3.0, 3.0, 3.0, 0.0, 1.0, 3.0, 0.0, 3.0, 1.0, 1.0, 3.0, 1.0, 1.0, 1.0, 2.0, 2.0, 3.0, 2.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 4.0, 1.0, 1.0, 4.0, 2.0, 5.0, 6.0, 0.0, 2.0, 2.0, 3.0, 0.0, 0.0, 2.0, 4.0, 2.0, 1.0, 2.0, 1.0, 3.0, 1.0, 1.0, 2.0, 2.0, 2.0, 2.0, 1.0, 1.0, 4.0, 2.0, 1.0, 3.0, 3.0, 2.0, 2.0, 5.0, 3.0, 0.0, 1.0, 2.0, 1.0, 0.0, 2.0, 2.0, 1.0, 1.0, 3.0, 0.0, 1.0, 1.0, 2.0, 0.0, 1.0, 1.0, 1.0, 6.0, 2.0, 0.0, 1.0, 0.0, 3.0, 4.0, 2.0, 2.0, 2.0, 3.0, 0.0, 1.0, 0.0, 1.0, 0.0, 2.0, 0.0, 2.0], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.1481344375694271, "mean_inference_ms": 0.3802255356935413, "mean_action_processing_ms": 0.02737247805593964, "mean_env_wait_ms": 0.39120007780715993, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 701440, "timesteps_this_iter": 0, "agent_timesteps_total": 701440, "timers": {"sample_time_ms": 1308.848, "sample_throughput": 3911.837, "load_time_ms": 0.118, "load_throughput": 43480130.553, "learn_time_ms": 66.123, "learn_throughput": 77430.941, "update_time_ms": 2.961}, "info": {"learner": {"default_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 234.7346649169922, "policy_entropy": 7974.8798828125, "policy_loss": 96.55770111083984, "vf_loss": 39.907920837402344}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 701440, "num_agent_steps_sampled": 701440, "num_steps_trained": 701440, "num_agent_steps_trained": 701440, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 348, "training_iteration": 18, "trial_id": "6184f_00000", "experiment_id": "f2b91da2b7784e16a8a98abdfbd268d1", "date": "2024-06-12_13-25-30", "timestamp": 1718166330, "time_this_iter_s": 10.517021417617798, "time_total_s": 180.81309008598328, "pid": 76400, "hostname": "DESKTOP-LQ219J4", "node_ip": "192.168.46.185", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 20, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 5000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 500, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "rware", "env_args": {"n_agents": 4, "column_height": 1, "max_inactivity_steps": null, "max_steps": 500, "fast_obs": true, "msg_bits": 0, "sensor_range": 1, "shelf_rows": 1, "shelf_columns": 3, "request_queue_size": 4, "reward_type": "RewardType.INDIVIDUAL", "map_name": "customized_map", "map_size": "tiny", "difficulty": "medium"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": true, "force_coop": false, "local_mode": true, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 4, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 100, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64}, "algorithm": "maa2c", "space_obs": "Dict(obs:Box([-100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100.], [100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.], (112,), float32))", "space_act": "Discrete(5)", "num_agents": 4, "episode_limit": 500, "policy_mapping_info": {"all_scenario": {"description": "rware all scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2", "agent_3"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "rware_customized_map", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 10, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.policy_template.MAA2CTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x7f1c5cd1fd30>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "grad_clip": 40.0, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "microbatch_size": null}, "time_since_restore": 180.81309008598328, "timesteps_since_restore": 0, "iterations_since_restore": 18, "perf": {"cpu_util_percent": 3.9466666666666668, "ram_util_percent": 34.02}}
{"episode_reward_max": 6.0, "episode_reward_min": 0.0, "episode_reward_mean": 1.72, "episode_len_mean": 500.0, "episode_media": {}, "episodes_this_iter": 20, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 4.0, 1.0, 1.0, 4.0, 2.0, 5.0, 6.0, 0.0, 2.0, 2.0, 3.0, 0.0, 0.0, 2.0, 4.0, 2.0, 1.0, 2.0, 1.0, 3.0, 1.0, 1.0, 2.0, 2.0, 2.0, 2.0, 1.0, 1.0, 4.0, 2.0, 1.0, 3.0, 3.0, 2.0, 2.0, 5.0, 3.0, 0.0, 1.0, 2.0, 1.0, 0.0, 2.0, 2.0, 1.0, 1.0, 3.0, 0.0, 1.0, 1.0, 2.0, 0.0, 1.0, 1.0, 1.0, 6.0, 2.0, 0.0, 1.0, 0.0, 3.0, 4.0, 2.0, 2.0, 2.0, 3.0, 0.0, 1.0, 0.0, 1.0, 0.0, 2.0, 0.0, 2.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 3.0, 2.0, 1.0, 2.0, 3.0, 2.0, 3.0, 1.0, 1.0, 4.0, 1.0, 2.0, 2.0, 1.0], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.14802328474384602, "mean_inference_ms": 0.3799513683760763, "mean_action_processing_ms": 0.027348959111819764, "mean_env_wait_ms": 0.3909071684015337, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 742400, "timesteps_this_iter": 0, "agent_timesteps_total": 742400, "timers": {"sample_time_ms": 1305.311, "sample_throughput": 3922.436, "load_time_ms": 0.121, "load_throughput": 42223429.965, "learn_time_ms": 66.048, "learn_throughput": 77519.769, "update_time_ms": 2.757}, "info": {"learner": {"default_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 40.10715103149414, "policy_entropy": 7986.3359375, "policy_loss": -14.378985404968262, "vf_loss": 9.718297004699707}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 742400, "num_agent_steps_sampled": 742400, "num_steps_trained": 742400, "num_agent_steps_trained": 742400, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 368, "training_iteration": 19, "trial_id": "6184f_00000", "experiment_id": "f2b91da2b7784e16a8a98abdfbd268d1", "date": "2024-06-12_13-25-41", "timestamp": 1718166341, "time_this_iter_s": 10.40284538269043, "time_total_s": 191.2159354686737, "pid": 76400, "hostname": "DESKTOP-LQ219J4", "node_ip": "192.168.46.185", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 20, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 5000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 500, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "rware", "env_args": {"n_agents": 4, "column_height": 1, "max_inactivity_steps": null, "max_steps": 500, "fast_obs": true, "msg_bits": 0, "sensor_range": 1, "shelf_rows": 1, "shelf_columns": 3, "request_queue_size": 4, "reward_type": "RewardType.INDIVIDUAL", "map_name": "customized_map", "map_size": "tiny", "difficulty": "medium"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": true, "force_coop": false, "local_mode": true, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 4, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 100, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64}, "algorithm": "maa2c", "space_obs": "Dict(obs:Box([-100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100.], [100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.], (112,), float32))", "space_act": "Discrete(5)", "num_agents": 4, "episode_limit": 500, "policy_mapping_info": {"all_scenario": {"description": "rware all scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2", "agent_3"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "rware_customized_map", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 10, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.policy_template.MAA2CTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x7f1c5cd1f670>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "grad_clip": 40.0, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "microbatch_size": null}, "time_since_restore": 191.2159354686737, "timesteps_since_restore": 0, "iterations_since_restore": 19, "perf": {"cpu_util_percent": 4.2, "ram_util_percent": 34.66428571428572}}
{"episode_reward_max": 6.0, "episode_reward_min": 0.0, "episode_reward_mean": 1.63, "episode_len_mean": 500.0, "episode_media": {}, "episodes_this_iter": 20, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [4.0, 2.0, 1.0, 2.0, 1.0, 3.0, 1.0, 1.0, 2.0, 2.0, 2.0, 2.0, 1.0, 1.0, 4.0, 2.0, 1.0, 3.0, 3.0, 2.0, 2.0, 5.0, 3.0, 0.0, 1.0, 2.0, 1.0, 0.0, 2.0, 2.0, 1.0, 1.0, 3.0, 0.0, 1.0, 1.0, 2.0, 0.0, 1.0, 1.0, 1.0, 6.0, 2.0, 0.0, 1.0, 0.0, 3.0, 4.0, 2.0, 2.0, 2.0, 3.0, 0.0, 1.0, 0.0, 1.0, 0.0, 2.0, 0.0, 2.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 3.0, 2.0, 1.0, 2.0, 3.0, 2.0, 3.0, 1.0, 1.0, 4.0, 1.0, 2.0, 2.0, 1.0, 1.0, 4.0, 2.0, 1.0, 2.0, 0.0, 1.0, 1.0, 1.0, 1.0, 2.0, 1.0, 3.0, 0.0, 1.0, 2.0, 3.0, 0.0, 1.0, 1.0], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.1479358200648045, "mean_inference_ms": 0.37973351747964273, "mean_action_processing_ms": 0.027331922679613624, "mean_env_wait_ms": 0.3906815538082097, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 783360, "timesteps_this_iter": 0, "agent_timesteps_total": 783360, "timers": {"sample_time_ms": 1322.949, "sample_throughput": 3870.14, "load_time_ms": 0.125, "load_throughput": 40857755.86, "learn_time_ms": 64.996, "learn_throughput": 78774.478, "update_time_ms": 2.848}, "info": {"learner": {"default_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 57.26101303100586, "policy_entropy": 7986.88525390625, "policy_loss": 20.269634246826172, "vf_loss": 16.117399215698242}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 783360, "num_agent_steps_sampled": 783360, "num_steps_trained": 783360, "num_agent_steps_trained": 783360, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 388, "training_iteration": 20, "trial_id": "6184f_00000", "experiment_id": "f2b91da2b7784e16a8a98abdfbd268d1", "date": "2024-06-12_13-25-51", "timestamp": 1718166351, "time_this_iter_s": 10.576585531234741, "time_total_s": 201.79252099990845, "pid": 76400, "hostname": "DESKTOP-LQ219J4", "node_ip": "192.168.46.185", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 20, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 5000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 500, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "rware", "env_args": {"n_agents": 4, "column_height": 1, "max_inactivity_steps": null, "max_steps": 500, "fast_obs": true, "msg_bits": 0, "sensor_range": 1, "shelf_rows": 1, "shelf_columns": 3, "request_queue_size": 4, "reward_type": "RewardType.INDIVIDUAL", "map_name": "customized_map", "map_size": "tiny", "difficulty": "medium"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": true, "force_coop": false, "local_mode": true, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 4, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 100, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64}, "algorithm": "maa2c", "space_obs": "Dict(obs:Box([-100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100.], [100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.], (112,), float32))", "space_act": "Discrete(5)", "num_agents": 4, "episode_limit": 500, "policy_mapping_info": {"all_scenario": {"description": "rware all scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2", "agent_3"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "rware_customized_map", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 10, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.policy_template.MAA2CTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x7f1c5c12da60>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "grad_clip": 40.0, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "microbatch_size": null}, "time_since_restore": 201.79252099990845, "timesteps_since_restore": 0, "iterations_since_restore": 20, "perf": {"cpu_util_percent": 4.62, "ram_util_percent": 35.313333333333325}}
{"episode_reward_max": 6.0, "episode_reward_min": 0.0, "episode_reward_mean": 1.6, "episode_len_mean": 500.0, "episode_media": {}, "episodes_this_iter": 24, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [1.0, 2.0, 1.0, 0.0, 2.0, 2.0, 1.0, 1.0, 3.0, 0.0, 1.0, 1.0, 2.0, 0.0, 1.0, 1.0, 1.0, 6.0, 2.0, 0.0, 1.0, 0.0, 3.0, 4.0, 2.0, 2.0, 2.0, 3.0, 0.0, 1.0, 0.0, 1.0, 0.0, 2.0, 0.0, 2.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 3.0, 2.0, 1.0, 2.0, 3.0, 2.0, 3.0, 1.0, 1.0, 4.0, 1.0, 2.0, 2.0, 1.0, 1.0, 4.0, 2.0, 1.0, 2.0, 0.0, 1.0, 1.0, 1.0, 1.0, 2.0, 1.0, 3.0, 0.0, 1.0, 2.0, 3.0, 0.0, 1.0, 1.0, 1.0, 3.0, 3.0, 0.0, 0.0, 4.0, 2.0, 1.0, 5.0, 4.0, 0.0, 2.0, 3.0, 0.0, 1.0, 0.0, 6.0, 2.0, 0.0, 2.0, 2.0, 1.0, 2.0, 3.0], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.14785509949823109, "mean_inference_ms": 0.37946623587937395, "mean_action_processing_ms": 0.027309320475176868, "mean_env_wait_ms": 0.3901913363085805, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 824320, "timesteps_this_iter": 0, "agent_timesteps_total": 824320, "timers": {"sample_time_ms": 1301.64, "sample_throughput": 3933.499, "load_time_ms": 0.124, "load_throughput": 41305705.867, "learn_time_ms": 65.555, "learn_throughput": 78102.527, "update_time_ms": 2.759}, "info": {"learner": {"default_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 54.903621673583984, "policy_entropy": 7988.3212890625, "policy_loss": -1.4618678092956543, "vf_loss": 30.768444061279297}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 824320, "num_agent_steps_sampled": 824320, "num_steps_trained": 824320, "num_agent_steps_trained": 824320, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 412, "training_iteration": 21, "trial_id": "6184f_00000", "experiment_id": "f2b91da2b7784e16a8a98abdfbd268d1", "date": "2024-06-12_13-26-02", "timestamp": 1718166362, "time_this_iter_s": 10.365940570831299, "time_total_s": 212.15846157073975, "pid": 76400, "hostname": "DESKTOP-LQ219J4", "node_ip": "192.168.46.185", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 20, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 5000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 500, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "rware", "env_args": {"n_agents": 4, "column_height": 1, "max_inactivity_steps": null, "max_steps": 500, "fast_obs": true, "msg_bits": 0, "sensor_range": 1, "shelf_rows": 1, "shelf_columns": 3, "request_queue_size": 4, "reward_type": "RewardType.INDIVIDUAL", "map_name": "customized_map", "map_size": "tiny", "difficulty": "medium"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": true, "force_coop": false, "local_mode": true, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 4, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 100, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64}, "algorithm": "maa2c", "space_obs": "Dict(obs:Box([-100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100.], [100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.], (112,), float32))", "space_act": "Discrete(5)", "num_agents": 4, "episode_limit": 500, "policy_mapping_info": {"all_scenario": {"description": "rware all scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2", "agent_3"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "rware_customized_map", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 10, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.policy_template.MAA2CTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x7f1c5c1eedc0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "grad_clip": 40.0, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "microbatch_size": null}, "time_since_restore": 212.15846157073975, "timesteps_since_restore": 0, "iterations_since_restore": 21, "perf": {"cpu_util_percent": 4.513333333333333, "ram_util_percent": 35.973333333333336}}
{"episode_reward_max": 6.0, "episode_reward_min": 0.0, "episode_reward_mean": 1.7, "episode_len_mean": 500.0, "episode_media": {}, "episodes_this_iter": 20, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [1.0, 0.0, 3.0, 4.0, 2.0, 2.0, 2.0, 3.0, 0.0, 1.0, 0.0, 1.0, 0.0, 2.0, 0.0, 2.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 3.0, 2.0, 1.0, 2.0, 3.0, 2.0, 3.0, 1.0, 1.0, 4.0, 1.0, 2.0, 2.0, 1.0, 1.0, 4.0, 2.0, 1.0, 2.0, 0.0, 1.0, 1.0, 1.0, 1.0, 2.0, 1.0, 3.0, 0.0, 1.0, 2.0, 3.0, 0.0, 1.0, 1.0, 1.0, 3.0, 3.0, 0.0, 0.0, 4.0, 2.0, 1.0, 5.0, 4.0, 0.0, 2.0, 3.0, 0.0, 1.0, 0.0, 6.0, 2.0, 0.0, 2.0, 2.0, 1.0, 2.0, 3.0, 2.0, 1.0, 1.0, 1.0, 1.0, 2.0, 1.0, 2.0, 2.0, 3.0, 1.0, 0.0, 1.0, 3.0, 3.0, 0.0, 6.0, 2.0, 4.0, 2.0], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.14780368888777243, "mean_inference_ms": 0.37931927184458586, "mean_action_processing_ms": 0.027296284358311124, "mean_env_wait_ms": 0.3899774898658569, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 865280, "timesteps_this_iter": 0, "agent_timesteps_total": 865280, "timers": {"sample_time_ms": 1309.054, "sample_throughput": 3911.222, "load_time_ms": 0.122, "load_throughput": 41812376.324, "learn_time_ms": 66.338, "learn_throughput": 77180.316, "update_time_ms": 2.735}, "info": {"learner": {"default_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 72.75442504882812, "policy_entropy": 7964.8681640625, "policy_loss": 22.494483947753906, "vf_loss": 30.670555114746094}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 865280, "num_agent_steps_sampled": 865280, "num_steps_trained": 865280, "num_agent_steps_trained": 865280, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 432, "training_iteration": 22, "trial_id": "6184f_00000", "experiment_id": "f2b91da2b7784e16a8a98abdfbd268d1", "date": "2024-06-12_13-26-12", "timestamp": 1718166372, "time_this_iter_s": 10.449347734451294, "time_total_s": 222.60780930519104, "pid": 76400, "hostname": "DESKTOP-LQ219J4", "node_ip": "192.168.46.185", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 20, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 5000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 500, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "rware", "env_args": {"n_agents": 4, "column_height": 1, "max_inactivity_steps": null, "max_steps": 500, "fast_obs": true, "msg_bits": 0, "sensor_range": 1, "shelf_rows": 1, "shelf_columns": 3, "request_queue_size": 4, "reward_type": "RewardType.INDIVIDUAL", "map_name": "customized_map", "map_size": "tiny", "difficulty": "medium"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": true, "force_coop": false, "local_mode": true, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 4, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 100, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64}, "algorithm": "maa2c", "space_obs": "Dict(obs:Box([-100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100.], [100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.], (112,), float32))", "space_act": "Discrete(5)", "num_agents": 4, "episode_limit": 500, "policy_mapping_info": {"all_scenario": {"description": "rware all scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2", "agent_3"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "rware_customized_map", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 10, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.policy_template.MAA2CTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x7f1c5c12db80>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "grad_clip": 40.0, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "microbatch_size": null}, "time_since_restore": 222.60780930519104, "timesteps_since_restore": 0, "iterations_since_restore": 22, "perf": {"cpu_util_percent": 4.52, "ram_util_percent": 36.63999999999999}}
{"episode_reward_max": 6.0, "episode_reward_min": 0.0, "episode_reward_mean": 1.73, "episode_len_mean": 500.0, "episode_media": {}, "episodes_this_iter": 20, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [1.0, 1.0, 3.0, 2.0, 1.0, 2.0, 3.0, 2.0, 3.0, 1.0, 1.0, 4.0, 1.0, 2.0, 2.0, 1.0, 1.0, 4.0, 2.0, 1.0, 2.0, 0.0, 1.0, 1.0, 1.0, 1.0, 2.0, 1.0, 3.0, 0.0, 1.0, 2.0, 3.0, 0.0, 1.0, 1.0, 1.0, 3.0, 3.0, 0.0, 0.0, 4.0, 2.0, 1.0, 5.0, 4.0, 0.0, 2.0, 3.0, 0.0, 1.0, 0.0, 6.0, 2.0, 0.0, 2.0, 2.0, 1.0, 2.0, 3.0, 2.0, 1.0, 1.0, 1.0, 1.0, 2.0, 1.0, 2.0, 2.0, 3.0, 1.0, 0.0, 1.0, 3.0, 3.0, 0.0, 6.0, 2.0, 4.0, 2.0, 1.0, 2.0, 2.0, 1.0, 1.0, 0.0, 2.0, 1.0, 1.0, 4.0, 3.0, 3.0, 0.0, 0.0, 1.0, 3.0, 1.0, 2.0, 0.0, 2.0], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.14777249796677502, "mean_inference_ms": 0.37922021440150444, "mean_action_processing_ms": 0.027286548426277236, "mean_env_wait_ms": 0.38985891576546644, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 906240, "timesteps_this_iter": 0, "agent_timesteps_total": 906240, "timers": {"sample_time_ms": 1319.128, "sample_throughput": 3881.351, "load_time_ms": 0.121, "load_throughput": 42406865.087, "learn_time_ms": 65.513, "learn_throughput": 78152.154, "update_time_ms": 2.774}, "info": {"learner": {"default_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 61.575233459472656, "policy_entropy": 7934.650390625, "policy_loss": 9.464090347290039, "vf_loss": 27.140535354614258}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 906240, "num_agent_steps_sampled": 906240, "num_steps_trained": 906240, "num_agent_steps_trained": 906240, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 452, "training_iteration": 23, "trial_id": "6184f_00000", "experiment_id": "f2b91da2b7784e16a8a98abdfbd268d1", "date": "2024-06-12_13-26-23", "timestamp": 1718166383, "time_this_iter_s": 10.617981910705566, "time_total_s": 233.2257912158966, "pid": 76400, "hostname": "DESKTOP-LQ219J4", "node_ip": "192.168.46.185", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 20, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 5000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 500, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "rware", "env_args": {"n_agents": 4, "column_height": 1, "max_inactivity_steps": null, "max_steps": 500, "fast_obs": true, "msg_bits": 0, "sensor_range": 1, "shelf_rows": 1, "shelf_columns": 3, "request_queue_size": 4, "reward_type": "RewardType.INDIVIDUAL", "map_name": "customized_map", "map_size": "tiny", "difficulty": "medium"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": true, "force_coop": false, "local_mode": true, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 4, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 100, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64}, "algorithm": "maa2c", "space_obs": "Dict(obs:Box([-100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100.], [100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.], (112,), float32))", "space_act": "Discrete(5)", "num_agents": 4, "episode_limit": 500, "policy_mapping_info": {"all_scenario": {"description": "rware all scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2", "agent_3"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "rware_customized_map", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 10, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.policy_template.MAA2CTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x7f1c5c1ee1f0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "grad_clip": 40.0, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "microbatch_size": null}, "time_since_restore": 233.2257912158966, "timesteps_since_restore": 0, "iterations_since_restore": 23, "perf": {"cpu_util_percent": 4.0200000000000005, "ram_util_percent": 37.29333333333333}}
{"episode_reward_max": 6.0, "episode_reward_min": 0.0, "episode_reward_mean": 1.7, "episode_len_mean": 500.0, "episode_media": {}, "episodes_this_iter": 20, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [2.0, 0.0, 1.0, 1.0, 1.0, 1.0, 2.0, 1.0, 3.0, 0.0, 1.0, 2.0, 3.0, 0.0, 1.0, 1.0, 1.0, 3.0, 3.0, 0.0, 0.0, 4.0, 2.0, 1.0, 5.0, 4.0, 0.0, 2.0, 3.0, 0.0, 1.0, 0.0, 6.0, 2.0, 0.0, 2.0, 2.0, 1.0, 2.0, 3.0, 2.0, 1.0, 1.0, 1.0, 1.0, 2.0, 1.0, 2.0, 2.0, 3.0, 1.0, 0.0, 1.0, 3.0, 3.0, 0.0, 6.0, 2.0, 4.0, 2.0, 1.0, 2.0, 2.0, 1.0, 1.0, 0.0, 2.0, 1.0, 1.0, 4.0, 3.0, 3.0, 0.0, 0.0, 1.0, 3.0, 1.0, 2.0, 0.0, 2.0, 1.0, 3.0, 0.0, 2.0, 3.0, 2.0, 5.0, 1.0, 0.0, 2.0, 4.0, 0.0, 0.0, 1.0, 0.0, 1.0, 2.0, 4.0, 1.0, 3.0], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.14777384692431542, "mean_inference_ms": 0.37919173582868815, "mean_action_processing_ms": 0.027283739781010542, "mean_env_wait_ms": 0.38977767388769136, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 947200, "timesteps_this_iter": 0, "agent_timesteps_total": 947200, "timers": {"sample_time_ms": 1335.537, "sample_throughput": 3833.665, "load_time_ms": 0.12, "load_throughput": 42532851.02, "learn_time_ms": 66.561, "learn_throughput": 76922.05, "update_time_ms": 2.749}, "info": {"learner": {"default_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 98.50888061523438, "policy_entropy": 7938.3642578125, "policy_loss": -53.178672790527344, "vf_loss": 16.74481773376465}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 947200, "num_agent_steps_sampled": 947200, "num_steps_trained": 947200, "num_agent_steps_trained": 947200, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 472, "training_iteration": 24, "trial_id": "6184f_00000", "experiment_id": "f2b91da2b7784e16a8a98abdfbd268d1", "date": "2024-06-12_13-26-34", "timestamp": 1718166394, "time_this_iter_s": 10.661797761917114, "time_total_s": 243.88758897781372, "pid": 76400, "hostname": "DESKTOP-LQ219J4", "node_ip": "192.168.46.185", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 20, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 5000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 500, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "rware", "env_args": {"n_agents": 4, "column_height": 1, "max_inactivity_steps": null, "max_steps": 500, "fast_obs": true, "msg_bits": 0, "sensor_range": 1, "shelf_rows": 1, "shelf_columns": 3, "request_queue_size": 4, "reward_type": "RewardType.INDIVIDUAL", "map_name": "customized_map", "map_size": "tiny", "difficulty": "medium"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": true, "force_coop": false, "local_mode": true, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 4, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 100, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64}, "algorithm": "maa2c", "space_obs": "Dict(obs:Box([-100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100.], [100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.], (112,), float32))", "space_act": "Discrete(5)", "num_agents": 4, "episode_limit": 500, "policy_mapping_info": {"all_scenario": {"description": "rware all scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2", "agent_3"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "rware_customized_map", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 10, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.policy_template.MAA2CTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x7f1c5c1eee50>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "grad_clip": 40.0, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "microbatch_size": null}, "time_since_restore": 243.88758897781372, "timesteps_since_restore": 0, "iterations_since_restore": 24, "perf": {"cpu_util_percent": 4.526666666666666, "ram_util_percent": 37.94666666666667}}
{"episode_reward_max": 7.0, "episode_reward_min": 0.0, "episode_reward_mean": 1.77, "episode_len_mean": 500.0, "episode_media": {}, "episodes_this_iter": 20, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 4.0, 2.0, 1.0, 5.0, 4.0, 0.0, 2.0, 3.0, 0.0, 1.0, 0.0, 6.0, 2.0, 0.0, 2.0, 2.0, 1.0, 2.0, 3.0, 2.0, 1.0, 1.0, 1.0, 1.0, 2.0, 1.0, 2.0, 2.0, 3.0, 1.0, 0.0, 1.0, 3.0, 3.0, 0.0, 6.0, 2.0, 4.0, 2.0, 1.0, 2.0, 2.0, 1.0, 1.0, 0.0, 2.0, 1.0, 1.0, 4.0, 3.0, 3.0, 0.0, 0.0, 1.0, 3.0, 1.0, 2.0, 0.0, 2.0, 1.0, 3.0, 0.0, 2.0, 3.0, 2.0, 5.0, 1.0, 0.0, 2.0, 4.0, 0.0, 0.0, 1.0, 0.0, 1.0, 2.0, 4.0, 1.0, 3.0, 1.0, 1.0, 1.0, 3.0, 7.0, 0.0, 2.0, 0.0, 0.0, 1.0, 2.0, 1.0, 1.0, 2.0, 1.0, 0.0, 3.0, 2.0, 2.0, 4.0], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.147757403520146, "mean_inference_ms": 0.3791186244070201, "mean_action_processing_ms": 0.027276414005999106, "mean_env_wait_ms": 0.38970824884197275, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 988160, "timesteps_this_iter": 0, "agent_timesteps_total": 988160, "timers": {"sample_time_ms": 1304.349, "sample_throughput": 3925.329, "load_time_ms": 0.121, "load_throughput": 42406865.087, "learn_time_ms": 65.403, "learn_throughput": 78283.347, "update_time_ms": 2.712}, "info": {"learner": {"default_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 65.59150695800781, "policy_entropy": 7979.8447265625, "policy_loss": -38.364662170410156, "vf_loss": 9.138931274414062}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 988160, "num_agent_steps_sampled": 988160, "num_steps_trained": 988160, "num_agent_steps_trained": 988160, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 492, "training_iteration": 25, "trial_id": "6184f_00000", "experiment_id": "f2b91da2b7784e16a8a98abdfbd268d1", "date": "2024-06-12_13-26-44", "timestamp": 1718166404, "time_this_iter_s": 10.411419153213501, "time_total_s": 254.29900813102722, "pid": 76400, "hostname": "DESKTOP-LQ219J4", "node_ip": "192.168.46.185", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 20, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 5000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 500, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "rware", "env_args": {"n_agents": 4, "column_height": 1, "max_inactivity_steps": null, "max_steps": 500, "fast_obs": true, "msg_bits": 0, "sensor_range": 1, "shelf_rows": 1, "shelf_columns": 3, "request_queue_size": 4, "reward_type": "RewardType.INDIVIDUAL", "map_name": "customized_map", "map_size": "tiny", "difficulty": "medium"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": true, "force_coop": false, "local_mode": true, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 4, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 100, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64}, "algorithm": "maa2c", "space_obs": "Dict(obs:Box([-100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100.], [100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.], (112,), float32))", "space_act": "Discrete(5)", "num_agents": 4, "episode_limit": 500, "policy_mapping_info": {"all_scenario": {"description": "rware all scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2", "agent_3"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "rware_customized_map", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 10, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.policy_template.MAA2CTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x7f1c5cd1f550>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "grad_clip": 40.0, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "microbatch_size": null}, "time_since_restore": 254.29900813102722, "timesteps_since_restore": 0, "iterations_since_restore": 25, "perf": {"cpu_util_percent": 4.713333333333334, "ram_util_percent": 38.57333333333334}}
{"episode_reward_max": 7.0, "episode_reward_min": 0.0, "episode_reward_mean": 1.67, "episode_len_mean": 500.0, "episode_media": {}, "episodes_this_iter": 20, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [2.0, 1.0, 1.0, 1.0, 1.0, 2.0, 1.0, 2.0, 2.0, 3.0, 1.0, 0.0, 1.0, 3.0, 3.0, 0.0, 6.0, 2.0, 4.0, 2.0, 1.0, 2.0, 2.0, 1.0, 1.0, 0.0, 2.0, 1.0, 1.0, 4.0, 3.0, 3.0, 0.0, 0.0, 1.0, 3.0, 1.0, 2.0, 0.0, 2.0, 1.0, 3.0, 0.0, 2.0, 3.0, 2.0, 5.0, 1.0, 0.0, 2.0, 4.0, 0.0, 0.0, 1.0, 0.0, 1.0, 2.0, 4.0, 1.0, 3.0, 1.0, 1.0, 1.0, 3.0, 7.0, 0.0, 2.0, 0.0, 0.0, 1.0, 2.0, 1.0, 1.0, 2.0, 1.0, 0.0, 3.0, 2.0, 2.0, 4.0, 1.0, 2.0, 3.0, 2.0, 2.0, 3.0, 3.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 2.0, 2.0, 0.0, 0.0, 2.0, 3.0, 2.0], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.14774629841234518, "mean_inference_ms": 0.3791197899762605, "mean_action_processing_ms": 0.027273763562202343, "mean_env_wait_ms": 0.389848547379347, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 1029120, "timesteps_this_iter": 0, "agent_timesteps_total": 1029120, "timers": {"sample_time_ms": 1305.512, "sample_throughput": 3921.834, "load_time_ms": 0.128, "load_throughput": 40027654.203, "learn_time_ms": 65.093, "learn_throughput": 78656.412, "update_time_ms": 2.736}, "info": {"learner": {"default_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 83.50286865234375, "policy_entropy": 7940.583984375, "policy_loss": 25.494243621826172, "vf_loss": 26.350379943847656}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 1029120, "num_agent_steps_sampled": 1029120, "num_steps_trained": 1029120, "num_agent_steps_trained": 1029120, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 512, "training_iteration": 26, "trial_id": "6184f_00000", "experiment_id": "f2b91da2b7784e16a8a98abdfbd268d1", "date": "2024-06-12_13-26-54", "timestamp": 1718166414, "time_this_iter_s": 10.470441818237305, "time_total_s": 264.7694499492645, "pid": 76400, "hostname": "DESKTOP-LQ219J4", "node_ip": "192.168.46.185", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 20, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 5000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 500, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "rware", "env_args": {"n_agents": 4, "column_height": 1, "max_inactivity_steps": null, "max_steps": 500, "fast_obs": true, "msg_bits": 0, "sensor_range": 1, "shelf_rows": 1, "shelf_columns": 3, "request_queue_size": 4, "reward_type": "RewardType.INDIVIDUAL", "map_name": "customized_map", "map_size": "tiny", "difficulty": "medium"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": true, "force_coop": false, "local_mode": true, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 4, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 100, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64}, "algorithm": "maa2c", "space_obs": "Dict(obs:Box([-100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100.], [100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.], (112,), float32))", "space_act": "Discrete(5)", "num_agents": 4, "episode_limit": 500, "policy_mapping_info": {"all_scenario": {"description": "rware all scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2", "agent_3"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "rware_customized_map", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 10, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.policy_template.MAA2CTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x7f1c5cd1fd30>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "grad_clip": 40.0, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "microbatch_size": null}, "time_since_restore": 264.7694499492645, "timesteps_since_restore": 0, "iterations_since_restore": 26, "perf": {"cpu_util_percent": 4.36, "ram_util_percent": 39.27333333333333}}
{"episode_reward_max": 7.0, "episode_reward_min": 0.0, "episode_reward_mean": 1.69, "episode_len_mean": 500.0, "episode_media": {}, "episodes_this_iter": 20, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [1.0, 2.0, 2.0, 1.0, 1.0, 0.0, 2.0, 1.0, 1.0, 4.0, 3.0, 3.0, 0.0, 0.0, 1.0, 3.0, 1.0, 2.0, 0.0, 2.0, 1.0, 3.0, 0.0, 2.0, 3.0, 2.0, 5.0, 1.0, 0.0, 2.0, 4.0, 0.0, 0.0, 1.0, 0.0, 1.0, 2.0, 4.0, 1.0, 3.0, 1.0, 1.0, 1.0, 3.0, 7.0, 0.0, 2.0, 0.0, 0.0, 1.0, 2.0, 1.0, 1.0, 2.0, 1.0, 0.0, 3.0, 2.0, 2.0, 4.0, 1.0, 2.0, 3.0, 2.0, 2.0, 3.0, 3.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 2.0, 2.0, 0.0, 0.0, 2.0, 3.0, 2.0, 3.0, 0.0, 2.0, 1.0, 2.0, 1.0, 0.0, 1.0, 3.0, 2.0, 1.0, 1.0, 1.0, 5.0, 6.0, 5.0, 1.0, 3.0, 2.0, 0.0], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.14777432901398768, "mean_inference_ms": 0.3791651465291473, "mean_action_processing_ms": 0.02727293652415697, "mean_env_wait_ms": 0.38994502859405544, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 1070080, "timesteps_this_iter": 0, "agent_timesteps_total": 1070080, "timers": {"sample_time_ms": 1335.393, "sample_throughput": 3834.079, "load_time_ms": 0.123, "load_throughput": 41601775.436, "learn_time_ms": 79.466, "learn_throughput": 64429.928, "update_time_ms": 2.886}, "info": {"learner": {"default_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 37.965824127197266, "policy_entropy": 7957.75537109375, "policy_loss": -0.2753048539161682, "vf_loss": 17.65415382385254}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 1070080, "num_agent_steps_sampled": 1070080, "num_steps_trained": 1070080, "num_agent_steps_trained": 1070080, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 532, "training_iteration": 27, "trial_id": "6184f_00000", "experiment_id": "f2b91da2b7784e16a8a98abdfbd268d1", "date": "2024-06-12_13-27-05", "timestamp": 1718166425, "time_this_iter_s": 10.89670729637146, "time_total_s": 275.666157245636, "pid": 76400, "hostname": "DESKTOP-LQ219J4", "node_ip": "192.168.46.185", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 20, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 5000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 500, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "rware", "env_args": {"n_agents": 4, "column_height": 1, "max_inactivity_steps": null, "max_steps": 500, "fast_obs": true, "msg_bits": 0, "sensor_range": 1, "shelf_rows": 1, "shelf_columns": 3, "request_queue_size": 4, "reward_type": "RewardType.INDIVIDUAL", "map_name": "customized_map", "map_size": "tiny", "difficulty": "medium"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": true, "force_coop": false, "local_mode": true, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 4, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 100, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64}, "algorithm": "maa2c", "space_obs": "Dict(obs:Box([-100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100.], [100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.], (112,), float32))", "space_act": "Discrete(5)", "num_agents": 4, "episode_limit": 500, "policy_mapping_info": {"all_scenario": {"description": "rware all scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2", "agent_3"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "rware_customized_map", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 10, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.policy_template.MAA2CTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x7f1c5c1ee700>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "grad_clip": 40.0, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "microbatch_size": null}, "time_since_restore": 275.666157245636, "timesteps_since_restore": 0, "iterations_since_restore": 27, "perf": {"cpu_util_percent": 4.512499999999999, "ram_util_percent": 39.925}}
{"episode_reward_max": 7.0, "episode_reward_min": 0.0, "episode_reward_mean": 1.8, "episode_len_mean": 500.0, "episode_media": {}, "episodes_this_iter": 20, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [1.0, 3.0, 0.0, 2.0, 3.0, 2.0, 5.0, 1.0, 0.0, 2.0, 4.0, 0.0, 0.0, 1.0, 0.0, 1.0, 2.0, 4.0, 1.0, 3.0, 1.0, 1.0, 1.0, 3.0, 7.0, 0.0, 2.0, 0.0, 0.0, 1.0, 2.0, 1.0, 1.0, 2.0, 1.0, 0.0, 3.0, 2.0, 2.0, 4.0, 1.0, 2.0, 3.0, 2.0, 2.0, 3.0, 3.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 2.0, 2.0, 0.0, 0.0, 2.0, 3.0, 2.0, 3.0, 0.0, 2.0, 1.0, 2.0, 1.0, 0.0, 1.0, 3.0, 2.0, 1.0, 1.0, 1.0, 5.0, 6.0, 5.0, 1.0, 3.0, 2.0, 0.0, 3.0, 1.0, 3.0, 2.0, 3.0, 1.0, 3.0, 5.0, 0.0, 4.0, 1.0, 0.0, 0.0, 2.0, 0.0, 1.0, 1.0, 6.0, 5.0, 0.0], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.14780490996071471, "mean_inference_ms": 0.3792136906135943, "mean_action_processing_ms": 0.027272776333383292, "mean_env_wait_ms": 0.3900216238667868, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 1111040, "timesteps_this_iter": 0, "agent_timesteps_total": 1111040, "timers": {"sample_time_ms": 1344.058, "sample_throughput": 3809.359, "load_time_ms": 0.126, "load_throughput": 40480370.368, "learn_time_ms": 78.247, "learn_throughput": 65433.879, "update_time_ms": 2.903}, "info": {"learner": {"default_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 28.527462005615234, "policy_entropy": 7913.0498046875, "policy_loss": -6.632356643676758, "vf_loss": 17.61195945739746}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 1111040, "num_agent_steps_sampled": 1111040, "num_steps_trained": 1111040, "num_agent_steps_trained": 1111040, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 552, "training_iteration": 28, "trial_id": "6184f_00000", "experiment_id": "f2b91da2b7784e16a8a98abdfbd268d1", "date": "2024-06-12_13-27-16", "timestamp": 1718166436, "time_this_iter_s": 10.638737440109253, "time_total_s": 286.30489468574524, "pid": 76400, "hostname": "DESKTOP-LQ219J4", "node_ip": "192.168.46.185", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 20, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 5000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 500, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "rware", "env_args": {"n_agents": 4, "column_height": 1, "max_inactivity_steps": null, "max_steps": 500, "fast_obs": true, "msg_bits": 0, "sensor_range": 1, "shelf_rows": 1, "shelf_columns": 3, "request_queue_size": 4, "reward_type": "RewardType.INDIVIDUAL", "map_name": "customized_map", "map_size": "tiny", "difficulty": "medium"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": true, "force_coop": false, "local_mode": true, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 4, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 100, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64}, "algorithm": "maa2c", "space_obs": "Dict(obs:Box([-100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100.], [100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.], (112,), float32))", "space_act": "Discrete(5)", "num_agents": 4, "episode_limit": 500, "policy_mapping_info": {"all_scenario": {"description": "rware all scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2", "agent_3"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "rware_customized_map", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 10, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.policy_template.MAA2CTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x7f1c5c12d670>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "grad_clip": 40.0, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "microbatch_size": null}, "time_since_restore": 286.30489468574524, "timesteps_since_restore": 0, "iterations_since_restore": 28, "perf": {"cpu_util_percent": 4.066666666666666, "ram_util_percent": 40.633333333333326}}
{"episode_reward_max": 7.0, "episode_reward_min": 0.0, "episode_reward_mean": 1.9, "episode_len_mean": 500.0, "episode_media": {}, "episodes_this_iter": 24, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [7.0, 0.0, 2.0, 0.0, 0.0, 1.0, 2.0, 1.0, 1.0, 2.0, 1.0, 0.0, 3.0, 2.0, 2.0, 4.0, 1.0, 2.0, 3.0, 2.0, 2.0, 3.0, 3.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 2.0, 2.0, 0.0, 0.0, 2.0, 3.0, 2.0, 3.0, 0.0, 2.0, 1.0, 2.0, 1.0, 0.0, 1.0, 3.0, 2.0, 1.0, 1.0, 1.0, 5.0, 6.0, 5.0, 1.0, 3.0, 2.0, 0.0, 3.0, 1.0, 3.0, 2.0, 3.0, 1.0, 3.0, 5.0, 0.0, 4.0, 1.0, 0.0, 0.0, 2.0, 0.0, 1.0, 1.0, 6.0, 5.0, 0.0, 0.0, 1.0, 3.0, 5.0, 5.0, 0.0, 3.0, 3.0, 3.0, 1.0, 1.0, 1.0, 1.0, 2.0, 3.0, 6.0, 3.0, 0.0, 4.0, 1.0, 1.0, 2.0, 2.0, 0.0], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.14783357630426275, "mean_inference_ms": 0.3791952746572663, "mean_action_processing_ms": 0.02726449201360538, "mean_env_wait_ms": 0.38996980769742406, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 1152000, "timesteps_this_iter": 0, "agent_timesteps_total": 1152000, "timers": {"sample_time_ms": 1325.886, "sample_throughput": 3861.568, "load_time_ms": 0.126, "load_throughput": 40633560.038, "learn_time_ms": 65.581, "learn_throughput": 78070.953, "update_time_ms": 2.785}, "info": {"learner": {"default_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 241.81666564941406, "policy_entropy": 7973.5751953125, "policy_loss": -113.72061920166016, "vf_loss": 1.931809425354004}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 1152000, "num_agent_steps_sampled": 1152000, "num_steps_trained": 1152000, "num_agent_steps_trained": 1152000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 576, "training_iteration": 29, "trial_id": "6184f_00000", "experiment_id": "f2b91da2b7784e16a8a98abdfbd268d1", "date": "2024-06-12_13-27-27", "timestamp": 1718166447, "time_this_iter_s": 10.571533203125, "time_total_s": 296.87642788887024, "pid": 76400, "hostname": "DESKTOP-LQ219J4", "node_ip": "192.168.46.185", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 20, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 5000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 500, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "rware", "env_args": {"n_agents": 4, "column_height": 1, "max_inactivity_steps": null, "max_steps": 500, "fast_obs": true, "msg_bits": 0, "sensor_range": 1, "shelf_rows": 1, "shelf_columns": 3, "request_queue_size": 4, "reward_type": "RewardType.INDIVIDUAL", "map_name": "customized_map", "map_size": "tiny", "difficulty": "medium"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": true, "force_coop": false, "local_mode": true, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 4, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 100, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64}, "algorithm": "maa2c", "space_obs": "Dict(obs:Box([-100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100.], [100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.], (112,), float32))", "space_act": "Discrete(5)", "num_agents": 4, "episode_limit": 500, "policy_mapping_info": {"all_scenario": {"description": "rware all scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2", "agent_3"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "rware_customized_map", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 10, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.policy_template.MAA2CTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x7f1d70045af0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "grad_clip": 40.0, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "microbatch_size": null}, "time_since_restore": 296.87642788887024, "timesteps_since_restore": 0, "iterations_since_restore": 29, "perf": {"cpu_util_percent": 3.906666666666667, "ram_util_percent": 41.266666666666666}}
{"episode_reward_max": 6.0, "episode_reward_min": 0.0, "episode_reward_mean": 1.91, "episode_len_mean": 500.0, "episode_media": {}, "episodes_this_iter": 20, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [2.0, 3.0, 3.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 2.0, 2.0, 0.0, 0.0, 2.0, 3.0, 2.0, 3.0, 0.0, 2.0, 1.0, 2.0, 1.0, 0.0, 1.0, 3.0, 2.0, 1.0, 1.0, 1.0, 5.0, 6.0, 5.0, 1.0, 3.0, 2.0, 0.0, 3.0, 1.0, 3.0, 2.0, 3.0, 1.0, 3.0, 5.0, 0.0, 4.0, 1.0, 0.0, 0.0, 2.0, 0.0, 1.0, 1.0, 6.0, 5.0, 0.0, 0.0, 1.0, 3.0, 5.0, 5.0, 0.0, 3.0, 3.0, 3.0, 1.0, 1.0, 1.0, 1.0, 2.0, 3.0, 6.0, 3.0, 0.0, 4.0, 1.0, 1.0, 2.0, 2.0, 0.0, 1.0, 1.0, 0.0, 3.0, 2.0, 2.0, 2.0, 3.0, 3.0, 2.0, 1.0, 0.0, 2.0, 1.0, 2.0, 2.0, 5.0, 2.0, 1.0, 2.0], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.1478793344808656, "mean_inference_ms": 0.37926966537980844, "mean_action_processing_ms": 0.027264139952824368, "mean_env_wait_ms": 0.39004111231817057, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 1192960, "timesteps_this_iter": 0, "agent_timesteps_total": 1192960, "timers": {"sample_time_ms": 1323.493, "sample_throughput": 3868.552, "load_time_ms": 0.126, "load_throughput": 40633560.038, "learn_time_ms": 66.381, "learn_throughput": 77130.696, "update_time_ms": 2.754}, "info": {"learner": {"default_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 57.44462966918945, "policy_entropy": 7917.97705078125, "policy_loss": 10.435007095336914, "vf_loss": 21.177654266357422}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 1192960, "num_agent_steps_sampled": 1192960, "num_steps_trained": 1192960, "num_agent_steps_trained": 1192960, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 596, "training_iteration": 30, "trial_id": "6184f_00000", "experiment_id": "f2b91da2b7784e16a8a98abdfbd268d1", "date": "2024-06-12_13-27-37", "timestamp": 1718166457, "time_this_iter_s": 10.541180849075317, "time_total_s": 307.41760873794556, "pid": 76400, "hostname": "DESKTOP-LQ219J4", "node_ip": "192.168.46.185", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 20, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 5000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 500, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "rware", "env_args": {"n_agents": 4, "column_height": 1, "max_inactivity_steps": null, "max_steps": 500, "fast_obs": true, "msg_bits": 0, "sensor_range": 1, "shelf_rows": 1, "shelf_columns": 3, "request_queue_size": 4, "reward_type": "RewardType.INDIVIDUAL", "map_name": "customized_map", "map_size": "tiny", "difficulty": "medium"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": true, "force_coop": false, "local_mode": true, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 4, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 100, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64}, "algorithm": "maa2c", "space_obs": "Dict(obs:Box([-100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100.], [100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.], (112,), float32))", "space_act": "Discrete(5)", "num_agents": 4, "episode_limit": 500, "policy_mapping_info": {"all_scenario": {"description": "rware all scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2", "agent_3"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "rware_customized_map", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 10, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.policy_template.MAA2CTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x7f1c5cd1f3a0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "grad_clip": 40.0, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "microbatch_size": null}, "time_since_restore": 307.41760873794556, "timesteps_since_restore": 0, "iterations_since_restore": 30, "perf": {"cpu_util_percent": 4.0, "ram_util_percent": 41.96}}
{"episode_reward_max": 6.0, "episode_reward_min": 0.0, "episode_reward_mean": 1.96, "episode_len_mean": 500.0, "episode_media": {}, "episodes_this_iter": 20, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [2.0, 1.0, 0.0, 1.0, 3.0, 2.0, 1.0, 1.0, 1.0, 5.0, 6.0, 5.0, 1.0, 3.0, 2.0, 0.0, 3.0, 1.0, 3.0, 2.0, 3.0, 1.0, 3.0, 5.0, 0.0, 4.0, 1.0, 0.0, 0.0, 2.0, 0.0, 1.0, 1.0, 6.0, 5.0, 0.0, 0.0, 1.0, 3.0, 5.0, 5.0, 0.0, 3.0, 3.0, 3.0, 1.0, 1.0, 1.0, 1.0, 2.0, 3.0, 6.0, 3.0, 0.0, 4.0, 1.0, 1.0, 2.0, 2.0, 0.0, 1.0, 1.0, 0.0, 3.0, 2.0, 2.0, 2.0, 3.0, 3.0, 2.0, 1.0, 0.0, 2.0, 1.0, 2.0, 2.0, 5.0, 2.0, 1.0, 2.0, 1.0, 2.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 2.0, 1.0, 3.0, 3.0, 2.0, 4.0, 2.0, 1.0, 1.0, 4.0, 3.0], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.14790791993155436, "mean_inference_ms": 0.3793025271999143, "mean_action_processing_ms": 0.02726067555921703, "mean_env_wait_ms": 0.39002831038233027, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 1233920, "timesteps_this_iter": 0, "agent_timesteps_total": 1233920, "timers": {"sample_time_ms": 1307.126, "sample_throughput": 3916.992, "load_time_ms": 0.126, "load_throughput": 40572145.248, "learn_time_ms": 66.459, "learn_throughput": 77039.551, "update_time_ms": 2.79}, "info": {"learner": {"default_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 76.46672821044922, "policy_entropy": 7960.5732421875, "policy_loss": -43.266666412353516, "vf_loss": 14.905057907104492}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 1233920, "num_agent_steps_sampled": 1233920, "num_steps_trained": 1233920, "num_agent_steps_trained": 1233920, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 616, "training_iteration": 31, "trial_id": "6184f_00000", "experiment_id": "f2b91da2b7784e16a8a98abdfbd268d1", "date": "2024-06-12_13-27-48", "timestamp": 1718166468, "time_this_iter_s": 10.374133110046387, "time_total_s": 317.79174184799194, "pid": 76400, "hostname": "DESKTOP-LQ219J4", "node_ip": "192.168.46.185", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 20, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 5000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 500, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "rware", "env_args": {"n_agents": 4, "column_height": 1, "max_inactivity_steps": null, "max_steps": 500, "fast_obs": true, "msg_bits": 0, "sensor_range": 1, "shelf_rows": 1, "shelf_columns": 3, "request_queue_size": 4, "reward_type": "RewardType.INDIVIDUAL", "map_name": "customized_map", "map_size": "tiny", "difficulty": "medium"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": true, "force_coop": false, "local_mode": true, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 4, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 100, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64}, "algorithm": "maa2c", "space_obs": "Dict(obs:Box([-100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100.], [100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.], (112,), float32))", "space_act": "Discrete(5)", "num_agents": 4, "episode_limit": 500, "policy_mapping_info": {"all_scenario": {"description": "rware all scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2", "agent_3"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "rware_customized_map", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 10, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.policy_template.MAA2CTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x7f1d70128670>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "grad_clip": 40.0, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "microbatch_size": null}, "time_since_restore": 317.79174184799194, "timesteps_since_restore": 0, "iterations_since_restore": 31, "perf": {"cpu_util_percent": 3.886666666666667, "ram_util_percent": 42.633333333333326}}
{"episode_reward_max": 6.0, "episode_reward_min": 0.0, "episode_reward_mean": 1.82, "episode_len_mean": 500.0, "episode_media": {}, "episodes_this_iter": 20, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [3.0, 1.0, 3.0, 5.0, 0.0, 4.0, 1.0, 0.0, 0.0, 2.0, 0.0, 1.0, 1.0, 6.0, 5.0, 0.0, 0.0, 1.0, 3.0, 5.0, 5.0, 0.0, 3.0, 3.0, 3.0, 1.0, 1.0, 1.0, 1.0, 2.0, 3.0, 6.0, 3.0, 0.0, 4.0, 1.0, 1.0, 2.0, 2.0, 0.0, 1.0, 1.0, 0.0, 3.0, 2.0, 2.0, 2.0, 3.0, 3.0, 2.0, 1.0, 0.0, 2.0, 1.0, 2.0, 2.0, 5.0, 2.0, 1.0, 2.0, 1.0, 2.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 2.0, 1.0, 3.0, 3.0, 2.0, 4.0, 2.0, 1.0, 1.0, 4.0, 3.0, 5.0, 0.0, 4.0, 1.0, 0.0, 0.0, 1.0, 1.0, 3.0, 2.0, 0.0, 3.0, 3.0, 1.0, 1.0, 0.0, 0.0, 2.0, 1.0, 1.0], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.1479098522591916, "mean_inference_ms": 0.3792514584775317, "mean_action_processing_ms": 0.02725432283817299, "mean_env_wait_ms": 0.3899697190613931, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 1274880, "timesteps_this_iter": 0, "agent_timesteps_total": 1274880, "timers": {"sample_time_ms": 1304.079, "sample_throughput": 3926.142, "load_time_ms": 0.128, "load_throughput": 39938323.377, "learn_time_ms": 66.598, "learn_throughput": 76878.679, "update_time_ms": 2.799}, "info": {"learner": {"default_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 54.302955627441406, "policy_entropy": 7931.23291015625, "policy_loss": -19.192047119140625, "vf_loss": 11.662443161010742}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 1274880, "num_agent_steps_sampled": 1274880, "num_steps_trained": 1274880, "num_agent_steps_trained": 1274880, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 636, "training_iteration": 32, "trial_id": "6184f_00000", "experiment_id": "f2b91da2b7784e16a8a98abdfbd268d1", "date": "2024-06-12_13-27-58", "timestamp": 1718166478, "time_this_iter_s": 10.45746898651123, "time_total_s": 328.2492108345032, "pid": 76400, "hostname": "DESKTOP-LQ219J4", "node_ip": "192.168.46.185", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 20, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 5000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 500, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "rware", "env_args": {"n_agents": 4, "column_height": 1, "max_inactivity_steps": null, "max_steps": 500, "fast_obs": true, "msg_bits": 0, "sensor_range": 1, "shelf_rows": 1, "shelf_columns": 3, "request_queue_size": 4, "reward_type": "RewardType.INDIVIDUAL", "map_name": "customized_map", "map_size": "tiny", "difficulty": "medium"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": true, "force_coop": false, "local_mode": true, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 4, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 100, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64}, "algorithm": "maa2c", "space_obs": "Dict(obs:Box([-100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100.], [100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.], (112,), float32))", "space_act": "Discrete(5)", "num_agents": 4, "episode_limit": 500, "policy_mapping_info": {"all_scenario": {"description": "rware all scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2", "agent_3"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "rware_customized_map", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 10, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.policy_template.MAA2CTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x7f1c5c11c1f0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "grad_clip": 40.0, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "microbatch_size": null}, "time_since_restore": 328.2492108345032, "timesteps_since_restore": 0, "iterations_since_restore": 32, "perf": {"cpu_util_percent": 4.04, "ram_util_percent": 43.28}}
{"episode_reward_max": 6.0, "episode_reward_min": 0.0, "episode_reward_mean": 1.82, "episode_len_mean": 500.0, "episode_media": {}, "episodes_this_iter": 20, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [5.0, 0.0, 3.0, 3.0, 3.0, 1.0, 1.0, 1.0, 1.0, 2.0, 3.0, 6.0, 3.0, 0.0, 4.0, 1.0, 1.0, 2.0, 2.0, 0.0, 1.0, 1.0, 0.0, 3.0, 2.0, 2.0, 2.0, 3.0, 3.0, 2.0, 1.0, 0.0, 2.0, 1.0, 2.0, 2.0, 5.0, 2.0, 1.0, 2.0, 1.0, 2.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 2.0, 1.0, 3.0, 3.0, 2.0, 4.0, 2.0, 1.0, 1.0, 4.0, 3.0, 5.0, 0.0, 4.0, 1.0, 0.0, 0.0, 1.0, 1.0, 3.0, 2.0, 0.0, 3.0, 3.0, 1.0, 1.0, 0.0, 0.0, 2.0, 1.0, 1.0, 2.0, 0.0, 1.0, 1.0, 1.0, 1.0, 2.0, 0.0, 6.0, 2.0, 6.0, 2.0, 2.0, 3.0, 3.0, 3.0, 1.0, 1.0, 2.0, 2.0], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.14790704633999124, "mean_inference_ms": 0.37918797837635965, "mean_action_processing_ms": 0.027247327101486488, "mean_env_wait_ms": 0.38987249335561047, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 1315840, "timesteps_this_iter": 0, "agent_timesteps_total": 1315840, "timers": {"sample_time_ms": 1318.517, "sample_throughput": 3883.15, "load_time_ms": 0.128, "load_throughput": 40087430.427, "learn_time_ms": 65.951, "learn_throughput": 77632.958, "update_time_ms": 2.733}, "info": {"learner": {"default_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 44.103546142578125, "policy_entropy": 7948.4248046875, "policy_loss": -16.011465072631836, "vf_loss": 18.528785705566406}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 1315840, "num_agent_steps_sampled": 1315840, "num_steps_trained": 1315840, "num_agent_steps_trained": 1315840, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 656, "training_iteration": 33, "trial_id": "6184f_00000", "experiment_id": "f2b91da2b7784e16a8a98abdfbd268d1", "date": "2024-06-12_13-28-09", "timestamp": 1718166489, "time_this_iter_s": 10.539324522018433, "time_total_s": 338.7885353565216, "pid": 76400, "hostname": "DESKTOP-LQ219J4", "node_ip": "192.168.46.185", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 20, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 5000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 500, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "rware", "env_args": {"n_agents": 4, "column_height": 1, "max_inactivity_steps": null, "max_steps": 500, "fast_obs": true, "msg_bits": 0, "sensor_range": 1, "shelf_rows": 1, "shelf_columns": 3, "request_queue_size": 4, "reward_type": "RewardType.INDIVIDUAL", "map_name": "customized_map", "map_size": "tiny", "difficulty": "medium"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": true, "force_coop": false, "local_mode": true, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 4, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 100, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64}, "algorithm": "maa2c", "space_obs": "Dict(obs:Box([-100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100.], [100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.], (112,), float32))", "space_act": "Discrete(5)", "num_agents": 4, "episode_limit": 500, "policy_mapping_info": {"all_scenario": {"description": "rware all scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2", "agent_3"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "rware_customized_map", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 10, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.policy_template.MAA2CTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x7f1d70045b80>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "grad_clip": 40.0, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "microbatch_size": null}, "time_since_restore": 338.7885353565216, "timesteps_since_restore": 0, "iterations_since_restore": 33, "perf": {"cpu_util_percent": 4.300000000000001, "ram_util_percent": 43.92000000000001}}
{"episode_reward_max": 6.0, "episode_reward_min": 0.0, "episode_reward_mean": 1.73, "episode_len_mean": 500.0, "episode_media": {}, "episodes_this_iter": 20, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [1.0, 1.0, 0.0, 3.0, 2.0, 2.0, 2.0, 3.0, 3.0, 2.0, 1.0, 0.0, 2.0, 1.0, 2.0, 2.0, 5.0, 2.0, 1.0, 2.0, 1.0, 2.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 2.0, 1.0, 3.0, 3.0, 2.0, 4.0, 2.0, 1.0, 1.0, 4.0, 3.0, 5.0, 0.0, 4.0, 1.0, 0.0, 0.0, 1.0, 1.0, 3.0, 2.0, 0.0, 3.0, 3.0, 1.0, 1.0, 0.0, 0.0, 2.0, 1.0, 1.0, 2.0, 0.0, 1.0, 1.0, 1.0, 1.0, 2.0, 0.0, 6.0, 2.0, 6.0, 2.0, 2.0, 3.0, 3.0, 3.0, 1.0, 1.0, 2.0, 2.0, 1.0, 2.0, 0.0, 0.0, 5.0, 0.0, 3.0, 1.0, 1.0, 1.0, 3.0, 1.0, 4.0, 1.0, 0.0, 2.0, 3.0, 3.0, 2.0, 0.0], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.14791419599908515, "mean_inference_ms": 0.3792121924006271, "mean_action_processing_ms": 0.027249043567596668, "mean_env_wait_ms": 0.3898937450426233, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 1356800, "timesteps_this_iter": 0, "agent_timesteps_total": 1356800, "timers": {"sample_time_ms": 1331.295, "sample_throughput": 3845.881, "load_time_ms": 0.137, "load_throughput": 37484441.403, "learn_time_ms": 66.834, "learn_throughput": 76607.882, "update_time_ms": 2.787}, "info": {"learner": {"default_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 150.410400390625, "policy_entropy": 7957.4306640625, "policy_loss": -83.35221862792969, "vf_loss": 2.951695442199707}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 1356800, "num_agent_steps_sampled": 1356800, "num_steps_trained": 1356800, "num_agent_steps_trained": 1356800, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 676, "training_iteration": 34, "trial_id": "6184f_00000", "experiment_id": "f2b91da2b7784e16a8a98abdfbd268d1", "date": "2024-06-12_13-28-19", "timestamp": 1718166499, "time_this_iter_s": 10.72671914100647, "time_total_s": 349.5152544975281, "pid": 76400, "hostname": "DESKTOP-LQ219J4", "node_ip": "192.168.46.185", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 20, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 5000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 500, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "rware", "env_args": {"n_agents": 4, "column_height": 1, "max_inactivity_steps": null, "max_steps": 500, "fast_obs": true, "msg_bits": 0, "sensor_range": 1, "shelf_rows": 1, "shelf_columns": 3, "request_queue_size": 4, "reward_type": "RewardType.INDIVIDUAL", "map_name": "customized_map", "map_size": "tiny", "difficulty": "medium"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": true, "force_coop": false, "local_mode": true, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 4, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 100, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64}, "algorithm": "maa2c", "space_obs": "Dict(obs:Box([-100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100.], [100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.], (112,), float32))", "space_act": "Discrete(5)", "num_agents": 4, "episode_limit": 500, "policy_mapping_info": {"all_scenario": {"description": "rware all scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2", "agent_3"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "rware_customized_map", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 10, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.policy_template.MAA2CTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x7f1d983148b0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "grad_clip": 40.0, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "microbatch_size": null}, "time_since_restore": 349.5152544975281, "timesteps_since_restore": 0, "iterations_since_restore": 34, "perf": {"cpu_util_percent": 4.24, "ram_util_percent": 44.58666666666666}}
{"episode_reward_max": 6.0, "episode_reward_min": 0.0, "episode_reward_mean": 1.76, "episode_len_mean": 500.0, "episode_media": {}, "episodes_this_iter": 20, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [1.0, 2.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 2.0, 1.0, 3.0, 3.0, 2.0, 4.0, 2.0, 1.0, 1.0, 4.0, 3.0, 5.0, 0.0, 4.0, 1.0, 0.0, 0.0, 1.0, 1.0, 3.0, 2.0, 0.0, 3.0, 3.0, 1.0, 1.0, 0.0, 0.0, 2.0, 1.0, 1.0, 2.0, 0.0, 1.0, 1.0, 1.0, 1.0, 2.0, 0.0, 6.0, 2.0, 6.0, 2.0, 2.0, 3.0, 3.0, 3.0, 1.0, 1.0, 2.0, 2.0, 1.0, 2.0, 0.0, 0.0, 5.0, 0.0, 3.0, 1.0, 1.0, 1.0, 3.0, 1.0, 4.0, 1.0, 0.0, 2.0, 3.0, 3.0, 2.0, 0.0, 0.0, 3.0, 1.0, 3.0, 0.0, 3.0, 4.0, 0.0, 4.0, 0.0, 2.0, 4.0, 1.0, 1.0, 2.0, 3.0, 0.0, 3.0, 4.0, 2.0], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.1479381998999453, "mean_inference_ms": 0.3792315611894354, "mean_action_processing_ms": 0.027249842378846402, "mean_env_wait_ms": 0.38988065096656643, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 1397760, "timesteps_this_iter": 0, "agent_timesteps_total": 1397760, "timers": {"sample_time_ms": 1365.062, "sample_throughput": 3750.746, "load_time_ms": 0.133, "load_throughput": 38457801.719, "learn_time_ms": 68.616, "learn_throughput": 74618.285, "update_time_ms": 2.843}, "info": {"learner": {"default_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 49.693355560302734, "policy_entropy": 7943.22802734375, "policy_loss": -0.9706697463989258, "vf_loss": 14.386577606201172}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 1397760, "num_agent_steps_sampled": 1397760, "num_steps_trained": 1397760, "num_agent_steps_trained": 1397760, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 696, "training_iteration": 35, "trial_id": "6184f_00000", "experiment_id": "f2b91da2b7784e16a8a98abdfbd268d1", "date": "2024-06-12_13-28-30", "timestamp": 1718166510, "time_this_iter_s": 10.797574281692505, "time_total_s": 360.3128287792206, "pid": 76400, "hostname": "DESKTOP-LQ219J4", "node_ip": "192.168.46.185", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 20, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 5000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 500, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "rware", "env_args": {"n_agents": 4, "column_height": 1, "max_inactivity_steps": null, "max_steps": 500, "fast_obs": true, "msg_bits": 0, "sensor_range": 1, "shelf_rows": 1, "shelf_columns": 3, "request_queue_size": 4, "reward_type": "RewardType.INDIVIDUAL", "map_name": "customized_map", "map_size": "tiny", "difficulty": "medium"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": true, "force_coop": false, "local_mode": true, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 4, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 100, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64}, "algorithm": "maa2c", "space_obs": "Dict(obs:Box([-100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100.], [100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.], (112,), float32))", "space_act": "Discrete(5)", "num_agents": 4, "episode_limit": 500, "policy_mapping_info": {"all_scenario": {"description": "rware all scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2", "agent_3"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "rware_customized_map", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 10, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.policy_template.MAA2CTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x7f1c4cf2d700>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "grad_clip": 40.0, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "microbatch_size": null}, "time_since_restore": 360.3128287792206, "timesteps_since_restore": 0, "iterations_since_restore": 35, "perf": {"cpu_util_percent": 4.59375, "ram_util_percent": 45.1875}}
{"episode_reward_max": 6.0, "episode_reward_min": 0.0, "episode_reward_mean": 1.84, "episode_len_mean": 500.0, "episode_media": {}, "episodes_this_iter": 20, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [5.0, 0.0, 4.0, 1.0, 0.0, 0.0, 1.0, 1.0, 3.0, 2.0, 0.0, 3.0, 3.0, 1.0, 1.0, 0.0, 0.0, 2.0, 1.0, 1.0, 2.0, 0.0, 1.0, 1.0, 1.0, 1.0, 2.0, 0.0, 6.0, 2.0, 6.0, 2.0, 2.0, 3.0, 3.0, 3.0, 1.0, 1.0, 2.0, 2.0, 1.0, 2.0, 0.0, 0.0, 5.0, 0.0, 3.0, 1.0, 1.0, 1.0, 3.0, 1.0, 4.0, 1.0, 0.0, 2.0, 3.0, 3.0, 2.0, 0.0, 0.0, 3.0, 1.0, 3.0, 0.0, 3.0, 4.0, 0.0, 4.0, 0.0, 2.0, 4.0, 1.0, 1.0, 2.0, 3.0, 0.0, 3.0, 4.0, 2.0, 0.0, 1.0, 4.0, 2.0, 1.0, 2.0, 3.0, 5.0, 1.0, 0.0, 1.0, 1.0, 4.0, 1.0, 1.0, 3.0, 1.0, 4.0, 3.0, 3.0], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.14798614377288244, "mean_inference_ms": 0.3793184891687061, "mean_action_processing_ms": 0.027255863690090667, "mean_env_wait_ms": 0.38994341756297546, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 1438720, "timesteps_this_iter": 0, "agent_timesteps_total": 1438720, "timers": {"sample_time_ms": 1349.172, "sample_throughput": 3794.92, "load_time_ms": 0.13, "load_throughput": 39432310.834, "learn_time_ms": 66.41, "learn_throughput": 77097.08, "update_time_ms": 2.815}, "info": {"learner": {"default_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 60.2363166809082, "policy_entropy": 7907.783203125, "policy_loss": 19.021501541137695, "vf_loss": 27.269784927368164}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 1438720, "num_agent_steps_sampled": 1438720, "num_steps_trained": 1438720, "num_agent_steps_trained": 1438720, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 716, "training_iteration": 36, "trial_id": "6184f_00000", "experiment_id": "f2b91da2b7784e16a8a98abdfbd268d1", "date": "2024-06-12_13-28-41", "timestamp": 1718166521, "time_this_iter_s": 10.665993690490723, "time_total_s": 370.9788224697113, "pid": 76400, "hostname": "DESKTOP-LQ219J4", "node_ip": "192.168.46.185", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 20, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 5000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 500, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "rware", "env_args": {"n_agents": 4, "column_height": 1, "max_inactivity_steps": null, "max_steps": 500, "fast_obs": true, "msg_bits": 0, "sensor_range": 1, "shelf_rows": 1, "shelf_columns": 3, "request_queue_size": 4, "reward_type": "RewardType.INDIVIDUAL", "map_name": "customized_map", "map_size": "tiny", "difficulty": "medium"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": true, "force_coop": false, "local_mode": true, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 4, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 100, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64}, "algorithm": "maa2c", "space_obs": "Dict(obs:Box([-100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100.], [100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.], (112,), float32))", "space_act": "Discrete(5)", "num_agents": 4, "episode_limit": 500, "policy_mapping_info": {"all_scenario": {"description": "rware all scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2", "agent_3"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "rware_customized_map", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 10, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.policy_template.MAA2CTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x7f1c5c128d30>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "grad_clip": 40.0, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "microbatch_size": null}, "time_since_restore": 370.9788224697113, "timesteps_since_restore": 0, "iterations_since_restore": 36, "perf": {"cpu_util_percent": 4.08, "ram_util_percent": 45.88}}
{"episode_reward_max": 6.0, "episode_reward_min": 0.0, "episode_reward_mean": 1.85, "episode_len_mean": 500.0, "episode_media": {}, "episodes_this_iter": 20, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [2.0, 0.0, 1.0, 1.0, 1.0, 1.0, 2.0, 0.0, 6.0, 2.0, 6.0, 2.0, 2.0, 3.0, 3.0, 3.0, 1.0, 1.0, 2.0, 2.0, 1.0, 2.0, 0.0, 0.0, 5.0, 0.0, 3.0, 1.0, 1.0, 1.0, 3.0, 1.0, 4.0, 1.0, 0.0, 2.0, 3.0, 3.0, 2.0, 0.0, 0.0, 3.0, 1.0, 3.0, 0.0, 3.0, 4.0, 0.0, 4.0, 0.0, 2.0, 4.0, 1.0, 1.0, 2.0, 3.0, 0.0, 3.0, 4.0, 2.0, 0.0, 1.0, 4.0, 2.0, 1.0, 2.0, 3.0, 5.0, 1.0, 0.0, 1.0, 1.0, 4.0, 1.0, 1.0, 3.0, 1.0, 4.0, 3.0, 3.0, 2.0, 2.0, 1.0, 4.0, 3.0, 0.0, 2.0, 2.0, 1.0, 1.0, 1.0, 1.0, 3.0, 0.0, 0.0, 1.0, 2.0, 1.0, 2.0, 1.0], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.14804445895149404, "mean_inference_ms": 0.37942786559409625, "mean_action_processing_ms": 0.027261616016174564, "mean_env_wait_ms": 0.3900314746350967, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 1479680, "timesteps_this_iter": 0, "agent_timesteps_total": 1479680, "timers": {"sample_time_ms": 1320.816, "sample_throughput": 3876.393, "load_time_ms": 0.134, "load_throughput": 38157136.603, "learn_time_ms": 70.911, "learn_throughput": 72203.279, "update_time_ms": 2.887}, "info": {"learner": {"default_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 123.94034576416016, "policy_entropy": 7912.138671875, "policy_loss": 54.37655258178711, "vf_loss": 26.923837661743164}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 1479680, "num_agent_steps_sampled": 1479680, "num_steps_trained": 1479680, "num_agent_steps_trained": 1479680, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 736, "training_iteration": 37, "trial_id": "6184f_00000", "experiment_id": "f2b91da2b7784e16a8a98abdfbd268d1", "date": "2024-06-12_13-28-51", "timestamp": 1718166531, "time_this_iter_s": 10.610395431518555, "time_total_s": 381.58921790122986, "pid": 76400, "hostname": "DESKTOP-LQ219J4", "node_ip": "192.168.46.185", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 20, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 5000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 500, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "rware", "env_args": {"n_agents": 4, "column_height": 1, "max_inactivity_steps": null, "max_steps": 500, "fast_obs": true, "msg_bits": 0, "sensor_range": 1, "shelf_rows": 1, "shelf_columns": 3, "request_queue_size": 4, "reward_type": "RewardType.INDIVIDUAL", "map_name": "customized_map", "map_size": "tiny", "difficulty": "medium"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": true, "force_coop": false, "local_mode": true, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 4, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 100, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64}, "algorithm": "maa2c", "space_obs": "Dict(obs:Box([-100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100.], [100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.], (112,), float32))", "space_act": "Discrete(5)", "num_agents": 4, "episode_limit": 500, "policy_mapping_info": {"all_scenario": {"description": "rware all scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2", "agent_3"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "rware_customized_map", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 10, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.policy_template.MAA2CTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x7f1d983148b0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "grad_clip": 40.0, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "microbatch_size": null}, "time_since_restore": 381.58921790122986, "timesteps_since_restore": 0, "iterations_since_restore": 37, "perf": {"cpu_util_percent": 4.113333333333333, "ram_util_percent": 46.52666666666666}}
{"episode_reward_max": 6.0, "episode_reward_min": 0.0, "episode_reward_mean": 1.93, "episode_len_mean": 500.0, "episode_media": {}, "episodes_this_iter": 24, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [5.0, 0.0, 3.0, 1.0, 1.0, 1.0, 3.0, 1.0, 4.0, 1.0, 0.0, 2.0, 3.0, 3.0, 2.0, 0.0, 0.0, 3.0, 1.0, 3.0, 0.0, 3.0, 4.0, 0.0, 4.0, 0.0, 2.0, 4.0, 1.0, 1.0, 2.0, 3.0, 0.0, 3.0, 4.0, 2.0, 0.0, 1.0, 4.0, 2.0, 1.0, 2.0, 3.0, 5.0, 1.0, 0.0, 1.0, 1.0, 4.0, 1.0, 1.0, 3.0, 1.0, 4.0, 3.0, 3.0, 2.0, 2.0, 1.0, 4.0, 3.0, 0.0, 2.0, 2.0, 1.0, 1.0, 1.0, 1.0, 3.0, 0.0, 0.0, 1.0, 2.0, 1.0, 2.0, 1.0, 3.0, 4.0, 5.0, 5.0, 1.0, 0.0, 2.0, 4.0, 1.0, 1.0, 4.0, 0.0, 2.0, 0.0, 3.0, 1.0, 4.0, 6.0, 0.0, 1.0, 2.0, 0.0, 1.0, 2.0], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.1481280699311918, "mean_inference_ms": 0.37954505453979054, "mean_action_processing_ms": 0.02726665282306116, "mean_env_wait_ms": 0.39008342378314126, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 1520640, "timesteps_this_iter": 0, "agent_timesteps_total": 1520640, "timers": {"sample_time_ms": 1343.616, "sample_throughput": 3810.613, "load_time_ms": 0.135, "load_throughput": 37914612.429, "learn_time_ms": 67.547, "learn_throughput": 75799.06, "update_time_ms": 2.93}, "info": {"learner": {"default_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 99.88272094726562, "policy_entropy": 7959.85546875, "policy_loss": 0.13507556915283203, "vf_loss": 47.02057647705078}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 1520640, "num_agent_steps_sampled": 1520640, "num_steps_trained": 1520640, "num_agent_steps_trained": 1520640, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 760, "training_iteration": 38, "trial_id": "6184f_00000", "experiment_id": "f2b91da2b7784e16a8a98abdfbd268d1", "date": "2024-06-12_13-29-02", "timestamp": 1718166542, "time_this_iter_s": 10.731356859207153, "time_total_s": 392.320574760437, "pid": 76400, "hostname": "DESKTOP-LQ219J4", "node_ip": "192.168.46.185", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 20, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 5000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 500, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "rware", "env_args": {"n_agents": 4, "column_height": 1, "max_inactivity_steps": null, "max_steps": 500, "fast_obs": true, "msg_bits": 0, "sensor_range": 1, "shelf_rows": 1, "shelf_columns": 3, "request_queue_size": 4, "reward_type": "RewardType.INDIVIDUAL", "map_name": "customized_map", "map_size": "tiny", "difficulty": "medium"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": true, "force_coop": false, "local_mode": true, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 4, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 100, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64}, "algorithm": "maa2c", "space_obs": "Dict(obs:Box([-100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100.], [100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.], (112,), float32))", "space_act": "Discrete(5)", "num_agents": 4, "episode_limit": 500, "policy_mapping_info": {"all_scenario": {"description": "rware all scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2", "agent_3"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "rware_customized_map", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 10, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.policy_template.MAA2CTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x7f1c5cd1f310>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "grad_clip": 40.0, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "microbatch_size": null}, "time_since_restore": 392.320574760437, "timesteps_since_restore": 0, "iterations_since_restore": 38, "perf": {"cpu_util_percent": 4.24, "ram_util_percent": 47.17999999999999}}
{"episode_reward_max": 6.0, "episode_reward_min": 0.0, "episode_reward_mean": 1.91, "episode_len_mean": 500.0, "episode_media": {}, "episodes_this_iter": 20, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 3.0, 4.0, 0.0, 4.0, 0.0, 2.0, 4.0, 1.0, 1.0, 2.0, 3.0, 0.0, 3.0, 4.0, 2.0, 0.0, 1.0, 4.0, 2.0, 1.0, 2.0, 3.0, 5.0, 1.0, 0.0, 1.0, 1.0, 4.0, 1.0, 1.0, 3.0, 1.0, 4.0, 3.0, 3.0, 2.0, 2.0, 1.0, 4.0, 3.0, 0.0, 2.0, 2.0, 1.0, 1.0, 1.0, 1.0, 3.0, 0.0, 0.0, 1.0, 2.0, 1.0, 2.0, 1.0, 3.0, 4.0, 5.0, 5.0, 1.0, 0.0, 2.0, 4.0, 1.0, 1.0, 4.0, 0.0, 2.0, 0.0, 3.0, 1.0, 4.0, 6.0, 0.0, 1.0, 2.0, 0.0, 1.0, 2.0, 4.0, 1.0, 1.0, 3.0, 1.0, 2.0, 3.0, 1.0, 2.0, 2.0, 1.0, 1.0, 2.0, 0.0, 5.0, 2.0, 4.0, 0.0, 0.0, 0.0], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.1481738555410742, "mean_inference_ms": 0.3796205816433369, "mean_action_processing_ms": 0.027268696194692542, "mean_env_wait_ms": 0.39013241798627163, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 1561600, "timesteps_this_iter": 0, "agent_timesteps_total": 1561600, "timers": {"sample_time_ms": 1315.194, "sample_throughput": 3892.961, "load_time_ms": 0.143, "load_throughput": 35821245.171, "learn_time_ms": 65.575, "learn_throughput": 78079.014, "update_time_ms": 2.904}, "info": {"learner": {"default_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 94.22257995605469, "policy_entropy": 7921.72802734375, "policy_loss": -51.66926956176758, "vf_loss": 19.74483299255371}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 1561600, "num_agent_steps_sampled": 1561600, "num_steps_trained": 1561600, "num_agent_steps_trained": 1561600, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 780, "training_iteration": 39, "trial_id": "6184f_00000", "experiment_id": "f2b91da2b7784e16a8a98abdfbd268d1", "date": "2024-06-12_13-29-13", "timestamp": 1718166553, "time_this_iter_s": 10.425106763839722, "time_total_s": 402.74568152427673, "pid": 76400, "hostname": "DESKTOP-LQ219J4", "node_ip": "192.168.46.185", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 20, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 5000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 500, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "rware", "env_args": {"n_agents": 4, "column_height": 1, "max_inactivity_steps": null, "max_steps": 500, "fast_obs": true, "msg_bits": 0, "sensor_range": 1, "shelf_rows": 1, "shelf_columns": 3, "request_queue_size": 4, "reward_type": "RewardType.INDIVIDUAL", "map_name": "customized_map", "map_size": "tiny", "difficulty": "medium"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": true, "force_coop": false, "local_mode": true, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 4, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 100, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64}, "algorithm": "maa2c", "space_obs": "Dict(obs:Box([-100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100.], [100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.], (112,), float32))", "space_act": "Discrete(5)", "num_agents": 4, "episode_limit": 500, "policy_mapping_info": {"all_scenario": {"description": "rware all scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2", "agent_3"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "rware_customized_map", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 10, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.policy_template.MAA2CTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x7f1c5c12da60>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "grad_clip": 40.0, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "microbatch_size": null}, "time_since_restore": 402.74568152427673, "timesteps_since_restore": 0, "iterations_since_restore": 39, "perf": {"cpu_util_percent": 4.153333333333333, "ram_util_percent": 47.84}}
{"episode_reward_max": 7.0, "episode_reward_min": 0.0, "episode_reward_mean": 1.92, "episode_len_mean": 500.0, "episode_media": {}, "episodes_this_iter": 20, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [1.0, 2.0, 3.0, 5.0, 1.0, 0.0, 1.0, 1.0, 4.0, 1.0, 1.0, 3.0, 1.0, 4.0, 3.0, 3.0, 2.0, 2.0, 1.0, 4.0, 3.0, 0.0, 2.0, 2.0, 1.0, 1.0, 1.0, 1.0, 3.0, 0.0, 0.0, 1.0, 2.0, 1.0, 2.0, 1.0, 3.0, 4.0, 5.0, 5.0, 1.0, 0.0, 2.0, 4.0, 1.0, 1.0, 4.0, 0.0, 2.0, 0.0, 3.0, 1.0, 4.0, 6.0, 0.0, 1.0, 2.0, 0.0, 1.0, 2.0, 4.0, 1.0, 1.0, 3.0, 1.0, 2.0, 3.0, 1.0, 2.0, 2.0, 1.0, 1.0, 2.0, 0.0, 5.0, 2.0, 4.0, 0.0, 0.0, 0.0, 2.0, 2.0, 1.0, 7.0, 3.0, 1.0, 2.0, 2.0, 1.0, 2.0, 2.0, 3.0, 2.0, 2.0, 6.0, 2.0, 0.0, 1.0, 0.0, 0.0], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.14819043392966091, "mean_inference_ms": 0.3796158611938395, "mean_action_processing_ms": 0.027265030391086346, "mean_env_wait_ms": 0.39009055578934143, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 1602560, "timesteps_this_iter": 0, "agent_timesteps_total": 1602560, "timers": {"sample_time_ms": 1301.589, "sample_throughput": 3933.654, "load_time_ms": 0.145, "load_throughput": 35407809.53, "learn_time_ms": 66.22, "learn_throughput": 77317.477, "update_time_ms": 2.85}, "info": {"learner": {"default_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 47.802677154541016, "policy_entropy": 7950.0947265625, "policy_loss": -20.738637924194336, "vf_loss": 16.640668869018555}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 1602560, "num_agent_steps_sampled": 1602560, "num_steps_trained": 1602560, "num_agent_steps_trained": 1602560, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 800, "training_iteration": 40, "trial_id": "6184f_00000", "experiment_id": "f2b91da2b7784e16a8a98abdfbd268d1", "date": "2024-06-12_13-29-23", "timestamp": 1718166563, "time_this_iter_s": 10.387319087982178, "time_total_s": 413.1330006122589, "pid": 76400, "hostname": "DESKTOP-LQ219J4", "node_ip": "192.168.46.185", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 20, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 5000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 500, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "rware", "env_args": {"n_agents": 4, "column_height": 1, "max_inactivity_steps": null, "max_steps": 500, "fast_obs": true, "msg_bits": 0, "sensor_range": 1, "shelf_rows": 1, "shelf_columns": 3, "request_queue_size": 4, "reward_type": "RewardType.INDIVIDUAL", "map_name": "customized_map", "map_size": "tiny", "difficulty": "medium"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": true, "force_coop": false, "local_mode": true, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 4, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 100, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64}, "algorithm": "maa2c", "space_obs": "Dict(obs:Box([-100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100.], [100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.], (112,), float32))", "space_act": "Discrete(5)", "num_agents": 4, "episode_limit": 500, "policy_mapping_info": {"all_scenario": {"description": "rware all scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2", "agent_3"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "rware_customized_map", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 10, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.policy_template.MAA2CTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x7f1d983148b0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "grad_clip": 40.0, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "microbatch_size": null}, "time_since_restore": 413.1330006122589, "timesteps_since_restore": 0, "iterations_since_restore": 40, "perf": {"cpu_util_percent": 3.933333333333333, "ram_util_percent": 48.513333333333335}}
{"episode_reward_max": 7.0, "episode_reward_min": 0.0, "episode_reward_mean": 1.89, "episode_len_mean": 500.0, "episode_media": {}, "episodes_this_iter": 20, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [3.0, 0.0, 2.0, 2.0, 1.0, 1.0, 1.0, 1.0, 3.0, 0.0, 0.0, 1.0, 2.0, 1.0, 2.0, 1.0, 3.0, 4.0, 5.0, 5.0, 1.0, 0.0, 2.0, 4.0, 1.0, 1.0, 4.0, 0.0, 2.0, 0.0, 3.0, 1.0, 4.0, 6.0, 0.0, 1.0, 2.0, 0.0, 1.0, 2.0, 4.0, 1.0, 1.0, 3.0, 1.0, 2.0, 3.0, 1.0, 2.0, 2.0, 1.0, 1.0, 2.0, 0.0, 5.0, 2.0, 4.0, 0.0, 0.0, 0.0, 2.0, 2.0, 1.0, 7.0, 3.0, 1.0, 2.0, 2.0, 1.0, 2.0, 2.0, 3.0, 2.0, 2.0, 6.0, 2.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 3.0, 1.0, 4.0, 2.0, 3.0, 2.0, 2.0, 1.0, 1.0, 7.0, 0.0, 3.0, 2.0, 3.0, 2.0, 1.0, 1.0], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.14820299883570948, "mean_inference_ms": 0.37959688042308926, "mean_action_processing_ms": 0.027260051871628912, "mean_env_wait_ms": 0.3900126867104731, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 1643520, "timesteps_this_iter": 0, "agent_timesteps_total": 1643520, "timers": {"sample_time_ms": 1314.793, "sample_throughput": 3894.149, "load_time_ms": 0.145, "load_throughput": 35274041.524, "learn_time_ms": 67.789, "learn_throughput": 75528.684, "update_time_ms": 2.855}, "info": {"learner": {"default_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 221.27383422851562, "policy_entropy": 7960.89453125, "policy_loss": -114.46199798583984, "vf_loss": 9.561905860900879}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 1643520, "num_agent_steps_sampled": 1643520, "num_steps_trained": 1643520, "num_agent_steps_trained": 1643520, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 820, "training_iteration": 41, "trial_id": "6184f_00000", "experiment_id": "f2b91da2b7784e16a8a98abdfbd268d1", "date": "2024-06-12_13-29-34", "timestamp": 1718166574, "time_this_iter_s": 10.560309410095215, "time_total_s": 423.6933100223541, "pid": 76400, "hostname": "DESKTOP-LQ219J4", "node_ip": "192.168.46.185", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 20, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 5000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 500, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "rware", "env_args": {"n_agents": 4, "column_height": 1, "max_inactivity_steps": null, "max_steps": 500, "fast_obs": true, "msg_bits": 0, "sensor_range": 1, "shelf_rows": 1, "shelf_columns": 3, "request_queue_size": 4, "reward_type": "RewardType.INDIVIDUAL", "map_name": "customized_map", "map_size": "tiny", "difficulty": "medium"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": true, "force_coop": false, "local_mode": true, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 4, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 100, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64}, "algorithm": "maa2c", "space_obs": "Dict(obs:Box([-100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100.], [100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.], (112,), float32))", "space_act": "Discrete(5)", "num_agents": 4, "episode_limit": 500, "policy_mapping_info": {"all_scenario": {"description": "rware all scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2", "agent_3"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "rware_customized_map", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 10, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.policy_template.MAA2CTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x7f1c5c007820>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "grad_clip": 40.0, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "microbatch_size": null}, "time_since_restore": 423.6933100223541, "timesteps_since_restore": 0, "iterations_since_restore": 41, "perf": {"cpu_util_percent": 3.96, "ram_util_percent": 49.17999999999999}}
{"episode_reward_max": 7.0, "episode_reward_min": 0.0, "episode_reward_mean": 1.98, "episode_len_mean": 500.0, "episode_media": {}, "episodes_this_iter": 20, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [1.0, 0.0, 2.0, 4.0, 1.0, 1.0, 4.0, 0.0, 2.0, 0.0, 3.0, 1.0, 4.0, 6.0, 0.0, 1.0, 2.0, 0.0, 1.0, 2.0, 4.0, 1.0, 1.0, 3.0, 1.0, 2.0, 3.0, 1.0, 2.0, 2.0, 1.0, 1.0, 2.0, 0.0, 5.0, 2.0, 4.0, 0.0, 0.0, 0.0, 2.0, 2.0, 1.0, 7.0, 3.0, 1.0, 2.0, 2.0, 1.0, 2.0, 2.0, 3.0, 2.0, 2.0, 6.0, 2.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 3.0, 1.0, 4.0, 2.0, 3.0, 2.0, 2.0, 1.0, 1.0, 7.0, 0.0, 3.0, 2.0, 3.0, 2.0, 1.0, 1.0, 2.0, 3.0, 3.0, 3.0, 2.0, 1.0, 1.0, 1.0, 3.0, 0.0, 1.0, 1.0, 6.0, 4.0, 2.0, 3.0, 5.0, 2.0, 2.0, 2.0], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.1482401226549202, "mean_inference_ms": 0.3796250152241105, "mean_action_processing_ms": 0.027258977560541794, "mean_env_wait_ms": 0.38999339570703256, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 1684480, "timesteps_this_iter": 0, "agent_timesteps_total": 1684480, "timers": {"sample_time_ms": 1351.608, "sample_throughput": 3788.08, "load_time_ms": 0.157, "load_throughput": 32661348.259, "learn_time_ms": 67.786, "learn_throughput": 75531.632, "update_time_ms": 2.831}, "info": {"learner": {"default_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 99.06897735595703, "policy_entropy": 7894.888671875, "policy_loss": -49.07720184326172, "vf_loss": 17.26494026184082}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 1684480, "num_agent_steps_sampled": 1684480, "num_steps_trained": 1684480, "num_agent_steps_trained": 1684480, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 840, "training_iteration": 42, "trial_id": "6184f_00000", "experiment_id": "f2b91da2b7784e16a8a98abdfbd268d1", "date": "2024-06-12_13-29-44", "timestamp": 1718166584, "time_this_iter_s": 10.897026300430298, "time_total_s": 434.5903363227844, "pid": 76400, "hostname": "DESKTOP-LQ219J4", "node_ip": "192.168.46.185", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 20, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 5000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 500, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "rware", "env_args": {"n_agents": 4, "column_height": 1, "max_inactivity_steps": null, "max_steps": 500, "fast_obs": true, "msg_bits": 0, "sensor_range": 1, "shelf_rows": 1, "shelf_columns": 3, "request_queue_size": 4, "reward_type": "RewardType.INDIVIDUAL", "map_name": "customized_map", "map_size": "tiny", "difficulty": "medium"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": true, "force_coop": false, "local_mode": true, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 4, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 100, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64}, "algorithm": "maa2c", "space_obs": "Dict(obs:Box([-100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100.], [100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.], (112,), float32))", "space_act": "Discrete(5)", "num_agents": 4, "episode_limit": 500, "policy_mapping_info": {"all_scenario": {"description": "rware all scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2", "agent_3"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "rware_customized_map", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 10, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.policy_template.MAA2CTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x7f1c5cd1fdc0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "grad_clip": 40.0, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "microbatch_size": null}, "time_since_restore": 434.5903363227844, "timesteps_since_restore": 0, "iterations_since_restore": 42, "perf": {"cpu_util_percent": 4.13125, "ram_util_percent": 49.85625}}
{"episode_reward_max": 7.0, "episode_reward_min": 0.0, "episode_reward_mean": 1.97, "episode_len_mean": 500.0, "episode_media": {}, "episodes_this_iter": 20, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [4.0, 1.0, 1.0, 3.0, 1.0, 2.0, 3.0, 1.0, 2.0, 2.0, 1.0, 1.0, 2.0, 0.0, 5.0, 2.0, 4.0, 0.0, 0.0, 0.0, 2.0, 2.0, 1.0, 7.0, 3.0, 1.0, 2.0, 2.0, 1.0, 2.0, 2.0, 3.0, 2.0, 2.0, 6.0, 2.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 3.0, 1.0, 4.0, 2.0, 3.0, 2.0, 2.0, 1.0, 1.0, 7.0, 0.0, 3.0, 2.0, 3.0, 2.0, 1.0, 1.0, 2.0, 3.0, 3.0, 3.0, 2.0, 1.0, 1.0, 1.0, 3.0, 0.0, 1.0, 1.0, 6.0, 4.0, 2.0, 3.0, 5.0, 2.0, 2.0, 2.0, 2.0, 3.0, 2.0, 1.0, 2.0, 3.0, 1.0, 1.0, 0.0, 0.0, 1.0, 4.0, 3.0, 3.0, 3.0, 1.0, 1.0, 0.0, 1.0, 2.0], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.14827836385847484, "mean_inference_ms": 0.3796933724121612, "mean_action_processing_ms": 0.027261672295424973, "mean_env_wait_ms": 0.3900379388572591, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 1725440, "timesteps_this_iter": 0, "agent_timesteps_total": 1725440, "timers": {"sample_time_ms": 1373.131, "sample_throughput": 3728.704, "load_time_ms": 0.172, "load_throughput": 29793058.38, "learn_time_ms": 69.925, "learn_throughput": 73221.735, "update_time_ms": 2.836}, "info": {"learner": {"default_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 62.639366149902344, "policy_entropy": 7956.390625, "policy_loss": 13.362507820129395, "vf_loss": 14.693380355834961}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 1725440, "num_agent_steps_sampled": 1725440, "num_steps_trained": 1725440, "num_agent_steps_trained": 1725440, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 860, "training_iteration": 43, "trial_id": "6184f_00000", "experiment_id": "f2b91da2b7784e16a8a98abdfbd268d1", "date": "2024-06-12_13-29-55", "timestamp": 1718166595, "time_this_iter_s": 10.84433388710022, "time_total_s": 445.43467020988464, "pid": 76400, "hostname": "DESKTOP-LQ219J4", "node_ip": "192.168.46.185", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 20, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 5000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 500, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "rware", "env_args": {"n_agents": 4, "column_height": 1, "max_inactivity_steps": null, "max_steps": 500, "fast_obs": true, "msg_bits": 0, "sensor_range": 1, "shelf_rows": 1, "shelf_columns": 3, "request_queue_size": 4, "reward_type": "RewardType.INDIVIDUAL", "map_name": "customized_map", "map_size": "tiny", "difficulty": "medium"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": true, "force_coop": false, "local_mode": true, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 4, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 100, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64}, "algorithm": "maa2c", "space_obs": "Dict(obs:Box([-100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100.], [100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.], (112,), float32))", "space_act": "Discrete(5)", "num_agents": 4, "episode_limit": 500, "policy_mapping_info": {"all_scenario": {"description": "rware all scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2", "agent_3"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "rware_customized_map", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 10, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.policy_template.MAA2CTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x7f1d983148b0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "grad_clip": 40.0, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "microbatch_size": null}, "time_since_restore": 445.43467020988464, "timesteps_since_restore": 0, "iterations_since_restore": 43, "perf": {"cpu_util_percent": 4.373333333333333, "ram_util_percent": 50.52666666666667}}
{"episode_reward_max": 7.0, "episode_reward_min": 0.0, "episode_reward_mean": 1.96, "episode_len_mean": 500.0, "episode_media": {}, "episodes_this_iter": 20, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [2.0, 2.0, 1.0, 7.0, 3.0, 1.0, 2.0, 2.0, 1.0, 2.0, 2.0, 3.0, 2.0, 2.0, 6.0, 2.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 3.0, 1.0, 4.0, 2.0, 3.0, 2.0, 2.0, 1.0, 1.0, 7.0, 0.0, 3.0, 2.0, 3.0, 2.0, 1.0, 1.0, 2.0, 3.0, 3.0, 3.0, 2.0, 1.0, 1.0, 1.0, 3.0, 0.0, 1.0, 1.0, 6.0, 4.0, 2.0, 3.0, 5.0, 2.0, 2.0, 2.0, 2.0, 3.0, 2.0, 1.0, 2.0, 3.0, 1.0, 1.0, 0.0, 0.0, 1.0, 4.0, 3.0, 3.0, 3.0, 1.0, 1.0, 0.0, 1.0, 2.0, 4.0, 1.0, 1.0, 2.0, 2.0, 1.0, 0.0, 2.0, 1.0, 0.0, 1.0, 3.0, 1.0, 2.0, 6.0, 0.0, 1.0, 3.0, 2.0, 1.0], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.1483513847607384, "mean_inference_ms": 0.3797934325663684, "mean_action_processing_ms": 0.02726519719537631, "mean_env_wait_ms": 0.3901391066465817, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 1766400, "timesteps_this_iter": 0, "agent_timesteps_total": 1766400, "timers": {"sample_time_ms": 1359.185, "sample_throughput": 3766.963, "load_time_ms": 0.151, "load_throughput": 33963049.945, "learn_time_ms": 67.634, "learn_throughput": 75701.772, "update_time_ms": 2.841}, "info": {"learner": {"default_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 36.554622650146484, "policy_entropy": 7955.94677734375, "policy_loss": -20.600692749023438, "vf_loss": 6.454331398010254}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 1766400, "num_agent_steps_sampled": 1766400, "num_steps_trained": 1766400, "num_agent_steps_trained": 1766400, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 880, "training_iteration": 44, "trial_id": "6184f_00000", "experiment_id": "f2b91da2b7784e16a8a98abdfbd268d1", "date": "2024-06-12_13-30-06", "timestamp": 1718166606, "time_this_iter_s": 10.902008295059204, "time_total_s": 456.33667850494385, "pid": 76400, "hostname": "DESKTOP-LQ219J4", "node_ip": "192.168.46.185", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 20, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 5000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 500, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "rware", "env_args": {"n_agents": 4, "column_height": 1, "max_inactivity_steps": null, "max_steps": 500, "fast_obs": true, "msg_bits": 0, "sensor_range": 1, "shelf_rows": 1, "shelf_columns": 3, "request_queue_size": 4, "reward_type": "RewardType.INDIVIDUAL", "map_name": "customized_map", "map_size": "tiny", "difficulty": "medium"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": true, "force_coop": false, "local_mode": true, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 4, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 100, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64}, "algorithm": "maa2c", "space_obs": "Dict(obs:Box([-100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100.], [100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.], (112,), float32))", "space_act": "Discrete(5)", "num_agents": 4, "episode_limit": 500, "policy_mapping_info": {"all_scenario": {"description": "rware all scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2", "agent_3"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "rware_customized_map", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 10, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.policy_template.MAA2CTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x7f1c5cd1f5e0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "grad_clip": 40.0, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "microbatch_size": null}, "time_since_restore": 456.33667850494385, "timesteps_since_restore": 0, "iterations_since_restore": 44, "perf": {"cpu_util_percent": 4.725, "ram_util_percent": 51.16875}}
{"episode_reward_max": 8.0, "episode_reward_min": 0.0, "episode_reward_mean": 2.0, "episode_len_mean": 500.0, "episode_media": {}, "episodes_this_iter": 20, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 1.0, 1.0, 3.0, 1.0, 4.0, 2.0, 3.0, 2.0, 2.0, 1.0, 1.0, 7.0, 0.0, 3.0, 2.0, 3.0, 2.0, 1.0, 1.0, 2.0, 3.0, 3.0, 3.0, 2.0, 1.0, 1.0, 1.0, 3.0, 0.0, 1.0, 1.0, 6.0, 4.0, 2.0, 3.0, 5.0, 2.0, 2.0, 2.0, 2.0, 3.0, 2.0, 1.0, 2.0, 3.0, 1.0, 1.0, 0.0, 0.0, 1.0, 4.0, 3.0, 3.0, 3.0, 1.0, 1.0, 0.0, 1.0, 2.0, 4.0, 1.0, 1.0, 2.0, 2.0, 1.0, 0.0, 2.0, 1.0, 0.0, 1.0, 3.0, 1.0, 2.0, 6.0, 0.0, 1.0, 3.0, 2.0, 1.0, 1.0, 3.0, 2.0, 3.0, 1.0, 2.0, 0.0, 8.0, 1.0, 5.0, 1.0, 0.0, 2.0, 2.0, 4.0, 2.0, 1.0, 1.0, 2.0, 4.0], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.14844075292965736, "mean_inference_ms": 0.3799362183539418, "mean_action_processing_ms": 0.027272289120841346, "mean_env_wait_ms": 0.3902974112133357, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 1807360, "timesteps_this_iter": 0, "agent_timesteps_total": 1807360, "timers": {"sample_time_ms": 1346.496, "sample_throughput": 3802.462, "load_time_ms": 0.144, "load_throughput": 35577926.574, "learn_time_ms": 66.993, "learn_throughput": 76426.169, "update_time_ms": 2.913}, "info": {"learner": {"default_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 60.38676834106445, "policy_entropy": 7878.8466796875, "policy_loss": -35.11016845703125, "vf_loss": 12.610917091369629}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 1807360, "num_agent_steps_sampled": 1807360, "num_steps_trained": 1807360, "num_agent_steps_trained": 1807360, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 900, "training_iteration": 45, "trial_id": "6184f_00000", "experiment_id": "f2b91da2b7784e16a8a98abdfbd268d1", "date": "2024-06-12_13-30-17", "timestamp": 1718166617, "time_this_iter_s": 10.668998718261719, "time_total_s": 467.00567722320557, "pid": 76400, "hostname": "DESKTOP-LQ219J4", "node_ip": "192.168.46.185", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 20, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 5000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 500, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "rware", "env_args": {"n_agents": 4, "column_height": 1, "max_inactivity_steps": null, "max_steps": 500, "fast_obs": true, "msg_bits": 0, "sensor_range": 1, "shelf_rows": 1, "shelf_columns": 3, "request_queue_size": 4, "reward_type": "RewardType.INDIVIDUAL", "map_name": "customized_map", "map_size": "tiny", "difficulty": "medium"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": true, "force_coop": false, "local_mode": true, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 4, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 100, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64}, "algorithm": "maa2c", "space_obs": "Dict(obs:Box([-100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100.], [100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.], (112,), float32))", "space_act": "Discrete(5)", "num_agents": 4, "episode_limit": 500, "policy_mapping_info": {"all_scenario": {"description": "rware all scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2", "agent_3"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "rware_customized_map", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 10, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.policy_template.MAA2CTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x7f1c5c12db80>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "grad_clip": 40.0, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "microbatch_size": null}, "time_since_restore": 467.00567722320557, "timesteps_since_restore": 0, "iterations_since_restore": 45, "perf": {"cpu_util_percent": 4.013333333333333, "ram_util_percent": 51.826666666666675}}
{"episode_reward_max": 8.0, "episode_reward_min": 0.0, "episode_reward_mean": 2.0, "episode_len_mean": 500.0, "episode_media": {}, "episodes_this_iter": 24, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [2.0, 1.0, 1.0, 1.0, 3.0, 0.0, 1.0, 1.0, 6.0, 4.0, 2.0, 3.0, 5.0, 2.0, 2.0, 2.0, 2.0, 3.0, 2.0, 1.0, 2.0, 3.0, 1.0, 1.0, 0.0, 0.0, 1.0, 4.0, 3.0, 3.0, 3.0, 1.0, 1.0, 0.0, 1.0, 2.0, 4.0, 1.0, 1.0, 2.0, 2.0, 1.0, 0.0, 2.0, 1.0, 0.0, 1.0, 3.0, 1.0, 2.0, 6.0, 0.0, 1.0, 3.0, 2.0, 1.0, 1.0, 3.0, 2.0, 3.0, 1.0, 2.0, 0.0, 8.0, 1.0, 5.0, 1.0, 0.0, 2.0, 2.0, 4.0, 2.0, 1.0, 1.0, 2.0, 4.0, 2.0, 1.0, 2.0, 1.0, 2.0, 3.0, 0.0, 2.0, 0.0, 3.0, 4.0, 1.0, 2.0, 1.0, 0.0, 6.0, 1.0, 3.0, 2.0, 2.0, 6.0, 1.0, 4.0, 2.0], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.14856574470344555, "mean_inference_ms": 0.38010483537984435, "mean_action_processing_ms": 0.027279654745207393, "mean_env_wait_ms": 0.39049207211223125, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 1848320, "timesteps_this_iter": 0, "agent_timesteps_total": 1848320, "timers": {"sample_time_ms": 1347.665, "sample_throughput": 3799.164, "load_time_ms": 0.146, "load_throughput": 34963914.816, "learn_time_ms": 70.199, "learn_throughput": 72935.548, "update_time_ms": 2.865}, "info": {"learner": {"default_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 173.24887084960938, "policy_entropy": 7930.3974609375, "policy_loss": 58.56828689575195, "vf_loss": 47.43319320678711}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 1848320, "num_agent_steps_sampled": 1848320, "num_steps_trained": 1848320, "num_agent_steps_trained": 1848320, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 924, "training_iteration": 46, "trial_id": "6184f_00000", "experiment_id": "f2b91da2b7784e16a8a98abdfbd268d1", "date": "2024-06-12_13-30-28", "timestamp": 1718166628, "time_this_iter_s": 10.834883451461792, "time_total_s": 477.84056067466736, "pid": 76400, "hostname": "DESKTOP-LQ219J4", "node_ip": "192.168.46.185", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 20, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 5000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 500, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "rware", "env_args": {"n_agents": 4, "column_height": 1, "max_inactivity_steps": null, "max_steps": 500, "fast_obs": true, "msg_bits": 0, "sensor_range": 1, "shelf_rows": 1, "shelf_columns": 3, "request_queue_size": 4, "reward_type": "RewardType.INDIVIDUAL", "map_name": "customized_map", "map_size": "tiny", "difficulty": "medium"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": true, "force_coop": false, "local_mode": true, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 4, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 100, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64}, "algorithm": "maa2c", "space_obs": "Dict(obs:Box([-100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100.], [100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.], (112,), float32))", "space_act": "Discrete(5)", "num_agents": 4, "episode_limit": 500, "policy_mapping_info": {"all_scenario": {"description": "rware all scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2", "agent_3"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "rware_customized_map", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 10, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.policy_template.MAA2CTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x7f1c5c11c790>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "grad_clip": 40.0, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "microbatch_size": null}, "time_since_restore": 477.84056067466736, "timesteps_since_restore": 0, "iterations_since_restore": 46, "perf": {"cpu_util_percent": 4.546666666666666, "ram_util_percent": 52.46666666666667}}
{"episode_reward_max": 8.0, "episode_reward_min": 0.0, "episode_reward_mean": 2.02, "episode_len_mean": 500.0, "episode_media": {}, "episodes_this_iter": 20, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [2.0, 3.0, 1.0, 1.0, 0.0, 0.0, 1.0, 4.0, 3.0, 3.0, 3.0, 1.0, 1.0, 0.0, 1.0, 2.0, 4.0, 1.0, 1.0, 2.0, 2.0, 1.0, 0.0, 2.0, 1.0, 0.0, 1.0, 3.0, 1.0, 2.0, 6.0, 0.0, 1.0, 3.0, 2.0, 1.0, 1.0, 3.0, 2.0, 3.0, 1.0, 2.0, 0.0, 8.0, 1.0, 5.0, 1.0, 0.0, 2.0, 2.0, 4.0, 2.0, 1.0, 1.0, 2.0, 4.0, 2.0, 1.0, 2.0, 1.0, 2.0, 3.0, 0.0, 2.0, 0.0, 3.0, 4.0, 1.0, 2.0, 1.0, 0.0, 6.0, 1.0, 3.0, 2.0, 2.0, 6.0, 1.0, 4.0, 2.0, 1.0, 1.0, 3.0, 4.0, 1.0, 5.0, 1.0, 2.0, 1.0, 3.0, 2.0, 1.0, 3.0, 3.0, 4.0, 3.0, 1.0, 0.0, 5.0, 2.0], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.14866192710196205, "mean_inference_ms": 0.380282499260721, "mean_action_processing_ms": 0.027289213706243515, "mean_env_wait_ms": 0.3906962475854863, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 1889280, "timesteps_this_iter": 0, "agent_timesteps_total": 1889280, "timers": {"sample_time_ms": 1368.672, "sample_throughput": 3740.853, "load_time_ms": 0.147, "load_throughput": 34715222.244, "learn_time_ms": 69.379, "learn_throughput": 73797.221, "update_time_ms": 2.912}, "info": {"learner": {"default_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 49.25271224975586, "policy_entropy": 7943.0458984375, "policy_loss": 10.535940170288086, "vf_loss": 22.058652877807617}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 1889280, "num_agent_steps_sampled": 1889280, "num_steps_trained": 1889280, "num_agent_steps_trained": 1889280, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 944, "training_iteration": 47, "trial_id": "6184f_00000", "experiment_id": "f2b91da2b7784e16a8a98abdfbd268d1", "date": "2024-06-12_13-30-39", "timestamp": 1718166639, "time_this_iter_s": 10.989173173904419, "time_total_s": 488.8297338485718, "pid": 76400, "hostname": "DESKTOP-LQ219J4", "node_ip": "192.168.46.185", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 20, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 5000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 500, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "rware", "env_args": {"n_agents": 4, "column_height": 1, "max_inactivity_steps": null, "max_steps": 500, "fast_obs": true, "msg_bits": 0, "sensor_range": 1, "shelf_rows": 1, "shelf_columns": 3, "request_queue_size": 4, "reward_type": "RewardType.INDIVIDUAL", "map_name": "customized_map", "map_size": "tiny", "difficulty": "medium"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": true, "force_coop": false, "local_mode": true, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 4, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 100, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64}, "algorithm": "maa2c", "space_obs": "Dict(obs:Box([-100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100.], [100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.], (112,), float32))", "space_act": "Discrete(5)", "num_agents": 4, "episode_limit": 500, "policy_mapping_info": {"all_scenario": {"description": "rware all scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2", "agent_3"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "rware_customized_map", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 10, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.policy_template.MAA2CTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x7f1c5cd1fa60>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "grad_clip": 40.0, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "microbatch_size": null}, "time_since_restore": 488.8297338485718, "timesteps_since_restore": 0, "iterations_since_restore": 47, "perf": {"cpu_util_percent": 4.625, "ram_util_percent": 53.1375}}
{"episode_reward_max": 11.0, "episode_reward_min": 0.0, "episode_reward_mean": 2.31, "episode_len_mean": 500.0, "episode_media": {}, "episodes_this_iter": 20, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [2.0, 1.0, 0.0, 2.0, 1.0, 0.0, 1.0, 3.0, 1.0, 2.0, 6.0, 0.0, 1.0, 3.0, 2.0, 1.0, 1.0, 3.0, 2.0, 3.0, 1.0, 2.0, 0.0, 8.0, 1.0, 5.0, 1.0, 0.0, 2.0, 2.0, 4.0, 2.0, 1.0, 1.0, 2.0, 4.0, 2.0, 1.0, 2.0, 1.0, 2.0, 3.0, 0.0, 2.0, 0.0, 3.0, 4.0, 1.0, 2.0, 1.0, 0.0, 6.0, 1.0, 3.0, 2.0, 2.0, 6.0, 1.0, 4.0, 2.0, 1.0, 1.0, 3.0, 4.0, 1.0, 5.0, 1.0, 2.0, 1.0, 3.0, 2.0, 1.0, 3.0, 3.0, 4.0, 3.0, 1.0, 0.0, 5.0, 2.0, 1.0, 1.0, 2.0, 5.0, 3.0, 4.0, 5.0, 5.0, 4.0, 0.0, 2.0, 11.0, 2.0, 2.0, 3.0, 1.0, 3.0, 2.0, 2.0, 5.0], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.14875413698153467, "mean_inference_ms": 0.3804560844522439, "mean_action_processing_ms": 0.02729907774102491, "mean_env_wait_ms": 0.3908316792402751, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 1930240, "timesteps_this_iter": 0, "agent_timesteps_total": 1930240, "timers": {"sample_time_ms": 1363.505, "sample_throughput": 3755.029, "load_time_ms": 0.157, "load_throughput": 32656381.509, "learn_time_ms": 74.219, "learn_throughput": 68985.463, "update_time_ms": 2.833}, "info": {"learner": {"default_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 74.54672241210938, "policy_entropy": 7925.80078125, "policy_loss": -30.752044677734375, "vf_loss": 34.134159088134766}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 1930240, "num_agent_steps_sampled": 1930240, "num_steps_trained": 1930240, "num_agent_steps_trained": 1930240, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 964, "training_iteration": 48, "trial_id": "6184f_00000", "experiment_id": "f2b91da2b7784e16a8a98abdfbd268d1", "date": "2024-06-12_13-30-50", "timestamp": 1718166650, "time_this_iter_s": 10.84249997138977, "time_total_s": 499.67223381996155, "pid": 76400, "hostname": "DESKTOP-LQ219J4", "node_ip": "192.168.46.185", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 20, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 5000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 500, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "rware", "env_args": {"n_agents": 4, "column_height": 1, "max_inactivity_steps": null, "max_steps": 500, "fast_obs": true, "msg_bits": 0, "sensor_range": 1, "shelf_rows": 1, "shelf_columns": 3, "request_queue_size": 4, "reward_type": "RewardType.INDIVIDUAL", "map_name": "customized_map", "map_size": "tiny", "difficulty": "medium"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": true, "force_coop": false, "local_mode": true, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 4, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 100, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64}, "algorithm": "maa2c", "space_obs": "Dict(obs:Box([-100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100.], [100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.], (112,), float32))", "space_act": "Discrete(5)", "num_agents": 4, "episode_limit": 500, "policy_mapping_info": {"all_scenario": {"description": "rware all scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2", "agent_3"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "rware_customized_map", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 10, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.policy_template.MAA2CTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x7f1c5c0864c0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "grad_clip": 40.0, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "microbatch_size": null}, "time_since_restore": 499.67223381996155, "timesteps_since_restore": 0, "iterations_since_restore": 48, "perf": {"cpu_util_percent": 4.7125, "ram_util_percent": 53.74375}}
{"episode_reward_max": 11.0, "episode_reward_min": 0.0, "episode_reward_mean": 2.54, "episode_len_mean": 500.0, "episode_media": {}, "episodes_this_iter": 20, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [1.0, 2.0, 0.0, 8.0, 1.0, 5.0, 1.0, 0.0, 2.0, 2.0, 4.0, 2.0, 1.0, 1.0, 2.0, 4.0, 2.0, 1.0, 2.0, 1.0, 2.0, 3.0, 0.0, 2.0, 0.0, 3.0, 4.0, 1.0, 2.0, 1.0, 0.0, 6.0, 1.0, 3.0, 2.0, 2.0, 6.0, 1.0, 4.0, 2.0, 1.0, 1.0, 3.0, 4.0, 1.0, 5.0, 1.0, 2.0, 1.0, 3.0, 2.0, 1.0, 3.0, 3.0, 4.0, 3.0, 1.0, 0.0, 5.0, 2.0, 1.0, 1.0, 2.0, 5.0, 3.0, 4.0, 5.0, 5.0, 4.0, 0.0, 2.0, 11.0, 2.0, 2.0, 3.0, 1.0, 3.0, 2.0, 2.0, 5.0, 0.0, 3.0, 1.0, 6.0, 2.0, 3.0, 5.0, 5.0, 5.0, 4.0, 3.0, 1.0, 0.0, 2.0, 2.0, 2.0, 4.0, 3.0, 4.0, 3.0], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.14884512975388575, "mean_inference_ms": 0.3806303017604749, "mean_action_processing_ms": 0.027309535181640972, "mean_env_wait_ms": 0.3909810736247964, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 1971200, "timesteps_this_iter": 0, "agent_timesteps_total": 1971200, "timers": {"sample_time_ms": 1364.359, "sample_throughput": 3752.678, "load_time_ms": 0.155, "load_throughput": 32941918.208, "learn_time_ms": 68.432, "learn_throughput": 74818.697, "update_time_ms": 2.983}, "info": {"learner": {"default_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 148.108642578125, "policy_entropy": 7887.916015625, "policy_loss": 37.37828826904297, "vf_loss": 43.13669967651367}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 1971200, "num_agent_steps_sampled": 1971200, "num_steps_trained": 1971200, "num_agent_steps_trained": 1971200, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 984, "training_iteration": 49, "trial_id": "6184f_00000", "experiment_id": "f2b91da2b7784e16a8a98abdfbd268d1", "date": "2024-06-12_13-31-01", "timestamp": 1718166661, "time_this_iter_s": 10.964316129684448, "time_total_s": 510.636549949646, "pid": 76400, "hostname": "DESKTOP-LQ219J4", "node_ip": "192.168.46.185", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 20, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 5000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 500, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "rware", "env_args": {"n_agents": 4, "column_height": 1, "max_inactivity_steps": null, "max_steps": 500, "fast_obs": true, "msg_bits": 0, "sensor_range": 1, "shelf_rows": 1, "shelf_columns": 3, "request_queue_size": 4, "reward_type": "RewardType.INDIVIDUAL", "map_name": "customized_map", "map_size": "tiny", "difficulty": "medium"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": true, "force_coop": false, "local_mode": true, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 4, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 100, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64}, "algorithm": "maa2c", "space_obs": "Dict(obs:Box([-100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100.], [100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.], (112,), float32))", "space_act": "Discrete(5)", "num_agents": 4, "episode_limit": 500, "policy_mapping_info": {"all_scenario": {"description": "rware all scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2", "agent_3"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "rware_customized_map", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 10, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.policy_template.MAA2CTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x7f1c5c11c790>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "grad_clip": 40.0, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "microbatch_size": null}, "time_since_restore": 510.636549949646, "timesteps_since_restore": 0, "iterations_since_restore": 49, "perf": {"cpu_util_percent": 4.453333333333332, "ram_util_percent": 54.38}}
{"episode_reward_max": 11.0, "episode_reward_min": 0.0, "episode_reward_mean": 2.61, "episode_len_mean": 500.0, "episode_media": {}, "episodes_this_iter": 20, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [2.0, 3.0, 0.0, 2.0, 0.0, 3.0, 4.0, 1.0, 2.0, 1.0, 0.0, 6.0, 1.0, 3.0, 2.0, 2.0, 6.0, 1.0, 4.0, 2.0, 1.0, 1.0, 3.0, 4.0, 1.0, 5.0, 1.0, 2.0, 1.0, 3.0, 2.0, 1.0, 3.0, 3.0, 4.0, 3.0, 1.0, 0.0, 5.0, 2.0, 1.0, 1.0, 2.0, 5.0, 3.0, 4.0, 5.0, 5.0, 4.0, 0.0, 2.0, 11.0, 2.0, 2.0, 3.0, 1.0, 3.0, 2.0, 2.0, 5.0, 0.0, 3.0, 1.0, 6.0, 2.0, 3.0, 5.0, 5.0, 5.0, 4.0, 3.0, 1.0, 0.0, 2.0, 2.0, 2.0, 4.0, 3.0, 4.0, 3.0, 6.0, 0.0, 2.0, 4.0, 4.0, 3.0, 1.0, 2.0, 4.0, 4.0, 5.0, 0.0, 1.0, 2.0, 1.0, 4.0, 2.0, 1.0, 0.0, 3.0], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.14894132861192766, "mean_inference_ms": 0.3808166332077589, "mean_action_processing_ms": 0.02732141348948166, "mean_env_wait_ms": 0.39118317463357405, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 2012160, "timesteps_this_iter": 0, "agent_timesteps_total": 2012160, "timers": {"sample_time_ms": 1362.807, "sample_throughput": 3756.952, "load_time_ms": 0.153, "load_throughput": 33455112.136, "learn_time_ms": 68.939, "learn_throughput": 74268.716, "update_time_ms": 2.929}, "info": {"learner": {"default_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 88.69042205810547, "policy_entropy": 7896.1357421875, "policy_loss": 35.645999908447266, "vf_loss": 20.03581428527832}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 2012160, "num_agent_steps_sampled": 2012160, "num_steps_trained": 2012160, "num_agent_steps_trained": 2012160, "num_steps_trained_this_iter": 0}, "evaluation": {"episode_reward_max": 4.0, "episode_reward_min": 0.0, "episode_reward_mean": 2.3, "episode_len_mean": 500.0, "episode_media": {}, "episodes_this_iter": 10, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [3.0, 0.0, 2.0, 2.0, 1.0, 2.0, 4.0, 4.0, 1.0, 4.0], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.09137572014100596, "mean_inference_ms": 0.3938166719988522, "mean_action_processing_ms": 0.026723333083017185, "mean_env_wait_ms": 0.38464930838905464, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}}, "done": true, "episodes_total": 1004, "training_iteration": 50, "trial_id": "6184f_00000", "experiment_id": "f2b91da2b7784e16a8a98abdfbd268d1", "date": "2024-06-12_13-31-16", "timestamp": 1718166676, "time_this_iter_s": 15.346712589263916, "time_total_s": 525.9832625389099, "pid": 76400, "hostname": "DESKTOP-LQ219J4", "node_ip": "192.168.46.185", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 20, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 5000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 500, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "rware", "env_args": {"n_agents": 4, "column_height": 1, "max_inactivity_steps": null, "max_steps": 500, "fast_obs": true, "msg_bits": 0, "sensor_range": 1, "shelf_rows": 1, "shelf_columns": 3, "request_queue_size": 4, "reward_type": "RewardType.INDIVIDUAL", "map_name": "customized_map", "map_size": "tiny", "difficulty": "medium"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": true, "force_coop": false, "local_mode": true, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 4, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 100, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64}, "algorithm": "maa2c", "space_obs": "Dict(obs:Box([-100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100.], [100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.], (112,), float32))", "space_act": "Discrete(5)", "num_agents": 4, "episode_limit": 500, "policy_mapping_info": {"all_scenario": {"description": "rware all scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2", "agent_3"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "rware_customized_map", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 10, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.policy_template.MAA2CTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x7f1c5c11c1f0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "grad_clip": 40.0, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "microbatch_size": null}, "time_since_restore": 525.9832625389099, "timesteps_since_restore": 0, "iterations_since_restore": 50, "perf": {"cpu_util_percent": 4.45, "ram_util_percent": 55.12272727272728}}
