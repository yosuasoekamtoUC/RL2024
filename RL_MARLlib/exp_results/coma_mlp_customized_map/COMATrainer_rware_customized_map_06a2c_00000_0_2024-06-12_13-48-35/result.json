{"episode_reward_max": NaN, "episode_reward_min": NaN, "episode_reward_mean": NaN, "episode_len_mean": NaN, "episode_media": {}, "episodes_this_iter": 0, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [], "episode_lengths": []}, "sampler_perf": {}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 5120, "timesteps_this_iter": 0, "agent_timesteps_total": 5120, "timers": {"sample_time_ms": 1247.909, "sample_throughput": 4102.862, "load_time_ms": 0.206, "load_throughput": 24883935.666, "learn_time_ms": 52.305, "learn_throughput": 97886.977, "update_time_ms": 2.545}, "info": {"learner": {"default_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 41.388099670410156, "policy_entropy": 8047.12841796875, "policy_loss": -0.23395411670207977, "vf_loss": 8.314862251281738}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 5120, "num_agent_steps_sampled": 5120, "num_steps_trained": 5120, "num_agent_steps_trained": 5120}, "done": false, "episodes_total": 0, "training_iteration": 1, "trial_id": "06a2c_00000", "experiment_id": "da1bb264888d4dd88dc9d72bb32edab2", "date": "2024-06-12_13-48-36", "timestamp": 1718167716, "time_this_iter_s": 1.2947964668273926, "time_total_s": 1.2947964668273926, "pid": 88332, "hostname": "DESKTOP-LQ219J4", "node_ip": "192.168.46.185", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 20, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 5000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 500, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "rware", "env_args": {"n_agents": 4, "column_height": 1, "max_inactivity_steps": null, "max_steps": 500, "fast_obs": true, "msg_bits": 0, "sensor_range": 1, "shelf_rows": 1, "shelf_columns": 3, "request_queue_size": 4, "reward_type": "RewardType.INDIVIDUAL", "map_name": "customized_map", "map_size": "tiny", "difficulty": "medium"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": true, "force_coop": false, "local_mode": true, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 4, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 100, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64}, "algorithm": "coma", "space_obs": "Dict(obs:Box([-100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100.], [100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.], (112,), float32))", "space_act": "Discrete(5)", "num_agents": 4, "episode_limit": 500, "policy_mapping_info": {"all_scenario": {"description": "rware all scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2", "agent_3"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "rware_customized_map", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 10, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.policy_template.COMATorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x7ff3b8028790>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "grad_clip": 40.0, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "microbatch_size": null}, "time_since_restore": 1.2947964668273926, "timesteps_since_restore": 0, "iterations_since_restore": 1, "perf": {"cpu_util_percent": 8.25, "ram_util_percent": 22.45}}
{"episode_reward_max": 2.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.7, "episode_len_mean": 500.0, "episode_media": {}, "episodes_this_iter": 20, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [1.0, 2.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 2.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.14683656997045103, "mean_inference_ms": 0.37670956846327885, "mean_action_processing_ms": 0.027579385677338975, "mean_env_wait_ms": 0.3861658112202532, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 46080, "timesteps_this_iter": 0, "agent_timesteps_total": 46080, "timers": {"sample_time_ms": 1287.034, "sample_throughput": 3978.139, "load_time_ms": 0.104, "load_throughput": 49405298.65, "learn_time_ms": 50.278, "learn_throughput": 101834.123, "update_time_ms": 2.554}, "info": {"learner": {"default_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 29.47943878173828, "policy_entropy": 8046.27099609375, "policy_loss": -0.1870245635509491, "vf_loss": 4.238499641418457}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 46080, "num_agent_steps_sampled": 46080, "num_steps_trained": 46080, "num_agent_steps_trained": 46080, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 20, "training_iteration": 2, "trial_id": "06a2c_00000", "experiment_id": "da1bb264888d4dd88dc9d72bb32edab2", "date": "2024-06-12_13-48-47", "timestamp": 1718167727, "time_this_iter_s": 10.31976056098938, "time_total_s": 11.614557027816772, "pid": 88332, "hostname": "DESKTOP-LQ219J4", "node_ip": "192.168.46.185", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 20, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 5000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 500, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "rware", "env_args": {"n_agents": 4, "column_height": 1, "max_inactivity_steps": null, "max_steps": 500, "fast_obs": true, "msg_bits": 0, "sensor_range": 1, "shelf_rows": 1, "shelf_columns": 3, "request_queue_size": 4, "reward_type": "RewardType.INDIVIDUAL", "map_name": "customized_map", "map_size": "tiny", "difficulty": "medium"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": true, "force_coop": false, "local_mode": true, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 4, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 100, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64}, "algorithm": "coma", "space_obs": "Dict(obs:Box([-100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100.], [100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.], (112,), float32))", "space_act": "Discrete(5)", "num_agents": 4, "episode_limit": 500, "policy_mapping_info": {"all_scenario": {"description": "rware all scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2", "agent_3"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "rware_customized_map", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 10, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.policy_template.COMATorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x7ff3b81beaf0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "grad_clip": 40.0, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "microbatch_size": null}, "time_since_restore": 11.614557027816772, "timesteps_since_restore": 0, "iterations_since_restore": 2, "perf": {"cpu_util_percent": 4.286666666666666, "ram_util_percent": 23.3}}
{"episode_reward_max": 2.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.6, "episode_len_mean": 500.0, "episode_media": {}, "episodes_this_iter": 20, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [1.0, 2.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 2.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 2.0], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.14777396196083684, "mean_inference_ms": 0.37804439171691645, "mean_action_processing_ms": 0.027642919806908573, "mean_env_wait_ms": 0.3862451327208746, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 87040, "timesteps_this_iter": 0, "agent_timesteps_total": 87040, "timers": {"sample_time_ms": 1306.178, "sample_throughput": 3919.832, "load_time_ms": 0.096, "load_throughput": 53553208.18, "learn_time_ms": 50.386, "learn_throughput": 101616.106, "update_time_ms": 2.59}, "info": {"learner": {"default_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 26.024391174316406, "policy_entropy": 8046.5556640625, "policy_loss": 0.11446920037269592, "vf_loss": 8.099366188049316}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 87040, "num_agent_steps_sampled": 87040, "num_steps_trained": 87040, "num_agent_steps_trained": 87040, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 40, "training_iteration": 3, "trial_id": "06a2c_00000", "experiment_id": "da1bb264888d4dd88dc9d72bb32edab2", "date": "2024-06-12_13-48-57", "timestamp": 1718167737, "time_this_iter_s": 10.436345100402832, "time_total_s": 22.050902128219604, "pid": 88332, "hostname": "DESKTOP-LQ219J4", "node_ip": "192.168.46.185", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 20, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 5000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 500, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "rware", "env_args": {"n_agents": 4, "column_height": 1, "max_inactivity_steps": null, "max_steps": 500, "fast_obs": true, "msg_bits": 0, "sensor_range": 1, "shelf_rows": 1, "shelf_columns": 3, "request_queue_size": 4, "reward_type": "RewardType.INDIVIDUAL", "map_name": "customized_map", "map_size": "tiny", "difficulty": "medium"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": true, "force_coop": false, "local_mode": true, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 4, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 100, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64}, "algorithm": "coma", "space_obs": "Dict(obs:Box([-100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100.], [100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.], (112,), float32))", "space_act": "Discrete(5)", "num_agents": 4, "episode_limit": 500, "policy_mapping_info": {"all_scenario": {"description": "rware all scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2", "agent_3"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "rware_customized_map", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 10, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.policy_template.COMATorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x7ff3b8028310>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "grad_clip": 40.0, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "microbatch_size": null}, "time_since_restore": 22.050902128219604, "timesteps_since_restore": 0, "iterations_since_restore": 3, "perf": {"cpu_util_percent": 4.413333333333333, "ram_util_percent": 24.06}}
{"episode_reward_max": 2.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.65625, "episode_len_mean": 500.0, "episode_media": {}, "episodes_this_iter": 24, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [1.0, 2.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 2.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 2.0, 1.0, 1.0, 1.0, 2.0, 1.0, 0.0, 0.0, 0.0, 1.0, 2.0, 1.0, 1.0, 2.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.14851374101006382, "mean_inference_ms": 0.3792854319606708, "mean_action_processing_ms": 0.02771258800703137, "mean_env_wait_ms": 0.3876541046064385, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 128000, "timesteps_this_iter": 0, "agent_timesteps_total": 128000, "timers": {"sample_time_ms": 1324.629, "sample_throughput": 3865.233, "load_time_ms": 0.114, "load_throughput": 45105726.696, "learn_time_ms": 50.586, "learn_throughput": 101213.136, "update_time_ms": 2.704}, "info": {"learner": {"default_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 28.3444881439209, "policy_entropy": 8044.4267578125, "policy_loss": 0.30765455961227417, "vf_loss": 12.739813804626465}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 128000, "num_agent_steps_sampled": 128000, "num_steps_trained": 128000, "num_agent_steps_trained": 128000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 64, "training_iteration": 4, "trial_id": "06a2c_00000", "experiment_id": "da1bb264888d4dd88dc9d72bb32edab2", "date": "2024-06-12_13-49-08", "timestamp": 1718167748, "time_this_iter_s": 10.598637819290161, "time_total_s": 32.649539947509766, "pid": 88332, "hostname": "DESKTOP-LQ219J4", "node_ip": "192.168.46.185", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 20, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 5000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 500, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "rware", "env_args": {"n_agents": 4, "column_height": 1, "max_inactivity_steps": null, "max_steps": 500, "fast_obs": true, "msg_bits": 0, "sensor_range": 1, "shelf_rows": 1, "shelf_columns": 3, "request_queue_size": 4, "reward_type": "RewardType.INDIVIDUAL", "map_name": "customized_map", "map_size": "tiny", "difficulty": "medium"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": true, "force_coop": false, "local_mode": true, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 4, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 100, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64}, "algorithm": "coma", "space_obs": "Dict(obs:Box([-100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100.], [100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.], (112,), float32))", "space_act": "Discrete(5)", "num_agents": 4, "episode_limit": 500, "policy_mapping_info": {"all_scenario": {"description": "rware all scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2", "agent_3"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "rware_customized_map", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 10, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.policy_template.COMATorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x7ff3b804a820>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "grad_clip": 40.0, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "microbatch_size": null}, "time_since_restore": 32.649539947509766, "timesteps_since_restore": 0, "iterations_since_restore": 4, "perf": {"cpu_util_percent": 4.180000000000001, "ram_util_percent": 24.69333333333333}}
{"episode_reward_max": 4.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.75, "episode_len_mean": 500.0, "episode_media": {}, "episodes_this_iter": 20, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [1.0, 2.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 2.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 2.0, 1.0, 1.0, 1.0, 2.0, 1.0, 0.0, 0.0, 0.0, 1.0, 2.0, 1.0, 1.0, 2.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 4.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 3.0, 0.0, 1.0, 1.0, 2.0, 2.0, 1.0, 0.0, 0.0, 0.0, 1.0], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.14903330778605503, "mean_inference_ms": 0.3803306847053503, "mean_action_processing_ms": 0.02778442994358419, "mean_env_wait_ms": 0.3890415377677747, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 168960, "timesteps_this_iter": 0, "agent_timesteps_total": 168960, "timers": {"sample_time_ms": 1338.674, "sample_throughput": 3824.681, "load_time_ms": 0.105, "load_throughput": 48773192.096, "learn_time_ms": 50.878, "learn_throughput": 100631.99, "update_time_ms": 2.832}, "info": {"learner": {"default_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 30.358919143676758, "policy_entropy": 8031.68408203125, "policy_loss": 0.19884267449378967, "vf_loss": 15.04343318939209}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 168960, "num_agent_steps_sampled": 168960, "num_steps_trained": 168960, "num_agent_steps_trained": 168960, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 84, "training_iteration": 5, "trial_id": "06a2c_00000", "experiment_id": "da1bb264888d4dd88dc9d72bb32edab2", "date": "2024-06-12_13-49-18", "timestamp": 1718167758, "time_this_iter_s": 10.749524116516113, "time_total_s": 43.39906406402588, "pid": 88332, "hostname": "DESKTOP-LQ219J4", "node_ip": "192.168.46.185", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 20, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 5000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 500, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "rware", "env_args": {"n_agents": 4, "column_height": 1, "max_inactivity_steps": null, "max_steps": 500, "fast_obs": true, "msg_bits": 0, "sensor_range": 1, "shelf_rows": 1, "shelf_columns": 3, "request_queue_size": 4, "reward_type": "RewardType.INDIVIDUAL", "map_name": "customized_map", "map_size": "tiny", "difficulty": "medium"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": true, "force_coop": false, "local_mode": true, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 4, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 100, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64}, "algorithm": "coma", "space_obs": "Dict(obs:Box([-100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100.], [100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.], (112,), float32))", "space_act": "Discrete(5)", "num_agents": 4, "episode_limit": 500, "policy_mapping_info": {"all_scenario": {"description": "rware all scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2", "agent_3"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "rware_customized_map", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 10, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.policy_template.COMATorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x7ff3b81beaf0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "grad_clip": 40.0, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "microbatch_size": null}, "time_since_restore": 43.39906406402588, "timesteps_since_restore": 0, "iterations_since_restore": 5, "perf": {"cpu_util_percent": 4.173333333333334, "ram_util_percent": 25.373333333333335}}
{"episode_reward_max": 4.0, "episode_reward_min": 0.0, "episode_reward_mean": 0.87, "episode_len_mean": 500.0, "episode_media": {}, "episodes_this_iter": 20, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 2.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 2.0, 1.0, 1.0, 1.0, 2.0, 1.0, 0.0, 0.0, 0.0, 1.0, 2.0, 1.0, 1.0, 2.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 4.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 3.0, 0.0, 1.0, 1.0, 2.0, 2.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 3.0, 4.0, 2.0, 1.0, 2.0, 1.0, 0.0, 1.0, 2.0, 1.0, 3.0, 1.0, 2.0, 0.0, 0.0, 2.0], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.14959026116760132, "mean_inference_ms": 0.38129185860514114, "mean_action_processing_ms": 0.02783303998873433, "mean_env_wait_ms": 0.3906183320964056, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 209920, "timesteps_this_iter": 0, "agent_timesteps_total": 209920, "timers": {"sample_time_ms": 1341.539, "sample_throughput": 3816.511, "load_time_ms": 0.103, "load_throughput": 49618383.734, "learn_time_ms": 50.442, "learn_throughput": 101502.995, "update_time_ms": 2.666}, "info": {"learner": {"default_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 50.455596923828125, "policy_entropy": 8006.60205078125, "policy_loss": -0.582076370716095, "vf_loss": 26.622217178344727}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 209920, "num_agent_steps_sampled": 209920, "num_steps_trained": 209920, "num_agent_steps_trained": 209920, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 104, "training_iteration": 6, "trial_id": "06a2c_00000", "experiment_id": "da1bb264888d4dd88dc9d72bb32edab2", "date": "2024-06-12_13-49-29", "timestamp": 1718167769, "time_this_iter_s": 10.714436292648315, "time_total_s": 54.113500356674194, "pid": 88332, "hostname": "DESKTOP-LQ219J4", "node_ip": "192.168.46.185", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 20, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 5000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 500, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "rware", "env_args": {"n_agents": 4, "column_height": 1, "max_inactivity_steps": null, "max_steps": 500, "fast_obs": true, "msg_bits": 0, "sensor_range": 1, "shelf_rows": 1, "shelf_columns": 3, "request_queue_size": 4, "reward_type": "RewardType.INDIVIDUAL", "map_name": "customized_map", "map_size": "tiny", "difficulty": "medium"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": true, "force_coop": false, "local_mode": true, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 4, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 100, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64}, "algorithm": "coma", "space_obs": "Dict(obs:Box([-100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100.], [100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.], (112,), float32))", "space_act": "Discrete(5)", "num_agents": 4, "episode_limit": 500, "policy_mapping_info": {"all_scenario": {"description": "rware all scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2", "agent_3"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "rware_customized_map", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 10, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.policy_template.COMATorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x7ff2a4e701f0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "grad_clip": 40.0, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "microbatch_size": null}, "time_since_restore": 54.113500356674194, "timesteps_since_restore": 0, "iterations_since_restore": 6, "perf": {"cpu_util_percent": 4.125, "ram_util_percent": 26.0625}}
{"episode_reward_max": 4.0, "episode_reward_min": 0.0, "episode_reward_mean": 1.01, "episode_len_mean": 500.0, "episode_media": {}, "episodes_this_iter": 20, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 2.0, 1.0, 1.0, 1.0, 2.0, 1.0, 0.0, 0.0, 0.0, 1.0, 2.0, 1.0, 1.0, 2.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 4.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 3.0, 0.0, 1.0, 1.0, 2.0, 2.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 3.0, 4.0, 2.0, 1.0, 2.0, 1.0, 0.0, 1.0, 2.0, 1.0, 3.0, 1.0, 2.0, 0.0, 0.0, 2.0, 2.0, 0.0, 0.0, 2.0, 3.0, 0.0, 2.0, 1.0, 2.0, 2.0, 3.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 3.0, 0.0, 0.0], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.15053582560017006, "mean_inference_ms": 0.3828779253123342, "mean_action_processing_ms": 0.02791601536459484, "mean_env_wait_ms": 0.39258877985147317, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 250880, "timesteps_this_iter": 0, "agent_timesteps_total": 250880, "timers": {"sample_time_ms": 1337.741, "sample_throughput": 3827.348, "load_time_ms": 0.105, "load_throughput": 48773192.096, "learn_time_ms": 50.88, "learn_throughput": 100628.406, "update_time_ms": 2.722}, "info": {"learner": {"default_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 48.4835090637207, "policy_entropy": 7975.21435546875, "policy_loss": -0.47600847482681274, "vf_loss": 7.291515350341797}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 250880, "num_agent_steps_sampled": 250880, "num_steps_trained": 250880, "num_agent_steps_trained": 250880, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 124, "training_iteration": 7, "trial_id": "06a2c_00000", "experiment_id": "da1bb264888d4dd88dc9d72bb32edab2", "date": "2024-06-12_13-49-40", "timestamp": 1718167780, "time_this_iter_s": 10.70192289352417, "time_total_s": 64.81542325019836, "pid": 88332, "hostname": "DESKTOP-LQ219J4", "node_ip": "192.168.46.185", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 20, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 5000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 500, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "rware", "env_args": {"n_agents": 4, "column_height": 1, "max_inactivity_steps": null, "max_steps": 500, "fast_obs": true, "msg_bits": 0, "sensor_range": 1, "shelf_rows": 1, "shelf_columns": 3, "request_queue_size": 4, "reward_type": "RewardType.INDIVIDUAL", "map_name": "customized_map", "map_size": "tiny", "difficulty": "medium"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": true, "force_coop": false, "local_mode": true, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 4, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 100, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64}, "algorithm": "coma", "space_obs": "Dict(obs:Box([-100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100.], [100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.], (112,), float32))", "space_act": "Discrete(5)", "num_agents": 4, "episode_limit": 500, "policy_mapping_info": {"all_scenario": {"description": "rware all scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2", "agent_3"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "rware_customized_map", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 10, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.policy_template.COMATorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x7ff3b81bef70>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "grad_clip": 40.0, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "microbatch_size": null}, "time_since_restore": 64.81542325019836, "timesteps_since_restore": 0, "iterations_since_restore": 7, "perf": {"cpu_util_percent": 4.08, "ram_util_percent": 26.779999999999998}}
{"episode_reward_max": 4.0, "episode_reward_min": 0.0, "episode_reward_mean": 1.13, "episode_len_mean": 500.0, "episode_media": {}, "episodes_this_iter": 20, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [1.0, 0.0, 0.0, 0.0, 1.0, 2.0, 1.0, 1.0, 2.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 4.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 3.0, 0.0, 1.0, 1.0, 2.0, 2.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 3.0, 4.0, 2.0, 1.0, 2.0, 1.0, 0.0, 1.0, 2.0, 1.0, 3.0, 1.0, 2.0, 0.0, 0.0, 2.0, 2.0, 0.0, 0.0, 2.0, 3.0, 0.0, 2.0, 1.0, 2.0, 2.0, 3.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 3.0, 0.0, 0.0, 1.0, 2.0, 2.0, 2.0, 1.0, 0.0, 1.0, 0.0, 1.0, 2.0, 2.0, 1.0, 1.0, 2.0, 3.0, 1.0, 2.0, 0.0, 2.0, 0.0], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.15118223238359613, "mean_inference_ms": 0.38395363367873414, "mean_action_processing_ms": 0.027968772112512565, "mean_env_wait_ms": 0.39467812531376156, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 291840, "timesteps_this_iter": 0, "agent_timesteps_total": 291840, "timers": {"sample_time_ms": 1331.775, "sample_throughput": 3844.494, "load_time_ms": 0.118, "load_throughput": 43383508.04, "learn_time_ms": 50.728, "learn_throughput": 100931.237, "update_time_ms": 2.752}, "info": {"learner": {"default_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 37.00435256958008, "policy_entropy": 8012.50439453125, "policy_loss": -0.729170024394989, "vf_loss": 24.04373550415039}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 291840, "num_agent_steps_sampled": 291840, "num_steps_trained": 291840, "num_agent_steps_trained": 291840, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 144, "training_iteration": 8, "trial_id": "06a2c_00000", "experiment_id": "da1bb264888d4dd88dc9d72bb32edab2", "date": "2024-06-12_13-49-51", "timestamp": 1718167791, "time_this_iter_s": 10.680048704147339, "time_total_s": 75.4954719543457, "pid": 88332, "hostname": "DESKTOP-LQ219J4", "node_ip": "192.168.46.185", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 20, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 5000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 500, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "rware", "env_args": {"n_agents": 4, "column_height": 1, "max_inactivity_steps": null, "max_steps": 500, "fast_obs": true, "msg_bits": 0, "sensor_range": 1, "shelf_rows": 1, "shelf_columns": 3, "request_queue_size": 4, "reward_type": "RewardType.INDIVIDUAL", "map_name": "customized_map", "map_size": "tiny", "difficulty": "medium"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": true, "force_coop": false, "local_mode": true, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 4, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 100, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64}, "algorithm": "coma", "space_obs": "Dict(obs:Box([-100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100.], [100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.], (112,), float32))", "space_act": "Discrete(5)", "num_agents": 4, "episode_limit": 500, "policy_mapping_info": {"all_scenario": {"description": "rware all scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2", "agent_3"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "rware_customized_map", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 10, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.policy_template.COMATorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x7ff3b81beaf0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "grad_clip": 40.0, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "microbatch_size": null}, "time_since_restore": 75.4954719543457, "timesteps_since_restore": 0, "iterations_since_restore": 8, "perf": {"cpu_util_percent": 4.14, "ram_util_percent": 27.4}}
{"episode_reward_max": 4.0, "episode_reward_min": 0.0, "episode_reward_mean": 1.16, "episode_len_mean": 500.0, "episode_media": {}, "episodes_this_iter": 20, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [1.0, 1.0, 4.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 3.0, 0.0, 1.0, 1.0, 2.0, 2.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 3.0, 4.0, 2.0, 1.0, 2.0, 1.0, 0.0, 1.0, 2.0, 1.0, 3.0, 1.0, 2.0, 0.0, 0.0, 2.0, 2.0, 0.0, 0.0, 2.0, 3.0, 0.0, 2.0, 1.0, 2.0, 2.0, 3.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 3.0, 0.0, 0.0, 1.0, 2.0, 2.0, 2.0, 1.0, 0.0, 1.0, 0.0, 1.0, 2.0, 2.0, 1.0, 1.0, 2.0, 3.0, 1.0, 2.0, 0.0, 2.0, 0.0, 1.0, 0.0, 3.0, 0.0, 0.0, 2.0, 0.0, 2.0, 1.0, 2.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.1516853254863395, "mean_inference_ms": 0.38480638693926345, "mean_action_processing_ms": 0.028005427565927072, "mean_env_wait_ms": 0.39602451331216115, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 332800, "timesteps_this_iter": 0, "agent_timesteps_total": 332800, "timers": {"sample_time_ms": 1331.307, "sample_throughput": 3845.846, "load_time_ms": 0.12, "load_throughput": 42795608.768, "learn_time_ms": 51.207, "learn_throughput": 99986.993, "update_time_ms": 2.755}, "info": {"learner": {"default_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 21.674339294433594, "policy_entropy": 8037.52001953125, "policy_loss": -0.6597511172294617, "vf_loss": 10.421903610229492}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 332800, "num_agent_steps_sampled": 332800, "num_steps_trained": 332800, "num_agent_steps_trained": 332800, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 164, "training_iteration": 9, "trial_id": "06a2c_00000", "experiment_id": "da1bb264888d4dd88dc9d72bb32edab2", "date": "2024-06-12_13-50-01", "timestamp": 1718167801, "time_this_iter_s": 10.64133071899414, "time_total_s": 86.13680267333984, "pid": 88332, "hostname": "DESKTOP-LQ219J4", "node_ip": "192.168.46.185", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 20, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 5000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 500, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "rware", "env_args": {"n_agents": 4, "column_height": 1, "max_inactivity_steps": null, "max_steps": 500, "fast_obs": true, "msg_bits": 0, "sensor_range": 1, "shelf_rows": 1, "shelf_columns": 3, "request_queue_size": 4, "reward_type": "RewardType.INDIVIDUAL", "map_name": "customized_map", "map_size": "tiny", "difficulty": "medium"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": true, "force_coop": false, "local_mode": true, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 4, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 100, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64}, "algorithm": "coma", "space_obs": "Dict(obs:Box([-100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100.], [100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.], (112,), float32))", "space_act": "Discrete(5)", "num_agents": 4, "episode_limit": 500, "policy_mapping_info": {"all_scenario": {"description": "rware all scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2", "agent_3"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "rware_customized_map", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 10, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.policy_template.COMATorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x7ff3b8161a60>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "grad_clip": 40.0, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "microbatch_size": null}, "time_since_restore": 86.13680267333984, "timesteps_since_restore": 0, "iterations_since_restore": 9, "perf": {"cpu_util_percent": 4.233333333333333, "ram_util_percent": 28.059999999999995}}
{"episode_reward_max": 4.0, "episode_reward_min": 0.0, "episode_reward_mean": 1.21, "episode_len_mean": 500.0, "episode_media": {}, "episodes_this_iter": 20, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 1.0, 1.0, 0.0, 3.0, 4.0, 2.0, 1.0, 2.0, 1.0, 0.0, 1.0, 2.0, 1.0, 3.0, 1.0, 2.0, 0.0, 0.0, 2.0, 2.0, 0.0, 0.0, 2.0, 3.0, 0.0, 2.0, 1.0, 2.0, 2.0, 3.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 3.0, 0.0, 0.0, 1.0, 2.0, 2.0, 2.0, 1.0, 0.0, 1.0, 0.0, 1.0, 2.0, 2.0, 1.0, 1.0, 2.0, 3.0, 1.0, 2.0, 0.0, 2.0, 0.0, 1.0, 0.0, 3.0, 0.0, 0.0, 2.0, 0.0, 2.0, 1.0, 2.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 2.0, 1.0, 0.0, 3.0, 3.0, 0.0, 0.0, 1.0, 1.0, 2.0, 1.0, 2.0, 2.0, 0.0, 1.0, 1.0, 1.0, 1.0, 3.0, 1.0], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.15199718133674367, "mean_inference_ms": 0.3850938344450368, "mean_action_processing_ms": 0.027997968986422535, "mean_env_wait_ms": 0.39684626447593707, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 373760, "timesteps_this_iter": 0, "agent_timesteps_total": 373760, "timers": {"sample_time_ms": 1325.026, "sample_throughput": 3864.075, "load_time_ms": 0.114, "load_throughput": 45020621.551, "learn_time_ms": 50.388, "learn_throughput": 101611.634, "update_time_ms": 2.797}, "info": {"learner": {"default_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 36.341400146484375, "policy_entropy": 8039.82861328125, "policy_loss": -0.11801686882972717, "vf_loss": 12.926573753356934}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 373760, "num_agent_steps_sampled": 373760, "num_steps_trained": 373760, "num_agent_steps_trained": 373760, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 184, "training_iteration": 10, "trial_id": "06a2c_00000", "experiment_id": "da1bb264888d4dd88dc9d72bb32edab2", "date": "2024-06-12_13-50-12", "timestamp": 1718167812, "time_this_iter_s": 10.59013819694519, "time_total_s": 96.72694087028503, "pid": 88332, "hostname": "DESKTOP-LQ219J4", "node_ip": "192.168.46.185", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 20, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 5000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 500, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "rware", "env_args": {"n_agents": 4, "column_height": 1, "max_inactivity_steps": null, "max_steps": 500, "fast_obs": true, "msg_bits": 0, "sensor_range": 1, "shelf_rows": 1, "shelf_columns": 3, "request_queue_size": 4, "reward_type": "RewardType.INDIVIDUAL", "map_name": "customized_map", "map_size": "tiny", "difficulty": "medium"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": true, "force_coop": false, "local_mode": true, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 4, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 100, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64}, "algorithm": "coma", "space_obs": "Dict(obs:Box([-100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100.], [100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.], (112,), float32))", "space_act": "Discrete(5)", "num_agents": 4, "episode_limit": 500, "policy_mapping_info": {"all_scenario": {"description": "rware all scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2", "agent_3"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "rware_customized_map", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 10, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.policy_template.COMATorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x7ff3b8161f70>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "grad_clip": 40.0, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "microbatch_size": null}, "time_since_restore": 96.72694087028503, "timesteps_since_restore": 0, "iterations_since_restore": 10, "perf": {"cpu_util_percent": 4.3066666666666675, "ram_util_percent": 28.69333333333333}}
{"episode_reward_max": 3.0, "episode_reward_min": 0.0, "episode_reward_mean": 1.13, "episode_len_mean": 500.0, "episode_media": {}, "episodes_this_iter": 20, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [2.0, 0.0, 0.0, 2.0, 3.0, 0.0, 2.0, 1.0, 2.0, 2.0, 3.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 3.0, 0.0, 0.0, 1.0, 2.0, 2.0, 2.0, 1.0, 0.0, 1.0, 0.0, 1.0, 2.0, 2.0, 1.0, 1.0, 2.0, 3.0, 1.0, 2.0, 0.0, 2.0, 0.0, 1.0, 0.0, 3.0, 0.0, 0.0, 2.0, 0.0, 2.0, 1.0, 2.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 2.0, 1.0, 0.0, 3.0, 3.0, 0.0, 0.0, 1.0, 1.0, 2.0, 1.0, 2.0, 2.0, 0.0, 1.0, 1.0, 1.0, 1.0, 3.0, 1.0, 1.0, 2.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 3.0, 1.0, 2.0, 1.0, 2.0, 0.0, 1.0, 0.0, 0.0, 3.0], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.15219580930842494, "mean_inference_ms": 0.38524099087194896, "mean_action_processing_ms": 0.027990050146389958, "mean_env_wait_ms": 0.3973750130382864, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 414720, "timesteps_this_iter": 0, "agent_timesteps_total": 414720, "timers": {"sample_time_ms": 1331.731, "sample_throughput": 3844.619, "load_time_ms": 0.112, "load_throughput": 45584454.426, "learn_time_ms": 50.601, "learn_throughput": 101183.855, "update_time_ms": 2.815}, "info": {"learner": {"default_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 26.49856948852539, "policy_entropy": 8023.4794921875, "policy_loss": -0.2831309735774994, "vf_loss": 2.9626288414001465}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 414720, "num_agent_steps_sampled": 414720, "num_steps_trained": 414720, "num_agent_steps_trained": 414720, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 204, "training_iteration": 11, "trial_id": "06a2c_00000", "experiment_id": "da1bb264888d4dd88dc9d72bb32edab2", "date": "2024-06-12_13-50-22", "timestamp": 1718167822, "time_this_iter_s": 10.700615644454956, "time_total_s": 107.42755651473999, "pid": 88332, "hostname": "DESKTOP-LQ219J4", "node_ip": "192.168.46.185", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 20, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 5000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 500, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "rware", "env_args": {"n_agents": 4, "column_height": 1, "max_inactivity_steps": null, "max_steps": 500, "fast_obs": true, "msg_bits": 0, "sensor_range": 1, "shelf_rows": 1, "shelf_columns": 3, "request_queue_size": 4, "reward_type": "RewardType.INDIVIDUAL", "map_name": "customized_map", "map_size": "tiny", "difficulty": "medium"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": true, "force_coop": false, "local_mode": true, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 4, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 100, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64}, "algorithm": "coma", "space_obs": "Dict(obs:Box([-100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100.], [100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.], (112,), float32))", "space_act": "Discrete(5)", "num_agents": 4, "episode_limit": 500, "policy_mapping_info": {"all_scenario": {"description": "rware all scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2", "agent_3"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "rware_customized_map", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 10, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.policy_template.COMATorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x7ff2a4e70790>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "grad_clip": 40.0, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "microbatch_size": null}, "time_since_restore": 107.42755651473999, "timesteps_since_restore": 0, "iterations_since_restore": 11, "perf": {"cpu_util_percent": 4.1625, "ram_util_percent": 29.3625}}
{"episode_reward_max": 3.0, "episode_reward_min": 0.0, "episode_reward_mean": 1.03, "episode_len_mean": 500.0, "episode_media": {}, "episodes_this_iter": 20, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [1.0, 2.0, 2.0, 2.0, 1.0, 0.0, 1.0, 0.0, 1.0, 2.0, 2.0, 1.0, 1.0, 2.0, 3.0, 1.0, 2.0, 0.0, 2.0, 0.0, 1.0, 0.0, 3.0, 0.0, 0.0, 2.0, 0.0, 2.0, 1.0, 2.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 2.0, 1.0, 0.0, 3.0, 3.0, 0.0, 0.0, 1.0, 1.0, 2.0, 1.0, 2.0, 2.0, 0.0, 1.0, 1.0, 1.0, 1.0, 3.0, 1.0, 1.0, 2.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 3.0, 1.0, 2.0, 1.0, 2.0, 0.0, 1.0, 0.0, 0.0, 3.0, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 3.0, 1.0, 1.0, 2.0, 1.0, 0.0, 2.0], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.15232598248319995, "mean_inference_ms": 0.38523420835531275, "mean_action_processing_ms": 0.027980089462383947, "mean_env_wait_ms": 0.39762278368595183, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 455680, "timesteps_this_iter": 0, "agent_timesteps_total": 455680, "timers": {"sample_time_ms": 1325.25, "sample_throughput": 3863.423, "load_time_ms": 0.112, "load_throughput": 45896209.617, "learn_time_ms": 50.705, "learn_throughput": 100975.943, "update_time_ms": 2.823}, "info": {"learner": {"default_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 21.55995750427246, "policy_entropy": 8018.091796875, "policy_loss": -0.7131727337837219, "vf_loss": 7.694703102111816}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 455680, "num_agent_steps_sampled": 455680, "num_steps_trained": 455680, "num_agent_steps_trained": 455680, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 224, "training_iteration": 12, "trial_id": "06a2c_00000", "experiment_id": "da1bb264888d4dd88dc9d72bb32edab2", "date": "2024-06-12_13-50-33", "timestamp": 1718167833, "time_this_iter_s": 10.565263271331787, "time_total_s": 117.99281978607178, "pid": 88332, "hostname": "DESKTOP-LQ219J4", "node_ip": "192.168.46.185", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 20, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 5000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 500, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "rware", "env_args": {"n_agents": 4, "column_height": 1, "max_inactivity_steps": null, "max_steps": 500, "fast_obs": true, "msg_bits": 0, "sensor_range": 1, "shelf_rows": 1, "shelf_columns": 3, "request_queue_size": 4, "reward_type": "RewardType.INDIVIDUAL", "map_name": "customized_map", "map_size": "tiny", "difficulty": "medium"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": true, "force_coop": false, "local_mode": true, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 4, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 100, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64}, "algorithm": "coma", "space_obs": "Dict(obs:Box([-100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100.], [100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.], (112,), float32))", "space_act": "Discrete(5)", "num_agents": 4, "episode_limit": 500, "policy_mapping_info": {"all_scenario": {"description": "rware all scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2", "agent_3"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "rware_customized_map", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 10, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.policy_template.COMATorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x7ff3b8161af0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "grad_clip": 40.0, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "microbatch_size": null}, "time_since_restore": 117.99281978607178, "timesteps_since_restore": 0, "iterations_since_restore": 12, "perf": {"cpu_util_percent": 4.093333333333334, "ram_util_percent": 30.00666666666667}}
{"episode_reward_max": 4.0, "episode_reward_min": 0.0, "episode_reward_mean": 1.05, "episode_len_mean": 500.0, "episode_media": {}, "episodes_this_iter": 24, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 2.0, 0.0, 2.0, 1.0, 2.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 2.0, 1.0, 0.0, 3.0, 3.0, 0.0, 0.0, 1.0, 1.0, 2.0, 1.0, 2.0, 2.0, 0.0, 1.0, 1.0, 1.0, 1.0, 3.0, 1.0, 1.0, 2.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 3.0, 1.0, 2.0, 1.0, 2.0, 0.0, 1.0, 0.0, 0.0, 3.0, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 3.0, 1.0, 1.0, 2.0, 1.0, 0.0, 2.0, 1.0, 2.0, 1.0, 1.0, 0.0, 1.0, 1.0, 2.0, 0.0, 1.0, 0.0, 2.0, 2.0, 4.0, 1.0, 2.0, 4.0, 0.0, 1.0, 2.0, 0.0, 0.0, 2.0, 2.0], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.15235725313891474, "mean_inference_ms": 0.3849865278667122, "mean_action_processing_ms": 0.027955162387956395, "mean_env_wait_ms": 0.3978549386378248, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 496640, "timesteps_this_iter": 0, "agent_timesteps_total": 496640, "timers": {"sample_time_ms": 1311.895, "sample_throughput": 3902.751, "load_time_ms": 0.11, "load_throughput": 46755576.921, "learn_time_ms": 49.591, "learn_throughput": 103243.612, "update_time_ms": 2.683}, "info": {"learner": {"default_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 34.408390045166016, "policy_entropy": 8017.3525390625, "policy_loss": -1.564980149269104, "vf_loss": 19.288551330566406}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 496640, "num_agent_steps_sampled": 496640, "num_steps_trained": 496640, "num_agent_steps_trained": 496640, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 248, "training_iteration": 13, "trial_id": "06a2c_00000", "experiment_id": "da1bb264888d4dd88dc9d72bb32edab2", "date": "2024-06-12_13-50-44", "timestamp": 1718167844, "time_this_iter_s": 10.448732376098633, "time_total_s": 128.4415521621704, "pid": 88332, "hostname": "DESKTOP-LQ219J4", "node_ip": "192.168.46.185", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 20, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 5000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 500, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "rware", "env_args": {"n_agents": 4, "column_height": 1, "max_inactivity_steps": null, "max_steps": 500, "fast_obs": true, "msg_bits": 0, "sensor_range": 1, "shelf_rows": 1, "shelf_columns": 3, "request_queue_size": 4, "reward_type": "RewardType.INDIVIDUAL", "map_name": "customized_map", "map_size": "tiny", "difficulty": "medium"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": true, "force_coop": false, "local_mode": true, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 4, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 100, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64}, "algorithm": "coma", "space_obs": "Dict(obs:Box([-100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100.], [100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.], (112,), float32))", "space_act": "Discrete(5)", "num_agents": 4, "episode_limit": 500, "policy_mapping_info": {"all_scenario": {"description": "rware all scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2", "agent_3"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "rware_customized_map", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 10, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.policy_template.COMATorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x7ff2a4e701f0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "grad_clip": 40.0, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "microbatch_size": null}, "time_since_restore": 128.4415521621704, "timesteps_since_restore": 0, "iterations_since_restore": 13, "perf": {"cpu_util_percent": 4.093333333333333, "ram_util_percent": 30.673333333333332}}
{"episode_reward_max": 4.0, "episode_reward_min": 0.0, "episode_reward_mean": 1.07, "episode_len_mean": 500.0, "episode_media": {}, "episodes_this_iter": 20, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [3.0, 0.0, 0.0, 1.0, 1.0, 2.0, 1.0, 2.0, 2.0, 0.0, 1.0, 1.0, 1.0, 1.0, 3.0, 1.0, 1.0, 2.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 3.0, 1.0, 2.0, 1.0, 2.0, 0.0, 1.0, 0.0, 0.0, 3.0, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 3.0, 1.0, 1.0, 2.0, 1.0, 0.0, 2.0, 1.0, 2.0, 1.0, 1.0, 0.0, 1.0, 1.0, 2.0, 0.0, 1.0, 0.0, 2.0, 2.0, 4.0, 1.0, 2.0, 4.0, 0.0, 1.0, 2.0, 0.0, 0.0, 2.0, 2.0, 2.0, 0.0, 1.0, 2.0, 2.0, 2.0, 2.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 2.0, 0.0, 2.0, 0.0], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.15235259385665612, "mean_inference_ms": 0.3847466229298344, "mean_action_processing_ms": 0.027928457141035937, "mean_env_wait_ms": 0.3976295763778211, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 537600, "timesteps_this_iter": 0, "agent_timesteps_total": 537600, "timers": {"sample_time_ms": 1304.965, "sample_throughput": 3923.477, "load_time_ms": 0.108, "load_throughput": 47626605.633, "learn_time_ms": 49.74, "learn_throughput": 102934.859, "update_time_ms": 2.718}, "info": {"learner": {"default_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 46.347190856933594, "policy_entropy": 8015.44921875, "policy_loss": -0.63921719789505, "vf_loss": 3.9766886234283447}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 537600, "num_agent_steps_sampled": 537600, "num_steps_trained": 537600, "num_agent_steps_trained": 537600, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 268, "training_iteration": 14, "trial_id": "06a2c_00000", "experiment_id": "da1bb264888d4dd88dc9d72bb32edab2", "date": "2024-06-12_13-50-54", "timestamp": 1718167854, "time_this_iter_s": 10.387709379196167, "time_total_s": 138.82926154136658, "pid": 88332, "hostname": "DESKTOP-LQ219J4", "node_ip": "192.168.46.185", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 20, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 5000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 500, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "rware", "env_args": {"n_agents": 4, "column_height": 1, "max_inactivity_steps": null, "max_steps": 500, "fast_obs": true, "msg_bits": 0, "sensor_range": 1, "shelf_rows": 1, "shelf_columns": 3, "request_queue_size": 4, "reward_type": "RewardType.INDIVIDUAL", "map_name": "customized_map", "map_size": "tiny", "difficulty": "medium"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": true, "force_coop": false, "local_mode": true, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 4, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 100, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64}, "algorithm": "coma", "space_obs": "Dict(obs:Box([-100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100.], [100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.], (112,), float32))", "space_act": "Discrete(5)", "num_agents": 4, "episode_limit": 500, "policy_mapping_info": {"all_scenario": {"description": "rware all scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2", "agent_3"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "rware_customized_map", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 10, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.policy_template.COMATorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x7ff3b8161550>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "grad_clip": 40.0, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "microbatch_size": null}, "time_since_restore": 138.82926154136658, "timesteps_since_restore": 0, "iterations_since_restore": 14, "perf": {"cpu_util_percent": 4.06, "ram_util_percent": 31.35333333333334}}
{"episode_reward_max": 4.0, "episode_reward_min": 0.0, "episode_reward_mean": 1.14, "episode_len_mean": 500.0, "episode_media": {}, "episodes_this_iter": 20, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 3.0, 1.0, 2.0, 1.0, 2.0, 0.0, 1.0, 0.0, 0.0, 3.0, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 3.0, 1.0, 1.0, 2.0, 1.0, 0.0, 2.0, 1.0, 2.0, 1.0, 1.0, 0.0, 1.0, 1.0, 2.0, 0.0, 1.0, 0.0, 2.0, 2.0, 4.0, 1.0, 2.0, 4.0, 0.0, 1.0, 2.0, 0.0, 0.0, 2.0, 2.0, 2.0, 0.0, 1.0, 2.0, 2.0, 2.0, 2.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 2.0, 0.0, 2.0, 0.0, 1.0, 1.0, 1.0, 2.0, 3.0, 1.0, 0.0, 3.0, 1.0, 0.0, 3.0, 2.0, 2.0, 0.0, 3.0, 1.0, 1.0, 3.0, 1.0, 1.0], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.15236409877047508, "mean_inference_ms": 0.38456646022598834, "mean_action_processing_ms": 0.027905615263274938, "mean_env_wait_ms": 0.39742066064408804, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 578560, "timesteps_this_iter": 0, "agent_timesteps_total": 578560, "timers": {"sample_time_ms": 1327.425, "sample_throughput": 3857.093, "load_time_ms": 0.115, "load_throughput": 44415380.517, "learn_time_ms": 50.59, "learn_throughput": 101204.789, "update_time_ms": 2.769}, "info": {"learner": {"default_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 34.127193450927734, "policy_entropy": 8025.8935546875, "policy_loss": -1.5522822141647339, "vf_loss": 25.154218673706055}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 578560, "num_agent_steps_sampled": 578560, "num_steps_trained": 578560, "num_agent_steps_trained": 578560, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 288, "training_iteration": 15, "trial_id": "06a2c_00000", "experiment_id": "da1bb264888d4dd88dc9d72bb32edab2", "date": "2024-06-12_13-51-05", "timestamp": 1718167865, "time_this_iter_s": 10.665892601013184, "time_total_s": 149.49515414237976, "pid": 88332, "hostname": "DESKTOP-LQ219J4", "node_ip": "192.168.46.185", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 20, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 5000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 500, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "rware", "env_args": {"n_agents": 4, "column_height": 1, "max_inactivity_steps": null, "max_steps": 500, "fast_obs": true, "msg_bits": 0, "sensor_range": 1, "shelf_rows": 1, "shelf_columns": 3, "request_queue_size": 4, "reward_type": "RewardType.INDIVIDUAL", "map_name": "customized_map", "map_size": "tiny", "difficulty": "medium"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": true, "force_coop": false, "local_mode": true, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 4, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 100, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64}, "algorithm": "coma", "space_obs": "Dict(obs:Box([-100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100.], [100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.], (112,), float32))", "space_act": "Discrete(5)", "num_agents": 4, "episode_limit": 500, "policy_mapping_info": {"all_scenario": {"description": "rware all scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2", "agent_3"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "rware_customized_map", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 10, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.policy_template.COMATorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x7ff3b812e0d0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "grad_clip": 40.0, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "microbatch_size": null}, "time_since_restore": 149.49515414237976, "timesteps_since_restore": 0, "iterations_since_restore": 15, "perf": {"cpu_util_percent": 4.066666666666666, "ram_util_percent": 32.02}}
{"episode_reward_max": 4.0, "episode_reward_min": 0.0, "episode_reward_mean": 1.18, "episode_len_mean": 500.0, "episode_media": {}, "episodes_this_iter": 20, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 3.0, 1.0, 1.0, 2.0, 1.0, 0.0, 2.0, 1.0, 2.0, 1.0, 1.0, 0.0, 1.0, 1.0, 2.0, 0.0, 1.0, 0.0, 2.0, 2.0, 4.0, 1.0, 2.0, 4.0, 0.0, 1.0, 2.0, 0.0, 0.0, 2.0, 2.0, 2.0, 0.0, 1.0, 2.0, 2.0, 2.0, 2.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 2.0, 0.0, 2.0, 0.0, 1.0, 1.0, 1.0, 2.0, 3.0, 1.0, 0.0, 3.0, 1.0, 0.0, 3.0, 2.0, 2.0, 0.0, 3.0, 1.0, 1.0, 3.0, 1.0, 1.0, 1.0, 2.0, 1.0, 1.0, 2.0, 1.0, 2.0, 1.0, 2.0, 3.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 1.0], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.15237400736004073, "mean_inference_ms": 0.38440942534738354, "mean_action_processing_ms": 0.027887655389357842, "mean_env_wait_ms": 0.39723166075650723, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 619520, "timesteps_this_iter": 0, "agent_timesteps_total": 619520, "timers": {"sample_time_ms": 1350.257, "sample_throughput": 3791.871, "load_time_ms": 0.123, "load_throughput": 41593717.761, "learn_time_ms": 49.948, "learn_throughput": 102506.214, "update_time_ms": 2.858}, "info": {"learner": {"default_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 31.47789764404297, "policy_entropy": 8012.482421875, "policy_loss": 0.094410240650177, "vf_loss": 19.52811050415039}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 619520, "num_agent_steps_sampled": 619520, "num_steps_trained": 619520, "num_agent_steps_trained": 619520, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 308, "training_iteration": 16, "trial_id": "06a2c_00000", "experiment_id": "da1bb264888d4dd88dc9d72bb32edab2", "date": "2024-06-12_13-51-15", "timestamp": 1718167875, "time_this_iter_s": 10.722207307815552, "time_total_s": 160.2173614501953, "pid": 88332, "hostname": "DESKTOP-LQ219J4", "node_ip": "192.168.46.185", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 20, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 5000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 500, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "rware", "env_args": {"n_agents": 4, "column_height": 1, "max_inactivity_steps": null, "max_steps": 500, "fast_obs": true, "msg_bits": 0, "sensor_range": 1, "shelf_rows": 1, "shelf_columns": 3, "request_queue_size": 4, "reward_type": "RewardType.INDIVIDUAL", "map_name": "customized_map", "map_size": "tiny", "difficulty": "medium"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": true, "force_coop": false, "local_mode": true, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 4, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 100, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64}, "algorithm": "coma", "space_obs": "Dict(obs:Box([-100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100.], [100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.], (112,), float32))", "space_act": "Discrete(5)", "num_agents": 4, "episode_limit": 500, "policy_mapping_info": {"all_scenario": {"description": "rware all scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2", "agent_3"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "rware_customized_map", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 10, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.policy_template.COMATorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x7ff3b81beee0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "grad_clip": 40.0, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "microbatch_size": null}, "time_since_restore": 160.2173614501953, "timesteps_since_restore": 0, "iterations_since_restore": 16, "perf": {"cpu_util_percent": 4.066666666666667, "ram_util_percent": 32.633333333333326}}
{"episode_reward_max": 4.0, "episode_reward_min": 0.0, "episode_reward_mean": 1.25, "episode_len_mean": 500.0, "episode_media": {}, "episodes_this_iter": 20, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 1.0, 1.0, 2.0, 0.0, 1.0, 0.0, 2.0, 2.0, 4.0, 1.0, 2.0, 4.0, 0.0, 1.0, 2.0, 0.0, 0.0, 2.0, 2.0, 2.0, 0.0, 1.0, 2.0, 2.0, 2.0, 2.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 2.0, 0.0, 2.0, 0.0, 1.0, 1.0, 1.0, 2.0, 3.0, 1.0, 0.0, 3.0, 1.0, 0.0, 3.0, 2.0, 2.0, 0.0, 3.0, 1.0, 1.0, 3.0, 1.0, 1.0, 1.0, 2.0, 1.0, 1.0, 2.0, 1.0, 2.0, 1.0, 2.0, 3.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 1.0, 1.0, 3.0, 0.0, 0.0, 2.0, 2.0, 0.0, 2.0, 0.0, 0.0, 0.0, 1.0, 0.0, 3.0, 1.0, 3.0, 1.0, 2.0, 2.0, 3.0], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.15236752474393037, "mean_inference_ms": 0.3842319954218698, "mean_action_processing_ms": 0.027869255230846584, "mean_env_wait_ms": 0.39704068847847607, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 660480, "timesteps_this_iter": 0, "agent_timesteps_total": 660480, "timers": {"sample_time_ms": 1303.398, "sample_throughput": 3928.194, "load_time_ms": 0.117, "load_throughput": 43790449.592, "learn_time_ms": 49.579, "learn_throughput": 103270.124, "update_time_ms": 2.692}, "info": {"learner": {"default_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 39.41424560546875, "policy_entropy": 8015.01513671875, "policy_loss": -1.9611570835113525, "vf_loss": 26.61045265197754}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 660480, "num_agent_steps_sampled": 660480, "num_steps_trained": 660480, "num_agent_steps_trained": 660480, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 328, "training_iteration": 17, "trial_id": "06a2c_00000", "experiment_id": "da1bb264888d4dd88dc9d72bb32edab2", "date": "2024-06-12_13-51-26", "timestamp": 1718167886, "time_this_iter_s": 10.446396350860596, "time_total_s": 170.6637578010559, "pid": 88332, "hostname": "DESKTOP-LQ219J4", "node_ip": "192.168.46.185", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 20, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 5000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 500, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "rware", "env_args": {"n_agents": 4, "column_height": 1, "max_inactivity_steps": null, "max_steps": 500, "fast_obs": true, "msg_bits": 0, "sensor_range": 1, "shelf_rows": 1, "shelf_columns": 3, "request_queue_size": 4, "reward_type": "RewardType.INDIVIDUAL", "map_name": "customized_map", "map_size": "tiny", "difficulty": "medium"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": true, "force_coop": false, "local_mode": true, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 4, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 100, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64}, "algorithm": "coma", "space_obs": "Dict(obs:Box([-100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100.], [100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.], (112,), float32))", "space_act": "Discrete(5)", "num_agents": 4, "episode_limit": 500, "policy_mapping_info": {"all_scenario": {"description": "rware all scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2", "agent_3"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "rware_customized_map", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 10, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.policy_template.COMATorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x7ff2a4e70280>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "grad_clip": 40.0, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "microbatch_size": null}, "time_since_restore": 170.6637578010559, "timesteps_since_restore": 0, "iterations_since_restore": 17, "perf": {"cpu_util_percent": 4.1066666666666665, "ram_util_percent": 33.28666666666667}}
{"episode_reward_max": 3.0, "episode_reward_min": 0.0, "episode_reward_mean": 1.3, "episode_len_mean": 500.0, "episode_media": {}, "episodes_this_iter": 20, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [2.0, 0.0, 1.0, 2.0, 2.0, 2.0, 2.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 2.0, 0.0, 2.0, 0.0, 1.0, 1.0, 1.0, 2.0, 3.0, 1.0, 0.0, 3.0, 1.0, 0.0, 3.0, 2.0, 2.0, 0.0, 3.0, 1.0, 1.0, 3.0, 1.0, 1.0, 1.0, 2.0, 1.0, 1.0, 2.0, 1.0, 2.0, 1.0, 2.0, 3.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 1.0, 1.0, 3.0, 0.0, 0.0, 2.0, 2.0, 0.0, 2.0, 0.0, 0.0, 0.0, 1.0, 0.0, 3.0, 1.0, 3.0, 1.0, 2.0, 2.0, 3.0, 3.0, 1.0, 1.0, 3.0, 3.0, 3.0, 3.0, 1.0, 2.0, 2.0, 2.0, 0.0, 0.0, 1.0, 0.0, 2.0, 1.0, 0.0, 1.0, 3.0], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.15238992640618754, "mean_inference_ms": 0.3841625716217196, "mean_action_processing_ms": 0.02785539188067188, "mean_env_wait_ms": 0.3966428531484503, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 701440, "timesteps_this_iter": 0, "agent_timesteps_total": 701440, "timers": {"sample_time_ms": 1312.868, "sample_throughput": 3899.86, "load_time_ms": 0.121, "load_throughput": 42165396.584, "learn_time_ms": 49.809, "learn_throughput": 102792.219, "update_time_ms": 2.804}, "info": {"learner": {"default_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 33.79868698120117, "policy_entropy": 7967.78515625, "policy_loss": 0.5416038036346436, "vf_loss": 14.436887741088867}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 701440, "num_agent_steps_sampled": 701440, "num_steps_trained": 701440, "num_agent_steps_trained": 701440, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 348, "training_iteration": 18, "trial_id": "06a2c_00000", "experiment_id": "da1bb264888d4dd88dc9d72bb32edab2", "date": "2024-06-12_13-51-36", "timestamp": 1718167896, "time_this_iter_s": 10.507089138031006, "time_total_s": 181.1708469390869, "pid": 88332, "hostname": "DESKTOP-LQ219J4", "node_ip": "192.168.46.185", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 20, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 5000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 500, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "rware", "env_args": {"n_agents": 4, "column_height": 1, "max_inactivity_steps": null, "max_steps": 500, "fast_obs": true, "msg_bits": 0, "sensor_range": 1, "shelf_rows": 1, "shelf_columns": 3, "request_queue_size": 4, "reward_type": "RewardType.INDIVIDUAL", "map_name": "customized_map", "map_size": "tiny", "difficulty": "medium"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": true, "force_coop": false, "local_mode": true, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 4, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 100, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64}, "algorithm": "coma", "space_obs": "Dict(obs:Box([-100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100.], [100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.], (112,), float32))", "space_act": "Discrete(5)", "num_agents": 4, "episode_limit": 500, "policy_mapping_info": {"all_scenario": {"description": "rware all scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2", "agent_3"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "rware_customized_map", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 10, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.policy_template.COMATorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x7ff3b812e0d0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "grad_clip": 40.0, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "microbatch_size": null}, "time_since_restore": 181.1708469390869, "timesteps_since_restore": 0, "iterations_since_restore": 18, "perf": {"cpu_util_percent": 4.113333333333333, "ram_util_percent": 33.95333333333333}}
{"episode_reward_max": 4.0, "episode_reward_min": 0.0, "episode_reward_mean": 1.37, "episode_len_mean": 500.0, "episode_media": {}, "episodes_this_iter": 20, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [1.0, 1.0, 1.0, 2.0, 3.0, 1.0, 0.0, 3.0, 1.0, 0.0, 3.0, 2.0, 2.0, 0.0, 3.0, 1.0, 1.0, 3.0, 1.0, 1.0, 1.0, 2.0, 1.0, 1.0, 2.0, 1.0, 2.0, 1.0, 2.0, 3.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 1.0, 1.0, 3.0, 0.0, 0.0, 2.0, 2.0, 0.0, 2.0, 0.0, 0.0, 0.0, 1.0, 0.0, 3.0, 1.0, 3.0, 1.0, 2.0, 2.0, 3.0, 3.0, 1.0, 1.0, 3.0, 3.0, 3.0, 3.0, 1.0, 2.0, 2.0, 2.0, 0.0, 0.0, 1.0, 0.0, 2.0, 1.0, 0.0, 1.0, 3.0, 0.0, 1.0, 2.0, 2.0, 1.0, 0.0, 3.0, 0.0, 1.0, 1.0, 1.0, 4.0, 0.0, 3.0, 1.0, 2.0, 1.0, 2.0, 0.0, 2.0], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.1524422819550887, "mean_inference_ms": 0.3841235410102907, "mean_action_processing_ms": 0.027849258885723267, "mean_env_wait_ms": 0.3966680303986279, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 742400, "timesteps_this_iter": 0, "agent_timesteps_total": 742400, "timers": {"sample_time_ms": 1320.515, "sample_throughput": 3877.276, "load_time_ms": 0.121, "load_throughput": 42390123.332, "learn_time_ms": 49.616, "learn_throughput": 103192.859, "update_time_ms": 2.785}, "info": {"learner": {"default_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 47.82830047607422, "policy_entropy": 8006.86474609375, "policy_loss": -2.988517999649048, "vf_loss": 22.928747177124023}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 742400, "num_agent_steps_sampled": 742400, "num_steps_trained": 742400, "num_agent_steps_trained": 742400, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 368, "training_iteration": 19, "trial_id": "06a2c_00000", "experiment_id": "da1bb264888d4dd88dc9d72bb32edab2", "date": "2024-06-12_13-51-47", "timestamp": 1718167907, "time_this_iter_s": 10.59673023223877, "time_total_s": 191.76757717132568, "pid": 88332, "hostname": "DESKTOP-LQ219J4", "node_ip": "192.168.46.185", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 20, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 5000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 500, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "rware", "env_args": {"n_agents": 4, "column_height": 1, "max_inactivity_steps": null, "max_steps": 500, "fast_obs": true, "msg_bits": 0, "sensor_range": 1, "shelf_rows": 1, "shelf_columns": 3, "request_queue_size": 4, "reward_type": "RewardType.INDIVIDUAL", "map_name": "customized_map", "map_size": "tiny", "difficulty": "medium"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": true, "force_coop": false, "local_mode": true, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 4, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 100, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64}, "algorithm": "coma", "space_obs": "Dict(obs:Box([-100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100.], [100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.], (112,), float32))", "space_act": "Discrete(5)", "num_agents": 4, "episode_limit": 500, "policy_mapping_info": {"all_scenario": {"description": "rware all scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2", "agent_3"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "rware_customized_map", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 10, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.policy_template.COMATorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x7ff3b804ac10>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "grad_clip": 40.0, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "microbatch_size": null}, "time_since_restore": 191.76757717132568, "timesteps_since_restore": 0, "iterations_since_restore": 19, "perf": {"cpu_util_percent": 4.08, "ram_util_percent": 34.593333333333334}}
{"episode_reward_max": 4.0, "episode_reward_min": 0.0, "episode_reward_mean": 1.28, "episode_len_mean": 500.0, "episode_media": {}, "episodes_this_iter": 20, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [1.0, 2.0, 1.0, 1.0, 2.0, 1.0, 2.0, 1.0, 2.0, 3.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 1.0, 1.0, 3.0, 0.0, 0.0, 2.0, 2.0, 0.0, 2.0, 0.0, 0.0, 0.0, 1.0, 0.0, 3.0, 1.0, 3.0, 1.0, 2.0, 2.0, 3.0, 3.0, 1.0, 1.0, 3.0, 3.0, 3.0, 3.0, 1.0, 2.0, 2.0, 2.0, 0.0, 0.0, 1.0, 0.0, 2.0, 1.0, 0.0, 1.0, 3.0, 0.0, 1.0, 2.0, 2.0, 1.0, 0.0, 3.0, 0.0, 1.0, 1.0, 1.0, 4.0, 0.0, 3.0, 1.0, 2.0, 1.0, 2.0, 0.0, 2.0, 3.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 2.0, 1.0, 1.0, 1.0, 0.0, 1.0, 3.0, 2.0, 2.0, 0.0, 0.0], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.15250938699355088, "mean_inference_ms": 0.3841169846831173, "mean_action_processing_ms": 0.027846451042492382, "mean_env_wait_ms": 0.3967312173752184, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 783360, "timesteps_this_iter": 0, "agent_timesteps_total": 783360, "timers": {"sample_time_ms": 1345.442, "sample_throughput": 3805.44, "load_time_ms": 0.119, "load_throughput": 43200234.319, "learn_time_ms": 50.561, "learn_throughput": 101263.822, "update_time_ms": 2.775}, "info": {"learner": {"default_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 49.261985778808594, "policy_entropy": 8009.060546875, "policy_loss": 0.8794113993644714, "vf_loss": 17.989683151245117}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 783360, "num_agent_steps_sampled": 783360, "num_steps_trained": 783360, "num_agent_steps_trained": 783360, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 388, "training_iteration": 20, "trial_id": "06a2c_00000", "experiment_id": "da1bb264888d4dd88dc9d72bb32edab2", "date": "2024-06-12_13-51-58", "timestamp": 1718167918, "time_this_iter_s": 10.782993078231812, "time_total_s": 202.5505702495575, "pid": 88332, "hostname": "DESKTOP-LQ219J4", "node_ip": "192.168.46.185", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 20, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 5000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 500, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "rware", "env_args": {"n_agents": 4, "column_height": 1, "max_inactivity_steps": null, "max_steps": 500, "fast_obs": true, "msg_bits": 0, "sensor_range": 1, "shelf_rows": 1, "shelf_columns": 3, "request_queue_size": 4, "reward_type": "RewardType.INDIVIDUAL", "map_name": "customized_map", "map_size": "tiny", "difficulty": "medium"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": true, "force_coop": false, "local_mode": true, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 4, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 100, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64}, "algorithm": "coma", "space_obs": "Dict(obs:Box([-100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100.], [100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.], (112,), float32))", "space_act": "Discrete(5)", "num_agents": 4, "episode_limit": 500, "policy_mapping_info": {"all_scenario": {"description": "rware all scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2", "agent_3"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "rware_customized_map", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 10, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.policy_template.COMATorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x7ff2a4eca4c0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "grad_clip": 40.0, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "microbatch_size": null}, "time_since_restore": 202.5505702495575, "timesteps_since_restore": 0, "iterations_since_restore": 20, "perf": {"cpu_util_percent": 3.9437499999999996, "ram_util_percent": 35.26875}}
{"episode_reward_max": 4.0, "episode_reward_min": 0.0, "episode_reward_mean": 1.32, "episode_len_mean": 500.0, "episode_media": {}, "episodes_this_iter": 24, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [2.0, 2.0, 0.0, 2.0, 0.0, 0.0, 0.0, 1.0, 0.0, 3.0, 1.0, 3.0, 1.0, 2.0, 2.0, 3.0, 3.0, 1.0, 1.0, 3.0, 3.0, 3.0, 3.0, 1.0, 2.0, 2.0, 2.0, 0.0, 0.0, 1.0, 0.0, 2.0, 1.0, 0.0, 1.0, 3.0, 0.0, 1.0, 2.0, 2.0, 1.0, 0.0, 3.0, 0.0, 1.0, 1.0, 1.0, 4.0, 0.0, 3.0, 1.0, 2.0, 1.0, 2.0, 0.0, 2.0, 3.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 2.0, 1.0, 1.0, 1.0, 0.0, 1.0, 3.0, 2.0, 2.0, 0.0, 0.0, 2.0, 2.0, 0.0, 1.0, 3.0, 1.0, 1.0, 1.0, 3.0, 1.0, 4.0, 0.0, 2.0, 2.0, 1.0, 0.0, 1.0, 1.0, 2.0, 0.0, 0.0, 0.0, 1.0, 1.0], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.15259471312437287, "mean_inference_ms": 0.3840923547498429, "mean_action_processing_ms": 0.027844941177730575, "mean_env_wait_ms": 0.3970154355181971, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 824320, "timesteps_this_iter": 0, "agent_timesteps_total": 824320, "timers": {"sample_time_ms": 1349.785, "sample_throughput": 3793.196, "load_time_ms": 0.125, "load_throughput": 41068725.339, "learn_time_ms": 51.022, "learn_throughput": 100348.015, "update_time_ms": 2.786}, "info": {"learner": {"default_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 24.71550750732422, "policy_entropy": 8032.08837890625, "policy_loss": -0.973405659198761, "vf_loss": 10.734817504882812}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 824320, "num_agent_steps_sampled": 824320, "num_steps_trained": 824320, "num_agent_steps_trained": 824320, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 412, "training_iteration": 21, "trial_id": "06a2c_00000", "experiment_id": "da1bb264888d4dd88dc9d72bb32edab2", "date": "2024-06-12_13-52-09", "timestamp": 1718167929, "time_this_iter_s": 10.813371658325195, "time_total_s": 213.3639419078827, "pid": 88332, "hostname": "DESKTOP-LQ219J4", "node_ip": "192.168.46.185", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 20, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 5000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 500, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "rware", "env_args": {"n_agents": 4, "column_height": 1, "max_inactivity_steps": null, "max_steps": 500, "fast_obs": true, "msg_bits": 0, "sensor_range": 1, "shelf_rows": 1, "shelf_columns": 3, "request_queue_size": 4, "reward_type": "RewardType.INDIVIDUAL", "map_name": "customized_map", "map_size": "tiny", "difficulty": "medium"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": true, "force_coop": false, "local_mode": true, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 4, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 100, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64}, "algorithm": "coma", "space_obs": "Dict(obs:Box([-100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100.], [100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.], (112,), float32))", "space_act": "Discrete(5)", "num_agents": 4, "episode_limit": 500, "policy_mapping_info": {"all_scenario": {"description": "rware all scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2", "agent_3"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "rware_customized_map", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 10, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.policy_template.COMATorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x7ff3b804a940>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "grad_clip": 40.0, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "microbatch_size": null}, "time_since_restore": 213.3639419078827, "timesteps_since_restore": 0, "iterations_since_restore": 21, "perf": {"cpu_util_percent": 4.093333333333334, "ram_util_percent": 35.94666666666667}}
{"episode_reward_max": 4.0, "episode_reward_min": 0.0, "episode_reward_mean": 1.23, "episode_len_mean": 500.0, "episode_media": {}, "episodes_this_iter": 20, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [3.0, 3.0, 3.0, 1.0, 2.0, 2.0, 2.0, 0.0, 0.0, 1.0, 0.0, 2.0, 1.0, 0.0, 1.0, 3.0, 0.0, 1.0, 2.0, 2.0, 1.0, 0.0, 3.0, 0.0, 1.0, 1.0, 1.0, 4.0, 0.0, 3.0, 1.0, 2.0, 1.0, 2.0, 0.0, 2.0, 3.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 2.0, 1.0, 1.0, 1.0, 0.0, 1.0, 3.0, 2.0, 2.0, 0.0, 0.0, 2.0, 2.0, 0.0, 1.0, 3.0, 1.0, 1.0, 1.0, 3.0, 1.0, 4.0, 0.0, 2.0, 2.0, 1.0, 0.0, 1.0, 1.0, 2.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 2.0, 1.0, 2.0, 0.0, 1.0, 2.0, 1.0, 0.0, 0.0, 1.0, 0.0, 2.0, 3.0, 1.0, 2.0, 2.0], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.15271927638641858, "mean_inference_ms": 0.3842540786783505, "mean_action_processing_ms": 0.027854306447200324, "mean_env_wait_ms": 0.3971635215521745, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 865280, "timesteps_this_iter": 0, "agent_timesteps_total": 865280, "timers": {"sample_time_ms": 1342.935, "sample_throughput": 3812.544, "load_time_ms": 0.119, "load_throughput": 43113504.276, "learn_time_ms": 50.983, "learn_throughput": 100424.928, "update_time_ms": 2.878}, "info": {"learner": {"default_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 28.494226455688477, "policy_entropy": 8025.74853515625, "policy_loss": 0.4604033827781677, "vf_loss": 3.911663293838501}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 865280, "num_agent_steps_sampled": 865280, "num_steps_trained": 865280, "num_agent_steps_trained": 865280, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 432, "training_iteration": 22, "trial_id": "06a2c_00000", "experiment_id": "da1bb264888d4dd88dc9d72bb32edab2", "date": "2024-06-12_13-52-19", "timestamp": 1718167939, "time_this_iter_s": 10.732252836227417, "time_total_s": 224.0961947441101, "pid": 88332, "hostname": "DESKTOP-LQ219J4", "node_ip": "192.168.46.185", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 20, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 5000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 500, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "rware", "env_args": {"n_agents": 4, "column_height": 1, "max_inactivity_steps": null, "max_steps": 500, "fast_obs": true, "msg_bits": 0, "sensor_range": 1, "shelf_rows": 1, "shelf_columns": 3, "request_queue_size": 4, "reward_type": "RewardType.INDIVIDUAL", "map_name": "customized_map", "map_size": "tiny", "difficulty": "medium"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": true, "force_coop": false, "local_mode": true, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 4, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 100, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64}, "algorithm": "coma", "space_obs": "Dict(obs:Box([-100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100.], [100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.], (112,), float32))", "space_act": "Discrete(5)", "num_agents": 4, "episode_limit": 500, "policy_mapping_info": {"all_scenario": {"description": "rware all scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2", "agent_3"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "rware_customized_map", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 10, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.policy_template.COMATorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x7ff3b8299dc0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "grad_clip": 40.0, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "microbatch_size": null}, "time_since_restore": 224.0961947441101, "timesteps_since_restore": 0, "iterations_since_restore": 22, "perf": {"cpu_util_percent": 4.1, "ram_util_percent": 36.586666666666666}}
{"episode_reward_max": 4.0, "episode_reward_min": 0.0, "episode_reward_mean": 1.22, "episode_len_mean": 500.0, "episode_media": {}, "episodes_this_iter": 20, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [1.0, 0.0, 3.0, 0.0, 1.0, 1.0, 1.0, 4.0, 0.0, 3.0, 1.0, 2.0, 1.0, 2.0, 0.0, 2.0, 3.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 2.0, 1.0, 1.0, 1.0, 0.0, 1.0, 3.0, 2.0, 2.0, 0.0, 0.0, 2.0, 2.0, 0.0, 1.0, 3.0, 1.0, 1.0, 1.0, 3.0, 1.0, 4.0, 0.0, 2.0, 2.0, 1.0, 0.0, 1.0, 1.0, 2.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 2.0, 1.0, 2.0, 0.0, 1.0, 2.0, 1.0, 0.0, 0.0, 1.0, 0.0, 2.0, 3.0, 1.0, 2.0, 2.0, 2.0, 2.0, 0.0, 2.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 2.0, 2.0, 0.0, 2.0, 3.0, 1.0, 3.0], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.15286376251417466, "mean_inference_ms": 0.38450188789780343, "mean_action_processing_ms": 0.027868582309473738, "mean_env_wait_ms": 0.3973770561756426, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 906240, "timesteps_this_iter": 0, "agent_timesteps_total": 906240, "timers": {"sample_time_ms": 1348.37, "sample_throughput": 3797.176, "load_time_ms": 0.12, "load_throughput": 42676543.084, "learn_time_ms": 50.779, "learn_throughput": 100828.592, "update_time_ms": 2.752}, "info": {"learner": {"default_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 28.238487243652344, "policy_entropy": 8024.92529296875, "policy_loss": -1.332724690437317, "vf_loss": 2.8121821880340576}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 906240, "num_agent_steps_sampled": 906240, "num_steps_trained": 906240, "num_agent_steps_trained": 906240, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 452, "training_iteration": 23, "trial_id": "06a2c_00000", "experiment_id": "da1bb264888d4dd88dc9d72bb32edab2", "date": "2024-06-12_13-52-30", "timestamp": 1718167950, "time_this_iter_s": 10.746127605438232, "time_total_s": 234.84232234954834, "pid": 88332, "hostname": "DESKTOP-LQ219J4", "node_ip": "192.168.46.185", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 20, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 5000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 500, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "rware", "env_args": {"n_agents": 4, "column_height": 1, "max_inactivity_steps": null, "max_steps": 500, "fast_obs": true, "msg_bits": 0, "sensor_range": 1, "shelf_rows": 1, "shelf_columns": 3, "request_queue_size": 4, "reward_type": "RewardType.INDIVIDUAL", "map_name": "customized_map", "map_size": "tiny", "difficulty": "medium"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": true, "force_coop": false, "local_mode": true, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 4, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 100, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64}, "algorithm": "coma", "space_obs": "Dict(obs:Box([-100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100.], [100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.], (112,), float32))", "space_act": "Discrete(5)", "num_agents": 4, "episode_limit": 500, "policy_mapping_info": {"all_scenario": {"description": "rware all scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2", "agent_3"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "rware_customized_map", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 10, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.policy_template.COMATorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x7ff3b804ab80>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "grad_clip": 40.0, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "microbatch_size": null}, "time_since_restore": 234.84232234954834, "timesteps_since_restore": 0, "iterations_since_restore": 23, "perf": {"cpu_util_percent": 4.018750000000001, "ram_util_percent": 37.25}}
{"episode_reward_max": 5.0, "episode_reward_min": 0.0, "episode_reward_mean": 1.2, "episode_len_mean": 500.0, "episode_media": {}, "episodes_this_iter": 20, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 1.0, 1.0, 0.0, 2.0, 1.0, 1.0, 1.0, 0.0, 1.0, 3.0, 2.0, 2.0, 0.0, 0.0, 2.0, 2.0, 0.0, 1.0, 3.0, 1.0, 1.0, 1.0, 3.0, 1.0, 4.0, 0.0, 2.0, 2.0, 1.0, 0.0, 1.0, 1.0, 2.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 2.0, 1.0, 2.0, 0.0, 1.0, 2.0, 1.0, 0.0, 0.0, 1.0, 0.0, 2.0, 3.0, 1.0, 2.0, 2.0, 2.0, 2.0, 0.0, 2.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 2.0, 2.0, 0.0, 2.0, 3.0, 1.0, 3.0, 0.0, 1.0, 1.0, 0.0, 2.0, 0.0, 2.0, 0.0, 0.0, 1.0, 2.0, 1.0, 2.0, 2.0, 0.0, 1.0, 1.0, 4.0, 5.0, 1.0], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.15301246401988675, "mean_inference_ms": 0.3847823401961956, "mean_action_processing_ms": 0.02788433054663574, "mean_env_wait_ms": 0.3975821519083482, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 947200, "timesteps_this_iter": 0, "agent_timesteps_total": 947200, "timers": {"sample_time_ms": 1344.813, "sample_throughput": 3807.221, "load_time_ms": 0.12, "load_throughput": 42499181.635, "learn_time_ms": 50.982, "learn_throughput": 100426.76, "update_time_ms": 2.797}, "info": {"learner": {"default_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 23.13217544555664, "policy_entropy": 7991.20458984375, "policy_loss": -0.23275797069072723, "vf_loss": 11.612509727478027}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 947200, "num_agent_steps_sampled": 947200, "num_steps_trained": 947200, "num_agent_steps_trained": 947200, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 472, "training_iteration": 24, "trial_id": "06a2c_00000", "experiment_id": "da1bb264888d4dd88dc9d72bb32edab2", "date": "2024-06-12_13-52-41", "timestamp": 1718167961, "time_this_iter_s": 10.714366674423218, "time_total_s": 245.55668902397156, "pid": 88332, "hostname": "DESKTOP-LQ219J4", "node_ip": "192.168.46.185", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 20, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 5000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 500, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "rware", "env_args": {"n_agents": 4, "column_height": 1, "max_inactivity_steps": null, "max_steps": 500, "fast_obs": true, "msg_bits": 0, "sensor_range": 1, "shelf_rows": 1, "shelf_columns": 3, "request_queue_size": 4, "reward_type": "RewardType.INDIVIDUAL", "map_name": "customized_map", "map_size": "tiny", "difficulty": "medium"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": true, "force_coop": false, "local_mode": true, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 4, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 100, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64}, "algorithm": "coma", "space_obs": "Dict(obs:Box([-100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100.], [100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.], (112,), float32))", "space_act": "Discrete(5)", "num_agents": 4, "episode_limit": 500, "policy_mapping_info": {"all_scenario": {"description": "rware all scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2", "agent_3"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "rware_customized_map", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 10, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.policy_template.COMATorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x7ff3b8299ca0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "grad_clip": 40.0, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "microbatch_size": null}, "time_since_restore": 245.55668902397156, "timesteps_since_restore": 0, "iterations_since_restore": 24, "perf": {"cpu_util_percent": 4.1466666666666665, "ram_util_percent": 37.913333333333334}}
{"episode_reward_max": 5.0, "episode_reward_min": 0.0, "episode_reward_mean": 1.4, "episode_len_mean": 500.0, "episode_media": {}, "episodes_this_iter": 20, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [3.0, 1.0, 1.0, 1.0, 3.0, 1.0, 4.0, 0.0, 2.0, 2.0, 1.0, 0.0, 1.0, 1.0, 2.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 2.0, 1.0, 2.0, 0.0, 1.0, 2.0, 1.0, 0.0, 0.0, 1.0, 0.0, 2.0, 3.0, 1.0, 2.0, 2.0, 2.0, 2.0, 0.0, 2.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 2.0, 2.0, 0.0, 2.0, 3.0, 1.0, 3.0, 0.0, 1.0, 1.0, 0.0, 2.0, 0.0, 2.0, 0.0, 0.0, 1.0, 2.0, 1.0, 2.0, 2.0, 0.0, 1.0, 1.0, 4.0, 5.0, 1.0, 2.0, 5.0, 1.0, 3.0, 2.0, 5.0, 1.0, 3.0, 3.0, 2.0, 1.0, 5.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 2.0, 1.0], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.15314054720485992, "mean_inference_ms": 0.38502388401008764, "mean_action_processing_ms": 0.027897025225340967, "mean_env_wait_ms": 0.3977671775363632, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 988160, "timesteps_this_iter": 0, "agent_timesteps_total": 988160, "timers": {"sample_time_ms": 1347.405, "sample_throughput": 3799.897, "load_time_ms": 0.124, "load_throughput": 41242244.056, "learn_time_ms": 50.633, "learn_throughput": 101119.868, "update_time_ms": 2.787}, "info": {"learner": {"default_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 53.25885772705078, "policy_entropy": 7963.46533203125, "policy_loss": -0.25997695326805115, "vf_loss": 8.663715362548828}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 988160, "num_agent_steps_sampled": 988160, "num_steps_trained": 988160, "num_agent_steps_trained": 988160, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 492, "training_iteration": 25, "trial_id": "06a2c_00000", "experiment_id": "da1bb264888d4dd88dc9d72bb32edab2", "date": "2024-06-12_13-52-52", "timestamp": 1718167972, "time_this_iter_s": 10.779743671417236, "time_total_s": 256.3364326953888, "pid": 88332, "hostname": "DESKTOP-LQ219J4", "node_ip": "192.168.46.185", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 20, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 5000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 500, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "rware", "env_args": {"n_agents": 4, "column_height": 1, "max_inactivity_steps": null, "max_steps": 500, "fast_obs": true, "msg_bits": 0, "sensor_range": 1, "shelf_rows": 1, "shelf_columns": 3, "request_queue_size": 4, "reward_type": "RewardType.INDIVIDUAL", "map_name": "customized_map", "map_size": "tiny", "difficulty": "medium"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": true, "force_coop": false, "local_mode": true, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 4, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 100, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64}, "algorithm": "coma", "space_obs": "Dict(obs:Box([-100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100.], [100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.], (112,), float32))", "space_act": "Discrete(5)", "num_agents": 4, "episode_limit": 500, "policy_mapping_info": {"all_scenario": {"description": "rware all scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2", "agent_3"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "rware_customized_map", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 10, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.policy_template.COMATorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x7ff2a4e70b80>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "grad_clip": 40.0, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "microbatch_size": null}, "time_since_restore": 256.3364326953888, "timesteps_since_restore": 0, "iterations_since_restore": 25, "perf": {"cpu_util_percent": 3.9999999999999996, "ram_util_percent": 38.54}}
{"episode_reward_max": 5.0, "episode_reward_min": 0.0, "episode_reward_mean": 1.39, "episode_len_mean": 500.0, "episode_media": {}, "episodes_this_iter": 20, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 1.0, 0.0, 2.0, 1.0, 2.0, 0.0, 1.0, 2.0, 1.0, 0.0, 0.0, 1.0, 0.0, 2.0, 3.0, 1.0, 2.0, 2.0, 2.0, 2.0, 0.0, 2.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 2.0, 2.0, 0.0, 2.0, 3.0, 1.0, 3.0, 0.0, 1.0, 1.0, 0.0, 2.0, 0.0, 2.0, 0.0, 0.0, 1.0, 2.0, 1.0, 2.0, 2.0, 0.0, 1.0, 1.0, 4.0, 5.0, 1.0, 2.0, 5.0, 1.0, 3.0, 2.0, 5.0, 1.0, 3.0, 3.0, 2.0, 1.0, 5.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 2.0, 1.0, 0.0, 4.0, 1.0, 1.0, 2.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 2.0, 1.0, 1.0, 0.0, 3.0, 3.0, 0.0, 2.0, 0.0], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.15325693773012547, "mean_inference_ms": 0.38528695834995813, "mean_action_processing_ms": 0.027907663588392168, "mean_env_wait_ms": 0.39772287230238396, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 1029120, "timesteps_this_iter": 0, "agent_timesteps_total": 1029120, "timers": {"sample_time_ms": 1341.319, "sample_throughput": 3817.138, "load_time_ms": 0.135, "load_throughput": 37867812.52, "learn_time_ms": 51.217, "learn_throughput": 99966.235, "update_time_ms": 2.882}, "info": {"learner": {"default_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 26.903182983398438, "policy_entropy": 8001.8349609375, "policy_loss": 0.38762974739074707, "vf_loss": 5.580808639526367}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 1029120, "num_agent_steps_sampled": 1029120, "num_steps_trained": 1029120, "num_agent_steps_trained": 1029120, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 512, "training_iteration": 26, "trial_id": "06a2c_00000", "experiment_id": "da1bb264888d4dd88dc9d72bb32edab2", "date": "2024-06-12_13-53-02", "timestamp": 1718167982, "time_this_iter_s": 10.731614828109741, "time_total_s": 267.06804752349854, "pid": 88332, "hostname": "DESKTOP-LQ219J4", "node_ip": "192.168.46.185", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 20, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 5000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 500, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "rware", "env_args": {"n_agents": 4, "column_height": 1, "max_inactivity_steps": null, "max_steps": 500, "fast_obs": true, "msg_bits": 0, "sensor_range": 1, "shelf_rows": 1, "shelf_columns": 3, "request_queue_size": 4, "reward_type": "RewardType.INDIVIDUAL", "map_name": "customized_map", "map_size": "tiny", "difficulty": "medium"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": true, "force_coop": false, "local_mode": true, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 4, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 100, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64}, "algorithm": "coma", "space_obs": "Dict(obs:Box([-100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100.], [100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.], (112,), float32))", "space_act": "Discrete(5)", "num_agents": 4, "episode_limit": 500, "policy_mapping_info": {"all_scenario": {"description": "rware all scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2", "agent_3"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "rware_customized_map", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 10, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.policy_template.COMATorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x7ff3b812e0d0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "grad_clip": 40.0, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "microbatch_size": null}, "time_since_restore": 267.06804752349854, "timesteps_since_restore": 0, "iterations_since_restore": 26, "perf": {"cpu_util_percent": 4.04375, "ram_util_percent": 39.199999999999996}}
{"episode_reward_max": 5.0, "episode_reward_min": 0.0, "episode_reward_mean": 1.47, "episode_len_mean": 500.0, "episode_media": {}, "episodes_this_iter": 20, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [2.0, 2.0, 0.0, 2.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 2.0, 2.0, 0.0, 2.0, 3.0, 1.0, 3.0, 0.0, 1.0, 1.0, 0.0, 2.0, 0.0, 2.0, 0.0, 0.0, 1.0, 2.0, 1.0, 2.0, 2.0, 0.0, 1.0, 1.0, 4.0, 5.0, 1.0, 2.0, 5.0, 1.0, 3.0, 2.0, 5.0, 1.0, 3.0, 3.0, 2.0, 1.0, 5.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 2.0, 1.0, 0.0, 4.0, 1.0, 1.0, 2.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 2.0, 1.0, 1.0, 0.0, 3.0, 3.0, 0.0, 2.0, 0.0, 2.0, 3.0, 1.0, 0.0, 4.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 3.0, 2.0, 1.0, 2.0, 2.0, 1.0, 2.0, 0.0, 2.0], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.1533664508759121, "mean_inference_ms": 0.3854974388096317, "mean_action_processing_ms": 0.027915906529392402, "mean_env_wait_ms": 0.3979336804091142, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 1070080, "timesteps_this_iter": 0, "agent_timesteps_total": 1070080, "timers": {"sample_time_ms": 1355.514, "sample_throughput": 3777.164, "load_time_ms": 0.129, "load_throughput": 39738779.571, "learn_time_ms": 51.003, "learn_throughput": 100385.354, "update_time_ms": 2.857}, "info": {"learner": {"default_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 48.99082565307617, "policy_entropy": 8029.8076171875, "policy_loss": -1.7628412246704102, "vf_loss": 20.777807235717773}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 1070080, "num_agent_steps_sampled": 1070080, "num_steps_trained": 1070080, "num_agent_steps_trained": 1070080, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 532, "training_iteration": 27, "trial_id": "06a2c_00000", "experiment_id": "da1bb264888d4dd88dc9d72bb32edab2", "date": "2024-06-12_13-53-13", "timestamp": 1718167993, "time_this_iter_s": 10.87214469909668, "time_total_s": 277.9401922225952, "pid": 88332, "hostname": "DESKTOP-LQ219J4", "node_ip": "192.168.46.185", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 20, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 5000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 500, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "rware", "env_args": {"n_agents": 4, "column_height": 1, "max_inactivity_steps": null, "max_steps": 500, "fast_obs": true, "msg_bits": 0, "sensor_range": 1, "shelf_rows": 1, "shelf_columns": 3, "request_queue_size": 4, "reward_type": "RewardType.INDIVIDUAL", "map_name": "customized_map", "map_size": "tiny", "difficulty": "medium"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": true, "force_coop": false, "local_mode": true, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 4, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 100, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64}, "algorithm": "coma", "space_obs": "Dict(obs:Box([-100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100.], [100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.], (112,), float32))", "space_act": "Discrete(5)", "num_agents": 4, "episode_limit": 500, "policy_mapping_info": {"all_scenario": {"description": "rware all scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2", "agent_3"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "rware_customized_map", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 10, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.policy_template.COMATorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x7ff2a4e70310>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "grad_clip": 40.0, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "microbatch_size": null}, "time_since_restore": 277.9401922225952, "timesteps_since_restore": 0, "iterations_since_restore": 27, "perf": {"cpu_util_percent": 4.1066666666666665, "ram_util_percent": 39.88}}
{"episode_reward_max": 5.0, "episode_reward_min": 0.0, "episode_reward_mean": 1.53, "episode_len_mean": 500.0, "episode_media": {}, "episodes_this_iter": 20, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 1.0, 1.0, 0.0, 2.0, 0.0, 2.0, 0.0, 0.0, 1.0, 2.0, 1.0, 2.0, 2.0, 0.0, 1.0, 1.0, 4.0, 5.0, 1.0, 2.0, 5.0, 1.0, 3.0, 2.0, 5.0, 1.0, 3.0, 3.0, 2.0, 1.0, 5.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 2.0, 1.0, 0.0, 4.0, 1.0, 1.0, 2.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 2.0, 1.0, 1.0, 0.0, 3.0, 3.0, 0.0, 2.0, 0.0, 2.0, 3.0, 1.0, 0.0, 4.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 3.0, 2.0, 1.0, 2.0, 2.0, 1.0, 2.0, 0.0, 2.0, 2.0, 2.0, 2.0, 2.0, 3.0, 0.0, 1.0, 1.0, 0.0, 5.0, 0.0, 1.0, 1.0, 4.0, 3.0, 3.0, 1.0, 1.0, 2.0, 0.0], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.15347960345531272, "mean_inference_ms": 0.38571628722359125, "mean_action_processing_ms": 0.02792548795462835, "mean_env_wait_ms": 0.3981507623847436, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 1111040, "timesteps_this_iter": 0, "agent_timesteps_total": 1111040, "timers": {"sample_time_ms": 1360.375, "sample_throughput": 3763.669, "load_time_ms": 0.13, "load_throughput": 39273658.522, "learn_time_ms": 50.758, "learn_throughput": 100871.691, "update_time_ms": 2.821}, "info": {"learner": {"default_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 35.00840759277344, "policy_entropy": 8012.0654296875, "policy_loss": -0.500447690486908, "vf_loss": 7.939033508300781}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 1111040, "num_agent_steps_sampled": 1111040, "num_steps_trained": 1111040, "num_agent_steps_trained": 1111040, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 552, "training_iteration": 28, "trial_id": "06a2c_00000", "experiment_id": "da1bb264888d4dd88dc9d72bb32edab2", "date": "2024-06-12_13-53-24", "timestamp": 1718168004, "time_this_iter_s": 10.85049819946289, "time_total_s": 288.7906904220581, "pid": 88332, "hostname": "DESKTOP-LQ219J4", "node_ip": "192.168.46.185", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 20, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 5000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 500, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "rware", "env_args": {"n_agents": 4, "column_height": 1, "max_inactivity_steps": null, "max_steps": 500, "fast_obs": true, "msg_bits": 0, "sensor_range": 1, "shelf_rows": 1, "shelf_columns": 3, "request_queue_size": 4, "reward_type": "RewardType.INDIVIDUAL", "map_name": "customized_map", "map_size": "tiny", "difficulty": "medium"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": true, "force_coop": false, "local_mode": true, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 4, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 100, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64}, "algorithm": "coma", "space_obs": "Dict(obs:Box([-100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100.], [100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.], (112,), float32))", "space_act": "Discrete(5)", "num_agents": 4, "episode_limit": 500, "policy_mapping_info": {"all_scenario": {"description": "rware all scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2", "agent_3"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "rware_customized_map", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 10, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.policy_template.COMATorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x7ff3b82999d0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "grad_clip": 40.0, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "microbatch_size": null}, "time_since_restore": 288.7906904220581, "timesteps_since_restore": 0, "iterations_since_restore": 28, "perf": {"cpu_util_percent": 4.00625, "ram_util_percent": 40.5125}}
{"episode_reward_max": 5.0, "episode_reward_min": 0.0, "episode_reward_mean": 1.56, "episode_len_mean": 500.0, "episode_media": {}, "episodes_this_iter": 24, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [2.0, 5.0, 1.0, 3.0, 3.0, 2.0, 1.0, 5.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 2.0, 1.0, 0.0, 4.0, 1.0, 1.0, 2.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 2.0, 1.0, 1.0, 0.0, 3.0, 3.0, 0.0, 2.0, 0.0, 2.0, 3.0, 1.0, 0.0, 4.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 3.0, 2.0, 1.0, 2.0, 2.0, 1.0, 2.0, 0.0, 2.0, 2.0, 2.0, 2.0, 2.0, 3.0, 0.0, 1.0, 1.0, 0.0, 5.0, 0.0, 1.0, 1.0, 4.0, 3.0, 3.0, 1.0, 1.0, 2.0, 0.0, 1.0, 4.0, 1.0, 2.0, 4.0, 4.0, 1.0, 1.0, 2.0, 1.0, 1.0, 2.0, 2.0, 0.0, 3.0, 2.0, 1.0, 0.0, 0.0, 1.0, 2.0, 2.0, 1.0, 2.0], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.15359886258814975, "mean_inference_ms": 0.3859084326633843, "mean_action_processing_ms": 0.027935060953789677, "mean_env_wait_ms": 0.3986837749978697, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 1152000, "timesteps_this_iter": 0, "agent_timesteps_total": 1152000, "timers": {"sample_time_ms": 1365.282, "sample_throughput": 3750.141, "load_time_ms": 0.141, "load_throughput": 36404198.135, "learn_time_ms": 52.75, "learn_throughput": 97060.969, "update_time_ms": 2.896}, "info": {"learner": {"default_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 44.2247428894043, "policy_entropy": 7986.28564453125, "policy_loss": -4.006475925445557, "vf_loss": 29.710186004638672}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 1152000, "num_agent_steps_sampled": 1152000, "num_steps_trained": 1152000, "num_agent_steps_trained": 1152000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 576, "training_iteration": 29, "trial_id": "06a2c_00000", "experiment_id": "da1bb264888d4dd88dc9d72bb32edab2", "date": "2024-06-12_13-53-35", "timestamp": 1718168015, "time_this_iter_s": 10.88960862159729, "time_total_s": 299.6802990436554, "pid": 88332, "hostname": "DESKTOP-LQ219J4", "node_ip": "192.168.46.185", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 20, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 5000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 500, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "rware", "env_args": {"n_agents": 4, "column_height": 1, "max_inactivity_steps": null, "max_steps": 500, "fast_obs": true, "msg_bits": 0, "sensor_range": 1, "shelf_rows": 1, "shelf_columns": 3, "request_queue_size": 4, "reward_type": "RewardType.INDIVIDUAL", "map_name": "customized_map", "map_size": "tiny", "difficulty": "medium"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": true, "force_coop": false, "local_mode": true, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 4, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 100, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64}, "algorithm": "coma", "space_obs": "Dict(obs:Box([-100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100.], [100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.], (112,), float32))", "space_act": "Discrete(5)", "num_agents": 4, "episode_limit": 500, "policy_mapping_info": {"all_scenario": {"description": "rware all scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2", "agent_3"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "rware_customized_map", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 10, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.policy_template.COMATorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x7ff3b8299b80>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "grad_clip": 40.0, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "microbatch_size": null}, "time_since_restore": 299.6802990436554, "timesteps_since_restore": 0, "iterations_since_restore": 29, "perf": {"cpu_util_percent": 4.08, "ram_util_percent": 41.193333333333335}}
{"episode_reward_max": 5.0, "episode_reward_min": 0.0, "episode_reward_mean": 1.51, "episode_len_mean": 500.0, "episode_media": {}, "episodes_this_iter": 20, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [2.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 2.0, 1.0, 1.0, 0.0, 3.0, 3.0, 0.0, 2.0, 0.0, 2.0, 3.0, 1.0, 0.0, 4.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 3.0, 2.0, 1.0, 2.0, 2.0, 1.0, 2.0, 0.0, 2.0, 2.0, 2.0, 2.0, 2.0, 3.0, 0.0, 1.0, 1.0, 0.0, 5.0, 0.0, 1.0, 1.0, 4.0, 3.0, 3.0, 1.0, 1.0, 2.0, 0.0, 1.0, 4.0, 1.0, 2.0, 4.0, 4.0, 1.0, 1.0, 2.0, 1.0, 1.0, 2.0, 2.0, 0.0, 3.0, 2.0, 1.0, 0.0, 0.0, 1.0, 2.0, 2.0, 1.0, 2.0, 1.0, 2.0, 2.0, 1.0, 2.0, 0.0, 1.0, 1.0, 2.0, 3.0, 2.0, 0.0, 1.0, 2.0, 1.0, 4.0, 1.0, 1.0, 3.0, 0.0], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.15371406700196732, "mean_inference_ms": 0.3861371512714177, "mean_action_processing_ms": 0.027945823135605924, "mean_env_wait_ms": 0.39897235239404444, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 1192960, "timesteps_this_iter": 0, "agent_timesteps_total": 1192960, "timers": {"sample_time_ms": 1361.086, "sample_throughput": 3761.703, "load_time_ms": 0.134, "load_throughput": 38184275.391, "learn_time_ms": 50.997, "learn_throughput": 100398.683, "update_time_ms": 3.071}, "info": {"learner": {"default_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 30.65847396850586, "policy_entropy": 7978.109375, "policy_loss": -1.1274806261062622, "vf_loss": 29.217071533203125}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 1192960, "num_agent_steps_sampled": 1192960, "num_steps_trained": 1192960, "num_agent_steps_trained": 1192960, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 596, "training_iteration": 30, "trial_id": "06a2c_00000", "experiment_id": "da1bb264888d4dd88dc9d72bb32edab2", "date": "2024-06-12_13-53-46", "timestamp": 1718168026, "time_this_iter_s": 10.89166522026062, "time_total_s": 310.571964263916, "pid": 88332, "hostname": "DESKTOP-LQ219J4", "node_ip": "192.168.46.185", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 20, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 5000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 500, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "rware", "env_args": {"n_agents": 4, "column_height": 1, "max_inactivity_steps": null, "max_steps": 500, "fast_obs": true, "msg_bits": 0, "sensor_range": 1, "shelf_rows": 1, "shelf_columns": 3, "request_queue_size": 4, "reward_type": "RewardType.INDIVIDUAL", "map_name": "customized_map", "map_size": "tiny", "difficulty": "medium"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": true, "force_coop": false, "local_mode": true, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 4, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 100, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64}, "algorithm": "coma", "space_obs": "Dict(obs:Box([-100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100.], [100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.], (112,), float32))", "space_act": "Discrete(5)", "num_agents": 4, "episode_limit": 500, "policy_mapping_info": {"all_scenario": {"description": "rware all scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2", "agent_3"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "rware_customized_map", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 10, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.policy_template.COMATorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x7ff2a4f02b80>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "grad_clip": 40.0, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "microbatch_size": null}, "time_since_restore": 310.571964263916, "timesteps_since_restore": 0, "iterations_since_restore": 30, "perf": {"cpu_util_percent": 4.018750000000001, "ram_util_percent": 41.806250000000006}}
{"episode_reward_max": 5.0, "episode_reward_min": 0.0, "episode_reward_mean": 1.53, "episode_len_mean": 500.0, "episode_media": {}, "episodes_this_iter": 20, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [4.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 3.0, 2.0, 1.0, 2.0, 2.0, 1.0, 2.0, 0.0, 2.0, 2.0, 2.0, 2.0, 2.0, 3.0, 0.0, 1.0, 1.0, 0.0, 5.0, 0.0, 1.0, 1.0, 4.0, 3.0, 3.0, 1.0, 1.0, 2.0, 0.0, 1.0, 4.0, 1.0, 2.0, 4.0, 4.0, 1.0, 1.0, 2.0, 1.0, 1.0, 2.0, 2.0, 0.0, 3.0, 2.0, 1.0, 0.0, 0.0, 1.0, 2.0, 2.0, 1.0, 2.0, 1.0, 2.0, 2.0, 1.0, 2.0, 0.0, 1.0, 1.0, 2.0, 3.0, 2.0, 0.0, 1.0, 2.0, 1.0, 4.0, 1.0, 1.0, 3.0, 0.0, 3.0, 1.0, 2.0, 2.0, 0.0, 2.0, 1.0, 1.0, 3.0, 2.0, 1.0, 1.0, 0.0, 1.0, 3.0, 1.0, 0.0, 2.0, 0.0, 0.0], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.153845652510102, "mean_inference_ms": 0.3863880001213028, "mean_action_processing_ms": 0.027958145155766456, "mean_env_wait_ms": 0.39924499701694927, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 1233920, "timesteps_this_iter": 0, "agent_timesteps_total": 1233920, "timers": {"sample_time_ms": 1368.201, "sample_throughput": 3742.141, "load_time_ms": 0.14, "load_throughput": 36503206.663, "learn_time_ms": 50.533, "learn_throughput": 101319.004, "update_time_ms": 2.968}, "info": {"learner": {"default_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 56.667964935302734, "policy_entropy": 8011.0556640625, "policy_loss": -1.9525587558746338, "vf_loss": 22.871889114379883}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 1233920, "num_agent_steps_sampled": 1233920, "num_steps_trained": 1233920, "num_agent_steps_trained": 1233920, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 616, "training_iteration": 31, "trial_id": "06a2c_00000", "experiment_id": "da1bb264888d4dd88dc9d72bb32edab2", "date": "2024-06-12_13-53-57", "timestamp": 1718168037, "time_this_iter_s": 10.922398805618286, "time_total_s": 321.4943630695343, "pid": 88332, "hostname": "DESKTOP-LQ219J4", "node_ip": "192.168.46.185", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 20, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 5000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 500, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "rware", "env_args": {"n_agents": 4, "column_height": 1, "max_inactivity_steps": null, "max_steps": 500, "fast_obs": true, "msg_bits": 0, "sensor_range": 1, "shelf_rows": 1, "shelf_columns": 3, "request_queue_size": 4, "reward_type": "RewardType.INDIVIDUAL", "map_name": "customized_map", "map_size": "tiny", "difficulty": "medium"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": true, "force_coop": false, "local_mode": true, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 4, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 100, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64}, "algorithm": "coma", "space_obs": "Dict(obs:Box([-100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100.], [100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.], (112,), float32))", "space_act": "Discrete(5)", "num_agents": 4, "episode_limit": 500, "policy_mapping_info": {"all_scenario": {"description": "rware all scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2", "agent_3"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "rware_customized_map", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 10, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.policy_template.COMATorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x7ff3b812e0d0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "grad_clip": 40.0, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "microbatch_size": null}, "time_since_restore": 321.4943630695343, "timesteps_since_restore": 0, "iterations_since_restore": 31, "perf": {"cpu_util_percent": 4.1000000000000005, "ram_util_percent": 42.466666666666676}}
{"episode_reward_max": 5.0, "episode_reward_min": 0.0, "episode_reward_mean": 1.38, "episode_len_mean": 500.0, "episode_media": {}, "episodes_this_iter": 20, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [3.0, 0.0, 1.0, 1.0, 0.0, 5.0, 0.0, 1.0, 1.0, 4.0, 3.0, 3.0, 1.0, 1.0, 2.0, 0.0, 1.0, 4.0, 1.0, 2.0, 4.0, 4.0, 1.0, 1.0, 2.0, 1.0, 1.0, 2.0, 2.0, 0.0, 3.0, 2.0, 1.0, 0.0, 0.0, 1.0, 2.0, 2.0, 1.0, 2.0, 1.0, 2.0, 2.0, 1.0, 2.0, 0.0, 1.0, 1.0, 2.0, 3.0, 2.0, 0.0, 1.0, 2.0, 1.0, 4.0, 1.0, 1.0, 3.0, 0.0, 3.0, 1.0, 2.0, 2.0, 0.0, 2.0, 1.0, 1.0, 3.0, 2.0, 1.0, 1.0, 0.0, 1.0, 3.0, 1.0, 0.0, 2.0, 0.0, 0.0, 1.0, 2.0, 1.0, 1.0, 0.0, 3.0, 0.0, 0.0, 1.0, 0.0, 2.0, 0.0, 1.0, 0.0, 1.0, 2.0, 0.0, 0.0, 0.0, 1.0], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.15396655943696824, "mean_inference_ms": 0.3866238223422145, "mean_action_processing_ms": 0.027971867804042115, "mean_env_wait_ms": 0.39954189279195135, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 1274880, "timesteps_this_iter": 0, "agent_timesteps_total": 1274880, "timers": {"sample_time_ms": 1357.589, "sample_throughput": 3771.392, "load_time_ms": 0.141, "load_throughput": 36281190.201, "learn_time_ms": 51.023, "learn_throughput": 100346.561, "update_time_ms": 3.017}, "info": {"learner": {"default_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 39.435569763183594, "policy_entropy": 8007.810546875, "policy_loss": 1.259311556816101, "vf_loss": 7.9545369148254395}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 1274880, "num_agent_steps_sampled": 1274880, "num_steps_trained": 1274880, "num_agent_steps_trained": 1274880, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 636, "training_iteration": 32, "trial_id": "06a2c_00000", "experiment_id": "da1bb264888d4dd88dc9d72bb32edab2", "date": "2024-06-12_13-54-08", "timestamp": 1718168048, "time_this_iter_s": 10.869683742523193, "time_total_s": 332.3640468120575, "pid": 88332, "hostname": "DESKTOP-LQ219J4", "node_ip": "192.168.46.185", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 20, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 5000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 500, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "rware", "env_args": {"n_agents": 4, "column_height": 1, "max_inactivity_steps": null, "max_steps": 500, "fast_obs": true, "msg_bits": 0, "sensor_range": 1, "shelf_rows": 1, "shelf_columns": 3, "request_queue_size": 4, "reward_type": "RewardType.INDIVIDUAL", "map_name": "customized_map", "map_size": "tiny", "difficulty": "medium"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": true, "force_coop": false, "local_mode": true, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 4, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 100, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64}, "algorithm": "coma", "space_obs": "Dict(obs:Box([-100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100.], [100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.], (112,), float32))", "space_act": "Discrete(5)", "num_agents": 4, "episode_limit": 500, "policy_mapping_info": {"all_scenario": {"description": "rware all scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2", "agent_3"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "rware_customized_map", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 10, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.policy_template.COMATorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x7ff2a4f02ca0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "grad_clip": 40.0, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "microbatch_size": null}, "time_since_restore": 332.3640468120575, "timesteps_since_restore": 0, "iterations_since_restore": 32, "perf": {"cpu_util_percent": 4.15625, "ram_util_percent": 43.1125}}
{"episode_reward_max": 4.0, "episode_reward_min": 0.0, "episode_reward_mean": 1.22, "episode_len_mean": 500.0, "episode_media": {}, "episodes_this_iter": 20, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [4.0, 4.0, 1.0, 1.0, 2.0, 1.0, 1.0, 2.0, 2.0, 0.0, 3.0, 2.0, 1.0, 0.0, 0.0, 1.0, 2.0, 2.0, 1.0, 2.0, 1.0, 2.0, 2.0, 1.0, 2.0, 0.0, 1.0, 1.0, 2.0, 3.0, 2.0, 0.0, 1.0, 2.0, 1.0, 4.0, 1.0, 1.0, 3.0, 0.0, 3.0, 1.0, 2.0, 2.0, 0.0, 2.0, 1.0, 1.0, 3.0, 2.0, 1.0, 1.0, 0.0, 1.0, 3.0, 1.0, 0.0, 2.0, 0.0, 0.0, 1.0, 2.0, 1.0, 1.0, 0.0, 3.0, 0.0, 0.0, 1.0, 0.0, 2.0, 0.0, 1.0, 0.0, 1.0, 2.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 3.0, 1.0, 1.0, 1.0, 0.0, 0.0, 3.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 2.0, 1.0, 1.0], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.15408760389708442, "mean_inference_ms": 0.38685182270605883, "mean_action_processing_ms": 0.02798584330862533, "mean_env_wait_ms": 0.39982253854270866, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 1315840, "timesteps_this_iter": 0, "agent_timesteps_total": 1315840, "timers": {"sample_time_ms": 1364.202, "sample_throughput": 3753.11, "load_time_ms": 0.13, "load_throughput": 39324000.146, "learn_time_ms": 51.22, "learn_throughput": 99961.488, "update_time_ms": 2.915}, "info": {"learner": {"default_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 33.2568244934082, "policy_entropy": 8033.9150390625, "policy_loss": -0.47019052505493164, "vf_loss": 13.644938468933105}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 1315840, "num_agent_steps_sampled": 1315840, "num_steps_trained": 1315840, "num_agent_steps_trained": 1315840, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 656, "training_iteration": 33, "trial_id": "06a2c_00000", "experiment_id": "da1bb264888d4dd88dc9d72bb32edab2", "date": "2024-06-12_13-54-19", "timestamp": 1718168059, "time_this_iter_s": 10.898728132247925, "time_total_s": 343.2627749443054, "pid": 88332, "hostname": "DESKTOP-LQ219J4", "node_ip": "192.168.46.185", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 20, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 5000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 500, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "rware", "env_args": {"n_agents": 4, "column_height": 1, "max_inactivity_steps": null, "max_steps": 500, "fast_obs": true, "msg_bits": 0, "sensor_range": 1, "shelf_rows": 1, "shelf_columns": 3, "request_queue_size": 4, "reward_type": "RewardType.INDIVIDUAL", "map_name": "customized_map", "map_size": "tiny", "difficulty": "medium"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": true, "force_coop": false, "local_mode": true, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 4, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 100, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64}, "algorithm": "coma", "space_obs": "Dict(obs:Box([-100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100.], [100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.], (112,), float32))", "space_act": "Discrete(5)", "num_agents": 4, "episode_limit": 500, "policy_mapping_info": {"all_scenario": {"description": "rware all scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2", "agent_3"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "rware_customized_map", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 10, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.policy_template.COMATorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x7ff2a4f02b80>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "grad_clip": 40.0, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "microbatch_size": null}, "time_since_restore": 343.2627749443054, "timesteps_since_restore": 0, "iterations_since_restore": 33, "perf": {"cpu_util_percent": 4.153333333333333, "ram_util_percent": 43.78}}
{"episode_reward_max": 5.0, "episode_reward_min": 0.0, "episode_reward_mean": 1.1, "episode_len_mean": 500.0, "episode_media": {}, "episodes_this_iter": 20, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [1.0, 2.0, 2.0, 1.0, 2.0, 0.0, 1.0, 1.0, 2.0, 3.0, 2.0, 0.0, 1.0, 2.0, 1.0, 4.0, 1.0, 1.0, 3.0, 0.0, 3.0, 1.0, 2.0, 2.0, 0.0, 2.0, 1.0, 1.0, 3.0, 2.0, 1.0, 1.0, 0.0, 1.0, 3.0, 1.0, 0.0, 2.0, 0.0, 0.0, 1.0, 2.0, 1.0, 1.0, 0.0, 3.0, 0.0, 0.0, 1.0, 0.0, 2.0, 0.0, 1.0, 0.0, 1.0, 2.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 3.0, 1.0, 1.0, 1.0, 0.0, 0.0, 3.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 2.0, 1.0, 1.0, 1.0, 0.0, 2.0, 1.0, 1.0, 1.0, 1.0, 0.0, 5.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.15421520697282673, "mean_inference_ms": 0.3871247081950769, "mean_action_processing_ms": 0.028000338816398074, "mean_env_wait_ms": 0.3998859664737332, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 1356800, "timesteps_this_iter": 0, "agent_timesteps_total": 1356800, "timers": {"sample_time_ms": 1355.341, "sample_throughput": 3777.648, "load_time_ms": 0.134, "load_throughput": 38089458.106, "learn_time_ms": 52.097, "learn_throughput": 98278.237, "update_time_ms": 2.833}, "info": {"learner": {"default_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 59.0222282409668, "policy_entropy": 8030.4609375, "policy_loss": 0.24137873947620392, "vf_loss": 34.82674026489258}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 1356800, "num_agent_steps_sampled": 1356800, "num_steps_trained": 1356800, "num_agent_steps_trained": 1356800, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 676, "training_iteration": 34, "trial_id": "06a2c_00000", "experiment_id": "da1bb264888d4dd88dc9d72bb32edab2", "date": "2024-06-12_13-54-29", "timestamp": 1718168069, "time_this_iter_s": 10.76142406463623, "time_total_s": 354.02419900894165, "pid": 88332, "hostname": "DESKTOP-LQ219J4", "node_ip": "192.168.46.185", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 20, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 5000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 500, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "rware", "env_args": {"n_agents": 4, "column_height": 1, "max_inactivity_steps": null, "max_steps": 500, "fast_obs": true, "msg_bits": 0, "sensor_range": 1, "shelf_rows": 1, "shelf_columns": 3, "request_queue_size": 4, "reward_type": "RewardType.INDIVIDUAL", "map_name": "customized_map", "map_size": "tiny", "difficulty": "medium"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": true, "force_coop": false, "local_mode": true, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 4, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 100, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64}, "algorithm": "coma", "space_obs": "Dict(obs:Box([-100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100.], [100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.], (112,), float32))", "space_act": "Discrete(5)", "num_agents": 4, "episode_limit": 500, "policy_mapping_info": {"all_scenario": {"description": "rware all scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2", "agent_3"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "rware_customized_map", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 10, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.policy_template.COMATorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x7ff2a4e70700>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "grad_clip": 40.0, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "microbatch_size": null}, "time_since_restore": 354.02419900894165, "timesteps_since_restore": 0, "iterations_since_restore": 34, "perf": {"cpu_util_percent": 4.1125, "ram_util_percent": 44.425}}
{"episode_reward_max": 5.0, "episode_reward_min": 0.0, "episode_reward_mean": 1.02, "episode_len_mean": 500.0, "episode_media": {}, "episodes_this_iter": 20, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [3.0, 1.0, 2.0, 2.0, 0.0, 2.0, 1.0, 1.0, 3.0, 2.0, 1.0, 1.0, 0.0, 1.0, 3.0, 1.0, 0.0, 2.0, 0.0, 0.0, 1.0, 2.0, 1.0, 1.0, 0.0, 3.0, 0.0, 0.0, 1.0, 0.0, 2.0, 0.0, 1.0, 0.0, 1.0, 2.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 3.0, 1.0, 1.0, 1.0, 0.0, 0.0, 3.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 2.0, 1.0, 1.0, 1.0, 0.0, 2.0, 1.0, 1.0, 1.0, 1.0, 0.0, 5.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 2.0, 1.0, 1.0, 3.0, 1.0, 3.0, 2.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 3.0, 0.0, 0.0, 2.0, 0.0], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.15431650907238256, "mean_inference_ms": 0.387299211882478, "mean_action_processing_ms": 0.02801132266848651, "mean_env_wait_ms": 0.4000324251140006, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 1397760, "timesteps_this_iter": 0, "agent_timesteps_total": 1397760, "timers": {"sample_time_ms": 1348.558, "sample_throughput": 3796.647, "load_time_ms": 0.133, "load_throughput": 38596039.684, "learn_time_ms": 50.836, "learn_throughput": 100716.566, "update_time_ms": 2.883}, "info": {"learner": {"default_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 24.72651481628418, "policy_entropy": 8033.72021484375, "policy_loss": -0.8310665488243103, "vf_loss": 15.25290584564209}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 1397760, "num_agent_steps_sampled": 1397760, "num_steps_trained": 1397760, "num_agent_steps_trained": 1397760, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 696, "training_iteration": 35, "trial_id": "06a2c_00000", "experiment_id": "da1bb264888d4dd88dc9d72bb32edab2", "date": "2024-06-12_13-54-40", "timestamp": 1718168080, "time_this_iter_s": 10.73703384399414, "time_total_s": 364.7612328529358, "pid": 88332, "hostname": "DESKTOP-LQ219J4", "node_ip": "192.168.46.185", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 20, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 5000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 500, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "rware", "env_args": {"n_agents": 4, "column_height": 1, "max_inactivity_steps": null, "max_steps": 500, "fast_obs": true, "msg_bits": 0, "sensor_range": 1, "shelf_rows": 1, "shelf_columns": 3, "request_queue_size": 4, "reward_type": "RewardType.INDIVIDUAL", "map_name": "customized_map", "map_size": "tiny", "difficulty": "medium"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": true, "force_coop": false, "local_mode": true, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 4, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 100, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64}, "algorithm": "coma", "space_obs": "Dict(obs:Box([-100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100.], [100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.], (112,), float32))", "space_act": "Discrete(5)", "num_agents": 4, "episode_limit": 500, "policy_mapping_info": {"all_scenario": {"description": "rware all scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2", "agent_3"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "rware_customized_map", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 10, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.policy_template.COMATorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x7ff2a4f02ee0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "grad_clip": 40.0, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "microbatch_size": null}, "time_since_restore": 364.7612328529358, "timesteps_since_restore": 0, "iterations_since_restore": 35, "perf": {"cpu_util_percent": 3.966666666666667, "ram_util_percent": 45.10666666666666}}
{"episode_reward_max": 5.0, "episode_reward_min": 0.0, "episode_reward_mean": 1.03, "episode_len_mean": 500.0, "episode_media": {}, "episodes_this_iter": 20, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [1.0, 2.0, 1.0, 1.0, 0.0, 3.0, 0.0, 0.0, 1.0, 0.0, 2.0, 0.0, 1.0, 0.0, 1.0, 2.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 3.0, 1.0, 1.0, 1.0, 0.0, 0.0, 3.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 2.0, 1.0, 1.0, 1.0, 0.0, 2.0, 1.0, 1.0, 1.0, 1.0, 0.0, 5.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 2.0, 1.0, 1.0, 3.0, 1.0, 3.0, 2.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 3.0, 0.0, 0.0, 2.0, 0.0, 2.0, 2.0, 3.0, 1.0, 1.0, 2.0, 0.0, 3.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 2.0, 0.0, 2.0, 4.0, 0.0, 1.0], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.15439952757200215, "mean_inference_ms": 0.38745761533344897, "mean_action_processing_ms": 0.028021688596146985, "mean_env_wait_ms": 0.4001235111513847, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 1438720, "timesteps_this_iter": 0, "agent_timesteps_total": 1438720, "timers": {"sample_time_ms": 1352.635, "sample_throughput": 3785.205, "load_time_ms": 0.137, "load_throughput": 37458287.947, "learn_time_ms": 50.972, "learn_throughput": 100448.039, "update_time_ms": 2.851}, "info": {"learner": {"default_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 17.640104293823242, "policy_entropy": 8026.69384765625, "policy_loss": -0.3086150288581848, "vf_loss": 4.838893890380859}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 1438720, "num_agent_steps_sampled": 1438720, "num_steps_trained": 1438720, "num_agent_steps_trained": 1438720, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 716, "training_iteration": 36, "trial_id": "06a2c_00000", "experiment_id": "da1bb264888d4dd88dc9d72bb32edab2", "date": "2024-06-12_13-54-51", "timestamp": 1718168091, "time_this_iter_s": 10.818410158157349, "time_total_s": 375.57964301109314, "pid": 88332, "hostname": "DESKTOP-LQ219J4", "node_ip": "192.168.46.185", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 20, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 5000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 500, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "rware", "env_args": {"n_agents": 4, "column_height": 1, "max_inactivity_steps": null, "max_steps": 500, "fast_obs": true, "msg_bits": 0, "sensor_range": 1, "shelf_rows": 1, "shelf_columns": 3, "request_queue_size": 4, "reward_type": "RewardType.INDIVIDUAL", "map_name": "customized_map", "map_size": "tiny", "difficulty": "medium"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": true, "force_coop": false, "local_mode": true, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 4, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 100, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64}, "algorithm": "coma", "space_obs": "Dict(obs:Box([-100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100.], [100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.], (112,), float32))", "space_act": "Discrete(5)", "num_agents": 4, "episode_limit": 500, "policy_mapping_info": {"all_scenario": {"description": "rware all scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2", "agent_3"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "rware_customized_map", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 10, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.policy_template.COMATorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x7ff3b804a820>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "grad_clip": 40.0, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "microbatch_size": null}, "time_since_restore": 375.57964301109314, "timesteps_since_restore": 0, "iterations_since_restore": 36, "perf": {"cpu_util_percent": 3.9999999999999996, "ram_util_percent": 45.72666666666667}}
{"episode_reward_max": 5.0, "episode_reward_min": 0.0, "episode_reward_mean": 1.11, "episode_len_mean": 500.0, "episode_media": {}, "episodes_this_iter": 20, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 3.0, 1.0, 1.0, 1.0, 0.0, 0.0, 3.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 2.0, 1.0, 1.0, 1.0, 0.0, 2.0, 1.0, 1.0, 1.0, 1.0, 0.0, 5.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 2.0, 1.0, 1.0, 3.0, 1.0, 3.0, 2.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 3.0, 0.0, 0.0, 2.0, 0.0, 2.0, 2.0, 3.0, 1.0, 1.0, 2.0, 0.0, 3.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 2.0, 0.0, 2.0, 4.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 2.0, 1.0, 2.0, 4.0, 2.0, 0.0, 2.0, 1.0, 2.0, 1.0, 2.0], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.15447331341482268, "mean_inference_ms": 0.38758913663394323, "mean_action_processing_ms": 0.028030171804908785, "mean_env_wait_ms": 0.40018311661264194, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 1479680, "timesteps_this_iter": 0, "agent_timesteps_total": 1479680, "timers": {"sample_time_ms": 1348.377, "sample_throughput": 3797.159, "load_time_ms": 0.137, "load_throughput": 37425647.403, "learn_time_ms": 50.94, "learn_throughput": 100509.908, "update_time_ms": 2.898}, "info": {"learner": {"default_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 23.19523811340332, "policy_entropy": 8012.1044921875, "policy_loss": -0.7961246371269226, "vf_loss": 8.129071235656738}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 1479680, "num_agent_steps_sampled": 1479680, "num_steps_trained": 1479680, "num_agent_steps_trained": 1479680, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 736, "training_iteration": 37, "trial_id": "06a2c_00000", "experiment_id": "da1bb264888d4dd88dc9d72bb32edab2", "date": "2024-06-12_13-55-02", "timestamp": 1718168102, "time_this_iter_s": 10.783932447433472, "time_total_s": 386.3635754585266, "pid": 88332, "hostname": "DESKTOP-LQ219J4", "node_ip": "192.168.46.185", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 20, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 5000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 500, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "rware", "env_args": {"n_agents": 4, "column_height": 1, "max_inactivity_steps": null, "max_steps": 500, "fast_obs": true, "msg_bits": 0, "sensor_range": 1, "shelf_rows": 1, "shelf_columns": 3, "request_queue_size": 4, "reward_type": "RewardType.INDIVIDUAL", "map_name": "customized_map", "map_size": "tiny", "difficulty": "medium"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": true, "force_coop": false, "local_mode": true, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 4, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 100, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64}, "algorithm": "coma", "space_obs": "Dict(obs:Box([-100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100.], [100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.], (112,), float32))", "space_act": "Discrete(5)", "num_agents": 4, "episode_limit": 500, "policy_mapping_info": {"all_scenario": {"description": "rware all scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2", "agent_3"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "rware_customized_map", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 10, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.policy_template.COMATorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x7ff2a4e70dc0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "grad_clip": 40.0, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "microbatch_size": null}, "time_since_restore": 386.3635754585266, "timesteps_since_restore": 0, "iterations_since_restore": 37, "perf": {"cpu_util_percent": 4.125, "ram_util_percent": 46.3875}}
{"episode_reward_max": 6.0, "episode_reward_min": 0.0, "episode_reward_mean": 1.26, "episode_len_mean": 500.0, "episode_media": {}, "episodes_this_iter": 24, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [1.0, 1.0, 1.0, 0.0, 5.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 2.0, 1.0, 1.0, 3.0, 1.0, 3.0, 2.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 3.0, 0.0, 0.0, 2.0, 0.0, 2.0, 2.0, 3.0, 1.0, 1.0, 2.0, 0.0, 3.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 2.0, 0.0, 2.0, 4.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 2.0, 1.0, 2.0, 4.0, 2.0, 0.0, 2.0, 1.0, 2.0, 1.0, 2.0, 1.0, 3.0, 3.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 3.0, 0.0, 1.0, 1.0, 6.0, 1.0, 0.0, 3.0, 0.0, 1.0, 1.0, 1.0, 2.0, 3.0, 1.0], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.1545236343588976, "mean_inference_ms": 0.3876469843137679, "mean_action_processing_ms": 0.0280384901033056, "mean_env_wait_ms": 0.4003491176983504, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 1520640, "timesteps_this_iter": 0, "agent_timesteps_total": 1520640, "timers": {"sample_time_ms": 1348.434, "sample_throughput": 3796.998, "load_time_ms": 0.135, "load_throughput": 37847790.765, "learn_time_ms": 51.263, "learn_throughput": 99877.293, "update_time_ms": 2.909}, "info": {"learner": {"default_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 28.86732292175293, "policy_entropy": 8009.515625, "policy_loss": -1.0930378437042236, "vf_loss": 12.0054292678833}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 1520640, "num_agent_steps_sampled": 1520640, "num_steps_trained": 1520640, "num_agent_steps_trained": 1520640, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 760, "training_iteration": 38, "trial_id": "06a2c_00000", "experiment_id": "da1bb264888d4dd88dc9d72bb32edab2", "date": "2024-06-12_13-55-13", "timestamp": 1718168113, "time_this_iter_s": 10.797420978546143, "time_total_s": 397.16099643707275, "pid": 88332, "hostname": "DESKTOP-LQ219J4", "node_ip": "192.168.46.185", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 20, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 5000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 500, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "rware", "env_args": {"n_agents": 4, "column_height": 1, "max_inactivity_steps": null, "max_steps": 500, "fast_obs": true, "msg_bits": 0, "sensor_range": 1, "shelf_rows": 1, "shelf_columns": 3, "request_queue_size": 4, "reward_type": "RewardType.INDIVIDUAL", "map_name": "customized_map", "map_size": "tiny", "difficulty": "medium"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": true, "force_coop": false, "local_mode": true, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 4, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 100, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64}, "algorithm": "coma", "space_obs": "Dict(obs:Box([-100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100.], [100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.], (112,), float32))", "space_act": "Discrete(5)", "num_agents": 4, "episode_limit": 500, "policy_mapping_info": {"all_scenario": {"description": "rware all scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2", "agent_3"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "rware_customized_map", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 10, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.policy_template.COMATorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x7ff2a4e70700>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "grad_clip": 40.0, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "microbatch_size": null}, "time_since_restore": 397.16099643707275, "timesteps_since_restore": 0, "iterations_since_restore": 38, "perf": {"cpu_util_percent": 4.213333333333333, "ram_util_percent": 47.07333333333333}}
{"episode_reward_max": 6.0, "episode_reward_min": 0.0, "episode_reward_mean": 1.35, "episode_len_mean": 500.0, "episode_media": {}, "episodes_this_iter": 20, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [1.0, 3.0, 1.0, 3.0, 2.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 3.0, 0.0, 0.0, 2.0, 0.0, 2.0, 2.0, 3.0, 1.0, 1.0, 2.0, 0.0, 3.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 2.0, 0.0, 2.0, 4.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 2.0, 1.0, 2.0, 4.0, 2.0, 0.0, 2.0, 1.0, 2.0, 1.0, 2.0, 1.0, 3.0, 3.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 3.0, 0.0, 1.0, 1.0, 6.0, 1.0, 0.0, 3.0, 0.0, 1.0, 1.0, 1.0, 2.0, 3.0, 1.0, 1.0, 3.0, 1.0, 2.0, 3.0, 0.0, 0.0, 0.0, 2.0, 2.0, 1.0, 3.0, 1.0, 2.0, 4.0, 0.0, 0.0, 0.0, 3.0, 2.0], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.15459019852289338, "mean_inference_ms": 0.3877482776813103, "mean_action_processing_ms": 0.028047880037771603, "mean_env_wait_ms": 0.40040380975144835, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 1561600, "timesteps_this_iter": 0, "agent_timesteps_total": 1561600, "timers": {"sample_time_ms": 1356.405, "sample_throughput": 3774.685, "load_time_ms": 0.135, "load_throughput": 37954818.805, "learn_time_ms": 50.502, "learn_throughput": 101381.569, "update_time_ms": 2.912}, "info": {"learner": {"default_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 89.17430877685547, "policy_entropy": 8000.14794921875, "policy_loss": -1.7492249011993408, "vf_loss": 46.427154541015625}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 1561600, "num_agent_steps_sampled": 1561600, "num_steps_trained": 1561600, "num_agent_steps_trained": 1561600, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 780, "training_iteration": 39, "trial_id": "06a2c_00000", "experiment_id": "da1bb264888d4dd88dc9d72bb32edab2", "date": "2024-06-12_13-55-23", "timestamp": 1718168123, "time_this_iter_s": 10.844982385635376, "time_total_s": 408.00597882270813, "pid": 88332, "hostname": "DESKTOP-LQ219J4", "node_ip": "192.168.46.185", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 20, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 5000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 500, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "rware", "env_args": {"n_agents": 4, "column_height": 1, "max_inactivity_steps": null, "max_steps": 500, "fast_obs": true, "msg_bits": 0, "sensor_range": 1, "shelf_rows": 1, "shelf_columns": 3, "request_queue_size": 4, "reward_type": "RewardType.INDIVIDUAL", "map_name": "customized_map", "map_size": "tiny", "difficulty": "medium"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": true, "force_coop": false, "local_mode": true, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 4, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 100, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64}, "algorithm": "coma", "space_obs": "Dict(obs:Box([-100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100.], [100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.], (112,), float32))", "space_act": "Discrete(5)", "num_agents": 4, "episode_limit": 500, "policy_mapping_info": {"all_scenario": {"description": "rware all scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2", "agent_3"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "rware_customized_map", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 10, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.policy_template.COMATorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x7ff2a4e70f70>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "grad_clip": 40.0, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "microbatch_size": null}, "time_since_restore": 408.00597882270813, "timesteps_since_restore": 0, "iterations_since_restore": 39, "perf": {"cpu_util_percent": 4.1812499999999995, "ram_util_percent": 47.7125}}
{"episode_reward_max": 7.0, "episode_reward_min": 0.0, "episode_reward_mean": 1.36, "episode_len_mean": 500.0, "episode_media": {}, "episodes_this_iter": 20, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [1.0, 2.0, 0.0, 3.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 2.0, 0.0, 2.0, 4.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 2.0, 1.0, 2.0, 4.0, 2.0, 0.0, 2.0, 1.0, 2.0, 1.0, 2.0, 1.0, 3.0, 3.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 3.0, 0.0, 1.0, 1.0, 6.0, 1.0, 0.0, 3.0, 0.0, 1.0, 1.0, 1.0, 2.0, 3.0, 1.0, 1.0, 3.0, 1.0, 2.0, 3.0, 0.0, 0.0, 0.0, 2.0, 2.0, 1.0, 3.0, 1.0, 2.0, 4.0, 0.0, 0.0, 0.0, 3.0, 2.0, 1.0, 1.0, 2.0, 0.0, 1.0, 4.0, 0.0, 4.0, 1.0, 0.0, 0.0, 0.0, 1.0, 2.0, 1.0, 7.0, 0.0, 0.0, 0.0, 1.0], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.15467485668702652, "mean_inference_ms": 0.38789573371107844, "mean_action_processing_ms": 0.028059603539436467, "mean_env_wait_ms": 0.40054875910329085, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 1602560, "timesteps_this_iter": 0, "agent_timesteps_total": 1602560, "timers": {"sample_time_ms": 1383.158, "sample_throughput": 3701.674, "load_time_ms": 0.137, "load_throughput": 37276230.654, "learn_time_ms": 52.323, "learn_throughput": 97852.989, "update_time_ms": 2.933}, "info": {"learner": {"default_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 30.296648025512695, "policy_entropy": 7972.1337890625, "policy_loss": -0.31208735704421997, "vf_loss": 20.59041976928711}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 1602560, "num_agent_steps_sampled": 1602560, "num_steps_trained": 1602560, "num_agent_steps_trained": 1602560, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 800, "training_iteration": 40, "trial_id": "06a2c_00000", "experiment_id": "da1bb264888d4dd88dc9d72bb32edab2", "date": "2024-06-12_13-55-35", "timestamp": 1718168135, "time_this_iter_s": 11.10279631614685, "time_total_s": 419.108775138855, "pid": 88332, "hostname": "DESKTOP-LQ219J4", "node_ip": "192.168.46.185", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 20, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 5000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 500, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "rware", "env_args": {"n_agents": 4, "column_height": 1, "max_inactivity_steps": null, "max_steps": 500, "fast_obs": true, "msg_bits": 0, "sensor_range": 1, "shelf_rows": 1, "shelf_columns": 3, "request_queue_size": 4, "reward_type": "RewardType.INDIVIDUAL", "map_name": "customized_map", "map_size": "tiny", "difficulty": "medium"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": true, "force_coop": false, "local_mode": true, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 4, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 100, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64}, "algorithm": "coma", "space_obs": "Dict(obs:Box([-100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100.], [100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.], (112,), float32))", "space_act": "Discrete(5)", "num_agents": 4, "episode_limit": 500, "policy_mapping_info": {"all_scenario": {"description": "rware all scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2", "agent_3"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "rware_customized_map", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 10, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.policy_template.COMATorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x7ff3b8299040>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "grad_clip": 40.0, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "microbatch_size": null}, "time_since_restore": 419.108775138855, "timesteps_since_restore": 0, "iterations_since_restore": 40, "perf": {"cpu_util_percent": 4.175, "ram_util_percent": 48.381249999999994}}
{"episode_reward_max": 7.0, "episode_reward_min": 0.0, "episode_reward_mean": 1.45, "episode_len_mean": 500.0, "episode_media": {}, "episodes_this_iter": 20, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [1.0, 0.0, 1.0, 1.0, 1.0, 2.0, 1.0, 2.0, 4.0, 2.0, 0.0, 2.0, 1.0, 2.0, 1.0, 2.0, 1.0, 3.0, 3.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 3.0, 0.0, 1.0, 1.0, 6.0, 1.0, 0.0, 3.0, 0.0, 1.0, 1.0, 1.0, 2.0, 3.0, 1.0, 1.0, 3.0, 1.0, 2.0, 3.0, 0.0, 0.0, 0.0, 2.0, 2.0, 1.0, 3.0, 1.0, 2.0, 4.0, 0.0, 0.0, 0.0, 3.0, 2.0, 1.0, 1.0, 2.0, 0.0, 1.0, 4.0, 0.0, 4.0, 1.0, 0.0, 0.0, 0.0, 1.0, 2.0, 1.0, 7.0, 0.0, 0.0, 0.0, 1.0, 2.0, 1.0, 2.0, 1.0, 3.0, 2.0, 2.0, 1.0, 1.0, 2.0, 0.0, 1.0, 0.0, 0.0, 3.0, 2.0, 1.0, 1.0, 2.0, 2.0], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.15476851955838503, "mean_inference_ms": 0.38805586704911477, "mean_action_processing_ms": 0.028071792460812775, "mean_env_wait_ms": 0.4007323321460335, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 1643520, "timesteps_this_iter": 0, "agent_timesteps_total": 1643520, "timers": {"sample_time_ms": 1377.944, "sample_throughput": 3715.68, "load_time_ms": 0.137, "load_throughput": 37393063.695, "learn_time_ms": 53.069, "learn_throughput": 96477.268, "update_time_ms": 2.859}, "info": {"learner": {"default_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 22.088613510131836, "policy_entropy": 7983.7138671875, "policy_loss": -2.2417802810668945, "vf_loss": 13.360803604125977}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 1643520, "num_agent_steps_sampled": 1643520, "num_steps_trained": 1643520, "num_agent_steps_trained": 1643520, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 820, "training_iteration": 41, "trial_id": "06a2c_00000", "experiment_id": "da1bb264888d4dd88dc9d72bb32edab2", "date": "2024-06-12_13-55-46", "timestamp": 1718168146, "time_this_iter_s": 11.00715708732605, "time_total_s": 430.11593222618103, "pid": 88332, "hostname": "DESKTOP-LQ219J4", "node_ip": "192.168.46.185", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 20, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 5000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 500, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "rware", "env_args": {"n_agents": 4, "column_height": 1, "max_inactivity_steps": null, "max_steps": 500, "fast_obs": true, "msg_bits": 0, "sensor_range": 1, "shelf_rows": 1, "shelf_columns": 3, "request_queue_size": 4, "reward_type": "RewardType.INDIVIDUAL", "map_name": "customized_map", "map_size": "tiny", "difficulty": "medium"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": true, "force_coop": false, "local_mode": true, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 4, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 100, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64}, "algorithm": "coma", "space_obs": "Dict(obs:Box([-100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100.], [100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.], (112,), float32))", "space_act": "Discrete(5)", "num_agents": 4, "episode_limit": 500, "policy_mapping_info": {"all_scenario": {"description": "rware all scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2", "agent_3"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "rware_customized_map", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 10, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.policy_template.COMATorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x7ff3b80a33a0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "grad_clip": 40.0, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "microbatch_size": null}, "time_since_restore": 430.11593222618103, "timesteps_since_restore": 0, "iterations_since_restore": 41, "perf": {"cpu_util_percent": 4.206666666666667, "ram_util_percent": 49.00666666666667}}
{"episode_reward_max": 7.0, "episode_reward_min": 0.0, "episode_reward_mean": 1.39, "episode_len_mean": 500.0, "episode_media": {}, "episodes_this_iter": 20, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [1.0, 1.0, 1.0, 1.0, 1.0, 3.0, 0.0, 1.0, 1.0, 6.0, 1.0, 0.0, 3.0, 0.0, 1.0, 1.0, 1.0, 2.0, 3.0, 1.0, 1.0, 3.0, 1.0, 2.0, 3.0, 0.0, 0.0, 0.0, 2.0, 2.0, 1.0, 3.0, 1.0, 2.0, 4.0, 0.0, 0.0, 0.0, 3.0, 2.0, 1.0, 1.0, 2.0, 0.0, 1.0, 4.0, 0.0, 4.0, 1.0, 0.0, 0.0, 0.0, 1.0, 2.0, 1.0, 7.0, 0.0, 0.0, 0.0, 1.0, 2.0, 1.0, 2.0, 1.0, 3.0, 2.0, 2.0, 1.0, 1.0, 2.0, 0.0, 1.0, 0.0, 0.0, 3.0, 2.0, 1.0, 1.0, 2.0, 2.0, 1.0, 2.0, 1.0, 0.0, 3.0, 0.0, 3.0, 2.0, 1.0, 0.0, 3.0, 3.0, 1.0, 0.0, 2.0, 0.0, 0.0, 0.0, 1.0, 2.0], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.15486989826672726, "mean_inference_ms": 0.3882422800036799, "mean_action_processing_ms": 0.028084824594440488, "mean_env_wait_ms": 0.4009525862080237, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 1684480, "timesteps_this_iter": 0, "agent_timesteps_total": 1684480, "timers": {"sample_time_ms": 1372.248, "sample_throughput": 3731.103, "load_time_ms": 0.144, "load_throughput": 35460430.119, "learn_time_ms": 57.584, "learn_throughput": 88913.993, "update_time_ms": 2.922}, "info": {"learner": {"default_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 39.385520935058594, "policy_entropy": 7960.68212890625, "policy_loss": -2.945030927658081, "vf_loss": 26.030536651611328}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 1684480, "num_agent_steps_sampled": 1684480, "num_steps_trained": 1684480, "num_agent_steps_trained": 1684480, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 840, "training_iteration": 42, "trial_id": "06a2c_00000", "experiment_id": "da1bb264888d4dd88dc9d72bb32edab2", "date": "2024-06-12_13-55-57", "timestamp": 1718168157, "time_this_iter_s": 11.02946925163269, "time_total_s": 441.1454014778137, "pid": 88332, "hostname": "DESKTOP-LQ219J4", "node_ip": "192.168.46.185", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 20, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 5000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 500, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "rware", "env_args": {"n_agents": 4, "column_height": 1, "max_inactivity_steps": null, "max_steps": 500, "fast_obs": true, "msg_bits": 0, "sensor_range": 1, "shelf_rows": 1, "shelf_columns": 3, "request_queue_size": 4, "reward_type": "RewardType.INDIVIDUAL", "map_name": "customized_map", "map_size": "tiny", "difficulty": "medium"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": true, "force_coop": false, "local_mode": true, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 4, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 100, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64}, "algorithm": "coma", "space_obs": "Dict(obs:Box([-100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100.], [100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.], (112,), float32))", "space_act": "Discrete(5)", "num_agents": 4, "episode_limit": 500, "policy_mapping_info": {"all_scenario": {"description": "rware all scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2", "agent_3"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "rware_customized_map", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 10, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.policy_template.COMATorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x7ff3b8028280>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "grad_clip": 40.0, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "microbatch_size": null}, "time_since_restore": 441.1454014778137, "timesteps_since_restore": 0, "iterations_since_restore": 42, "perf": {"cpu_util_percent": 4.125, "ram_util_percent": 49.61875}}
{"episode_reward_max": 7.0, "episode_reward_min": 0.0, "episode_reward_mean": 1.41, "episode_len_mean": 500.0, "episode_media": {}, "episodes_this_iter": 20, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [1.0, 3.0, 1.0, 2.0, 3.0, 0.0, 0.0, 0.0, 2.0, 2.0, 1.0, 3.0, 1.0, 2.0, 4.0, 0.0, 0.0, 0.0, 3.0, 2.0, 1.0, 1.0, 2.0, 0.0, 1.0, 4.0, 0.0, 4.0, 1.0, 0.0, 0.0, 0.0, 1.0, 2.0, 1.0, 7.0, 0.0, 0.0, 0.0, 1.0, 2.0, 1.0, 2.0, 1.0, 3.0, 2.0, 2.0, 1.0, 1.0, 2.0, 0.0, 1.0, 0.0, 0.0, 3.0, 2.0, 1.0, 1.0, 2.0, 2.0, 1.0, 2.0, 1.0, 0.0, 3.0, 0.0, 3.0, 2.0, 1.0, 0.0, 3.0, 3.0, 1.0, 0.0, 2.0, 0.0, 0.0, 0.0, 1.0, 2.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0, 2.0, 0.0, 0.0, 3.0, 3.0, 1.0, 4.0, 5.0, 1.0], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.1549840351080469, "mean_inference_ms": 0.3884808510372575, "mean_action_processing_ms": 0.02809811220980518, "mean_env_wait_ms": 0.40105204623997304, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 1725440, "timesteps_this_iter": 0, "agent_timesteps_total": 1725440, "timers": {"sample_time_ms": 1358.56, "sample_throughput": 3768.697, "load_time_ms": 0.161, "load_throughput": 31814572.563, "learn_time_ms": 56.331, "learn_throughput": 90891.507, "update_time_ms": 2.835}, "info": {"learner": {"default_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 35.9227294921875, "policy_entropy": 7961.4033203125, "policy_loss": -0.2671809792518616, "vf_loss": 0.3390654921531677}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 1725440, "num_agent_steps_sampled": 1725440, "num_steps_trained": 1725440, "num_agent_steps_trained": 1725440, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 860, "training_iteration": 43, "trial_id": "06a2c_00000", "experiment_id": "da1bb264888d4dd88dc9d72bb32edab2", "date": "2024-06-12_13-56-07", "timestamp": 1718168167, "time_this_iter_s": 10.85552191734314, "time_total_s": 452.00092339515686, "pid": 88332, "hostname": "DESKTOP-LQ219J4", "node_ip": "192.168.46.185", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 20, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 5000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 500, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "rware", "env_args": {"n_agents": 4, "column_height": 1, "max_inactivity_steps": null, "max_steps": 500, "fast_obs": true, "msg_bits": 0, "sensor_range": 1, "shelf_rows": 1, "shelf_columns": 3, "request_queue_size": 4, "reward_type": "RewardType.INDIVIDUAL", "map_name": "customized_map", "map_size": "tiny", "difficulty": "medium"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": true, "force_coop": false, "local_mode": true, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 4, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 100, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64}, "algorithm": "coma", "space_obs": "Dict(obs:Box([-100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100.], [100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.], (112,), float32))", "space_act": "Discrete(5)", "num_agents": 4, "episode_limit": 500, "policy_mapping_info": {"all_scenario": {"description": "rware all scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2", "agent_3"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "rware_customized_map", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 10, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.policy_template.COMATorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x7ff2a4e708b0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "grad_clip": 40.0, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "microbatch_size": null}, "time_since_restore": 452.00092339515686, "timesteps_since_restore": 0, "iterations_since_restore": 43, "perf": {"cpu_util_percent": 4.113333333333333, "ram_util_percent": 50.27333333333333}}
{"episode_reward_max": 7.0, "episode_reward_min": 0.0, "episode_reward_mean": 1.4, "episode_len_mean": 500.0, "episode_media": {}, "episodes_this_iter": 20, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [1.0, 1.0, 2.0, 0.0, 1.0, 4.0, 0.0, 4.0, 1.0, 0.0, 0.0, 0.0, 1.0, 2.0, 1.0, 7.0, 0.0, 0.0, 0.0, 1.0, 2.0, 1.0, 2.0, 1.0, 3.0, 2.0, 2.0, 1.0, 1.0, 2.0, 0.0, 1.0, 0.0, 0.0, 3.0, 2.0, 1.0, 1.0, 2.0, 2.0, 1.0, 2.0, 1.0, 0.0, 3.0, 0.0, 3.0, 2.0, 1.0, 0.0, 3.0, 3.0, 1.0, 0.0, 2.0, 0.0, 0.0, 0.0, 1.0, 2.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0, 2.0, 0.0, 0.0, 3.0, 3.0, 1.0, 4.0, 5.0, 1.0, 1.0, 1.0, 3.0, 0.0, 1.0, 0.0, 2.0, 3.0, 2.0, 1.0, 1.0, 2.0, 1.0, 1.0, 4.0, 0.0, 1.0, 0.0, 2.0, 3.0], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.15507264367420642, "mean_inference_ms": 0.3886641405610775, "mean_action_processing_ms": 0.02810943306756768, "mean_env_wait_ms": 0.40130016595612433, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 1766400, "timesteps_this_iter": 0, "agent_timesteps_total": 1766400, "timers": {"sample_time_ms": 1372.075, "sample_throughput": 3731.573, "load_time_ms": 0.14, "load_throughput": 36515620.609, "learn_time_ms": 53.379, "learn_throughput": 95918.107, "update_time_ms": 2.939}, "info": {"learner": {"default_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 41.59110641479492, "policy_entropy": 8001.11669921875, "policy_loss": -3.3379275798797607, "vf_loss": 6.163911819458008}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 1766400, "num_agent_steps_sampled": 1766400, "num_steps_trained": 1766400, "num_agent_steps_trained": 1766400, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 880, "training_iteration": 44, "trial_id": "06a2c_00000", "experiment_id": "da1bb264888d4dd88dc9d72bb32edab2", "date": "2024-06-12_13-56-18", "timestamp": 1718168178, "time_this_iter_s": 10.930530309677124, "time_total_s": 462.931453704834, "pid": 88332, "hostname": "DESKTOP-LQ219J4", "node_ip": "192.168.46.185", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 20, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 5000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 500, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "rware", "env_args": {"n_agents": 4, "column_height": 1, "max_inactivity_steps": null, "max_steps": 500, "fast_obs": true, "msg_bits": 0, "sensor_range": 1, "shelf_rows": 1, "shelf_columns": 3, "request_queue_size": 4, "reward_type": "RewardType.INDIVIDUAL", "map_name": "customized_map", "map_size": "tiny", "difficulty": "medium"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": true, "force_coop": false, "local_mode": true, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 4, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 100, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64}, "algorithm": "coma", "space_obs": "Dict(obs:Box([-100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100.], [100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.], (112,), float32))", "space_act": "Discrete(5)", "num_agents": 4, "episode_limit": 500, "policy_mapping_info": {"all_scenario": {"description": "rware all scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2", "agent_3"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "rware_customized_map", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 10, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.policy_template.COMATorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x7ff2a4e70550>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "grad_clip": 40.0, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "microbatch_size": null}, "time_since_restore": 462.931453704834, "timesteps_since_restore": 0, "iterations_since_restore": 44, "perf": {"cpu_util_percent": 4.231249999999999, "ram_util_percent": 50.9375}}
{"episode_reward_max": 5.0, "episode_reward_min": 0.0, "episode_reward_mean": 1.48, "episode_len_mean": 500.0, "episode_media": {}, "episodes_this_iter": 20, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [2.0, 1.0, 2.0, 1.0, 3.0, 2.0, 2.0, 1.0, 1.0, 2.0, 0.0, 1.0, 0.0, 0.0, 3.0, 2.0, 1.0, 1.0, 2.0, 2.0, 1.0, 2.0, 1.0, 0.0, 3.0, 0.0, 3.0, 2.0, 1.0, 0.0, 3.0, 3.0, 1.0, 0.0, 2.0, 0.0, 0.0, 0.0, 1.0, 2.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0, 2.0, 0.0, 0.0, 3.0, 3.0, 1.0, 4.0, 5.0, 1.0, 1.0, 1.0, 3.0, 0.0, 1.0, 0.0, 2.0, 3.0, 2.0, 1.0, 1.0, 2.0, 1.0, 1.0, 4.0, 0.0, 1.0, 0.0, 2.0, 3.0, 1.0, 1.0, 2.0, 1.0, 3.0, 0.0, 1.0, 1.0, 0.0, 2.0, 0.0, 1.0, 5.0, 3.0, 3.0, 2.0, 1.0, 2.0, 3.0, 2.0], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.15514774009981092, "mean_inference_ms": 0.3888116361876851, "mean_action_processing_ms": 0.028118032134739356, "mean_env_wait_ms": 0.4014766813986765, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 1807360, "timesteps_this_iter": 0, "agent_timesteps_total": 1807360, "timers": {"sample_time_ms": 1373.075, "sample_throughput": 3728.858, "load_time_ms": 0.134, "load_throughput": 38075951.206, "learn_time_ms": 52.101, "learn_throughput": 98269.962, "update_time_ms": 3.003}, "info": {"learner": {"default_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 44.074520111083984, "policy_entropy": 7988.6708984375, "policy_loss": -2.864588975906372, "vf_loss": 16.837865829467773}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 1807360, "num_agent_steps_sampled": 1807360, "num_steps_trained": 1807360, "num_agent_steps_trained": 1807360, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 900, "training_iteration": 45, "trial_id": "06a2c_00000", "experiment_id": "da1bb264888d4dd88dc9d72bb32edab2", "date": "2024-06-12_13-56-29", "timestamp": 1718168189, "time_this_iter_s": 10.88812255859375, "time_total_s": 473.81957626342773, "pid": 88332, "hostname": "DESKTOP-LQ219J4", "node_ip": "192.168.46.185", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 20, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 5000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 500, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "rware", "env_args": {"n_agents": 4, "column_height": 1, "max_inactivity_steps": null, "max_steps": 500, "fast_obs": true, "msg_bits": 0, "sensor_range": 1, "shelf_rows": 1, "shelf_columns": 3, "request_queue_size": 4, "reward_type": "RewardType.INDIVIDUAL", "map_name": "customized_map", "map_size": "tiny", "difficulty": "medium"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": true, "force_coop": false, "local_mode": true, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 4, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 100, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64}, "algorithm": "coma", "space_obs": "Dict(obs:Box([-100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100.], [100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.], (112,), float32))", "space_act": "Discrete(5)", "num_agents": 4, "episode_limit": 500, "policy_mapping_info": {"all_scenario": {"description": "rware all scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2", "agent_3"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "rware_customized_map", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 10, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.policy_template.COMATorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x7ff2a4e70280>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "grad_clip": 40.0, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "microbatch_size": null}, "time_since_restore": 473.81957626342773, "timesteps_since_restore": 0, "iterations_since_restore": 45, "perf": {"cpu_util_percent": 4.2375, "ram_util_percent": 51.58125}}
{"episode_reward_max": 5.0, "episode_reward_min": 0.0, "episode_reward_mean": 1.49, "episode_len_mean": 500.0, "episode_media": {}, "episodes_this_iter": 24, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [3.0, 0.0, 3.0, 2.0, 1.0, 0.0, 3.0, 3.0, 1.0, 0.0, 2.0, 0.0, 0.0, 0.0, 1.0, 2.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0, 2.0, 0.0, 0.0, 3.0, 3.0, 1.0, 4.0, 5.0, 1.0, 1.0, 1.0, 3.0, 0.0, 1.0, 0.0, 2.0, 3.0, 2.0, 1.0, 1.0, 2.0, 1.0, 1.0, 4.0, 0.0, 1.0, 0.0, 2.0, 3.0, 1.0, 1.0, 2.0, 1.0, 3.0, 0.0, 1.0, 1.0, 0.0, 2.0, 0.0, 1.0, 5.0, 3.0, 3.0, 2.0, 1.0, 2.0, 3.0, 2.0, 1.0, 4.0, 2.0, 0.0, 2.0, 0.0, 1.0, 1.0, 0.0, 3.0, 2.0, 1.0, 3.0, 1.0, 0.0, 3.0, 4.0, 1.0, 0.0, 1.0, 2.0, 1.0, 0.0, 1.0], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.15520213688795528, "mean_inference_ms": 0.38889081048949686, "mean_action_processing_ms": 0.02812320966971182, "mean_env_wait_ms": 0.40175486606243477, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 1848320, "timesteps_this_iter": 0, "agent_timesteps_total": 1848320, "timers": {"sample_time_ms": 1359.496, "sample_throughput": 3766.102, "load_time_ms": 0.138, "load_throughput": 37179426.039, "learn_time_ms": 52.907, "learn_throughput": 96772.817, "update_time_ms": 2.952}, "info": {"learner": {"default_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 40.93014144897461, "policy_entropy": 7980.56103515625, "policy_loss": -0.326299786567688, "vf_loss": 3.6552021503448486}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 1848320, "num_agent_steps_sampled": 1848320, "num_steps_trained": 1848320, "num_agent_steps_trained": 1848320, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 924, "training_iteration": 46, "trial_id": "06a2c_00000", "experiment_id": "da1bb264888d4dd88dc9d72bb32edab2", "date": "2024-06-12_13-56-40", "timestamp": 1718168200, "time_this_iter_s": 10.886502265930176, "time_total_s": 484.7060785293579, "pid": 88332, "hostname": "DESKTOP-LQ219J4", "node_ip": "192.168.46.185", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 20, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 5000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 500, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "rware", "env_args": {"n_agents": 4, "column_height": 1, "max_inactivity_steps": null, "max_steps": 500, "fast_obs": true, "msg_bits": 0, "sensor_range": 1, "shelf_rows": 1, "shelf_columns": 3, "request_queue_size": 4, "reward_type": "RewardType.INDIVIDUAL", "map_name": "customized_map", "map_size": "tiny", "difficulty": "medium"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": true, "force_coop": false, "local_mode": true, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 4, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 100, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64}, "algorithm": "coma", "space_obs": "Dict(obs:Box([-100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100.], [100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.], (112,), float32))", "space_act": "Discrete(5)", "num_agents": 4, "episode_limit": 500, "policy_mapping_info": {"all_scenario": {"description": "rware all scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2", "agent_3"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "rware_customized_map", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 10, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.policy_template.COMATorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x7ff3b811e430>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "grad_clip": 40.0, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "microbatch_size": null}, "time_since_restore": 484.7060785293579, "timesteps_since_restore": 0, "iterations_since_restore": 46, "perf": {"cpu_util_percent": 4.326666666666666, "ram_util_percent": 52.25333333333333}}
{"episode_reward_max": 5.0, "episode_reward_min": 0.0, "episode_reward_mean": 1.47, "episode_len_mean": 500.0, "episode_media": {}, "episodes_this_iter": 20, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [1.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0, 2.0, 0.0, 0.0, 3.0, 3.0, 1.0, 4.0, 5.0, 1.0, 1.0, 1.0, 3.0, 0.0, 1.0, 0.0, 2.0, 3.0, 2.0, 1.0, 1.0, 2.0, 1.0, 1.0, 4.0, 0.0, 1.0, 0.0, 2.0, 3.0, 1.0, 1.0, 2.0, 1.0, 3.0, 0.0, 1.0, 1.0, 0.0, 2.0, 0.0, 1.0, 5.0, 3.0, 3.0, 2.0, 1.0, 2.0, 3.0, 2.0, 1.0, 4.0, 2.0, 0.0, 2.0, 0.0, 1.0, 1.0, 0.0, 3.0, 2.0, 1.0, 3.0, 1.0, 0.0, 3.0, 4.0, 1.0, 0.0, 1.0, 2.0, 1.0, 0.0, 1.0, 3.0, 2.0, 0.0, 0.0, 4.0, 3.0, 3.0, 0.0, 0.0, 0.0, 1.0, 2.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.1552604294235781, "mean_inference_ms": 0.38900068142176036, "mean_action_processing_ms": 0.02812931159351824, "mean_env_wait_ms": 0.40186955755983417, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 1889280, "timesteps_this_iter": 0, "agent_timesteps_total": 1889280, "timers": {"sample_time_ms": 1362.881, "sample_throughput": 3756.747, "load_time_ms": 0.14, "load_throughput": 36652733.367, "learn_time_ms": 52.518, "learn_throughput": 97491.162, "update_time_ms": 2.932}, "info": {"learner": {"default_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 23.957645416259766, "policy_entropy": 8000.70556640625, "policy_loss": -0.11239020526409149, "vf_loss": 9.450336456298828}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 1889280, "num_agent_steps_sampled": 1889280, "num_steps_trained": 1889280, "num_agent_steps_trained": 1889280, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 944, "training_iteration": 47, "trial_id": "06a2c_00000", "experiment_id": "da1bb264888d4dd88dc9d72bb32edab2", "date": "2024-06-12_13-56-51", "timestamp": 1718168211, "time_this_iter_s": 10.918643951416016, "time_total_s": 495.6247224807739, "pid": 88332, "hostname": "DESKTOP-LQ219J4", "node_ip": "192.168.46.185", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 20, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 5000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 500, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "rware", "env_args": {"n_agents": 4, "column_height": 1, "max_inactivity_steps": null, "max_steps": 500, "fast_obs": true, "msg_bits": 0, "sensor_range": 1, "shelf_rows": 1, "shelf_columns": 3, "request_queue_size": 4, "reward_type": "RewardType.INDIVIDUAL", "map_name": "customized_map", "map_size": "tiny", "difficulty": "medium"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": true, "force_coop": false, "local_mode": true, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 4, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 100, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64}, "algorithm": "coma", "space_obs": "Dict(obs:Box([-100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100.], [100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.], (112,), float32))", "space_act": "Discrete(5)", "num_agents": 4, "episode_limit": 500, "policy_mapping_info": {"all_scenario": {"description": "rware all scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2", "agent_3"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "rware_customized_map", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 10, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.policy_template.COMATorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x7ff3b812e0d0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "grad_clip": 40.0, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "microbatch_size": null}, "time_since_restore": 495.6247224807739, "timesteps_since_restore": 0, "iterations_since_restore": 47, "perf": {"cpu_util_percent": 4.231249999999999, "ram_util_percent": 52.875}}
{"episode_reward_max": 5.0, "episode_reward_min": 0.0, "episode_reward_mean": 1.45, "episode_len_mean": 500.0, "episode_media": {}, "episodes_this_iter": 20, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [1.0, 0.0, 2.0, 3.0, 2.0, 1.0, 1.0, 2.0, 1.0, 1.0, 4.0, 0.0, 1.0, 0.0, 2.0, 3.0, 1.0, 1.0, 2.0, 1.0, 3.0, 0.0, 1.0, 1.0, 0.0, 2.0, 0.0, 1.0, 5.0, 3.0, 3.0, 2.0, 1.0, 2.0, 3.0, 2.0, 1.0, 4.0, 2.0, 0.0, 2.0, 0.0, 1.0, 1.0, 0.0, 3.0, 2.0, 1.0, 3.0, 1.0, 0.0, 3.0, 4.0, 1.0, 0.0, 1.0, 2.0, 1.0, 0.0, 1.0, 3.0, 2.0, 0.0, 0.0, 4.0, 3.0, 3.0, 0.0, 0.0, 0.0, 1.0, 2.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 4.0, 3.0, 3.0, 0.0, 0.0, 0.0, 3.0, 2.0, 3.0, 3.0, 1.0, 1.0, 2.0, 0.0, 0.0, 0.0, 1.0, 2.0, 2.0], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.15533119203796925, "mean_inference_ms": 0.3891306139346776, "mean_action_processing_ms": 0.02813607919485546, "mean_env_wait_ms": 0.401958334180148, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 1930240, "timesteps_this_iter": 0, "agent_timesteps_total": 1930240, "timers": {"sample_time_ms": 1373.349, "sample_throughput": 3728.113, "load_time_ms": 0.137, "load_throughput": 37295652.101, "learn_time_ms": 52.685, "learn_throughput": 97180.528, "update_time_ms": 2.843}, "info": {"learner": {"default_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 29.993030548095703, "policy_entropy": 8013.21826171875, "policy_loss": -2.279136896133423, "vf_loss": 8.622916221618652}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 1930240, "num_agent_steps_sampled": 1930240, "num_steps_trained": 1930240, "num_agent_steps_trained": 1930240, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 964, "training_iteration": 48, "trial_id": "06a2c_00000", "experiment_id": "da1bb264888d4dd88dc9d72bb32edab2", "date": "2024-06-12_13-57-02", "timestamp": 1718168222, "time_this_iter_s": 10.976322650909424, "time_total_s": 506.60104513168335, "pid": 88332, "hostname": "DESKTOP-LQ219J4", "node_ip": "192.168.46.185", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 20, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 5000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 500, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "rware", "env_args": {"n_agents": 4, "column_height": 1, "max_inactivity_steps": null, "max_steps": 500, "fast_obs": true, "msg_bits": 0, "sensor_range": 1, "shelf_rows": 1, "shelf_columns": 3, "request_queue_size": 4, "reward_type": "RewardType.INDIVIDUAL", "map_name": "customized_map", "map_size": "tiny", "difficulty": "medium"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": true, "force_coop": false, "local_mode": true, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 4, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 100, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64}, "algorithm": "coma", "space_obs": "Dict(obs:Box([-100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100.], [100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.], (112,), float32))", "space_act": "Discrete(5)", "num_agents": 4, "episode_limit": 500, "policy_mapping_info": {"all_scenario": {"description": "rware all scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2", "agent_3"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "rware_customized_map", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 10, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.policy_template.COMATorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x7ff3b811edc0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "grad_clip": 40.0, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "microbatch_size": null}, "time_since_restore": 506.60104513168335, "timesteps_since_restore": 0, "iterations_since_restore": 48, "perf": {"cpu_util_percent": 4.173333333333334, "ram_util_percent": 53.533333333333324}}
{"episode_reward_max": 5.0, "episode_reward_min": 0.0, "episode_reward_mean": 1.47, "episode_len_mean": 500.0, "episode_media": {}, "episodes_this_iter": 20, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [3.0, 0.0, 1.0, 1.0, 0.0, 2.0, 0.0, 1.0, 5.0, 3.0, 3.0, 2.0, 1.0, 2.0, 3.0, 2.0, 1.0, 4.0, 2.0, 0.0, 2.0, 0.0, 1.0, 1.0, 0.0, 3.0, 2.0, 1.0, 3.0, 1.0, 0.0, 3.0, 4.0, 1.0, 0.0, 1.0, 2.0, 1.0, 0.0, 1.0, 3.0, 2.0, 0.0, 0.0, 4.0, 3.0, 3.0, 0.0, 0.0, 0.0, 1.0, 2.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 4.0, 3.0, 3.0, 0.0, 0.0, 0.0, 3.0, 2.0, 3.0, 3.0, 1.0, 1.0, 2.0, 0.0, 0.0, 0.0, 1.0, 2.0, 2.0, 3.0, 1.0, 0.0, 2.0, 0.0, 0.0, 2.0, 1.0, 1.0, 0.0, 1.0, 2.0, 3.0, 1.0, 4.0, 2.0, 4.0, 1.0, 2.0, 1.0], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.1553941096846219, "mean_inference_ms": 0.38923741347462537, "mean_action_processing_ms": 0.02814140217645402, "mean_env_wait_ms": 0.4020409714977665, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 1971200, "timesteps_this_iter": 0, "agent_timesteps_total": 1971200, "timers": {"sample_time_ms": 1353.789, "sample_throughput": 3781.978, "load_time_ms": 0.15, "load_throughput": 34168395.354, "learn_time_ms": 59.713, "learn_throughput": 85743.327, "update_time_ms": 2.899}, "info": {"learner": {"default_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 38.7200927734375, "policy_entropy": 7974.9951171875, "policy_loss": -1.7035112380981445, "vf_loss": 17.29893684387207}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 1971200, "num_agent_steps_sampled": 1971200, "num_steps_trained": 1971200, "num_agent_steps_trained": 1971200, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 984, "training_iteration": 49, "trial_id": "06a2c_00000", "experiment_id": "da1bb264888d4dd88dc9d72bb32edab2", "date": "2024-06-12_13-57-13", "timestamp": 1718168233, "time_this_iter_s": 10.880318641662598, "time_total_s": 517.481363773346, "pid": 88332, "hostname": "DESKTOP-LQ219J4", "node_ip": "192.168.46.185", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 20, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 5000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 500, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "rware", "env_args": {"n_agents": 4, "column_height": 1, "max_inactivity_steps": null, "max_steps": 500, "fast_obs": true, "msg_bits": 0, "sensor_range": 1, "shelf_rows": 1, "shelf_columns": 3, "request_queue_size": 4, "reward_type": "RewardType.INDIVIDUAL", "map_name": "customized_map", "map_size": "tiny", "difficulty": "medium"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": true, "force_coop": false, "local_mode": true, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 4, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 100, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64}, "algorithm": "coma", "space_obs": "Dict(obs:Box([-100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100.], [100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.], (112,), float32))", "space_act": "Discrete(5)", "num_agents": 4, "episode_limit": 500, "policy_mapping_info": {"all_scenario": {"description": "rware all scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2", "agent_3"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "rware_customized_map", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 10, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.policy_template.COMATorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x7ff3b804aee0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "grad_clip": 40.0, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "microbatch_size": null}, "time_since_restore": 517.481363773346, "timesteps_since_restore": 0, "iterations_since_restore": 49, "perf": {"cpu_util_percent": 4.225, "ram_util_percent": 54.175}}
{"episode_reward_max": 4.0, "episode_reward_min": 0.0, "episode_reward_mean": 1.42, "episode_len_mean": 500.0, "episode_media": {}, "episodes_this_iter": 20, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [2.0, 0.0, 1.0, 1.0, 0.0, 3.0, 2.0, 1.0, 3.0, 1.0, 0.0, 3.0, 4.0, 1.0, 0.0, 1.0, 2.0, 1.0, 0.0, 1.0, 3.0, 2.0, 0.0, 0.0, 4.0, 3.0, 3.0, 0.0, 0.0, 0.0, 1.0, 2.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 4.0, 3.0, 3.0, 0.0, 0.0, 0.0, 3.0, 2.0, 3.0, 3.0, 1.0, 1.0, 2.0, 0.0, 0.0, 0.0, 1.0, 2.0, 2.0, 3.0, 1.0, 0.0, 2.0, 0.0, 0.0, 2.0, 1.0, 1.0, 0.0, 1.0, 2.0, 3.0, 1.0, 4.0, 2.0, 4.0, 1.0, 2.0, 1.0, 3.0, 3.0, 2.0, 2.0, 1.0, 1.0, 3.0, 2.0, 2.0, 0.0, 4.0, 0.0, 0.0, 0.0, 2.0, 2.0, 0.0, 2.0, 0.0, 2.0], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.15544686536845917, "mean_inference_ms": 0.38932266027613754, "mean_action_processing_ms": 0.02814631129564354, "mean_env_wait_ms": 0.40211240911074314, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 2012160, "timesteps_this_iter": 0, "agent_timesteps_total": 2012160, "timers": {"sample_time_ms": 1362.67, "sample_throughput": 3757.33, "load_time_ms": 0.151, "load_throughput": 33995308.659, "learn_time_ms": 59.374, "learn_throughput": 86233.726, "update_time_ms": 2.939}, "info": {"learner": {"default_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 27.981351852416992, "policy_entropy": 7980.92236328125, "policy_loss": 0.021027490496635437, "vf_loss": 10.802281379699707}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 2012160, "num_agent_steps_sampled": 2012160, "num_steps_trained": 2012160, "num_agent_steps_trained": 2012160, "num_steps_trained_this_iter": 0}, "evaluation": {"episode_reward_max": 4.0, "episode_reward_min": 0.0, "episode_reward_mean": 1.6, "episode_len_mean": 500.0, "episode_media": {}, "episodes_this_iter": 10, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [1.0, 1.0, 0.0, 2.0, 4.0, 1.0, 1.0, 1.0, 4.0, 1.0], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.09466590606744374, "mean_inference_ms": 0.39588353844123747, "mean_action_processing_ms": 0.02721337598935291, "mean_env_wait_ms": 0.39173064053571116, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}}, "done": true, "episodes_total": 1004, "training_iteration": 50, "trial_id": "06a2c_00000", "experiment_id": "da1bb264888d4dd88dc9d72bb32edab2", "date": "2024-06-12_13-57-28", "timestamp": 1718168248, "time_this_iter_s": 15.414814233779907, "time_total_s": 532.8961780071259, "pid": 88332, "hostname": "DESKTOP-LQ219J4", "node_ip": "192.168.46.185", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 20, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 5000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 500, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Centralized_Critic_Model", "custom_model_config": {"env": "rware", "env_args": {"n_agents": 4, "column_height": 1, "max_inactivity_steps": null, "max_steps": 500, "fast_obs": true, "msg_bits": 0, "sensor_range": 1, "shelf_rows": 1, "shelf_columns": 3, "request_queue_size": 4, "reward_type": "RewardType.INDIVIDUAL", "map_name": "customized_map", "map_size": "tiny", "difficulty": "medium"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": true, "force_coop": false, "local_mode": true, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 4, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 100, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64}, "algorithm": "coma", "space_obs": "Dict(obs:Box([-100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100.], [100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.], (112,), float32))", "space_act": "Discrete(5)", "num_agents": 4, "episode_limit": 500, "policy_mapping_info": {"all_scenario": {"description": "rware all scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2", "agent_3"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "rware_customized_map", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 10, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.policy_template.COMATorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x7ff3b804ac10>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "grad_clip": 40.0, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "microbatch_size": null}, "time_since_restore": 532.8961780071259, "timesteps_since_restore": 0, "iterations_since_restore": 50, "perf": {"cpu_util_percent": 4.136363636363636, "ram_util_percent": 54.94545454545455}}
