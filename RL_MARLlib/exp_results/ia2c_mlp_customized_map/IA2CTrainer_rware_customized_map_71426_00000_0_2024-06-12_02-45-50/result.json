{"episode_reward_max": 3.0, "episode_reward_min": 0.0, "episode_reward_mean": 1.125, "episode_len_mean": 500.0, "episode_media": {}, "episodes_this_iter": 8, "policy_reward_min": {"shared_policy": 0.0}, "policy_reward_max": {"shared_policy": 1.0}, "policy_reward_mean": {"shared_policy": 0.28125}, "custom_metrics": {}, "hist_stats": {"episode_reward": [3.0, 2.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500], "policy_shared_policy_reward": [1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.13051039637505865, "mean_inference_ms": 0.38396749677968156, "mean_action_processing_ms": 0.028997399710550088, "mean_env_wait_ms": 0.3944949249158673, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 5040, "timesteps_this_iter": 0, "agent_timesteps_total": 20160, "timers": {"sample_time_ms": 4968.288, "sample_throughput": 1014.434, "load_time_ms": 0.266, "load_throughput": 18925060.125, "learn_time_ms": 126.586, "learn_throughput": 39814.917, "update_time_ms": 2.056}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 137.14093017578125, "policy_entropy": 8046.6375732421875, "policy_loss": 61.11678171157837, "vf_loss": 15.908326745033264}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 5040, "num_agent_steps_sampled": 20160, "num_steps_trained": 5040, "num_agent_steps_trained": 20160}, "done": false, "episodes_total": 8, "training_iteration": 1, "trial_id": "71426_00000", "experiment_id": "84bca2f7b35f43248fca18d21abe2ebf", "date": "2024-06-12_02-45-56", "timestamp": 1718127956, "time_this_iter_s": 5.015439510345459, "time_total_s": 5.015439510345459, "pid": 363902, "hostname": "DESKTOP-LQ219J4", "node_ip": "192.168.46.185", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 20, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 5000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 500, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Base_Model", "custom_model_config": {"env": "rware", "env_args": {"n_agents": 4, "column_height": 1, "max_inactivity_steps": null, "max_steps": 500, "fast_obs": true, "msg_bits": 0, "sensor_range": 1, "shelf_rows": 1, "shelf_columns": 3, "request_queue_size": 4, "reward_type": "RewardType.INDIVIDUAL", "map_name": "customized_map", "map_size": "tiny", "difficulty": "medium"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": true, "force_coop": false, "local_mode": true, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 4, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 100, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64}, "algorithm": "ia2c", "space_obs": "Dict(obs:Box([-100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100.], [100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.], (112,), float32))", "space_act": "Discrete(5)", "num_agents": 4, "episode_limit": 500, "policy_mapping_info": {"all_scenario": {"description": "rware all scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2", "agent_3"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "rware_customized_map", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 10, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.IA2CTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_il.<locals>.<lambda> at 0x7f38086450d0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "grad_clip": 40.0, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "microbatch_size": null}, "time_since_restore": 5.015439510345459, "timesteps_since_restore": 0, "iterations_since_restore": 1, "perf": {"cpu_util_percent": 5.1875, "ram_util_percent": 31.5625}}
{"episode_reward_max": 3.0, "episode_reward_min": 0.0, "episode_reward_mean": 1.1071428571428572, "episode_len_mean": 500.0, "episode_media": {}, "episodes_this_iter": 20, "policy_reward_min": {"shared_policy": 0.0}, "policy_reward_max": {"shared_policy": 1.0}, "policy_reward_mean": {"shared_policy": 0.2767857142857143}, "custom_metrics": {}, "hist_stats": {"episode_reward": [3.0, 2.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 2.0, 0.0, 1.0, 1.0, 2.0, 1.0, 2.0, 1.0, 0.0, 3.0, 1.0, 1.0, 2.0, 1.0], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500], "policy_shared_policy_reward": [1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.13102748870714281, "mean_inference_ms": 0.3848540087442865, "mean_action_processing_ms": 0.029008626013284765, "mean_env_wait_ms": 0.39717796778247216, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 15120, "timesteps_this_iter": 0, "agent_timesteps_total": 60480, "timers": {"sample_time_ms": 5024.34, "sample_throughput": 1003.117, "load_time_ms": 0.168, "load_throughput": 29928209.759, "learn_time_ms": 125.42, "learn_throughput": 40185.025, "update_time_ms": 2.192}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 56.70347595214844, "policy_entropy": 8040.1390380859375, "policy_loss": 26.252917766571045, "vf_loss": 12.754360556602478}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 15120, "num_agent_steps_sampled": 60480, "num_steps_trained": 15120, "num_agent_steps_trained": 60480, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 28, "training_iteration": 2, "trial_id": "71426_00000", "experiment_id": "84bca2f7b35f43248fca18d21abe2ebf", "date": "2024-06-12_02-46-06", "timestamp": 1718127966, "time_this_iter_s": 10.090102672576904, "time_total_s": 15.105542182922363, "pid": 363902, "hostname": "DESKTOP-LQ219J4", "node_ip": "192.168.46.185", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 20, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 5000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 500, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Base_Model", "custom_model_config": {"env": "rware", "env_args": {"n_agents": 4, "column_height": 1, "max_inactivity_steps": null, "max_steps": 500, "fast_obs": true, "msg_bits": 0, "sensor_range": 1, "shelf_rows": 1, "shelf_columns": 3, "request_queue_size": 4, "reward_type": "RewardType.INDIVIDUAL", "map_name": "customized_map", "map_size": "tiny", "difficulty": "medium"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": true, "force_coop": false, "local_mode": true, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 4, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 100, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64}, "algorithm": "ia2c", "space_obs": "Dict(obs:Box([-100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100.], [100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.], (112,), float32))", "space_act": "Discrete(5)", "num_agents": 4, "episode_limit": 500, "policy_mapping_info": {"all_scenario": {"description": "rware all scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2", "agent_3"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "rware_customized_map", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 10, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.IA2CTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_il.<locals>.<lambda> at 0x7f38086c10d0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "grad_clip": 40.0, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "microbatch_size": null}, "time_since_restore": 15.105542182922363, "timesteps_since_restore": 0, "iterations_since_restore": 2, "perf": {"cpu_util_percent": 4.257142857142857, "ram_util_percent": 32.2}}
{"episode_reward_max": 5.0, "episode_reward_min": 0.0, "episode_reward_mean": 1.2291666666666667, "episode_len_mean": 500.0, "episode_media": {}, "episodes_this_iter": 20, "policy_reward_min": {"shared_policy": 0.0}, "policy_reward_max": {"shared_policy": 3.0}, "policy_reward_mean": {"shared_policy": 0.3072916666666667}, "custom_metrics": {}, "hist_stats": {"episode_reward": [3.0, 2.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 2.0, 0.0, 1.0, 1.0, 2.0, 1.0, 2.0, 1.0, 0.0, 3.0, 1.0, 1.0, 2.0, 1.0, 3.0, 1.0, 1.0, 0.0, 1.0, 2.0, 0.0, 0.0, 5.0, 2.0, 2.0, 1.0, 4.0, 2.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500], "policy_shared_policy_reward": [1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 2.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 3.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 2.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.131228539290701, "mean_inference_ms": 0.385276715076279, "mean_action_processing_ms": 0.029017830212715878, "mean_env_wait_ms": 0.3980990876657145, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 25200, "timesteps_this_iter": 0, "agent_timesteps_total": 100800, "timers": {"sample_time_ms": 5040.839, "sample_throughput": 999.834, "load_time_ms": 0.153, "load_throughput": 32865814.925, "learn_time_ms": 124.965, "learn_throughput": 40331.416, "update_time_ms": 2.156}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 64.67608642578125, "policy_entropy": 8021.6846923828125, "policy_loss": 28.506843090057373, "vf_loss": 17.80810785293579}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 25200, "num_agent_steps_sampled": 100800, "num_steps_trained": 25200, "num_agent_steps_trained": 100800, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 48, "training_iteration": 3, "trial_id": "71426_00000", "experiment_id": "84bca2f7b35f43248fca18d21abe2ebf", "date": "2024-06-12_02-46-16", "timestamp": 1718127976, "time_this_iter_s": 10.112085342407227, "time_total_s": 25.21762752532959, "pid": 363902, "hostname": "DESKTOP-LQ219J4", "node_ip": "192.168.46.185", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 20, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 5000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 500, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Base_Model", "custom_model_config": {"env": "rware", "env_args": {"n_agents": 4, "column_height": 1, "max_inactivity_steps": null, "max_steps": 500, "fast_obs": true, "msg_bits": 0, "sensor_range": 1, "shelf_rows": 1, "shelf_columns": 3, "request_queue_size": 4, "reward_type": "RewardType.INDIVIDUAL", "map_name": "customized_map", "map_size": "tiny", "difficulty": "medium"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": true, "force_coop": false, "local_mode": true, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 4, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 100, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64}, "algorithm": "ia2c", "space_obs": "Dict(obs:Box([-100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100.], [100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.], (112,), float32))", "space_act": "Discrete(5)", "num_agents": 4, "episode_limit": 500, "policy_mapping_info": {"all_scenario": {"description": "rware all scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2", "agent_3"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "rware_customized_map", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 10, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.IA2CTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_il.<locals>.<lambda> at 0x7f38081d5dc0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "grad_clip": 40.0, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "microbatch_size": null}, "time_since_restore": 25.21762752532959, "timesteps_since_restore": 0, "iterations_since_restore": 3, "perf": {"cpu_util_percent": 4.1499999999999995, "ram_util_percent": 32.57142857142858}}
{"episode_reward_max": 5.0, "episode_reward_min": 0.0, "episode_reward_mean": 1.338235294117647, "episode_len_mean": 500.0, "episode_media": {}, "episodes_this_iter": 20, "policy_reward_min": {"shared_policy": 0.0}, "policy_reward_max": {"shared_policy": 3.0}, "policy_reward_mean": {"shared_policy": 0.33455882352941174}, "custom_metrics": {}, "hist_stats": {"episode_reward": [3.0, 2.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 2.0, 0.0, 1.0, 1.0, 2.0, 1.0, 2.0, 1.0, 0.0, 3.0, 1.0, 1.0, 2.0, 1.0, 3.0, 1.0, 1.0, 0.0, 1.0, 2.0, 0.0, 0.0, 5.0, 2.0, 2.0, 1.0, 4.0, 2.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.0, 2.0, 3.0, 1.0, 2.0, 3.0, 1.0, 1.0, 2.0, 2.0, 3.0, 2.0, 2.0, 4.0, 1.0, 0.0, 0.0, 0.0], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500], "policy_shared_policy_reward": [1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 2.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 3.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 2.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 2.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.13152444460716803, "mean_inference_ms": 0.3860139156514, "mean_action_processing_ms": 0.02905305955711623, "mean_env_wait_ms": 0.3994108981182289, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 35280, "timesteps_this_iter": 0, "agent_timesteps_total": 141120, "timers": {"sample_time_ms": 5073.198, "sample_throughput": 993.456, "load_time_ms": 0.149, "load_throughput": 33722662.972, "learn_time_ms": 125.1, "learn_throughput": 40287.891, "update_time_ms": 2.249}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 73.30720520019531, "policy_entropy": 8003.9102783203125, "policy_loss": 25.68197786808014, "vf_loss": 18.66537296772003}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 35280, "num_agent_steps_sampled": 141120, "num_steps_trained": 35280, "num_agent_steps_trained": 141120, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 68, "training_iteration": 4, "trial_id": "71426_00000", "experiment_id": "84bca2f7b35f43248fca18d21abe2ebf", "date": "2024-06-12_02-46-26", "timestamp": 1718127986, "time_this_iter_s": 10.299930095672607, "time_total_s": 35.5175576210022, "pid": 363902, "hostname": "DESKTOP-LQ219J4", "node_ip": "192.168.46.185", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 20, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 5000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 500, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Base_Model", "custom_model_config": {"env": "rware", "env_args": {"n_agents": 4, "column_height": 1, "max_inactivity_steps": null, "max_steps": 500, "fast_obs": true, "msg_bits": 0, "sensor_range": 1, "shelf_rows": 1, "shelf_columns": 3, "request_queue_size": 4, "reward_type": "RewardType.INDIVIDUAL", "map_name": "customized_map", "map_size": "tiny", "difficulty": "medium"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": true, "force_coop": false, "local_mode": true, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 4, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 100, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64}, "algorithm": "ia2c", "space_obs": "Dict(obs:Box([-100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100.], [100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.], (112,), float32))", "space_act": "Discrete(5)", "num_agents": 4, "episode_limit": 500, "policy_mapping_info": {"all_scenario": {"description": "rware all scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2", "agent_3"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "rware_customized_map", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 10, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.IA2CTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_il.<locals>.<lambda> at 0x7f38086c1a60>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "grad_clip": 40.0, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "microbatch_size": null}, "time_since_restore": 35.5175576210022, "timesteps_since_restore": 0, "iterations_since_restore": 4, "perf": {"cpu_util_percent": 4.273333333333334, "ram_util_percent": 32.89333333333333}}
{"episode_reward_max": 5.0, "episode_reward_min": 0.0, "episode_reward_mean": 1.3863636363636365, "episode_len_mean": 500.0, "episode_media": {}, "episodes_this_iter": 20, "policy_reward_min": {"shared_policy": 0.0}, "policy_reward_max": {"shared_policy": 3.0}, "policy_reward_mean": {"shared_policy": 0.3465909090909091}, "custom_metrics": {}, "hist_stats": {"episode_reward": [3.0, 2.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 2.0, 0.0, 1.0, 1.0, 2.0, 1.0, 2.0, 1.0, 0.0, 3.0, 1.0, 1.0, 2.0, 1.0, 3.0, 1.0, 1.0, 0.0, 1.0, 2.0, 0.0, 0.0, 5.0, 2.0, 2.0, 1.0, 4.0, 2.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.0, 2.0, 3.0, 1.0, 2.0, 3.0, 1.0, 1.0, 2.0, 2.0, 3.0, 2.0, 2.0, 4.0, 1.0, 0.0, 0.0, 0.0, 2.0, 4.0, 2.0, 0.0, 2.0, 2.0, 0.0, 1.0, 2.0, 2.0, 1.0, 2.0, 1.0, 3.0, 1.0, 1.0, 0.0, 3.0, 1.0, 1.0], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500], "policy_shared_policy_reward": [1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 2.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 3.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 2.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 2.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 2.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.13164868099982432, "mean_inference_ms": 0.38624668878913665, "mean_action_processing_ms": 0.02905829677276628, "mean_env_wait_ms": 0.4000702300872403, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 45360, "timesteps_this_iter": 0, "agent_timesteps_total": 181440, "timers": {"sample_time_ms": 5068.417, "sample_throughput": 994.393, "load_time_ms": 0.144, "load_throughput": 35011709.503, "learn_time_ms": 124.58, "learn_throughput": 40455.85, "update_time_ms": 2.263}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 58.06721496582031, "policy_entropy": 8007.8612060546875, "policy_loss": 21.05185568332672, "vf_loss": 17.382370710372925}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 45360, "num_agent_steps_sampled": 181440, "num_steps_trained": 45360, "num_agent_steps_trained": 181440, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 88, "training_iteration": 5, "trial_id": "71426_00000", "experiment_id": "84bca2f7b35f43248fca18d21abe2ebf", "date": "2024-06-12_02-46-36", "timestamp": 1718127996, "time_this_iter_s": 10.08717131614685, "time_total_s": 45.60472893714905, "pid": 363902, "hostname": "DESKTOP-LQ219J4", "node_ip": "192.168.46.185", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 20, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 5000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 500, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Base_Model", "custom_model_config": {"env": "rware", "env_args": {"n_agents": 4, "column_height": 1, "max_inactivity_steps": null, "max_steps": 500, "fast_obs": true, "msg_bits": 0, "sensor_range": 1, "shelf_rows": 1, "shelf_columns": 3, "request_queue_size": 4, "reward_type": "RewardType.INDIVIDUAL", "map_name": "customized_map", "map_size": "tiny", "difficulty": "medium"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": true, "force_coop": false, "local_mode": true, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 4, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 100, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64}, "algorithm": "ia2c", "space_obs": "Dict(obs:Box([-100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100.], [100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.], (112,), float32))", "space_act": "Discrete(5)", "num_agents": 4, "episode_limit": 500, "policy_mapping_info": {"all_scenario": {"description": "rware all scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2", "agent_3"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "rware_customized_map", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 10, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.IA2CTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_il.<locals>.<lambda> at 0x7f38081d5f70>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "grad_clip": 40.0, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "microbatch_size": null}, "time_since_restore": 45.60472893714905, "timesteps_since_restore": 0, "iterations_since_restore": 5, "perf": {"cpu_util_percent": 4.366666666666666, "ram_util_percent": 33.27333333333334}}
{"episode_reward_max": 5.0, "episode_reward_min": 0.0, "episode_reward_mean": 1.34, "episode_len_mean": 500.0, "episode_media": {}, "episodes_this_iter": 20, "policy_reward_min": {"shared_policy": 0.0}, "policy_reward_max": {"shared_policy": 3.0}, "policy_reward_mean": {"shared_policy": 0.335}, "custom_metrics": {}, "hist_stats": {"episode_reward": [1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 2.0, 0.0, 1.0, 1.0, 2.0, 1.0, 2.0, 1.0, 0.0, 3.0, 1.0, 1.0, 2.0, 1.0, 3.0, 1.0, 1.0, 0.0, 1.0, 2.0, 0.0, 0.0, 5.0, 2.0, 2.0, 1.0, 4.0, 2.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.0, 2.0, 3.0, 1.0, 2.0, 3.0, 1.0, 1.0, 2.0, 2.0, 3.0, 2.0, 2.0, 4.0, 1.0, 0.0, 0.0, 0.0, 2.0, 4.0, 2.0, 0.0, 2.0, 2.0, 0.0, 1.0, 2.0, 2.0, 1.0, 2.0, 1.0, 3.0, 1.0, 1.0, 0.0, 3.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 2.0, 1.0, 2.0, 3.0, 1.0, 0.0, 1.0, 2.0, 1.0, 1.0, 0.0, 1.0, 1.0, 2.0, 0.0], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500], "policy_shared_policy_reward": [0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 2.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 3.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 2.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 2.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 2.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.13179369117237766, "mean_inference_ms": 0.38645453469211516, "mean_action_processing_ms": 0.029057237233583513, "mean_env_wait_ms": 0.4009275748611623, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 55440, "timesteps_this_iter": 0, "agent_timesteps_total": 221760, "timers": {"sample_time_ms": 5073.765, "sample_throughput": 993.345, "load_time_ms": 0.129, "load_throughput": 39125101.166, "learn_time_ms": 123.976, "learn_throughput": 40652.868, "update_time_ms": 2.283}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 60.800750732421875, "policy_entropy": 8021.3082275390625, "policy_loss": -12.043311953544617, "vf_loss": 9.018406420946121}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 55440, "num_agent_steps_sampled": 221760, "num_steps_trained": 55440, "num_agent_steps_trained": 221760, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 108, "training_iteration": 6, "trial_id": "71426_00000", "experiment_id": "84bca2f7b35f43248fca18d21abe2ebf", "date": "2024-06-12_02-46-46", "timestamp": 1718128006, "time_this_iter_s": 10.072264432907104, "time_total_s": 55.67699337005615, "pid": 363902, "hostname": "DESKTOP-LQ219J4", "node_ip": "192.168.46.185", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 20, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 5000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 500, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Base_Model", "custom_model_config": {"env": "rware", "env_args": {"n_agents": 4, "column_height": 1, "max_inactivity_steps": null, "max_steps": 500, "fast_obs": true, "msg_bits": 0, "sensor_range": 1, "shelf_rows": 1, "shelf_columns": 3, "request_queue_size": 4, "reward_type": "RewardType.INDIVIDUAL", "map_name": "customized_map", "map_size": "tiny", "difficulty": "medium"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": true, "force_coop": false, "local_mode": true, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 4, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 100, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64}, "algorithm": "ia2c", "space_obs": "Dict(obs:Box([-100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100.], [100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.], (112,), float32))", "space_act": "Discrete(5)", "num_agents": 4, "episode_limit": 500, "policy_mapping_info": {"all_scenario": {"description": "rware all scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2", "agent_3"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "rware_customized_map", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 10, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.IA2CTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_il.<locals>.<lambda> at 0x7f38081d5a60>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "grad_clip": 40.0, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "microbatch_size": null}, "time_since_restore": 55.67699337005615, "timesteps_since_restore": 0, "iterations_since_restore": 6, "perf": {"cpu_util_percent": 4.378571428571428, "ram_util_percent": 33.61428571428572}}
{"episode_reward_max": 5.0, "episode_reward_min": 0.0, "episode_reward_mean": 1.34, "episode_len_mean": 500.0, "episode_media": {}, "episodes_this_iter": 20, "policy_reward_min": {"shared_policy": 0.0}, "policy_reward_max": {"shared_policy": 3.0}, "policy_reward_mean": {"shared_policy": 0.335}, "custom_metrics": {}, "hist_stats": {"episode_reward": [3.0, 1.0, 1.0, 0.0, 1.0, 2.0, 0.0, 0.0, 5.0, 2.0, 2.0, 1.0, 4.0, 2.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.0, 2.0, 3.0, 1.0, 2.0, 3.0, 1.0, 1.0, 2.0, 2.0, 3.0, 2.0, 2.0, 4.0, 1.0, 0.0, 0.0, 0.0, 2.0, 4.0, 2.0, 0.0, 2.0, 2.0, 0.0, 1.0, 2.0, 2.0, 1.0, 2.0, 1.0, 3.0, 1.0, 1.0, 0.0, 3.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 2.0, 1.0, 2.0, 3.0, 1.0, 0.0, 1.0, 2.0, 1.0, 1.0, 0.0, 1.0, 1.0, 2.0, 0.0, 1.0, 1.0, 1.0, 0.0, 2.0, 1.0, 3.0, 0.0, 2.0, 0.0, 0.0, 0.0, 1.0, 1.0, 4.0, 1.0, 3.0, 0.0, 1.0, 0.0], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500], "policy_shared_policy_reward": [1.0, 0.0, 2.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 3.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 2.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 2.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 2.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 2.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.1319087993368981, "mean_inference_ms": 0.3866184889533558, "mean_action_processing_ms": 0.02905464836023649, "mean_env_wait_ms": 0.4015291997063274, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 65520, "timesteps_this_iter": 0, "agent_timesteps_total": 262080, "timers": {"sample_time_ms": 5067.867, "sample_throughput": 994.501, "load_time_ms": 0.131, "load_throughput": 38421105.344, "learn_time_ms": 123.166, "learn_throughput": 40920.3, "update_time_ms": 2.245}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 50.36743927001953, "policy_entropy": 8029.88671875, "policy_loss": 11.058924823999405, "vf_loss": 14.637724041938782}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 65520, "num_agent_steps_sampled": 262080, "num_steps_trained": 65520, "num_agent_steps_trained": 262080, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 128, "training_iteration": 7, "trial_id": "71426_00000", "experiment_id": "84bca2f7b35f43248fca18d21abe2ebf", "date": "2024-06-12_02-46-56", "timestamp": 1718128016, "time_this_iter_s": 10.027227878570557, "time_total_s": 65.70422124862671, "pid": 363902, "hostname": "DESKTOP-LQ219J4", "node_ip": "192.168.46.185", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 20, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 5000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 500, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Base_Model", "custom_model_config": {"env": "rware", "env_args": {"n_agents": 4, "column_height": 1, "max_inactivity_steps": null, "max_steps": 500, "fast_obs": true, "msg_bits": 0, "sensor_range": 1, "shelf_rows": 1, "shelf_columns": 3, "request_queue_size": 4, "reward_type": "RewardType.INDIVIDUAL", "map_name": "customized_map", "map_size": "tiny", "difficulty": "medium"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": true, "force_coop": false, "local_mode": true, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 4, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 100, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64}, "algorithm": "ia2c", "space_obs": "Dict(obs:Box([-100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100.], [100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.], (112,), float32))", "space_act": "Discrete(5)", "num_agents": 4, "episode_limit": 500, "policy_mapping_info": {"all_scenario": {"description": "rware all scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2", "agent_3"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "rware_customized_map", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 10, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.IA2CTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_il.<locals>.<lambda> at 0x7f38081d70d0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "grad_clip": 40.0, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "microbatch_size": null}, "time_since_restore": 65.70422124862671, "timesteps_since_restore": 0, "iterations_since_restore": 7, "perf": {"cpu_util_percent": 4.357142857142858, "ram_util_percent": 33.89999999999999}}
{"episode_reward_max": 4.0, "episode_reward_min": 0.0, "episode_reward_mean": 1.21, "episode_len_mean": 500.0, "episode_media": {}, "episodes_this_iter": 32, "policy_reward_min": {"shared_policy": 0.0}, "policy_reward_max": {"shared_policy": 2.0}, "policy_reward_mean": {"shared_policy": 0.3025}, "custom_metrics": {}, "hist_stats": {"episode_reward": [3.0, 2.0, 2.0, 4.0, 1.0, 0.0, 0.0, 0.0, 2.0, 4.0, 2.0, 0.0, 2.0, 2.0, 0.0, 1.0, 2.0, 2.0, 1.0, 2.0, 1.0, 3.0, 1.0, 1.0, 0.0, 3.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 2.0, 1.0, 2.0, 3.0, 1.0, 0.0, 1.0, 2.0, 1.0, 1.0, 0.0, 1.0, 1.0, 2.0, 0.0, 1.0, 1.0, 1.0, 0.0, 2.0, 1.0, 3.0, 0.0, 2.0, 0.0, 0.0, 0.0, 1.0, 1.0, 4.0, 1.0, 3.0, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 0.0, 3.0, 2.0, 0.0, 3.0, 1.0, 1.0, 0.0, 1.0, 2.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 2.0, 3.0, 2.0, 0.0, 2.0, 1.0, 2.0, 1.0, 1.0, 0.0, 3.0, 0.0, 0.0], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500], "policy_shared_policy_reward": [1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 2.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 2.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 2.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 2.0, 0.0, 1.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.13186335493125828, "mean_inference_ms": 0.38621408945763996, "mean_action_processing_ms": 0.029018366337278563, "mean_env_wait_ms": 0.4013867641539177, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 80640, "timesteps_this_iter": 0, "agent_timesteps_total": 322560, "timers": {"sample_time_ms": 5054.906, "sample_throughput": 997.051, "load_time_ms": 0.133, "load_throughput": 38033990.932, "learn_time_ms": 122.115, "learn_throughput": 41272.437, "update_time_ms": 2.231}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 56.29955291748047, "policy_entropy": 7998.2049560546875, "policy_loss": -31.360909551382065, "vf_loss": 5.2143294513225555}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 80640, "num_agent_steps_sampled": 322560, "num_steps_trained": 80640, "num_agent_steps_trained": 322560, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 160, "training_iteration": 8, "trial_id": "71426_00000", "experiment_id": "84bca2f7b35f43248fca18d21abe2ebf", "date": "2024-06-12_02-47-11", "timestamp": 1718128031, "time_this_iter_s": 15.038496494293213, "time_total_s": 80.74271774291992, "pid": 363902, "hostname": "DESKTOP-LQ219J4", "node_ip": "192.168.46.185", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 20, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 5000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 500, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Base_Model", "custom_model_config": {"env": "rware", "env_args": {"n_agents": 4, "column_height": 1, "max_inactivity_steps": null, "max_steps": 500, "fast_obs": true, "msg_bits": 0, "sensor_range": 1, "shelf_rows": 1, "shelf_columns": 3, "request_queue_size": 4, "reward_type": "RewardType.INDIVIDUAL", "map_name": "customized_map", "map_size": "tiny", "difficulty": "medium"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": true, "force_coop": false, "local_mode": true, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 4, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 100, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64}, "algorithm": "ia2c", "space_obs": "Dict(obs:Box([-100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100.], [100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.], (112,), float32))", "space_act": "Discrete(5)", "num_agents": 4, "episode_limit": 500, "policy_mapping_info": {"all_scenario": {"description": "rware all scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2", "agent_3"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "rware_customized_map", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 10, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.IA2CTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_il.<locals>.<lambda> at 0x7f38086515e0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "grad_clip": 40.0, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "microbatch_size": null}, "time_since_restore": 80.74271774291992, "timesteps_since_restore": 0, "iterations_since_restore": 8, "perf": {"cpu_util_percent": 4.218181818181819, "ram_util_percent": 34.24090909090909}}
{"episode_reward_max": 4.0, "episode_reward_min": 0.0, "episode_reward_mean": 1.18, "episode_len_mean": 500.0, "episode_media": {}, "episodes_this_iter": 20, "policy_reward_min": {"shared_policy": 0.0}, "policy_reward_max": {"shared_policy": 2.0}, "policy_reward_mean": {"shared_policy": 0.295}, "custom_metrics": {}, "hist_stats": {"episode_reward": [1.0, 3.0, 1.0, 1.0, 0.0, 3.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 2.0, 1.0, 2.0, 3.0, 1.0, 0.0, 1.0, 2.0, 1.0, 1.0, 0.0, 1.0, 1.0, 2.0, 0.0, 1.0, 1.0, 1.0, 0.0, 2.0, 1.0, 3.0, 0.0, 2.0, 0.0, 0.0, 0.0, 1.0, 1.0, 4.0, 1.0, 3.0, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 0.0, 3.0, 2.0, 0.0, 3.0, 1.0, 1.0, 0.0, 1.0, 2.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 2.0, 3.0, 2.0, 0.0, 2.0, 1.0, 2.0, 1.0, 1.0, 0.0, 3.0, 0.0, 0.0, 2.0, 1.0, 2.0, 0.0, 3.0, 1.0, 2.0, 2.0, 2.0, 2.0, 1.0, 1.0, 2.0, 1.0, 0.0, 0.0, 0.0, 4.0, 2.0, 1.0], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500], "policy_shared_policy_reward": [1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 2.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 2.0, 0.0, 1.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 2.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 2.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.13177898048982764, "mean_inference_ms": 0.3858101287555741, "mean_action_processing_ms": 0.02899086256563181, "mean_env_wait_ms": 0.4011221611059874, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 90720, "timesteps_this_iter": 0, "agent_timesteps_total": 362880, "timers": {"sample_time_ms": 5038.047, "sample_throughput": 1000.388, "load_time_ms": 0.133, "load_throughput": 37863679.312, "learn_time_ms": 121.762, "learn_throughput": 41392.122, "update_time_ms": 2.203}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 77.66024017333984, "policy_entropy": 7991.8790283203125, "policy_loss": 19.03954291343689, "vf_loss": 17.481754541397095}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 90720, "num_agent_steps_sampled": 362880, "num_steps_trained": 90720, "num_agent_steps_trained": 362880, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 180, "training_iteration": 9, "trial_id": "71426_00000", "experiment_id": "84bca2f7b35f43248fca18d21abe2ebf", "date": "2024-06-12_02-47-22", "timestamp": 1718128042, "time_this_iter_s": 10.077737092971802, "time_total_s": 90.82045483589172, "pid": 363902, "hostname": "DESKTOP-LQ219J4", "node_ip": "192.168.46.185", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 20, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 5000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 500, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Base_Model", "custom_model_config": {"env": "rware", "env_args": {"n_agents": 4, "column_height": 1, "max_inactivity_steps": null, "max_steps": 500, "fast_obs": true, "msg_bits": 0, "sensor_range": 1, "shelf_rows": 1, "shelf_columns": 3, "request_queue_size": 4, "reward_type": "RewardType.INDIVIDUAL", "map_name": "customized_map", "map_size": "tiny", "difficulty": "medium"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": true, "force_coop": false, "local_mode": true, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 4, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 100, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64}, "algorithm": "ia2c", "space_obs": "Dict(obs:Box([-100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100.], [100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.], (112,), float32))", "space_act": "Discrete(5)", "num_agents": 4, "episode_limit": 500, "policy_mapping_info": {"all_scenario": {"description": "rware all scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2", "agent_3"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "rware_customized_map", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 10, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.IA2CTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_il.<locals>.<lambda> at 0x7f38082f8d30>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "grad_clip": 40.0, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "microbatch_size": null}, "time_since_restore": 90.82045483589172, "timesteps_since_restore": 0, "iterations_since_restore": 9, "perf": {"cpu_util_percent": 4.321428571428572, "ram_util_percent": 34.60000000000001}}
{"episode_reward_max": 4.0, "episode_reward_min": 0.0, "episode_reward_mean": 1.32, "episode_len_mean": 500.0, "episode_media": {}, "episodes_this_iter": 20, "policy_reward_min": {"shared_policy": 0.0}, "policy_reward_max": {"shared_policy": 2.0}, "policy_reward_mean": {"shared_policy": 0.33}, "custom_metrics": {}, "hist_stats": {"episode_reward": [2.0, 1.0, 1.0, 0.0, 1.0, 1.0, 2.0, 0.0, 1.0, 1.0, 1.0, 0.0, 2.0, 1.0, 3.0, 0.0, 2.0, 0.0, 0.0, 0.0, 1.0, 1.0, 4.0, 1.0, 3.0, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 0.0, 3.0, 2.0, 0.0, 3.0, 1.0, 1.0, 0.0, 1.0, 2.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 2.0, 3.0, 2.0, 0.0, 2.0, 1.0, 2.0, 1.0, 1.0, 0.0, 3.0, 0.0, 0.0, 2.0, 1.0, 2.0, 0.0, 3.0, 1.0, 2.0, 2.0, 2.0, 2.0, 1.0, 1.0, 2.0, 1.0, 0.0, 0.0, 0.0, 4.0, 2.0, 1.0, 2.0, 2.0, 4.0, 2.0, 1.0, 3.0, 1.0, 1.0, 3.0, 2.0, 2.0, 0.0, 1.0, 2.0, 1.0, 4.0, 1.0, 1.0, 2.0, 3.0], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500], "policy_shared_policy_reward": [0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 2.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 2.0, 0.0, 1.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 2.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 2.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 2.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 2.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 2.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.13170226555380207, "mean_inference_ms": 0.3855094854104228, "mean_action_processing_ms": 0.028972408319243546, "mean_env_wait_ms": 0.4007348748866805, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 100800, "timesteps_this_iter": 0, "agent_timesteps_total": 403200, "timers": {"sample_time_ms": 5037.485, "sample_throughput": 1000.499, "load_time_ms": 0.137, "load_throughput": 36744815.157, "learn_time_ms": 121.337, "learn_throughput": 41537.179, "update_time_ms": 2.174}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 79.61991882324219, "policy_entropy": 7995.3074951171875, "policy_loss": 11.010471820831299, "vf_loss": 17.81268000602722}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 100800, "num_agent_steps_sampled": 403200, "num_steps_trained": 100800, "num_agent_steps_trained": 403200, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 200, "training_iteration": 10, "trial_id": "71426_00000", "experiment_id": "84bca2f7b35f43248fca18d21abe2ebf", "date": "2024-06-12_02-47-32", "timestamp": 1718128052, "time_this_iter_s": 10.092402219772339, "time_total_s": 100.91285705566406, "pid": 363902, "hostname": "DESKTOP-LQ219J4", "node_ip": "192.168.46.185", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 20, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 5000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 500, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Base_Model", "custom_model_config": {"env": "rware", "env_args": {"n_agents": 4, "column_height": 1, "max_inactivity_steps": null, "max_steps": 500, "fast_obs": true, "msg_bits": 0, "sensor_range": 1, "shelf_rows": 1, "shelf_columns": 3, "request_queue_size": 4, "reward_type": "RewardType.INDIVIDUAL", "map_name": "customized_map", "map_size": "tiny", "difficulty": "medium"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": true, "force_coop": false, "local_mode": true, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 4, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 100, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64}, "algorithm": "ia2c", "space_obs": "Dict(obs:Box([-100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100.], [100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.], (112,), float32))", "space_act": "Discrete(5)", "num_agents": 4, "episode_limit": 500, "policy_mapping_info": {"all_scenario": {"description": "rware all scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2", "agent_3"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "rware_customized_map", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 10, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.IA2CTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_il.<locals>.<lambda> at 0x7f38081d59d0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "grad_clip": 40.0, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "microbatch_size": null}, "time_since_restore": 100.91285705566406, "timesteps_since_restore": 0, "iterations_since_restore": 10, "perf": {"cpu_util_percent": 4.471428571428571, "ram_util_percent": 34.84999999999999}}
{"episode_reward_max": 4.0, "episode_reward_min": 0.0, "episode_reward_mean": 1.37, "episode_len_mean": 500.0, "episode_media": {}, "episodes_this_iter": 20, "policy_reward_min": {"shared_policy": 0.0}, "policy_reward_max": {"shared_policy": 2.0}, "policy_reward_mean": {"shared_policy": 0.3425}, "custom_metrics": {}, "hist_stats": {"episode_reward": [1.0, 1.0, 4.0, 1.0, 3.0, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 0.0, 3.0, 2.0, 0.0, 3.0, 1.0, 1.0, 0.0, 1.0, 2.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 2.0, 3.0, 2.0, 0.0, 2.0, 1.0, 2.0, 1.0, 1.0, 0.0, 3.0, 0.0, 0.0, 2.0, 1.0, 2.0, 0.0, 3.0, 1.0, 2.0, 2.0, 2.0, 2.0, 1.0, 1.0, 2.0, 1.0, 0.0, 0.0, 0.0, 4.0, 2.0, 1.0, 2.0, 2.0, 4.0, 2.0, 1.0, 3.0, 1.0, 1.0, 3.0, 2.0, 2.0, 0.0, 1.0, 2.0, 1.0, 4.0, 1.0, 1.0, 2.0, 3.0, 0.0, 1.0, 2.0, 1.0, 2.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 4.0, 3.0, 0.0, 0.0, 1.0, 1.0, 1.0, 3.0], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500], "policy_shared_policy_reward": [0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 2.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 2.0, 0.0, 1.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 2.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 2.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 2.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 2.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.13180023852850195, "mean_inference_ms": 0.3852641745510111, "mean_action_processing_ms": 0.028956500477971332, "mean_env_wait_ms": 0.40048763337283705, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 110880, "timesteps_this_iter": 0, "agent_timesteps_total": 443520, "timers": {"sample_time_ms": 5039.691, "sample_throughput": 1000.061, "load_time_ms": 0.137, "load_throughput": 36885870.11, "learn_time_ms": 121.224, "learn_throughput": 41575.82, "update_time_ms": 2.159}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 66.06890869140625, "policy_entropy": 7998.39501953125, "policy_loss": -15.737167924642563, "vf_loss": 14.39304369688034}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 110880, "num_agent_steps_sampled": 443520, "num_steps_trained": 110880, "num_agent_steps_trained": 443520, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 220, "training_iteration": 11, "trial_id": "71426_00000", "experiment_id": "84bca2f7b35f43248fca18d21abe2ebf", "date": "2024-06-12_02-47-42", "timestamp": 1718128062, "time_this_iter_s": 10.064112186431885, "time_total_s": 110.97696924209595, "pid": 363902, "hostname": "DESKTOP-LQ219J4", "node_ip": "192.168.46.185", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 20, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 5000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 500, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Base_Model", "custom_model_config": {"env": "rware", "env_args": {"n_agents": 4, "column_height": 1, "max_inactivity_steps": null, "max_steps": 500, "fast_obs": true, "msg_bits": 0, "sensor_range": 1, "shelf_rows": 1, "shelf_columns": 3, "request_queue_size": 4, "reward_type": "RewardType.INDIVIDUAL", "map_name": "customized_map", "map_size": "tiny", "difficulty": "medium"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": true, "force_coop": false, "local_mode": true, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 4, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 100, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64}, "algorithm": "ia2c", "space_obs": "Dict(obs:Box([-100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100.], [100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.], (112,), float32))", "space_act": "Discrete(5)", "num_agents": 4, "episode_limit": 500, "policy_mapping_info": {"all_scenario": {"description": "rware all scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2", "agent_3"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "rware_customized_map", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 10, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.IA2CTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_il.<locals>.<lambda> at 0x7f38086515e0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "grad_clip": 40.0, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "microbatch_size": null}, "time_since_restore": 110.97696924209595, "timesteps_since_restore": 0, "iterations_since_restore": 11, "perf": {"cpu_util_percent": 4.373333333333333, "ram_util_percent": 35.18666666666666}}
{"episode_reward_max": 5.0, "episode_reward_min": 0.0, "episode_reward_mean": 1.51, "episode_len_mean": 500.0, "episode_media": {}, "episodes_this_iter": 20, "policy_reward_min": {"shared_policy": 0.0}, "policy_reward_max": {"shared_policy": 2.0}, "policy_reward_mean": {"shared_policy": 0.3775}, "custom_metrics": {}, "hist_stats": {"episode_reward": [2.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 2.0, 3.0, 2.0, 0.0, 2.0, 1.0, 2.0, 1.0, 1.0, 0.0, 3.0, 0.0, 0.0, 2.0, 1.0, 2.0, 0.0, 3.0, 1.0, 2.0, 2.0, 2.0, 2.0, 1.0, 1.0, 2.0, 1.0, 0.0, 0.0, 0.0, 4.0, 2.0, 1.0, 2.0, 2.0, 4.0, 2.0, 1.0, 3.0, 1.0, 1.0, 3.0, 2.0, 2.0, 0.0, 1.0, 2.0, 1.0, 4.0, 1.0, 1.0, 2.0, 3.0, 0.0, 1.0, 2.0, 1.0, 2.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 4.0, 3.0, 0.0, 0.0, 1.0, 1.0, 1.0, 3.0, 2.0, 2.0, 1.0, 4.0, 1.0, 1.0, 0.0, 3.0, 2.0, 5.0, 1.0, 3.0, 4.0, 2.0, 0.0, 1.0, 1.0, 1.0, 1.0, 3.0], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500], "policy_shared_policy_reward": [1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 2.0, 0.0, 1.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 2.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 2.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 2.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 2.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 2.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 2.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.13189185170346904, "mean_inference_ms": 0.38507619332901766, "mean_action_processing_ms": 0.02893993471941779, "mean_env_wait_ms": 0.40039791985727613, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 120960, "timesteps_this_iter": 0, "agent_timesteps_total": 483840, "timers": {"sample_time_ms": 5044.605, "sample_throughput": 999.087, "load_time_ms": 0.139, "load_throughput": 36371803.441, "learn_time_ms": 121.881, "learn_throughput": 41351.751, "update_time_ms": 2.173}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 59.38092041015625, "policy_entropy": 7969.400146484375, "policy_loss": 7.37773722410202, "vf_loss": 19.526557445526123}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 120960, "num_agent_steps_sampled": 483840, "num_steps_trained": 120960, "num_agent_steps_trained": 483840, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 240, "training_iteration": 12, "trial_id": "71426_00000", "experiment_id": "84bca2f7b35f43248fca18d21abe2ebf", "date": "2024-06-12_02-47-52", "timestamp": 1718128072, "time_this_iter_s": 10.109628915786743, "time_total_s": 121.08659815788269, "pid": 363902, "hostname": "DESKTOP-LQ219J4", "node_ip": "192.168.46.185", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 20, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 5000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 500, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Base_Model", "custom_model_config": {"env": "rware", "env_args": {"n_agents": 4, "column_height": 1, "max_inactivity_steps": null, "max_steps": 500, "fast_obs": true, "msg_bits": 0, "sensor_range": 1, "shelf_rows": 1, "shelf_columns": 3, "request_queue_size": 4, "reward_type": "RewardType.INDIVIDUAL", "map_name": "customized_map", "map_size": "tiny", "difficulty": "medium"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": true, "force_coop": false, "local_mode": true, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 4, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 100, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64}, "algorithm": "ia2c", "space_obs": "Dict(obs:Box([-100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100.], [100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.], (112,), float32))", "space_act": "Discrete(5)", "num_agents": 4, "episode_limit": 500, "policy_mapping_info": {"all_scenario": {"description": "rware all scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2", "agent_3"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "rware_customized_map", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 10, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.IA2CTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_il.<locals>.<lambda> at 0x7f38086518b0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "grad_clip": 40.0, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "microbatch_size": null}, "time_since_restore": 121.08659815788269, "timesteps_since_restore": 0, "iterations_since_restore": 12, "perf": {"cpu_util_percent": 4.521428571428571, "ram_util_percent": 35.449999999999996}}
{"episode_reward_max": 5.0, "episode_reward_min": 0.0, "episode_reward_mean": 1.62, "episode_len_mean": 500.0, "episode_media": {}, "episodes_this_iter": 20, "policy_reward_min": {"shared_policy": 0.0}, "policy_reward_max": {"shared_policy": 2.0}, "policy_reward_mean": {"shared_policy": 0.405}, "custom_metrics": {}, "hist_stats": {"episode_reward": [2.0, 1.0, 2.0, 0.0, 3.0, 1.0, 2.0, 2.0, 2.0, 2.0, 1.0, 1.0, 2.0, 1.0, 0.0, 0.0, 0.0, 4.0, 2.0, 1.0, 2.0, 2.0, 4.0, 2.0, 1.0, 3.0, 1.0, 1.0, 3.0, 2.0, 2.0, 0.0, 1.0, 2.0, 1.0, 4.0, 1.0, 1.0, 2.0, 3.0, 0.0, 1.0, 2.0, 1.0, 2.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 4.0, 3.0, 0.0, 0.0, 1.0, 1.0, 1.0, 3.0, 2.0, 2.0, 1.0, 4.0, 1.0, 1.0, 0.0, 3.0, 2.0, 5.0, 1.0, 3.0, 4.0, 2.0, 0.0, 1.0, 1.0, 1.0, 1.0, 3.0, 1.0, 2.0, 3.0, 1.0, 1.0, 1.0, 1.0, 2.0, 2.0, 1.0, 1.0, 2.0, 3.0, 1.0, 2.0, 1.0, 3.0, 3.0, 0.0, 2.0], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500], "policy_shared_policy_reward": [1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 2.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 2.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 2.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 2.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 2.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 2.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 2.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.13202010678161644, "mean_inference_ms": 0.3850831589076698, "mean_action_processing_ms": 0.0289349164027078, "mean_env_wait_ms": 0.4002674695078133, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 131040, "timesteps_this_iter": 0, "agent_timesteps_total": 524160, "timers": {"sample_time_ms": 5042.338, "sample_throughput": 999.536, "load_time_ms": 0.137, "load_throughput": 36860143.261, "learn_time_ms": 122.879, "learn_throughput": 41016.109, "update_time_ms": 2.175}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 135.40626525878906, "policy_entropy": 7965.4853515625, "policy_loss": 7.592604637145996, "vf_loss": 14.488763153553009}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 131040, "num_agent_steps_sampled": 524160, "num_steps_trained": 131040, "num_agent_steps_trained": 524160, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 260, "training_iteration": 13, "trial_id": "71426_00000", "experiment_id": "84bca2f7b35f43248fca18d21abe2ebf", "date": "2024-06-12_02-48-02", "timestamp": 1718128082, "time_this_iter_s": 10.009265661239624, "time_total_s": 131.09586381912231, "pid": 363902, "hostname": "DESKTOP-LQ219J4", "node_ip": "192.168.46.185", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 20, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 5000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 500, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Base_Model", "custom_model_config": {"env": "rware", "env_args": {"n_agents": 4, "column_height": 1, "max_inactivity_steps": null, "max_steps": 500, "fast_obs": true, "msg_bits": 0, "sensor_range": 1, "shelf_rows": 1, "shelf_columns": 3, "request_queue_size": 4, "reward_type": "RewardType.INDIVIDUAL", "map_name": "customized_map", "map_size": "tiny", "difficulty": "medium"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": true, "force_coop": false, "local_mode": true, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 4, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 100, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64}, "algorithm": "ia2c", "space_obs": "Dict(obs:Box([-100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100.], [100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.], (112,), float32))", "space_act": "Discrete(5)", "num_agents": 4, "episode_limit": 500, "policy_mapping_info": {"all_scenario": {"description": "rware all scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2", "agent_3"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "rware_customized_map", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 10, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.IA2CTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_il.<locals>.<lambda> at 0x7f38086c10d0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "grad_clip": 40.0, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "microbatch_size": null}, "time_since_restore": 131.09586381912231, "timesteps_since_restore": 0, "iterations_since_restore": 13, "perf": {"cpu_util_percent": 4.153333333333334, "ram_util_percent": 35.81333333333334}}
{"episode_reward_max": 5.0, "episode_reward_min": 0.0, "episode_reward_mean": 1.69, "episode_len_mean": 500.0, "episode_media": {}, "episodes_this_iter": 20, "policy_reward_min": {"shared_policy": 0.0}, "policy_reward_max": {"shared_policy": 2.0}, "policy_reward_mean": {"shared_policy": 0.4225}, "custom_metrics": {}, "hist_stats": {"episode_reward": [2.0, 2.0, 4.0, 2.0, 1.0, 3.0, 1.0, 1.0, 3.0, 2.0, 2.0, 0.0, 1.0, 2.0, 1.0, 4.0, 1.0, 1.0, 2.0, 3.0, 0.0, 1.0, 2.0, 1.0, 2.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 4.0, 3.0, 0.0, 0.0, 1.0, 1.0, 1.0, 3.0, 2.0, 2.0, 1.0, 4.0, 1.0, 1.0, 0.0, 3.0, 2.0, 5.0, 1.0, 3.0, 4.0, 2.0, 0.0, 1.0, 1.0, 1.0, 1.0, 3.0, 1.0, 2.0, 3.0, 1.0, 1.0, 1.0, 1.0, 2.0, 2.0, 1.0, 1.0, 2.0, 3.0, 1.0, 2.0, 1.0, 3.0, 3.0, 0.0, 2.0, 3.0, 3.0, 3.0, 0.0, 2.0, 2.0, 0.0, 1.0, 3.0, 4.0, 2.0, 3.0, 2.0, 1.0, 1.0, 1.0, 0.0, 2.0, 1.0, 2.0], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500], "policy_shared_policy_reward": [1.0, 0.0, 1.0, 0.0, 2.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 2.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 2.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 2.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 2.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 2.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 2.0, 0.0, 0.0, 2.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.13212537056493345, "mean_inference_ms": 0.38503703952985674, "mean_action_processing_ms": 0.02892352383660751, "mean_env_wait_ms": 0.40013983181671153, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 141120, "timesteps_this_iter": 0, "agent_timesteps_total": 564480, "timers": {"sample_time_ms": 5050.033, "sample_throughput": 998.013, "load_time_ms": 0.139, "load_throughput": 36346788.446, "learn_time_ms": 124.108, "learn_throughput": 40609.774, "update_time_ms": 2.195}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 112.91404724121094, "policy_entropy": 7978.7109375, "policy_loss": 46.995344400405884, "vf_loss": 21.82201337814331}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 141120, "num_agent_steps_sampled": 564480, "num_steps_trained": 141120, "num_agent_steps_trained": 564480, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 280, "training_iteration": 14, "trial_id": "71426_00000", "experiment_id": "84bca2f7b35f43248fca18d21abe2ebf", "date": "2024-06-12_02-48-12", "timestamp": 1718128092, "time_this_iter_s": 10.154948949813843, "time_total_s": 141.25081276893616, "pid": 363902, "hostname": "DESKTOP-LQ219J4", "node_ip": "192.168.46.185", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 20, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 5000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 500, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Base_Model", "custom_model_config": {"env": "rware", "env_args": {"n_agents": 4, "column_height": 1, "max_inactivity_steps": null, "max_steps": 500, "fast_obs": true, "msg_bits": 0, "sensor_range": 1, "shelf_rows": 1, "shelf_columns": 3, "request_queue_size": 4, "reward_type": "RewardType.INDIVIDUAL", "map_name": "customized_map", "map_size": "tiny", "difficulty": "medium"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": true, "force_coop": false, "local_mode": true, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 4, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 100, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64}, "algorithm": "ia2c", "space_obs": "Dict(obs:Box([-100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100.], [100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.], (112,), float32))", "space_act": "Discrete(5)", "num_agents": 4, "episode_limit": 500, "policy_mapping_info": {"all_scenario": {"description": "rware all scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2", "agent_3"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "rware_customized_map", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 10, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.IA2CTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_il.<locals>.<lambda> at 0x7f3808651dc0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "grad_clip": 40.0, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "microbatch_size": null}, "time_since_restore": 141.25081276893616, "timesteps_since_restore": 0, "iterations_since_restore": 14, "perf": {"cpu_util_percent": 4.250000000000001, "ram_util_percent": 36.057142857142864}}
{"episode_reward_max": 7.0, "episode_reward_min": 0.0, "episode_reward_mean": 1.83, "episode_len_mean": 500.0, "episode_media": {}, "episodes_this_iter": 20, "policy_reward_min": {"shared_policy": 0.0}, "policy_reward_max": {"shared_policy": 3.0}, "policy_reward_mean": {"shared_policy": 0.4575}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 1.0, 2.0, 1.0, 2.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 4.0, 3.0, 0.0, 0.0, 1.0, 1.0, 1.0, 3.0, 2.0, 2.0, 1.0, 4.0, 1.0, 1.0, 0.0, 3.0, 2.0, 5.0, 1.0, 3.0, 4.0, 2.0, 0.0, 1.0, 1.0, 1.0, 1.0, 3.0, 1.0, 2.0, 3.0, 1.0, 1.0, 1.0, 1.0, 2.0, 2.0, 1.0, 1.0, 2.0, 3.0, 1.0, 2.0, 1.0, 3.0, 3.0, 0.0, 2.0, 3.0, 3.0, 3.0, 0.0, 2.0, 2.0, 0.0, 1.0, 3.0, 4.0, 2.0, 3.0, 2.0, 1.0, 1.0, 1.0, 0.0, 2.0, 1.0, 2.0, 0.0, 1.0, 2.0, 1.0, 2.0, 7.0, 4.0, 2.0, 3.0, 0.0, 3.0, 2.0, 1.0, 4.0, 1.0, 3.0, 5.0, 6.0, 2.0, 3.0], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500], "policy_shared_policy_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 2.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 2.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 2.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 2.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 2.0, 0.0, 0.0, 2.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 3.0, 3.0, 1.0, 0.0, 1.0, 2.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 2.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 2.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 3.0, 0.0, 1.0, 0.0, 3.0, 2.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.132232346482522, "mean_inference_ms": 0.3850188482332356, "mean_action_processing_ms": 0.028914032399485604, "mean_env_wait_ms": 0.3999995393645173, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 151200, "timesteps_this_iter": 0, "agent_timesteps_total": 604800, "timers": {"sample_time_ms": 5052.555, "sample_throughput": 997.515, "load_time_ms": 0.141, "load_throughput": 35720331.463, "learn_time_ms": 124.484, "learn_throughput": 40487.087, "update_time_ms": 2.175}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 154.4335479736328, "policy_entropy": 7976.21728515625, "policy_loss": 3.7196812629699707, "vf_loss": 19.195452213287354}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 151200, "num_agent_steps_sampled": 604800, "num_steps_trained": 151200, "num_agent_steps_trained": 604800, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 300, "training_iteration": 15, "trial_id": "71426_00000", "experiment_id": "84bca2f7b35f43248fca18d21abe2ebf", "date": "2024-06-12_02-48-22", "timestamp": 1718128102, "time_this_iter_s": 10.111739158630371, "time_total_s": 151.36255192756653, "pid": 363902, "hostname": "DESKTOP-LQ219J4", "node_ip": "192.168.46.185", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 20, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 5000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 500, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Base_Model", "custom_model_config": {"env": "rware", "env_args": {"n_agents": 4, "column_height": 1, "max_inactivity_steps": null, "max_steps": 500, "fast_obs": true, "msg_bits": 0, "sensor_range": 1, "shelf_rows": 1, "shelf_columns": 3, "request_queue_size": 4, "reward_type": "RewardType.INDIVIDUAL", "map_name": "customized_map", "map_size": "tiny", "difficulty": "medium"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": true, "force_coop": false, "local_mode": true, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 4, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 100, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64}, "algorithm": "ia2c", "space_obs": "Dict(obs:Box([-100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100.], [100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.], (112,), float32))", "space_act": "Discrete(5)", "num_agents": 4, "episode_limit": 500, "policy_mapping_info": {"all_scenario": {"description": "rware all scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2", "agent_3"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "rware_customized_map", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 10, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.IA2CTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_il.<locals>.<lambda> at 0x7f38086c1c10>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "grad_clip": 40.0, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "microbatch_size": null}, "time_since_restore": 151.36255192756653, "timesteps_since_restore": 0, "iterations_since_restore": 15, "perf": {"cpu_util_percent": 4.266666666666667, "ram_util_percent": 36.36666666666666}}
{"episode_reward_max": 7.0, "episode_reward_min": 0.0, "episode_reward_mean": 2.01, "episode_len_mean": 500.0, "episode_media": {}, "episodes_this_iter": 20, "policy_reward_min": {"shared_policy": 0.0}, "policy_reward_max": {"shared_policy": 3.0}, "policy_reward_mean": {"shared_policy": 0.5025}, "custom_metrics": {}, "hist_stats": {"episode_reward": [2.0, 2.0, 1.0, 4.0, 1.0, 1.0, 0.0, 3.0, 2.0, 5.0, 1.0, 3.0, 4.0, 2.0, 0.0, 1.0, 1.0, 1.0, 1.0, 3.0, 1.0, 2.0, 3.0, 1.0, 1.0, 1.0, 1.0, 2.0, 2.0, 1.0, 1.0, 2.0, 3.0, 1.0, 2.0, 1.0, 3.0, 3.0, 0.0, 2.0, 3.0, 3.0, 3.0, 0.0, 2.0, 2.0, 0.0, 1.0, 3.0, 4.0, 2.0, 3.0, 2.0, 1.0, 1.0, 1.0, 0.0, 2.0, 1.0, 2.0, 0.0, 1.0, 2.0, 1.0, 2.0, 7.0, 4.0, 2.0, 3.0, 0.0, 3.0, 2.0, 1.0, 4.0, 1.0, 3.0, 5.0, 6.0, 2.0, 3.0, 1.0, 3.0, 4.0, 3.0, 1.0, 3.0, 5.0, 1.0, 0.0, 5.0, 1.0, 2.0, 1.0, 1.0, 2.0, 3.0, 3.0, 0.0, 1.0, 2.0], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500], "policy_shared_policy_reward": [0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 2.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 2.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 2.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 2.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 2.0, 0.0, 0.0, 2.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 3.0, 3.0, 1.0, 0.0, 1.0, 2.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 2.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 2.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 3.0, 0.0, 1.0, 0.0, 3.0, 2.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 2.0, 0.0, 2.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 2.0, 0.0, 1.0, 1.0, 2.0, 2.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 2.0, 0.0, 2.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.13221896501328353, "mean_inference_ms": 0.38509573436245276, "mean_action_processing_ms": 0.02891086334770077, "mean_env_wait_ms": 0.4000935636586522, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 161280, "timesteps_this_iter": 0, "agent_timesteps_total": 645120, "timers": {"sample_time_ms": 5069.766, "sample_throughput": 994.129, "load_time_ms": 0.142, "load_throughput": 35486473.325, "learn_time_ms": 124.567, "learn_throughput": 40460.299, "update_time_ms": 2.2}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 254.9503173828125, "policy_entropy": 7936.885009765625, "policy_loss": 1.1353635787963867, "vf_loss": 19.076092958450317}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 161280, "num_agent_steps_sampled": 645120, "num_steps_trained": 161280, "num_agent_steps_trained": 645120, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 320, "training_iteration": 16, "trial_id": "71426_00000", "experiment_id": "84bca2f7b35f43248fca18d21abe2ebf", "date": "2024-06-12_02-48-32", "timestamp": 1718128112, "time_this_iter_s": 10.233887910842896, "time_total_s": 161.59643983840942, "pid": 363902, "hostname": "DESKTOP-LQ219J4", "node_ip": "192.168.46.185", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 20, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 5000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 500, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Base_Model", "custom_model_config": {"env": "rware", "env_args": {"n_agents": 4, "column_height": 1, "max_inactivity_steps": null, "max_steps": 500, "fast_obs": true, "msg_bits": 0, "sensor_range": 1, "shelf_rows": 1, "shelf_columns": 3, "request_queue_size": 4, "reward_type": "RewardType.INDIVIDUAL", "map_name": "customized_map", "map_size": "tiny", "difficulty": "medium"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": true, "force_coop": false, "local_mode": true, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 4, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 100, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64}, "algorithm": "ia2c", "space_obs": "Dict(obs:Box([-100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100.], [100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.], (112,), float32))", "space_act": "Discrete(5)", "num_agents": 4, "episode_limit": 500, "policy_mapping_info": {"all_scenario": {"description": "rware all scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2", "agent_3"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "rware_customized_map", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 10, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.IA2CTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_il.<locals>.<lambda> at 0x7f38081d5e50>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "grad_clip": 40.0, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "microbatch_size": null}, "time_since_restore": 161.59643983840942, "timesteps_since_restore": 0, "iterations_since_restore": 16, "perf": {"cpu_util_percent": 4.15, "ram_util_percent": 36.60000000000001}}
{"episode_reward_max": 7.0, "episode_reward_min": 0.0, "episode_reward_mean": 1.86, "episode_len_mean": 500.0, "episode_media": {}, "episodes_this_iter": 20, "policy_reward_min": {"shared_policy": 0.0}, "policy_reward_max": {"shared_policy": 3.0}, "policy_reward_mean": {"shared_policy": 0.465}, "custom_metrics": {}, "hist_stats": {"episode_reward": [1.0, 2.0, 3.0, 1.0, 1.0, 1.0, 1.0, 2.0, 2.0, 1.0, 1.0, 2.0, 3.0, 1.0, 2.0, 1.0, 3.0, 3.0, 0.0, 2.0, 3.0, 3.0, 3.0, 0.0, 2.0, 2.0, 0.0, 1.0, 3.0, 4.0, 2.0, 3.0, 2.0, 1.0, 1.0, 1.0, 0.0, 2.0, 1.0, 2.0, 0.0, 1.0, 2.0, 1.0, 2.0, 7.0, 4.0, 2.0, 3.0, 0.0, 3.0, 2.0, 1.0, 4.0, 1.0, 3.0, 5.0, 6.0, 2.0, 3.0, 1.0, 3.0, 4.0, 3.0, 1.0, 3.0, 5.0, 1.0, 0.0, 5.0, 1.0, 2.0, 1.0, 1.0, 2.0, 3.0, 3.0, 0.0, 1.0, 2.0, 2.0, 2.0, 0.0, 3.0, 0.0, 1.0, 1.0, 0.0, 2.0, 1.0, 0.0, 0.0, 0.0, 1.0, 2.0, 2.0, 2.0, 3.0, 1.0, 0.0], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500], "policy_shared_policy_reward": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 2.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 2.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 2.0, 0.0, 0.0, 2.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 3.0, 3.0, 1.0, 0.0, 1.0, 2.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 2.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 2.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 3.0, 0.0, 1.0, 0.0, 3.0, 2.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 2.0, 0.0, 2.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 2.0, 0.0, 1.0, 1.0, 2.0, 2.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 2.0, 0.0, 2.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.13220046670382968, "mean_inference_ms": 0.3851724182446453, "mean_action_processing_ms": 0.02891015007024678, "mean_env_wait_ms": 0.40020077009403066, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 171360, "timesteps_this_iter": 0, "agent_timesteps_total": 685440, "timers": {"sample_time_ms": 5072.351, "sample_throughput": 993.622, "load_time_ms": 0.142, "load_throughput": 35618015.434, "learn_time_ms": 124.939, "learn_throughput": 40339.759, "update_time_ms": 2.216}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 81.19725036621094, "policy_entropy": 7933.767822265625, "policy_loss": -6.940022230148315, "vf_loss": 13.906153917312622}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 171360, "num_agent_steps_sampled": 685440, "num_steps_trained": 171360, "num_agent_steps_trained": 685440, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 340, "training_iteration": 17, "trial_id": "71426_00000", "experiment_id": "84bca2f7b35f43248fca18d21abe2ebf", "date": "2024-06-12_02-48-43", "timestamp": 1718128123, "time_this_iter_s": 10.134000539779663, "time_total_s": 171.7304403781891, "pid": 363902, "hostname": "DESKTOP-LQ219J4", "node_ip": "192.168.46.185", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 20, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 5000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 500, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Base_Model", "custom_model_config": {"env": "rware", "env_args": {"n_agents": 4, "column_height": 1, "max_inactivity_steps": null, "max_steps": 500, "fast_obs": true, "msg_bits": 0, "sensor_range": 1, "shelf_rows": 1, "shelf_columns": 3, "request_queue_size": 4, "reward_type": "RewardType.INDIVIDUAL", "map_name": "customized_map", "map_size": "tiny", "difficulty": "medium"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": true, "force_coop": false, "local_mode": true, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 4, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 100, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64}, "algorithm": "ia2c", "space_obs": "Dict(obs:Box([-100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100.], [100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.], (112,), float32))", "space_act": "Discrete(5)", "num_agents": 4, "episode_limit": 500, "policy_mapping_info": {"all_scenario": {"description": "rware all scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2", "agent_3"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "rware_customized_map", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 10, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.IA2CTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_il.<locals>.<lambda> at 0x7f38082f8dc0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "grad_clip": 40.0, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "microbatch_size": null}, "time_since_restore": 171.7304403781891, "timesteps_since_restore": 0, "iterations_since_restore": 17, "perf": {"cpu_util_percent": 4.153333333333333, "ram_util_percent": 36.91333333333333}}
{"episode_reward_max": 7.0, "episode_reward_min": 0.0, "episode_reward_mean": 1.82, "episode_len_mean": 500.0, "episode_media": {}, "episodes_this_iter": 20, "policy_reward_min": {"shared_policy": 0.0}, "policy_reward_max": {"shared_policy": 3.0}, "policy_reward_mean": {"shared_policy": 0.455}, "custom_metrics": {}, "hist_stats": {"episode_reward": [3.0, 3.0, 3.0, 0.0, 2.0, 2.0, 0.0, 1.0, 3.0, 4.0, 2.0, 3.0, 2.0, 1.0, 1.0, 1.0, 0.0, 2.0, 1.0, 2.0, 0.0, 1.0, 2.0, 1.0, 2.0, 7.0, 4.0, 2.0, 3.0, 0.0, 3.0, 2.0, 1.0, 4.0, 1.0, 3.0, 5.0, 6.0, 2.0, 3.0, 1.0, 3.0, 4.0, 3.0, 1.0, 3.0, 5.0, 1.0, 0.0, 5.0, 1.0, 2.0, 1.0, 1.0, 2.0, 3.0, 3.0, 0.0, 1.0, 2.0, 2.0, 2.0, 0.0, 3.0, 0.0, 1.0, 1.0, 0.0, 2.0, 1.0, 0.0, 0.0, 0.0, 1.0, 2.0, 2.0, 2.0, 3.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 4.0, 3.0, 1.0, 1.0, 0.0, 1.0, 3.0, 2.0, 2.0, 2.0, 0.0, 2.0, 2.0, 0.0, 2.0, 2.0], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500], "policy_shared_policy_reward": [0.0, 0.0, 2.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 2.0, 0.0, 0.0, 2.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 3.0, 3.0, 1.0, 0.0, 1.0, 2.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 2.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 2.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 3.0, 0.0, 1.0, 0.0, 3.0, 2.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 2.0, 0.0, 2.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 2.0, 0.0, 1.0, 1.0, 2.0, 2.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 2.0, 0.0, 2.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 2.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.1321823092072317, "mean_inference_ms": 0.3852382103291872, "mean_action_processing_ms": 0.0289090155797095, "mean_env_wait_ms": 0.4003650955868679, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 181440, "timesteps_this_iter": 0, "agent_timesteps_total": 725760, "timers": {"sample_time_ms": 5072.907, "sample_throughput": 993.513, "load_time_ms": 0.145, "load_throughput": 34705782.564, "learn_time_ms": 123.874, "learn_throughput": 40686.654, "update_time_ms": 2.238}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 57.600318908691406, "policy_entropy": 7991.0155029296875, "policy_loss": 12.683137580752373, "vf_loss": 14.238853216171265}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 181440, "num_agent_steps_sampled": 725760, "num_steps_trained": 181440, "num_agent_steps_trained": 725760, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 360, "training_iteration": 18, "trial_id": "71426_00000", "experiment_id": "84bca2f7b35f43248fca18d21abe2ebf", "date": "2024-06-12_02-48-53", "timestamp": 1718128133, "time_this_iter_s": 10.015177726745605, "time_total_s": 181.7456181049347, "pid": 363902, "hostname": "DESKTOP-LQ219J4", "node_ip": "192.168.46.185", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 20, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 5000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 500, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Base_Model", "custom_model_config": {"env": "rware", "env_args": {"n_agents": 4, "column_height": 1, "max_inactivity_steps": null, "max_steps": 500, "fast_obs": true, "msg_bits": 0, "sensor_range": 1, "shelf_rows": 1, "shelf_columns": 3, "request_queue_size": 4, "reward_type": "RewardType.INDIVIDUAL", "map_name": "customized_map", "map_size": "tiny", "difficulty": "medium"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": true, "force_coop": false, "local_mode": true, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 4, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 100, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64}, "algorithm": "ia2c", "space_obs": "Dict(obs:Box([-100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100.], [100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.], (112,), float32))", "space_act": "Discrete(5)", "num_agents": 4, "episode_limit": 500, "policy_mapping_info": {"all_scenario": {"description": "rware all scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2", "agent_3"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "rware_customized_map", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 10, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.IA2CTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_il.<locals>.<lambda> at 0x7f38086450d0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "grad_clip": 40.0, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "microbatch_size": null}, "time_since_restore": 181.7456181049347, "timesteps_since_restore": 0, "iterations_since_restore": 18, "perf": {"cpu_util_percent": 4.042857142857143, "ram_util_percent": 37.14999999999999}}
{"episode_reward_max": 7.0, "episode_reward_min": 0.0, "episode_reward_mean": 1.71, "episode_len_mean": 500.0, "episode_media": {}, "episodes_this_iter": 20, "policy_reward_min": {"shared_policy": 0.0}, "policy_reward_max": {"shared_policy": 3.0}, "policy_reward_mean": {"shared_policy": 0.4275}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 1.0, 2.0, 1.0, 2.0, 7.0, 4.0, 2.0, 3.0, 0.0, 3.0, 2.0, 1.0, 4.0, 1.0, 3.0, 5.0, 6.0, 2.0, 3.0, 1.0, 3.0, 4.0, 3.0, 1.0, 3.0, 5.0, 1.0, 0.0, 5.0, 1.0, 2.0, 1.0, 1.0, 2.0, 3.0, 3.0, 0.0, 1.0, 2.0, 2.0, 2.0, 0.0, 3.0, 0.0, 1.0, 1.0, 0.0, 2.0, 1.0, 0.0, 0.0, 0.0, 1.0, 2.0, 2.0, 2.0, 3.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 4.0, 3.0, 1.0, 1.0, 0.0, 1.0, 3.0, 2.0, 2.0, 2.0, 0.0, 2.0, 2.0, 0.0, 2.0, 2.0, 3.0, 2.0, 0.0, 1.0, 3.0, 3.0, 2.0, 2.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 2.0], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500], "policy_shared_policy_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 3.0, 3.0, 1.0, 0.0, 1.0, 2.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 2.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 2.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 3.0, 0.0, 1.0, 0.0, 3.0, 2.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 2.0, 0.0, 2.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 2.0, 0.0, 1.0, 1.0, 2.0, 2.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 2.0, 0.0, 2.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 2.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 2.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.13220301678236707, "mean_inference_ms": 0.3854049958644651, "mean_action_processing_ms": 0.028918007196708357, "mean_env_wait_ms": 0.4005755003073625, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 191520, "timesteps_this_iter": 0, "agent_timesteps_total": 766080, "timers": {"sample_time_ms": 5096.425, "sample_throughput": 988.929, "load_time_ms": 0.146, "load_throughput": 34490605.58, "learn_time_ms": 124.774, "learn_throughput": 40392.906, "update_time_ms": 2.257}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 91.62138366699219, "policy_entropy": 7979.90869140625, "policy_loss": 2.5501580238342285, "vf_loss": 14.30643606185913}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 191520, "num_agent_steps_sampled": 766080, "num_steps_trained": 191520, "num_agent_steps_trained": 766080, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 380, "training_iteration": 19, "trial_id": "71426_00000", "experiment_id": "84bca2f7b35f43248fca18d21abe2ebf", "date": "2024-06-12_02-49-03", "timestamp": 1718128143, "time_this_iter_s": 10.398958444595337, "time_total_s": 192.14457654953003, "pid": 363902, "hostname": "DESKTOP-LQ219J4", "node_ip": "192.168.46.185", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 20, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 5000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 500, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Base_Model", "custom_model_config": {"env": "rware", "env_args": {"n_agents": 4, "column_height": 1, "max_inactivity_steps": null, "max_steps": 500, "fast_obs": true, "msg_bits": 0, "sensor_range": 1, "shelf_rows": 1, "shelf_columns": 3, "request_queue_size": 4, "reward_type": "RewardType.INDIVIDUAL", "map_name": "customized_map", "map_size": "tiny", "difficulty": "medium"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": true, "force_coop": false, "local_mode": true, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 4, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 100, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64}, "algorithm": "ia2c", "space_obs": "Dict(obs:Box([-100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100.], [100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.], (112,), float32))", "space_act": "Discrete(5)", "num_agents": 4, "episode_limit": 500, "policy_mapping_info": {"all_scenario": {"description": "rware all scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2", "agent_3"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "rware_customized_map", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 10, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.IA2CTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_il.<locals>.<lambda> at 0x7f3808651af0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "grad_clip": 40.0, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "microbatch_size": null}, "time_since_restore": 192.14457654953003, "timesteps_since_restore": 0, "iterations_since_restore": 19, "perf": {"cpu_util_percent": 4.533333333333333, "ram_util_percent": 37.480000000000004}}
{"episode_reward_max": 5.0, "episode_reward_min": 0.0, "episode_reward_mean": 1.54, "episode_len_mean": 500.0, "episode_media": {}, "episodes_this_iter": 20, "policy_reward_min": {"shared_policy": 0.0}, "policy_reward_max": {"shared_policy": 2.0}, "policy_reward_mean": {"shared_policy": 0.385}, "custom_metrics": {}, "hist_stats": {"episode_reward": [1.0, 3.0, 4.0, 3.0, 1.0, 3.0, 5.0, 1.0, 0.0, 5.0, 1.0, 2.0, 1.0, 1.0, 2.0, 3.0, 3.0, 0.0, 1.0, 2.0, 2.0, 2.0, 0.0, 3.0, 0.0, 1.0, 1.0, 0.0, 2.0, 1.0, 0.0, 0.0, 0.0, 1.0, 2.0, 2.0, 2.0, 3.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 4.0, 3.0, 1.0, 1.0, 0.0, 1.0, 3.0, 2.0, 2.0, 2.0, 0.0, 2.0, 2.0, 0.0, 2.0, 2.0, 3.0, 2.0, 0.0, 1.0, 3.0, 3.0, 2.0, 2.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 2.0, 2.0, 2.0, 2.0, 2.0, 1.0, 1.0, 2.0, 2.0, 1.0, 3.0, 2.0, 3.0, 0.0, 4.0, 3.0, 0.0, 0.0, 3.0, 1.0, 1.0], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500], "policy_shared_policy_reward": [0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 2.0, 0.0, 2.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 2.0, 0.0, 1.0, 1.0, 2.0, 2.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 2.0, 0.0, 2.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 2.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 2.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 2.0, 0.0, 1.0, 0.0, 1.0, 1.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 2.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 2.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.13227595356063637, "mean_inference_ms": 0.3857264454629584, "mean_action_processing_ms": 0.0289358882300525, "mean_env_wait_ms": 0.4008798142788275, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 201600, "timesteps_this_iter": 0, "agent_timesteps_total": 806400, "timers": {"sample_time_ms": 5132.439, "sample_throughput": 981.989, "load_time_ms": 0.146, "load_throughput": 34603522.933, "learn_time_ms": 125.108, "learn_throughput": 40285.139, "update_time_ms": 2.298}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 98.1098403930664, "policy_entropy": 7949.3079833984375, "policy_loss": 43.82550612092018, "vf_loss": 24.04227566719055}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 201600, "num_agent_steps_sampled": 806400, "num_steps_trained": 201600, "num_agent_steps_trained": 806400, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 400, "training_iteration": 20, "trial_id": "71426_00000", "experiment_id": "84bca2f7b35f43248fca18d21abe2ebf", "date": "2024-06-12_02-49-14", "timestamp": 1718128154, "time_this_iter_s": 10.466217994689941, "time_total_s": 202.61079454421997, "pid": 363902, "hostname": "DESKTOP-LQ219J4", "node_ip": "192.168.46.185", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 20, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 5000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 500, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Base_Model", "custom_model_config": {"env": "rware", "env_args": {"n_agents": 4, "column_height": 1, "max_inactivity_steps": null, "max_steps": 500, "fast_obs": true, "msg_bits": 0, "sensor_range": 1, "shelf_rows": 1, "shelf_columns": 3, "request_queue_size": 4, "reward_type": "RewardType.INDIVIDUAL", "map_name": "customized_map", "map_size": "tiny", "difficulty": "medium"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": true, "force_coop": false, "local_mode": true, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 4, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 100, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64}, "algorithm": "ia2c", "space_obs": "Dict(obs:Box([-100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100.], [100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.], (112,), float32))", "space_act": "Discrete(5)", "num_agents": 4, "episode_limit": 500, "policy_mapping_info": {"all_scenario": {"description": "rware all scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2", "agent_3"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "rware_customized_map", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 10, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.IA2CTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_il.<locals>.<lambda> at 0x7f38082f8820>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "grad_clip": 40.0, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "microbatch_size": null}, "time_since_restore": 202.61079454421997, "timesteps_since_restore": 0, "iterations_since_restore": 20, "perf": {"cpu_util_percent": 4.353333333333334, "ram_util_percent": 37.76666666666667}}
{"episode_reward_max": 6.0, "episode_reward_min": 0.0, "episode_reward_mean": 1.65, "episode_len_mean": 500.0, "episode_media": {}, "episodes_this_iter": 20, "policy_reward_min": {"shared_policy": 0.0}, "policy_reward_max": {"shared_policy": 3.0}, "policy_reward_mean": {"shared_policy": 0.4125}, "custom_metrics": {}, "hist_stats": {"episode_reward": [2.0, 2.0, 0.0, 3.0, 0.0, 1.0, 1.0, 0.0, 2.0, 1.0, 0.0, 0.0, 0.0, 1.0, 2.0, 2.0, 2.0, 3.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 4.0, 3.0, 1.0, 1.0, 0.0, 1.0, 3.0, 2.0, 2.0, 2.0, 0.0, 2.0, 2.0, 0.0, 2.0, 2.0, 3.0, 2.0, 0.0, 1.0, 3.0, 3.0, 2.0, 2.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 2.0, 2.0, 2.0, 2.0, 2.0, 1.0, 1.0, 2.0, 2.0, 1.0, 3.0, 2.0, 3.0, 0.0, 4.0, 3.0, 0.0, 0.0, 3.0, 1.0, 1.0, 3.0, 6.0, 0.0, 3.0, 2.0, 2.0, 2.0, 3.0, 3.0, 0.0, 3.0, 6.0, 5.0, 1.0, 3.0, 4.0, 2.0, 1.0, 1.0, 3.0], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500], "policy_shared_policy_reward": [0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 2.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 2.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 2.0, 0.0, 1.0, 0.0, 1.0, 1.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 2.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 2.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 2.0, 2.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 2.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 2.0, 1.0, 2.0, 1.0, 0.0, 2.0, 0.0, 3.0, 1.0, 0.0, 0.0, 0.0, 2.0, 0.0, 1.0, 0.0, 0.0, 2.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 2.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.13233561804563848, "mean_inference_ms": 0.38600774556772555, "mean_action_processing_ms": 0.028951722507955607, "mean_env_wait_ms": 0.40113157171538316, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 211680, "timesteps_this_iter": 0, "agent_timesteps_total": 846720, "timers": {"sample_time_ms": 5128.753, "sample_throughput": 982.695, "load_time_ms": 0.145, "load_throughput": 34866059.97, "learn_time_ms": 125.629, "learn_throughput": 40118.02, "update_time_ms": 2.317}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 124.97679138183594, "policy_entropy": 7946.621826171875, "policy_loss": -16.790535986423492, "vf_loss": 17.98291826248169}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 211680, "num_agent_steps_sampled": 846720, "num_steps_trained": 211680, "num_agent_steps_trained": 846720, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 420, "training_iteration": 21, "trial_id": "71426_00000", "experiment_id": "84bca2f7b35f43248fca18d21abe2ebf", "date": "2024-06-12_02-49-24", "timestamp": 1718128164, "time_this_iter_s": 10.200780630111694, "time_total_s": 212.81157517433167, "pid": 363902, "hostname": "DESKTOP-LQ219J4", "node_ip": "192.168.46.185", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 20, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 5000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 500, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Base_Model", "custom_model_config": {"env": "rware", "env_args": {"n_agents": 4, "column_height": 1, "max_inactivity_steps": null, "max_steps": 500, "fast_obs": true, "msg_bits": 0, "sensor_range": 1, "shelf_rows": 1, "shelf_columns": 3, "request_queue_size": 4, "reward_type": "RewardType.INDIVIDUAL", "map_name": "customized_map", "map_size": "tiny", "difficulty": "medium"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": true, "force_coop": false, "local_mode": true, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 4, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 100, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64}, "algorithm": "ia2c", "space_obs": "Dict(obs:Box([-100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100.], [100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.], (112,), float32))", "space_act": "Discrete(5)", "num_agents": 4, "episode_limit": 500, "policy_mapping_info": {"all_scenario": {"description": "rware all scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2", "agent_3"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "rware_customized_map", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 10, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.IA2CTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_il.<locals>.<lambda> at 0x7f380824d1f0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "grad_clip": 40.0, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "microbatch_size": null}, "time_since_restore": 212.81157517433167, "timesteps_since_restore": 0, "iterations_since_restore": 21, "perf": {"cpu_util_percent": 4.6000000000000005, "ram_util_percent": 38.0}}
{"episode_reward_max": 6.0, "episode_reward_min": 0.0, "episode_reward_mean": 1.74, "episode_len_mean": 500.0, "episode_media": {}, "episodes_this_iter": 20, "policy_reward_min": {"shared_policy": 0.0}, "policy_reward_max": {"shared_policy": 3.0}, "policy_reward_mean": {"shared_policy": 0.435}, "custom_metrics": {}, "hist_stats": {"episode_reward": [1.0, 0.0, 1.0, 0.0, 4.0, 3.0, 1.0, 1.0, 0.0, 1.0, 3.0, 2.0, 2.0, 2.0, 0.0, 2.0, 2.0, 0.0, 2.0, 2.0, 3.0, 2.0, 0.0, 1.0, 3.0, 3.0, 2.0, 2.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 2.0, 2.0, 2.0, 2.0, 2.0, 1.0, 1.0, 2.0, 2.0, 1.0, 3.0, 2.0, 3.0, 0.0, 4.0, 3.0, 0.0, 0.0, 3.0, 1.0, 1.0, 3.0, 6.0, 0.0, 3.0, 2.0, 2.0, 2.0, 3.0, 3.0, 0.0, 3.0, 6.0, 5.0, 1.0, 3.0, 4.0, 2.0, 1.0, 1.0, 3.0, 1.0, 3.0, 1.0, 3.0, 1.0, 1.0, 0.0, 2.0, 2.0, 2.0, 2.0, 3.0, 0.0, 1.0, 3.0, 4.0, 0.0, 0.0, 2.0, 1.0], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500], "policy_shared_policy_reward": [0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 2.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 2.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 2.0, 0.0, 1.0, 0.0, 1.0, 1.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 2.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 2.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 2.0, 2.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 2.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 2.0, 1.0, 2.0, 1.0, 0.0, 2.0, 0.0, 3.0, 1.0, 0.0, 0.0, 0.0, 2.0, 0.0, 1.0, 0.0, 0.0, 2.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 2.0, 1.0, 0.0, 0.0, 0.0, 2.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.13242989672477917, "mean_inference_ms": 0.38636370027719424, "mean_action_processing_ms": 0.028972346495249823, "mean_env_wait_ms": 0.40142334240701216, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 221760, "timesteps_this_iter": 0, "agent_timesteps_total": 887040, "timers": {"sample_time_ms": 5151.83, "sample_throughput": 978.293, "load_time_ms": 0.145, "load_throughput": 34757139.362, "learn_time_ms": 127.392, "learn_throughput": 39562.959, "update_time_ms": 2.303}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 195.53799438476562, "policy_entropy": 7972.1334228515625, "policy_loss": -5.540801525115967, "vf_loss": 25.52763271331787}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 221760, "num_agent_steps_sampled": 887040, "num_steps_trained": 221760, "num_agent_steps_trained": 887040, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 440, "training_iteration": 22, "trial_id": "71426_00000", "experiment_id": "84bca2f7b35f43248fca18d21abe2ebf", "date": "2024-06-12_02-49-34", "timestamp": 1718128174, "time_this_iter_s": 10.379211902618408, "time_total_s": 223.19078707695007, "pid": 363902, "hostname": "DESKTOP-LQ219J4", "node_ip": "192.168.46.185", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 20, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 5000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 500, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Base_Model", "custom_model_config": {"env": "rware", "env_args": {"n_agents": 4, "column_height": 1, "max_inactivity_steps": null, "max_steps": 500, "fast_obs": true, "msg_bits": 0, "sensor_range": 1, "shelf_rows": 1, "shelf_columns": 3, "request_queue_size": 4, "reward_type": "RewardType.INDIVIDUAL", "map_name": "customized_map", "map_size": "tiny", "difficulty": "medium"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": true, "force_coop": false, "local_mode": true, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 4, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 100, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64}, "algorithm": "ia2c", "space_obs": "Dict(obs:Box([-100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100.], [100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.], (112,), float32))", "space_act": "Discrete(5)", "num_agents": 4, "episode_limit": 500, "policy_mapping_info": {"all_scenario": {"description": "rware all scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2", "agent_3"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "rware_customized_map", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 10, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.IA2CTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_il.<locals>.<lambda> at 0x7f38281ee430>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "grad_clip": 40.0, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "microbatch_size": null}, "time_since_restore": 223.19078707695007, "timesteps_since_restore": 0, "iterations_since_restore": 22, "perf": {"cpu_util_percent": 4.500000000000001, "ram_util_percent": 38.3}}
{"episode_reward_max": 6.0, "episode_reward_min": 0.0, "episode_reward_mean": 1.79, "episode_len_mean": 500.0, "episode_media": {}, "episodes_this_iter": 20, "policy_reward_min": {"shared_policy": 0.0}, "policy_reward_max": {"shared_policy": 3.0}, "policy_reward_mean": {"shared_policy": 0.4475}, "custom_metrics": {}, "hist_stats": {"episode_reward": [3.0, 2.0, 0.0, 1.0, 3.0, 3.0, 2.0, 2.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 2.0, 2.0, 2.0, 2.0, 2.0, 1.0, 1.0, 2.0, 2.0, 1.0, 3.0, 2.0, 3.0, 0.0, 4.0, 3.0, 0.0, 0.0, 3.0, 1.0, 1.0, 3.0, 6.0, 0.0, 3.0, 2.0, 2.0, 2.0, 3.0, 3.0, 0.0, 3.0, 6.0, 5.0, 1.0, 3.0, 4.0, 2.0, 1.0, 1.0, 3.0, 1.0, 3.0, 1.0, 3.0, 1.0, 1.0, 0.0, 2.0, 2.0, 2.0, 2.0, 3.0, 0.0, 1.0, 3.0, 4.0, 0.0, 0.0, 2.0, 1.0, 0.0, 2.0, 5.0, 1.0, 1.0, 1.0, 0.0, 2.0, 2.0, 1.0, 4.0, 1.0, 2.0, 1.0, 0.0, 1.0, 1.0, 4.0, 1.0, 4.0], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500], "policy_shared_policy_reward": [1.0, 0.0, 0.0, 2.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 2.0, 0.0, 1.0, 0.0, 1.0, 1.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 2.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 2.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 2.0, 2.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 2.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 2.0, 1.0, 2.0, 1.0, 0.0, 2.0, 0.0, 3.0, 1.0, 0.0, 0.0, 0.0, 2.0, 0.0, 1.0, 0.0, 0.0, 2.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 2.0, 1.0, 0.0, 0.0, 0.0, 2.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 2.0, 0.0, 3.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 2.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 2.0, 0.0, 0.0, 1.0, 0.0, 2.0, 0.0, 0.0, 2.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.1326143285191012, "mean_inference_ms": 0.38678953917267833, "mean_action_processing_ms": 0.028996302336815032, "mean_env_wait_ms": 0.4017325625924639, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 231840, "timesteps_this_iter": 0, "agent_timesteps_total": 927360, "timers": {"sample_time_ms": 5178.225, "sample_throughput": 973.306, "load_time_ms": 0.145, "load_throughput": 34762855.057, "learn_time_ms": 128.498, "learn_throughput": 39222.282, "update_time_ms": 2.367}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 167.3514404296875, "policy_entropy": 7967.02587890625, "policy_loss": -34.25043869018555, "vf_loss": 19.792224884033203}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 231840, "num_agent_steps_sampled": 927360, "num_steps_trained": 231840, "num_agent_steps_trained": 927360, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 460, "training_iteration": 23, "trial_id": "71426_00000", "experiment_id": "84bca2f7b35f43248fca18d21abe2ebf", "date": "2024-06-12_02-49-44", "timestamp": 1718128184, "time_this_iter_s": 10.263832092285156, "time_total_s": 233.45461916923523, "pid": 363902, "hostname": "DESKTOP-LQ219J4", "node_ip": "192.168.46.185", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 20, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 5000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 500, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Base_Model", "custom_model_config": {"env": "rware", "env_args": {"n_agents": 4, "column_height": 1, "max_inactivity_steps": null, "max_steps": 500, "fast_obs": true, "msg_bits": 0, "sensor_range": 1, "shelf_rows": 1, "shelf_columns": 3, "request_queue_size": 4, "reward_type": "RewardType.INDIVIDUAL", "map_name": "customized_map", "map_size": "tiny", "difficulty": "medium"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": true, "force_coop": false, "local_mode": true, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 4, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 100, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64}, "algorithm": "ia2c", "space_obs": "Dict(obs:Box([-100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100.], [100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.], (112,), float32))", "space_act": "Discrete(5)", "num_agents": 4, "episode_limit": 500, "policy_mapping_info": {"all_scenario": {"description": "rware all scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2", "agent_3"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "rware_customized_map", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 10, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.IA2CTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_il.<locals>.<lambda> at 0x7f38086518b0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "grad_clip": 40.0, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "microbatch_size": null}, "time_since_restore": 233.45461916923523, "timesteps_since_restore": 0, "iterations_since_restore": 23, "perf": {"cpu_util_percent": 4.626666666666666, "ram_util_percent": 38.61333333333334}}
{"episode_reward_max": 6.0, "episode_reward_min": 0.0, "episode_reward_mean": 1.94, "episode_len_mean": 500.0, "episode_media": {}, "episodes_this_iter": 20, "policy_reward_min": {"shared_policy": 0.0}, "policy_reward_max": {"shared_policy": 3.0}, "policy_reward_mean": {"shared_policy": 0.485}, "custom_metrics": {}, "hist_stats": {"episode_reward": [2.0, 2.0, 2.0, 2.0, 1.0, 1.0, 2.0, 2.0, 1.0, 3.0, 2.0, 3.0, 0.0, 4.0, 3.0, 0.0, 0.0, 3.0, 1.0, 1.0, 3.0, 6.0, 0.0, 3.0, 2.0, 2.0, 2.0, 3.0, 3.0, 0.0, 3.0, 6.0, 5.0, 1.0, 3.0, 4.0, 2.0, 1.0, 1.0, 3.0, 1.0, 3.0, 1.0, 3.0, 1.0, 1.0, 0.0, 2.0, 2.0, 2.0, 2.0, 3.0, 0.0, 1.0, 3.0, 4.0, 0.0, 0.0, 2.0, 1.0, 0.0, 2.0, 5.0, 1.0, 1.0, 1.0, 0.0, 2.0, 2.0, 1.0, 4.0, 1.0, 2.0, 1.0, 0.0, 1.0, 1.0, 4.0, 1.0, 4.0, 4.0, 2.0, 0.0, 3.0, 1.0, 3.0, 1.0, 4.0, 0.0, 1.0, 0.0, 4.0, 1.0, 2.0, 2.0, 3.0, 3.0, 2.0, 2.0, 2.0], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500], "policy_shared_policy_reward": [1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 2.0, 0.0, 1.0, 0.0, 1.0, 1.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 2.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 2.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 2.0, 2.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 2.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 2.0, 1.0, 2.0, 1.0, 0.0, 2.0, 0.0, 3.0, 1.0, 0.0, 0.0, 0.0, 2.0, 0.0, 1.0, 0.0, 0.0, 2.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 2.0, 1.0, 0.0, 0.0, 0.0, 2.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 2.0, 0.0, 3.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 2.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 2.0, 0.0, 0.0, 1.0, 0.0, 2.0, 0.0, 0.0, 2.0, 1.0, 0.0, 2.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 2.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.1327673622593632, "mean_inference_ms": 0.38712156780838497, "mean_action_processing_ms": 0.029014180370228092, "mean_env_wait_ms": 0.4019194150598785, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 241920, "timesteps_this_iter": 0, "agent_timesteps_total": 967680, "timers": {"sample_time_ms": 5158.041, "sample_throughput": 977.115, "load_time_ms": 0.144, "load_throughput": 34946755.1, "learn_time_ms": 127.073, "learn_throughput": 39662.159, "update_time_ms": 2.341}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 102.46992492675781, "policy_entropy": 7973.533447265625, "policy_loss": 9.101934909820557, "vf_loss": 22.04123306274414}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 241920, "num_agent_steps_sampled": 967680, "num_steps_trained": 241920, "num_agent_steps_trained": 967680, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 480, "training_iteration": 24, "trial_id": "71426_00000", "experiment_id": "84bca2f7b35f43248fca18d21abe2ebf", "date": "2024-06-12_02-49-55", "timestamp": 1718128195, "time_this_iter_s": 10.184489011764526, "time_total_s": 243.63910818099976, "pid": 363902, "hostname": "DESKTOP-LQ219J4", "node_ip": "192.168.46.185", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 20, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 5000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 500, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Base_Model", "custom_model_config": {"env": "rware", "env_args": {"n_agents": 4, "column_height": 1, "max_inactivity_steps": null, "max_steps": 500, "fast_obs": true, "msg_bits": 0, "sensor_range": 1, "shelf_rows": 1, "shelf_columns": 3, "request_queue_size": 4, "reward_type": "RewardType.INDIVIDUAL", "map_name": "customized_map", "map_size": "tiny", "difficulty": "medium"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": true, "force_coop": false, "local_mode": true, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 4, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 100, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64}, "algorithm": "ia2c", "space_obs": "Dict(obs:Box([-100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100.], [100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.], (112,), float32))", "space_act": "Discrete(5)", "num_agents": 4, "episode_limit": 500, "policy_mapping_info": {"all_scenario": {"description": "rware all scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2", "agent_3"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "rware_customized_map", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 10, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.IA2CTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_il.<locals>.<lambda> at 0x7f382806e9d0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "grad_clip": 40.0, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "microbatch_size": null}, "time_since_restore": 243.63910818099976, "timesteps_since_restore": 0, "iterations_since_restore": 24, "perf": {"cpu_util_percent": 4.442857142857143, "ram_util_percent": 38.84999999999999}}
{"episode_reward_max": 6.0, "episode_reward_min": 0.0, "episode_reward_mean": 1.96, "episode_len_mean": 500.0, "episode_media": {}, "episodes_this_iter": 24, "policy_reward_min": {"shared_policy": 0.0}, "policy_reward_max": {"shared_policy": 3.0}, "policy_reward_mean": {"shared_policy": 0.49}, "custom_metrics": {}, "hist_stats": {"episode_reward": [2.0, 2.0, 2.0, 3.0, 3.0, 0.0, 3.0, 6.0, 5.0, 1.0, 3.0, 4.0, 2.0, 1.0, 1.0, 3.0, 1.0, 3.0, 1.0, 3.0, 1.0, 1.0, 0.0, 2.0, 2.0, 2.0, 2.0, 3.0, 0.0, 1.0, 3.0, 4.0, 0.0, 0.0, 2.0, 1.0, 0.0, 2.0, 5.0, 1.0, 1.0, 1.0, 0.0, 2.0, 2.0, 1.0, 4.0, 1.0, 2.0, 1.0, 0.0, 1.0, 1.0, 4.0, 1.0, 4.0, 4.0, 2.0, 0.0, 3.0, 1.0, 3.0, 1.0, 4.0, 0.0, 1.0, 0.0, 4.0, 1.0, 2.0, 2.0, 3.0, 3.0, 2.0, 2.0, 2.0, 6.0, 0.0, 3.0, 2.0, 2.0, 2.0, 3.0, 1.0, 1.0, 3.0, 2.0, 1.0, 1.0, 2.0, 3.0, 1.0, 0.0, 1.0, 0.0, 1.0, 2.0, 6.0, 2.0, 4.0], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500], "policy_shared_policy_reward": [0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 2.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 2.0, 1.0, 2.0, 1.0, 0.0, 2.0, 0.0, 3.0, 1.0, 0.0, 0.0, 0.0, 2.0, 0.0, 1.0, 0.0, 0.0, 2.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 2.0, 1.0, 0.0, 0.0, 0.0, 2.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 2.0, 0.0, 3.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 2.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 2.0, 0.0, 0.0, 1.0, 0.0, 2.0, 0.0, 0.0, 2.0, 1.0, 0.0, 2.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 2.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 3.0, 2.0, 0.0, 0.0, 0.0, 0.0, 1.0, 2.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 2.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 2.0, 2.0, 1.0, 0.0, 0.0, 1.0, 2.0, 0.0, 1.0, 1.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.13289541628178939, "mean_inference_ms": 0.3873547409347532, "mean_action_processing_ms": 0.029023223501108638, "mean_env_wait_ms": 0.4021509645791177, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 252000, "timesteps_this_iter": 0, "agent_timesteps_total": 1008000, "timers": {"sample_time_ms": 5142.674, "sample_throughput": 980.035, "load_time_ms": 0.145, "load_throughput": 34785736.646, "learn_time_ms": 126.834, "learn_throughput": 39737.088, "update_time_ms": 2.344}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 73.72737884521484, "policy_entropy": 7896.0816650390625, "policy_loss": -0.12828242778778076, "vf_loss": 16.030365705490112}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 252000, "num_agent_steps_sampled": 1008000, "num_steps_trained": 252000, "num_agent_steps_trained": 1008000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 504, "training_iteration": 25, "trial_id": "71426_00000", "experiment_id": "84bca2f7b35f43248fca18d21abe2ebf", "date": "2024-06-12_02-50-05", "timestamp": 1718128205, "time_this_iter_s": 10.322428703308105, "time_total_s": 253.96153688430786, "pid": 363902, "hostname": "DESKTOP-LQ219J4", "node_ip": "192.168.46.185", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 20, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 5000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 500, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Base_Model", "custom_model_config": {"env": "rware", "env_args": {"n_agents": 4, "column_height": 1, "max_inactivity_steps": null, "max_steps": 500, "fast_obs": true, "msg_bits": 0, "sensor_range": 1, "shelf_rows": 1, "shelf_columns": 3, "request_queue_size": 4, "reward_type": "RewardType.INDIVIDUAL", "map_name": "customized_map", "map_size": "tiny", "difficulty": "medium"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": true, "force_coop": false, "local_mode": true, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 4, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 100, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64}, "algorithm": "ia2c", "space_obs": "Dict(obs:Box([-100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100.], [100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.], (112,), float32))", "space_act": "Discrete(5)", "num_agents": 4, "episode_limit": 500, "policy_mapping_info": {"all_scenario": {"description": "rware all scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2", "agent_3"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "rware_customized_map", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 10, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.IA2CTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_il.<locals>.<lambda> at 0x7f382806e940>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "grad_clip": 40.0, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "microbatch_size": null}, "time_since_restore": 253.96153688430786, "timesteps_since_restore": 0, "iterations_since_restore": 25, "perf": {"cpu_util_percent": 4.6466666666666665, "ram_util_percent": 39.10000000000001}}
{"episode_reward_max": 6.0, "episode_reward_min": 0.0, "episode_reward_mean": 1.82, "episode_len_mean": 500.0, "episode_media": {}, "episodes_this_iter": 20, "policy_reward_min": {"shared_policy": 0.0}, "policy_reward_max": {"shared_policy": 3.0}, "policy_reward_mean": {"shared_policy": 0.455}, "custom_metrics": {}, "hist_stats": {"episode_reward": [1.0, 1.0, 0.0, 2.0, 2.0, 2.0, 2.0, 3.0, 0.0, 1.0, 3.0, 4.0, 0.0, 0.0, 2.0, 1.0, 0.0, 2.0, 5.0, 1.0, 1.0, 1.0, 0.0, 2.0, 2.0, 1.0, 4.0, 1.0, 2.0, 1.0, 0.0, 1.0, 1.0, 4.0, 1.0, 4.0, 4.0, 2.0, 0.0, 3.0, 1.0, 3.0, 1.0, 4.0, 0.0, 1.0, 0.0, 4.0, 1.0, 2.0, 2.0, 3.0, 3.0, 2.0, 2.0, 2.0, 6.0, 0.0, 3.0, 2.0, 2.0, 2.0, 3.0, 1.0, 1.0, 3.0, 2.0, 1.0, 1.0, 2.0, 3.0, 1.0, 0.0, 1.0, 0.0, 1.0, 2.0, 6.0, 2.0, 4.0, 0.0, 1.0, 0.0, 3.0, 2.0, 0.0, 0.0, 1.0, 2.0, 5.0, 3.0, 3.0, 2.0, 3.0, 1.0, 3.0, 0.0, 3.0, 2.0, 1.0], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500], "policy_shared_policy_reward": [0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 2.0, 0.0, 3.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 2.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 2.0, 0.0, 0.0, 1.0, 0.0, 2.0, 0.0, 0.0, 2.0, 1.0, 0.0, 2.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 2.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 3.0, 2.0, 0.0, 0.0, 0.0, 0.0, 1.0, 2.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 2.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 2.0, 2.0, 1.0, 0.0, 0.0, 1.0, 2.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 2.0, 1.0, 1.0, 2.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 2.0, 0.0, 0.0, 1.0, 0.0, 2.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.1330061363200499, "mean_inference_ms": 0.38759316342855543, "mean_action_processing_ms": 0.02903532838429159, "mean_env_wait_ms": 0.4022931310951887, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 262080, "timesteps_this_iter": 0, "agent_timesteps_total": 1048320, "timers": {"sample_time_ms": 5151.922, "sample_throughput": 978.276, "load_time_ms": 0.148, "load_throughput": 34150714.313, "learn_time_ms": 126.843, "learn_throughput": 39734.1, "update_time_ms": 2.343}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 86.4267349243164, "policy_entropy": 7913.3050537109375, "policy_loss": 7.4359323382377625, "vf_loss": 21.413776874542236}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 262080, "num_agent_steps_sampled": 1048320, "num_steps_trained": 262080, "num_agent_steps_trained": 1048320, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 524, "training_iteration": 26, "trial_id": "71426_00000", "experiment_id": "84bca2f7b35f43248fca18d21abe2ebf", "date": "2024-06-12_02-50-15", "timestamp": 1718128215, "time_this_iter_s": 10.292797803878784, "time_total_s": 264.25433468818665, "pid": 363902, "hostname": "DESKTOP-LQ219J4", "node_ip": "192.168.46.185", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 20, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 5000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 500, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Base_Model", "custom_model_config": {"env": "rware", "env_args": {"n_agents": 4, "column_height": 1, "max_inactivity_steps": null, "max_steps": 500, "fast_obs": true, "msg_bits": 0, "sensor_range": 1, "shelf_rows": 1, "shelf_columns": 3, "request_queue_size": 4, "reward_type": "RewardType.INDIVIDUAL", "map_name": "customized_map", "map_size": "tiny", "difficulty": "medium"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": true, "force_coop": false, "local_mode": true, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 4, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 100, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64}, "algorithm": "ia2c", "space_obs": "Dict(obs:Box([-100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100.], [100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.], (112,), float32))", "space_act": "Discrete(5)", "num_agents": 4, "episode_limit": 500, "policy_mapping_info": {"all_scenario": {"description": "rware all scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2", "agent_3"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "rware_customized_map", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 10, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.IA2CTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_il.<locals>.<lambda> at 0x7f380824d160>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "grad_clip": 40.0, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "microbatch_size": null}, "time_since_restore": 264.25433468818665, "timesteps_since_restore": 0, "iterations_since_restore": 26, "perf": {"cpu_util_percent": 4.506666666666666, "ram_util_percent": 39.41333333333333}}
{"episode_reward_max": 6.0, "episode_reward_min": 0.0, "episode_reward_mean": 1.78, "episode_len_mean": 500.0, "episode_media": {}, "episodes_this_iter": 20, "policy_reward_min": {"shared_policy": 0.0}, "policy_reward_max": {"shared_policy": 3.0}, "policy_reward_mean": {"shared_policy": 0.445}, "custom_metrics": {}, "hist_stats": {"episode_reward": [1.0, 1.0, 0.0, 2.0, 2.0, 1.0, 4.0, 1.0, 2.0, 1.0, 0.0, 1.0, 1.0, 4.0, 1.0, 4.0, 4.0, 2.0, 0.0, 3.0, 1.0, 3.0, 1.0, 4.0, 0.0, 1.0, 0.0, 4.0, 1.0, 2.0, 2.0, 3.0, 3.0, 2.0, 2.0, 2.0, 6.0, 0.0, 3.0, 2.0, 2.0, 2.0, 3.0, 1.0, 1.0, 3.0, 2.0, 1.0, 1.0, 2.0, 3.0, 1.0, 0.0, 1.0, 0.0, 1.0, 2.0, 6.0, 2.0, 4.0, 0.0, 1.0, 0.0, 3.0, 2.0, 0.0, 0.0, 1.0, 2.0, 5.0, 3.0, 3.0, 2.0, 3.0, 1.0, 3.0, 0.0, 3.0, 2.0, 1.0, 1.0, 3.0, 1.0, 1.0, 1.0, 3.0, 0.0, 2.0, 1.0, 1.0, 0.0, 2.0, 1.0, 2.0, 2.0, 3.0, 0.0, 1.0, 1.0, 2.0], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500], "policy_shared_policy_reward": [0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 2.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 2.0, 0.0, 0.0, 1.0, 0.0, 2.0, 0.0, 0.0, 2.0, 1.0, 0.0, 2.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 2.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 3.0, 2.0, 0.0, 0.0, 0.0, 0.0, 1.0, 2.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 2.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 2.0, 2.0, 1.0, 0.0, 0.0, 1.0, 2.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 2.0, 1.0, 1.0, 2.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 2.0, 0.0, 0.0, 1.0, 0.0, 2.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.13311154343474388, "mean_inference_ms": 0.3878003202454204, "mean_action_processing_ms": 0.029048415694388863, "mean_env_wait_ms": 0.4024298396174855, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 272160, "timesteps_this_iter": 0, "agent_timesteps_total": 1088640, "timers": {"sample_time_ms": 5153.744, "sample_throughput": 977.93, "load_time_ms": 0.147, "load_throughput": 34200440.317, "learn_time_ms": 127.422, "learn_throughput": 39553.728, "update_time_ms": 2.345}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 75.57577514648438, "policy_entropy": 7943.1112060546875, "policy_loss": -15.101492166519165, "vf_loss": 13.756853818893433}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 272160, "num_agent_steps_sampled": 1088640, "num_steps_trained": 272160, "num_agent_steps_trained": 1088640, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 544, "training_iteration": 27, "trial_id": "71426_00000", "experiment_id": "84bca2f7b35f43248fca18d21abe2ebf", "date": "2024-06-12_02-50-26", "timestamp": 1718128226, "time_this_iter_s": 10.396730184555054, "time_total_s": 274.6510648727417, "pid": 363902, "hostname": "DESKTOP-LQ219J4", "node_ip": "192.168.46.185", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 20, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 5000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 500, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Base_Model", "custom_model_config": {"env": "rware", "env_args": {"n_agents": 4, "column_height": 1, "max_inactivity_steps": null, "max_steps": 500, "fast_obs": true, "msg_bits": 0, "sensor_range": 1, "shelf_rows": 1, "shelf_columns": 3, "request_queue_size": 4, "reward_type": "RewardType.INDIVIDUAL", "map_name": "customized_map", "map_size": "tiny", "difficulty": "medium"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": true, "force_coop": false, "local_mode": true, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 4, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 100, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64}, "algorithm": "ia2c", "space_obs": "Dict(obs:Box([-100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100.], [100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.], (112,), float32))", "space_act": "Discrete(5)", "num_agents": 4, "episode_limit": 500, "policy_mapping_info": {"all_scenario": {"description": "rware all scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2", "agent_3"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "rware_customized_map", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 10, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.IA2CTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_il.<locals>.<lambda> at 0x7f38086c1dc0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "grad_clip": 40.0, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "microbatch_size": null}, "time_since_restore": 274.6510648727417, "timesteps_since_restore": 0, "iterations_since_restore": 27, "perf": {"cpu_util_percent": 4.635714285714286, "ram_util_percent": 39.65}}
{"episode_reward_max": 6.0, "episode_reward_min": 0.0, "episode_reward_mean": 1.97, "episode_len_mean": 500.0, "episode_media": {}, "episodes_this_iter": 20, "policy_reward_min": {"shared_policy": 0.0}, "policy_reward_max": {"shared_policy": 3.0}, "policy_reward_mean": {"shared_policy": 0.4925}, "custom_metrics": {}, "hist_stats": {"episode_reward": [1.0, 3.0, 1.0, 4.0, 0.0, 1.0, 0.0, 4.0, 1.0, 2.0, 2.0, 3.0, 3.0, 2.0, 2.0, 2.0, 6.0, 0.0, 3.0, 2.0, 2.0, 2.0, 3.0, 1.0, 1.0, 3.0, 2.0, 1.0, 1.0, 2.0, 3.0, 1.0, 0.0, 1.0, 0.0, 1.0, 2.0, 6.0, 2.0, 4.0, 0.0, 1.0, 0.0, 3.0, 2.0, 0.0, 0.0, 1.0, 2.0, 5.0, 3.0, 3.0, 2.0, 3.0, 1.0, 3.0, 0.0, 3.0, 2.0, 1.0, 1.0, 3.0, 1.0, 1.0, 1.0, 3.0, 0.0, 2.0, 1.0, 1.0, 0.0, 2.0, 1.0, 2.0, 2.0, 3.0, 0.0, 1.0, 1.0, 2.0, 1.0, 1.0, 5.0, 1.0, 3.0, 2.0, 1.0, 2.0, 3.0, 5.0, 5.0, 4.0, 3.0, 3.0, 1.0, 3.0, 4.0, 0.0, 3.0, 4.0], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500], "policy_shared_policy_reward": [0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 2.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 3.0, 2.0, 0.0, 0.0, 0.0, 0.0, 1.0, 2.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 2.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 2.0, 2.0, 1.0, 0.0, 0.0, 1.0, 2.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 2.0, 1.0, 1.0, 2.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 2.0, 0.0, 0.0, 1.0, 0.0, 2.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 2.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0, 2.0, 0.0, 1.0, 2.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 2.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 2.0, 0.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.1331613455219255, "mean_inference_ms": 0.38801319346830804, "mean_action_processing_ms": 0.029062114179198895, "mean_env_wait_ms": 0.40262187717103304, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 282240, "timesteps_this_iter": 0, "agent_timesteps_total": 1128960, "timers": {"sample_time_ms": 5160.806, "sample_throughput": 976.592, "load_time_ms": 0.159, "load_throughput": 31754982.965, "learn_time_ms": 128.935, "learn_throughput": 39089.477, "update_time_ms": 2.318}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 206.33917236328125, "policy_entropy": 7964.230712890625, "policy_loss": 13.137988567352295, "vf_loss": 23.804837465286255}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 282240, "num_agent_steps_sampled": 1128960, "num_steps_trained": 282240, "num_agent_steps_trained": 1128960, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 564, "training_iteration": 28, "trial_id": "71426_00000", "experiment_id": "84bca2f7b35f43248fca18d21abe2ebf", "date": "2024-06-12_02-50-36", "timestamp": 1718128236, "time_this_iter_s": 10.331530332565308, "time_total_s": 284.982595205307, "pid": 363902, "hostname": "DESKTOP-LQ219J4", "node_ip": "192.168.46.185", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 20, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 5000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 500, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Base_Model", "custom_model_config": {"env": "rware", "env_args": {"n_agents": 4, "column_height": 1, "max_inactivity_steps": null, "max_steps": 500, "fast_obs": true, "msg_bits": 0, "sensor_range": 1, "shelf_rows": 1, "shelf_columns": 3, "request_queue_size": 4, "reward_type": "RewardType.INDIVIDUAL", "map_name": "customized_map", "map_size": "tiny", "difficulty": "medium"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": true, "force_coop": false, "local_mode": true, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 4, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 100, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64}, "algorithm": "ia2c", "space_obs": "Dict(obs:Box([-100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100.], [100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.], (112,), float32))", "space_act": "Discrete(5)", "num_agents": 4, "episode_limit": 500, "policy_mapping_info": {"all_scenario": {"description": "rware all scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2", "agent_3"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "rware_customized_map", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 10, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.IA2CTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_il.<locals>.<lambda> at 0x7f3808645160>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "grad_clip": 40.0, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "microbatch_size": null}, "time_since_restore": 284.982595205307, "timesteps_since_restore": 0, "iterations_since_restore": 28, "perf": {"cpu_util_percent": 4.553333333333333, "ram_util_percent": 39.986666666666665}}
{"episode_reward_max": 6.0, "episode_reward_min": 0.0, "episode_reward_mean": 1.95, "episode_len_mean": 500.0, "episode_media": {}, "episodes_this_iter": 20, "policy_reward_min": {"shared_policy": 0.0}, "policy_reward_max": {"shared_policy": 2.0}, "policy_reward_mean": {"shared_policy": 0.4875}, "custom_metrics": {}, "hist_stats": {"episode_reward": [2.0, 2.0, 3.0, 1.0, 1.0, 3.0, 2.0, 1.0, 1.0, 2.0, 3.0, 1.0, 0.0, 1.0, 0.0, 1.0, 2.0, 6.0, 2.0, 4.0, 0.0, 1.0, 0.0, 3.0, 2.0, 0.0, 0.0, 1.0, 2.0, 5.0, 3.0, 3.0, 2.0, 3.0, 1.0, 3.0, 0.0, 3.0, 2.0, 1.0, 1.0, 3.0, 1.0, 1.0, 1.0, 3.0, 0.0, 2.0, 1.0, 1.0, 0.0, 2.0, 1.0, 2.0, 2.0, 3.0, 0.0, 1.0, 1.0, 2.0, 1.0, 1.0, 5.0, 1.0, 3.0, 2.0, 1.0, 2.0, 3.0, 5.0, 5.0, 4.0, 3.0, 3.0, 1.0, 3.0, 4.0, 0.0, 3.0, 4.0, 1.0, 2.0, 1.0, 1.0, 3.0, 5.0, 2.0, 2.0, 0.0, 3.0, 0.0, 1.0, 3.0, 2.0, 2.0, 2.0, 4.0, 3.0, 2.0, 1.0], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500], "policy_shared_policy_reward": [1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 2.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 2.0, 2.0, 1.0, 0.0, 0.0, 1.0, 2.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 2.0, 1.0, 1.0, 2.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 2.0, 0.0, 0.0, 1.0, 0.0, 2.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 2.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0, 2.0, 0.0, 1.0, 2.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 2.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 2.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 2.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 2.0, 2.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.13324801579813758, "mean_inference_ms": 0.38819490841188453, "mean_action_processing_ms": 0.02907244448153577, "mean_env_wait_ms": 0.4027998181965101, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 292320, "timesteps_this_iter": 0, "agent_timesteps_total": 1169280, "timers": {"sample_time_ms": 5162.462, "sample_throughput": 976.278, "load_time_ms": 0.161, "load_throughput": 31308193.365, "learn_time_ms": 138.451, "learn_throughput": 36402.77, "update_time_ms": 2.378}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 93.74539184570312, "policy_entropy": 7949.009765625, "policy_loss": -33.11089587211609, "vf_loss": 17.370927333831787}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 292320, "num_agent_steps_sampled": 1169280, "num_steps_trained": 292320, "num_agent_steps_trained": 1169280, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 584, "training_iteration": 29, "trial_id": "71426_00000", "experiment_id": "84bca2f7b35f43248fca18d21abe2ebf", "date": "2024-06-12_02-50-46", "timestamp": 1718128246, "time_this_iter_s": 10.298978567123413, "time_total_s": 295.2815737724304, "pid": 363902, "hostname": "DESKTOP-LQ219J4", "node_ip": "192.168.46.185", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 20, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 5000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 500, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Base_Model", "custom_model_config": {"env": "rware", "env_args": {"n_agents": 4, "column_height": 1, "max_inactivity_steps": null, "max_steps": 500, "fast_obs": true, "msg_bits": 0, "sensor_range": 1, "shelf_rows": 1, "shelf_columns": 3, "request_queue_size": 4, "reward_type": "RewardType.INDIVIDUAL", "map_name": "customized_map", "map_size": "tiny", "difficulty": "medium"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": true, "force_coop": false, "local_mode": true, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 4, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 100, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64}, "algorithm": "ia2c", "space_obs": "Dict(obs:Box([-100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100.], [100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.], (112,), float32))", "space_act": "Discrete(5)", "num_agents": 4, "episode_limit": 500, "policy_mapping_info": {"all_scenario": {"description": "rware all scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2", "agent_3"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "rware_customized_map", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 10, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.IA2CTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_il.<locals>.<lambda> at 0x7f38280b24c0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "grad_clip": 40.0, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "microbatch_size": null}, "time_since_restore": 295.2815737724304, "timesteps_since_restore": 0, "iterations_since_restore": 29, "perf": {"cpu_util_percent": 4.5, "ram_util_percent": 40.29999999999999}}
{"episode_reward_max": 6.0, "episode_reward_min": 0.0, "episode_reward_mean": 2.05, "episode_len_mean": 500.0, "episode_media": {}, "episodes_this_iter": 20, "policy_reward_min": {"shared_policy": 0.0}, "policy_reward_max": {"shared_policy": 2.0}, "policy_reward_mean": {"shared_policy": 0.5125}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 1.0, 0.0, 3.0, 2.0, 0.0, 0.0, 1.0, 2.0, 5.0, 3.0, 3.0, 2.0, 3.0, 1.0, 3.0, 0.0, 3.0, 2.0, 1.0, 1.0, 3.0, 1.0, 1.0, 1.0, 3.0, 0.0, 2.0, 1.0, 1.0, 0.0, 2.0, 1.0, 2.0, 2.0, 3.0, 0.0, 1.0, 1.0, 2.0, 1.0, 1.0, 5.0, 1.0, 3.0, 2.0, 1.0, 2.0, 3.0, 5.0, 5.0, 4.0, 3.0, 3.0, 1.0, 3.0, 4.0, 0.0, 3.0, 4.0, 1.0, 2.0, 1.0, 1.0, 3.0, 5.0, 2.0, 2.0, 0.0, 3.0, 0.0, 1.0, 3.0, 2.0, 2.0, 2.0, 4.0, 3.0, 2.0, 1.0, 3.0, 2.0, 3.0, 5.0, 0.0, 0.0, 0.0, 4.0, 0.0, 4.0, 2.0, 3.0, 6.0, 4.0, 3.0, 2.0, 1.0, 1.0, 1.0, 4.0], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500], "policy_shared_policy_reward": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 2.0, 1.0, 1.0, 2.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 2.0, 0.0, 0.0, 1.0, 0.0, 2.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 2.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0, 2.0, 0.0, 1.0, 2.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 2.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 2.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 2.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 2.0, 2.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 2.0, 2.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 1.0, 1.0, 2.0, 1.0, 2.0, 2.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.13333481268227493, "mean_inference_ms": 0.3884094697639769, "mean_action_processing_ms": 0.029086589588277142, "mean_env_wait_ms": 0.402878568670023, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 302400, "timesteps_this_iter": 0, "agent_timesteps_total": 1209600, "timers": {"sample_time_ms": 5177.566, "sample_throughput": 973.43, "load_time_ms": 0.161, "load_throughput": 31373244.524, "learn_time_ms": 139.987, "learn_throughput": 36003.315, "update_time_ms": 2.384}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 112.899658203125, "policy_entropy": 7912.3162841796875, "policy_loss": -14.561972379684448, "vf_loss": 21.69243550300598}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 302400, "num_agent_steps_sampled": 1209600, "num_steps_trained": 302400, "num_agent_steps_trained": 1209600, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 604, "training_iteration": 30, "trial_id": "71426_00000", "experiment_id": "84bca2f7b35f43248fca18d21abe2ebf", "date": "2024-06-12_02-50-57", "timestamp": 1718128257, "time_this_iter_s": 10.379966497421265, "time_total_s": 305.6615402698517, "pid": 363902, "hostname": "DESKTOP-LQ219J4", "node_ip": "192.168.46.185", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 20, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 5000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 500, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Base_Model", "custom_model_config": {"env": "rware", "env_args": {"n_agents": 4, "column_height": 1, "max_inactivity_steps": null, "max_steps": 500, "fast_obs": true, "msg_bits": 0, "sensor_range": 1, "shelf_rows": 1, "shelf_columns": 3, "request_queue_size": 4, "reward_type": "RewardType.INDIVIDUAL", "map_name": "customized_map", "map_size": "tiny", "difficulty": "medium"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": true, "force_coop": false, "local_mode": true, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 4, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 100, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64}, "algorithm": "ia2c", "space_obs": "Dict(obs:Box([-100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100.], [100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.], (112,), float32))", "space_act": "Discrete(5)", "num_agents": 4, "episode_limit": 500, "policy_mapping_info": {"all_scenario": {"description": "rware all scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2", "agent_3"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "rware_customized_map", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 10, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.IA2CTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_il.<locals>.<lambda> at 0x7f38082f8430>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "grad_clip": 40.0, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "microbatch_size": null}, "time_since_restore": 305.6615402698517, "timesteps_since_restore": 0, "iterations_since_restore": 30, "perf": {"cpu_util_percent": 4.58, "ram_util_percent": 40.513333333333335}}
{"episode_reward_max": 6.0, "episode_reward_min": 0.0, "episode_reward_mean": 1.98, "episode_len_mean": 500.0, "episode_media": {}, "episodes_this_iter": 20, "policy_reward_min": {"shared_policy": 0.0}, "policy_reward_max": {"shared_policy": 2.0}, "policy_reward_mean": {"shared_policy": 0.495}, "custom_metrics": {}, "hist_stats": {"episode_reward": [1.0, 3.0, 1.0, 1.0, 1.0, 3.0, 0.0, 2.0, 1.0, 1.0, 0.0, 2.0, 1.0, 2.0, 2.0, 3.0, 0.0, 1.0, 1.0, 2.0, 1.0, 1.0, 5.0, 1.0, 3.0, 2.0, 1.0, 2.0, 3.0, 5.0, 5.0, 4.0, 3.0, 3.0, 1.0, 3.0, 4.0, 0.0, 3.0, 4.0, 1.0, 2.0, 1.0, 1.0, 3.0, 5.0, 2.0, 2.0, 0.0, 3.0, 0.0, 1.0, 3.0, 2.0, 2.0, 2.0, 4.0, 3.0, 2.0, 1.0, 3.0, 2.0, 3.0, 5.0, 0.0, 0.0, 0.0, 4.0, 0.0, 4.0, 2.0, 3.0, 6.0, 4.0, 3.0, 2.0, 1.0, 1.0, 1.0, 4.0, 1.0, 1.0, 3.0, 0.0, 2.0, 2.0, 1.0, 1.0, 1.0, 2.0, 1.0, 0.0, 2.0, 1.0, 4.0, 0.0, 3.0, 2.0, 1.0, 0.0], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500], "policy_shared_policy_reward": [0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 2.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0, 2.0, 0.0, 1.0, 2.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 2.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 2.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 2.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 2.0, 2.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 2.0, 2.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 1.0, 1.0, 2.0, 1.0, 2.0, 2.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 2.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 2.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.13342820108928113, "mean_inference_ms": 0.38860165601330865, "mean_action_processing_ms": 0.02909870964098928, "mean_env_wait_ms": 0.4030401031794766, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 312480, "timesteps_this_iter": 0, "agent_timesteps_total": 1249920, "timers": {"sample_time_ms": 5184.122, "sample_throughput": 972.199, "load_time_ms": 0.159, "load_throughput": 31674096.734, "learn_time_ms": 140.748, "learn_throughput": 35808.782, "update_time_ms": 2.379}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 98.57071685791016, "policy_entropy": 7964.8455810546875, "policy_loss": -42.325742959976196, "vf_loss": 18.378017961978912}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 312480, "num_agent_steps_sampled": 1249920, "num_steps_trained": 312480, "num_agent_steps_trained": 1249920, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 624, "training_iteration": 31, "trial_id": "71426_00000", "experiment_id": "84bca2f7b35f43248fca18d21abe2ebf", "date": "2024-06-12_02-51-07", "timestamp": 1718128267, "time_this_iter_s": 10.362140893936157, "time_total_s": 316.02368116378784, "pid": 363902, "hostname": "DESKTOP-LQ219J4", "node_ip": "192.168.46.185", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 20, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 5000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 500, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Base_Model", "custom_model_config": {"env": "rware", "env_args": {"n_agents": 4, "column_height": 1, "max_inactivity_steps": null, "max_steps": 500, "fast_obs": true, "msg_bits": 0, "sensor_range": 1, "shelf_rows": 1, "shelf_columns": 3, "request_queue_size": 4, "reward_type": "RewardType.INDIVIDUAL", "map_name": "customized_map", "map_size": "tiny", "difficulty": "medium"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": true, "force_coop": false, "local_mode": true, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 4, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 100, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64}, "algorithm": "ia2c", "space_obs": "Dict(obs:Box([-100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100.], [100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.], (112,), float32))", "space_act": "Discrete(5)", "num_agents": 4, "episode_limit": 500, "policy_mapping_info": {"all_scenario": {"description": "rware all scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2", "agent_3"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "rware_customized_map", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 10, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.IA2CTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_il.<locals>.<lambda> at 0x7f380824d700>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "grad_clip": 40.0, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "microbatch_size": null}, "time_since_restore": 316.02368116378784, "timesteps_since_restore": 0, "iterations_since_restore": 31, "perf": {"cpu_util_percent": 4.673333333333332, "ram_util_percent": 40.839999999999996}}
{"episode_reward_max": 6.0, "episode_reward_min": 0.0, "episode_reward_mean": 2.07, "episode_len_mean": 500.0, "episode_media": {}, "episodes_this_iter": 20, "policy_reward_min": {"shared_policy": 0.0}, "policy_reward_max": {"shared_policy": 3.0}, "policy_reward_mean": {"shared_policy": 0.5175}, "custom_metrics": {}, "hist_stats": {"episode_reward": [1.0, 1.0, 5.0, 1.0, 3.0, 2.0, 1.0, 2.0, 3.0, 5.0, 5.0, 4.0, 3.0, 3.0, 1.0, 3.0, 4.0, 0.0, 3.0, 4.0, 1.0, 2.0, 1.0, 1.0, 3.0, 5.0, 2.0, 2.0, 0.0, 3.0, 0.0, 1.0, 3.0, 2.0, 2.0, 2.0, 4.0, 3.0, 2.0, 1.0, 3.0, 2.0, 3.0, 5.0, 0.0, 0.0, 0.0, 4.0, 0.0, 4.0, 2.0, 3.0, 6.0, 4.0, 3.0, 2.0, 1.0, 1.0, 1.0, 4.0, 1.0, 1.0, 3.0, 0.0, 2.0, 2.0, 1.0, 1.0, 1.0, 2.0, 1.0, 0.0, 2.0, 1.0, 4.0, 0.0, 3.0, 2.0, 1.0, 0.0, 1.0, 1.0, 2.0, 3.0, 0.0, 1.0, 3.0, 2.0, 6.0, 1.0, 1.0, 1.0, 0.0, 4.0, 2.0, 3.0, 1.0, 0.0, 3.0, 2.0], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500], "policy_shared_policy_reward": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 2.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0, 2.0, 0.0, 1.0, 2.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 2.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 2.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 2.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 2.0, 2.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 2.0, 2.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 1.0, 1.0, 2.0, 1.0, 2.0, 2.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 2.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 2.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 2.0, 0.0, 1.0, 3.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 2.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.1335034275635063, "mean_inference_ms": 0.3887622216199471, "mean_action_processing_ms": 0.029106903961346103, "mean_env_wait_ms": 0.40312755745118717, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 322560, "timesteps_this_iter": 0, "agent_timesteps_total": 1290240, "timers": {"sample_time_ms": 5169.795, "sample_throughput": 974.894, "load_time_ms": 0.158, "load_throughput": 31869881.14, "learn_time_ms": 138.722, "learn_throughput": 36331.671, "update_time_ms": 2.376}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 199.97250366210938, "policy_entropy": 7967.7608642578125, "policy_loss": -31.11613416671753, "vf_loss": 18.78708028793335}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 322560, "num_agent_steps_sampled": 1290240, "num_steps_trained": 322560, "num_agent_steps_trained": 1290240, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 644, "training_iteration": 32, "trial_id": "71426_00000", "experiment_id": "84bca2f7b35f43248fca18d21abe2ebf", "date": "2024-06-12_02-51-17", "timestamp": 1718128277, "time_this_iter_s": 10.234109878540039, "time_total_s": 326.2577910423279, "pid": 363902, "hostname": "DESKTOP-LQ219J4", "node_ip": "192.168.46.185", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 20, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 5000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 500, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Base_Model", "custom_model_config": {"env": "rware", "env_args": {"n_agents": 4, "column_height": 1, "max_inactivity_steps": null, "max_steps": 500, "fast_obs": true, "msg_bits": 0, "sensor_range": 1, "shelf_rows": 1, "shelf_columns": 3, "request_queue_size": 4, "reward_type": "RewardType.INDIVIDUAL", "map_name": "customized_map", "map_size": "tiny", "difficulty": "medium"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": true, "force_coop": false, "local_mode": true, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 4, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 100, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64}, "algorithm": "ia2c", "space_obs": "Dict(obs:Box([-100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100.], [100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.], (112,), float32))", "space_act": "Discrete(5)", "num_agents": 4, "episode_limit": 500, "policy_mapping_info": {"all_scenario": {"description": "rware all scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2", "agent_3"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "rware_customized_map", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 10, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.IA2CTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_il.<locals>.<lambda> at 0x7f3808651700>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "grad_clip": 40.0, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "microbatch_size": null}, "time_since_restore": 326.2577910423279, "timesteps_since_restore": 0, "iterations_since_restore": 32, "perf": {"cpu_util_percent": 4.428571428571428, "ram_util_percent": 41.10000000000001}}
{"episode_reward_max": 6.0, "episode_reward_min": 0.0, "episode_reward_mean": 1.88, "episode_len_mean": 500.0, "episode_media": {}, "episodes_this_iter": 20, "policy_reward_min": {"shared_policy": 0.0}, "policy_reward_max": {"shared_policy": 3.0}, "policy_reward_mean": {"shared_policy": 0.47}, "custom_metrics": {}, "hist_stats": {"episode_reward": [1.0, 2.0, 1.0, 1.0, 3.0, 5.0, 2.0, 2.0, 0.0, 3.0, 0.0, 1.0, 3.0, 2.0, 2.0, 2.0, 4.0, 3.0, 2.0, 1.0, 3.0, 2.0, 3.0, 5.0, 0.0, 0.0, 0.0, 4.0, 0.0, 4.0, 2.0, 3.0, 6.0, 4.0, 3.0, 2.0, 1.0, 1.0, 1.0, 4.0, 1.0, 1.0, 3.0, 0.0, 2.0, 2.0, 1.0, 1.0, 1.0, 2.0, 1.0, 0.0, 2.0, 1.0, 4.0, 0.0, 3.0, 2.0, 1.0, 0.0, 1.0, 1.0, 2.0, 3.0, 0.0, 1.0, 3.0, 2.0, 6.0, 1.0, 1.0, 1.0, 0.0, 4.0, 2.0, 3.0, 1.0, 0.0, 3.0, 2.0, 2.0, 2.0, 0.0, 3.0, 3.0, 2.0, 2.0, 1.0, 0.0, 1.0, 3.0, 1.0, 0.0, 1.0, 3.0, 0.0, 5.0, 1.0, 4.0, 1.0], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500], "policy_shared_policy_reward": [0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 2.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 2.0, 2.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 2.0, 2.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 1.0, 1.0, 2.0, 1.0, 2.0, 2.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 2.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 2.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 2.0, 0.0, 1.0, 3.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 2.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 2.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 2.0, 2.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 2.0, 1.0, 0.0, 0.0, 0.0, 1.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.1335699439106375, "mean_inference_ms": 0.3888958157012981, "mean_action_processing_ms": 0.029114833691553016, "mean_env_wait_ms": 0.4031702628465578, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 332640, "timesteps_this_iter": 0, "agent_timesteps_total": 1330560, "timers": {"sample_time_ms": 5156.213, "sample_throughput": 977.462, "load_time_ms": 0.147, "load_throughput": 34261413.549, "learn_time_ms": 136.943, "learn_throughput": 36803.766, "update_time_ms": 2.35}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 116.71475982666016, "policy_entropy": 7979.52001953125, "policy_loss": -2.3721396923065186, "vf_loss": 19.704211235046387}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 332640, "num_agent_steps_sampled": 1330560, "num_steps_trained": 332640, "num_agent_steps_trained": 1330560, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 664, "training_iteration": 33, "trial_id": "71426_00000", "experiment_id": "84bca2f7b35f43248fca18d21abe2ebf", "date": "2024-06-12_02-51-28", "timestamp": 1718128288, "time_this_iter_s": 10.213741540908813, "time_total_s": 336.4715325832367, "pid": 363902, "hostname": "DESKTOP-LQ219J4", "node_ip": "192.168.46.185", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 20, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 5000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 500, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Base_Model", "custom_model_config": {"env": "rware", "env_args": {"n_agents": 4, "column_height": 1, "max_inactivity_steps": null, "max_steps": 500, "fast_obs": true, "msg_bits": 0, "sensor_range": 1, "shelf_rows": 1, "shelf_columns": 3, "request_queue_size": 4, "reward_type": "RewardType.INDIVIDUAL", "map_name": "customized_map", "map_size": "tiny", "difficulty": "medium"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": true, "force_coop": false, "local_mode": true, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 4, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 100, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64}, "algorithm": "ia2c", "space_obs": "Dict(obs:Box([-100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100.], [100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.], (112,), float32))", "space_act": "Discrete(5)", "num_agents": 4, "episode_limit": 500, "policy_mapping_info": {"all_scenario": {"description": "rware all scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2", "agent_3"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "rware_customized_map", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 10, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.IA2CTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_il.<locals>.<lambda> at 0x7f38280b2160>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "grad_clip": 40.0, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "microbatch_size": null}, "time_since_restore": 336.4715325832367, "timesteps_since_restore": 0, "iterations_since_restore": 33, "perf": {"cpu_util_percent": 4.433333333333334, "ram_util_percent": 41.36666666666666}}
{"episode_reward_max": 6.0, "episode_reward_min": 0.0, "episode_reward_mean": 1.79, "episode_len_mean": 500.0, "episode_media": {}, "episodes_this_iter": 20, "policy_reward_min": {"shared_policy": 0.0}, "policy_reward_max": {"shared_policy": 3.0}, "policy_reward_mean": {"shared_policy": 0.4475}, "custom_metrics": {}, "hist_stats": {"episode_reward": [3.0, 2.0, 3.0, 5.0, 0.0, 0.0, 0.0, 4.0, 0.0, 4.0, 2.0, 3.0, 6.0, 4.0, 3.0, 2.0, 1.0, 1.0, 1.0, 4.0, 1.0, 1.0, 3.0, 0.0, 2.0, 2.0, 1.0, 1.0, 1.0, 2.0, 1.0, 0.0, 2.0, 1.0, 4.0, 0.0, 3.0, 2.0, 1.0, 0.0, 1.0, 1.0, 2.0, 3.0, 0.0, 1.0, 3.0, 2.0, 6.0, 1.0, 1.0, 1.0, 0.0, 4.0, 2.0, 3.0, 1.0, 0.0, 3.0, 2.0, 2.0, 2.0, 0.0, 3.0, 3.0, 2.0, 2.0, 1.0, 0.0, 1.0, 3.0, 1.0, 0.0, 1.0, 3.0, 0.0, 5.0, 1.0, 4.0, 1.0, 1.0, 2.0, 4.0, 2.0, 0.0, 2.0, 0.0, 0.0, 1.0, 1.0, 1.0, 2.0, 1.0, 2.0, 2.0, 1.0, 4.0, 3.0, 1.0, 1.0], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500], "policy_shared_policy_reward": [0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 2.0, 2.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 1.0, 1.0, 2.0, 1.0, 2.0, 2.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 2.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 2.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 2.0, 0.0, 1.0, 3.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 2.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 2.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 2.0, 2.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 2.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 2.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 2.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.13359360507718088, "mean_inference_ms": 0.38905059458084196, "mean_action_processing_ms": 0.02912482750797782, "mean_env_wait_ms": 0.4032701635093599, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 342720, "timesteps_this_iter": 0, "agent_timesteps_total": 1370880, "timers": {"sample_time_ms": 5164.494, "sample_throughput": 975.894, "load_time_ms": 0.143, "load_throughput": 35167679.521, "learn_time_ms": 127.559, "learn_throughput": 39511.152, "update_time_ms": 2.328}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 80.3348388671875, "policy_entropy": 7960.5640869140625, "policy_loss": -19.437192916870117, "vf_loss": 12.529326438903809}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 342720, "num_agent_steps_sampled": 1370880, "num_steps_trained": 342720, "num_agent_steps_trained": 1370880, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 684, "training_iteration": 34, "trial_id": "71426_00000", "experiment_id": "84bca2f7b35f43248fca18d21abe2ebf", "date": "2024-06-12_02-51-38", "timestamp": 1718128298, "time_this_iter_s": 10.287524223327637, "time_total_s": 346.75905680656433, "pid": 363902, "hostname": "DESKTOP-LQ219J4", "node_ip": "192.168.46.185", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 20, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 5000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 500, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Base_Model", "custom_model_config": {"env": "rware", "env_args": {"n_agents": 4, "column_height": 1, "max_inactivity_steps": null, "max_steps": 500, "fast_obs": true, "msg_bits": 0, "sensor_range": 1, "shelf_rows": 1, "shelf_columns": 3, "request_queue_size": 4, "reward_type": "RewardType.INDIVIDUAL", "map_name": "customized_map", "map_size": "tiny", "difficulty": "medium"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": true, "force_coop": false, "local_mode": true, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 4, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 100, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64}, "algorithm": "ia2c", "space_obs": "Dict(obs:Box([-100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100.], [100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.], (112,), float32))", "space_act": "Discrete(5)", "num_agents": 4, "episode_limit": 500, "policy_mapping_info": {"all_scenario": {"description": "rware all scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2", "agent_3"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "rware_customized_map", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 10, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.IA2CTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_il.<locals>.<lambda> at 0x7f38281ee430>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "grad_clip": 40.0, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "microbatch_size": null}, "time_since_restore": 346.75905680656433, "timesteps_since_restore": 0, "iterations_since_restore": 34, "perf": {"cpu_util_percent": 4.492857142857143, "ram_util_percent": 41.60714285714287}}
{"episode_reward_max": 6.0, "episode_reward_min": 0.0, "episode_reward_mean": 1.78, "episode_len_mean": 500.0, "episode_media": {}, "episodes_this_iter": 20, "policy_reward_min": {"shared_policy": 0.0}, "policy_reward_max": {"shared_policy": 3.0}, "policy_reward_mean": {"shared_policy": 0.445}, "custom_metrics": {}, "hist_stats": {"episode_reward": [1.0, 1.0, 3.0, 0.0, 2.0, 2.0, 1.0, 1.0, 1.0, 2.0, 1.0, 0.0, 2.0, 1.0, 4.0, 0.0, 3.0, 2.0, 1.0, 0.0, 1.0, 1.0, 2.0, 3.0, 0.0, 1.0, 3.0, 2.0, 6.0, 1.0, 1.0, 1.0, 0.0, 4.0, 2.0, 3.0, 1.0, 0.0, 3.0, 2.0, 2.0, 2.0, 0.0, 3.0, 3.0, 2.0, 2.0, 1.0, 0.0, 1.0, 3.0, 1.0, 0.0, 1.0, 3.0, 0.0, 5.0, 1.0, 4.0, 1.0, 1.0, 2.0, 4.0, 2.0, 0.0, 2.0, 0.0, 0.0, 1.0, 1.0, 1.0, 2.0, 1.0, 2.0, 2.0, 1.0, 4.0, 3.0, 1.0, 1.0, 4.0, 3.0, 0.0, 6.0, 4.0, 2.0, 2.0, 2.0, 1.0, 2.0, 3.0, 6.0, 2.0, 3.0, 0.0, 2.0, 0.0, 2.0, 3.0, 0.0], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500], "policy_shared_policy_reward": [1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 2.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 2.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 2.0, 0.0, 1.0, 3.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 2.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 2.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 2.0, 2.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 2.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 2.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 2.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 2.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 2.0, 2.0, 2.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 2.0, 0.0, 1.0, 0.0, 2.0, 1.0, 1.0, 2.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.13361680900423678, "mean_inference_ms": 0.389193864137754, "mean_action_processing_ms": 0.029134329863650735, "mean_env_wait_ms": 0.40330055946874876, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 352800, "timesteps_this_iter": 0, "agent_timesteps_total": 1411200, "timers": {"sample_time_ms": 5141.369, "sample_throughput": 980.284, "load_time_ms": 0.141, "load_throughput": 35708263.784, "learn_time_ms": 126.329, "learn_throughput": 39895.785, "update_time_ms": 2.333}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 100.10324096679688, "policy_entropy": 7926.7891845703125, "policy_loss": -7.097566768527031, "vf_loss": 16.205912232398987}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 352800, "num_agent_steps_sampled": 1411200, "num_steps_trained": 352800, "num_agent_steps_trained": 1411200, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 704, "training_iteration": 35, "trial_id": "71426_00000", "experiment_id": "84bca2f7b35f43248fca18d21abe2ebf", "date": "2024-06-12_02-51-48", "timestamp": 1718128308, "time_this_iter_s": 10.242141485214233, "time_total_s": 357.00119829177856, "pid": 363902, "hostname": "DESKTOP-LQ219J4", "node_ip": "192.168.46.185", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 20, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 5000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 500, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Base_Model", "custom_model_config": {"env": "rware", "env_args": {"n_agents": 4, "column_height": 1, "max_inactivity_steps": null, "max_steps": 500, "fast_obs": true, "msg_bits": 0, "sensor_range": 1, "shelf_rows": 1, "shelf_columns": 3, "request_queue_size": 4, "reward_type": "RewardType.INDIVIDUAL", "map_name": "customized_map", "map_size": "tiny", "difficulty": "medium"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": true, "force_coop": false, "local_mode": true, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 4, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 100, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64}, "algorithm": "ia2c", "space_obs": "Dict(obs:Box([-100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100.], [100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.], (112,), float32))", "space_act": "Discrete(5)", "num_agents": 4, "episode_limit": 500, "policy_mapping_info": {"all_scenario": {"description": "rware all scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2", "agent_3"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "rware_customized_map", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 10, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.IA2CTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_il.<locals>.<lambda> at 0x7f38081d59d0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "grad_clip": 40.0, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "microbatch_size": null}, "time_since_restore": 357.00119829177856, "timesteps_since_restore": 0, "iterations_since_restore": 35, "perf": {"cpu_util_percent": 4.4, "ram_util_percent": 41.94666666666667}}
{"episode_reward_max": 6.0, "episode_reward_min": 0.0, "episode_reward_mean": 1.89, "episode_len_mean": 500.0, "episode_media": {}, "episodes_this_iter": 20, "policy_reward_min": {"shared_policy": 0.0}, "policy_reward_max": {"shared_policy": 3.0}, "policy_reward_mean": {"shared_policy": 0.4725}, "custom_metrics": {}, "hist_stats": {"episode_reward": [1.0, 1.0, 2.0, 3.0, 0.0, 1.0, 3.0, 2.0, 6.0, 1.0, 1.0, 1.0, 0.0, 4.0, 2.0, 3.0, 1.0, 0.0, 3.0, 2.0, 2.0, 2.0, 0.0, 3.0, 3.0, 2.0, 2.0, 1.0, 0.0, 1.0, 3.0, 1.0, 0.0, 1.0, 3.0, 0.0, 5.0, 1.0, 4.0, 1.0, 1.0, 2.0, 4.0, 2.0, 0.0, 2.0, 0.0, 0.0, 1.0, 1.0, 1.0, 2.0, 1.0, 2.0, 2.0, 1.0, 4.0, 3.0, 1.0, 1.0, 4.0, 3.0, 0.0, 6.0, 4.0, 2.0, 2.0, 2.0, 1.0, 2.0, 3.0, 6.0, 2.0, 3.0, 0.0, 2.0, 0.0, 2.0, 3.0, 0.0, 3.0, 1.0, 4.0, 1.0, 1.0, 0.0, 2.0, 2.0, 5.0, 1.0, 3.0, 1.0, 1.0, 4.0, 2.0, 2.0, 1.0, 0.0, 1.0, 4.0], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500], "policy_shared_policy_reward": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 2.0, 0.0, 1.0, 3.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 2.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 2.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 2.0, 2.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 2.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 2.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 2.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 2.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 2.0, 2.0, 2.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 2.0, 0.0, 1.0, 0.0, 2.0, 1.0, 1.0, 2.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 2.0, 2.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 2.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 2.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.13363528580513553, "mean_inference_ms": 0.38931993869410436, "mean_action_processing_ms": 0.029141264667246508, "mean_env_wait_ms": 0.40332148408197327, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 362880, "timesteps_this_iter": 0, "agent_timesteps_total": 1451520, "timers": {"sample_time_ms": 5139.355, "sample_throughput": 980.668, "load_time_ms": 0.149, "load_throughput": 33725737.332, "learn_time_ms": 126.271, "learn_throughput": 39914.248, "update_time_ms": 2.348}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 57.447837829589844, "policy_entropy": 7947.0126953125, "policy_loss": 3.5233553647994995, "vf_loss": 19.18308162689209}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 362880, "num_agent_steps_sampled": 1451520, "num_steps_trained": 362880, "num_agent_steps_trained": 1451520, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 724, "training_iteration": 36, "trial_id": "71426_00000", "experiment_id": "84bca2f7b35f43248fca18d21abe2ebf", "date": "2024-06-12_02-51-59", "timestamp": 1718128319, "time_this_iter_s": 10.341573238372803, "time_total_s": 367.34277153015137, "pid": 363902, "hostname": "DESKTOP-LQ219J4", "node_ip": "192.168.46.185", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 20, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 5000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 500, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Base_Model", "custom_model_config": {"env": "rware", "env_args": {"n_agents": 4, "column_height": 1, "max_inactivity_steps": null, "max_steps": 500, "fast_obs": true, "msg_bits": 0, "sensor_range": 1, "shelf_rows": 1, "shelf_columns": 3, "request_queue_size": 4, "reward_type": "RewardType.INDIVIDUAL", "map_name": "customized_map", "map_size": "tiny", "difficulty": "medium"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": true, "force_coop": false, "local_mode": true, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 4, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 100, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64}, "algorithm": "ia2c", "space_obs": "Dict(obs:Box([-100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100.], [100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.], (112,), float32))", "space_act": "Discrete(5)", "num_agents": 4, "episode_limit": 500, "policy_mapping_info": {"all_scenario": {"description": "rware all scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2", "agent_3"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "rware_customized_map", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 10, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.IA2CTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_il.<locals>.<lambda> at 0x7f380824d670>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "grad_clip": 40.0, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "microbatch_size": null}, "time_since_restore": 367.34277153015137, "timesteps_since_restore": 0, "iterations_since_restore": 36, "perf": {"cpu_util_percent": 4.393333333333333, "ram_util_percent": 42.20000000000001}}
{"episode_reward_max": 6.0, "episode_reward_min": 0.0, "episode_reward_mean": 1.83, "episode_len_mean": 500.0, "episode_media": {}, "episodes_this_iter": 20, "policy_reward_min": {"shared_policy": 0.0}, "policy_reward_max": {"shared_policy": 2.0}, "policy_reward_mean": {"shared_policy": 0.4575}, "custom_metrics": {}, "hist_stats": {"episode_reward": [2.0, 2.0, 0.0, 3.0, 3.0, 2.0, 2.0, 1.0, 0.0, 1.0, 3.0, 1.0, 0.0, 1.0, 3.0, 0.0, 5.0, 1.0, 4.0, 1.0, 1.0, 2.0, 4.0, 2.0, 0.0, 2.0, 0.0, 0.0, 1.0, 1.0, 1.0, 2.0, 1.0, 2.0, 2.0, 1.0, 4.0, 3.0, 1.0, 1.0, 4.0, 3.0, 0.0, 6.0, 4.0, 2.0, 2.0, 2.0, 1.0, 2.0, 3.0, 6.0, 2.0, 3.0, 0.0, 2.0, 0.0, 2.0, 3.0, 0.0, 3.0, 1.0, 4.0, 1.0, 1.0, 0.0, 2.0, 2.0, 5.0, 1.0, 3.0, 1.0, 1.0, 4.0, 2.0, 2.0, 1.0, 0.0, 1.0, 4.0, 2.0, 3.0, 0.0, 1.0, 0.0, 2.0, 2.0, 2.0, 0.0, 3.0, 0.0, 5.0, 3.0, 1.0, 3.0, 0.0, 0.0, 1.0, 1.0, 2.0], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500], "policy_shared_policy_reward": [1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 2.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 2.0, 2.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 2.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 2.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 2.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 2.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 2.0, 2.0, 2.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 2.0, 0.0, 1.0, 0.0, 2.0, 1.0, 1.0, 2.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 2.0, 2.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 2.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 2.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 2.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 2.0, 1.0, 1.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 2.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.13365218838662596, "mean_inference_ms": 0.38943414303096546, "mean_action_processing_ms": 0.029147684648056667, "mean_env_wait_ms": 0.403357105352703, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 372960, "timesteps_this_iter": 0, "agent_timesteps_total": 1491840, "timers": {"sample_time_ms": 5140.549, "sample_throughput": 980.44, "load_time_ms": 0.151, "load_throughput": 33464131.961, "learn_time_ms": 126.624, "learn_throughput": 39802.862, "update_time_ms": 2.356}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 124.8693618774414, "policy_entropy": 7974.9620361328125, "policy_loss": -3.370035618543625, "vf_loss": 16.778213500976562}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 372960, "num_agent_steps_sampled": 1491840, "num_steps_trained": 372960, "num_agent_steps_trained": 1491840, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 744, "training_iteration": 37, "trial_id": "71426_00000", "experiment_id": "84bca2f7b35f43248fca18d21abe2ebf", "date": "2024-06-12_02-52-09", "timestamp": 1718128329, "time_this_iter_s": 10.253282070159912, "time_total_s": 377.5960536003113, "pid": 363902, "hostname": "DESKTOP-LQ219J4", "node_ip": "192.168.46.185", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 20, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 5000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 500, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Base_Model", "custom_model_config": {"env": "rware", "env_args": {"n_agents": 4, "column_height": 1, "max_inactivity_steps": null, "max_steps": 500, "fast_obs": true, "msg_bits": 0, "sensor_range": 1, "shelf_rows": 1, "shelf_columns": 3, "request_queue_size": 4, "reward_type": "RewardType.INDIVIDUAL", "map_name": "customized_map", "map_size": "tiny", "difficulty": "medium"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": true, "force_coop": false, "local_mode": true, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 4, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 100, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64}, "algorithm": "ia2c", "space_obs": "Dict(obs:Box([-100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100.], [100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.], (112,), float32))", "space_act": "Discrete(5)", "num_agents": 4, "episode_limit": 500, "policy_mapping_info": {"all_scenario": {"description": "rware all scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2", "agent_3"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "rware_customized_map", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 10, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.IA2CTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_il.<locals>.<lambda> at 0x7f382806e940>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "grad_clip": 40.0, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "microbatch_size": null}, "time_since_restore": 377.5960536003113, "timesteps_since_restore": 0, "iterations_since_restore": 37, "perf": {"cpu_util_percent": 4.4071428571428575, "ram_util_percent": 42.5}}
{"episode_reward_max": 6.0, "episode_reward_min": 0.0, "episode_reward_mean": 1.86, "episode_len_mean": 500.0, "episode_media": {}, "episodes_this_iter": 20, "policy_reward_min": {"shared_policy": 0.0}, "policy_reward_max": {"shared_policy": 2.0}, "policy_reward_mean": {"shared_policy": 0.465}, "custom_metrics": {}, "hist_stats": {"episode_reward": [1.0, 2.0, 4.0, 2.0, 0.0, 2.0, 0.0, 0.0, 1.0, 1.0, 1.0, 2.0, 1.0, 2.0, 2.0, 1.0, 4.0, 3.0, 1.0, 1.0, 4.0, 3.0, 0.0, 6.0, 4.0, 2.0, 2.0, 2.0, 1.0, 2.0, 3.0, 6.0, 2.0, 3.0, 0.0, 2.0, 0.0, 2.0, 3.0, 0.0, 3.0, 1.0, 4.0, 1.0, 1.0, 0.0, 2.0, 2.0, 5.0, 1.0, 3.0, 1.0, 1.0, 4.0, 2.0, 2.0, 1.0, 0.0, 1.0, 4.0, 2.0, 3.0, 0.0, 1.0, 0.0, 2.0, 2.0, 2.0, 0.0, 3.0, 0.0, 5.0, 3.0, 1.0, 3.0, 0.0, 0.0, 1.0, 1.0, 2.0, 2.0, 1.0, 3.0, 2.0, 2.0, 2.0, 0.0, 1.0, 2.0, 3.0, 3.0, 2.0, 1.0, 1.0, 1.0, 2.0, 2.0, 4.0, 2.0, 2.0], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500], "policy_shared_policy_reward": [0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 2.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 2.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 2.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 2.0, 2.0, 2.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 2.0, 0.0, 1.0, 0.0, 2.0, 1.0, 1.0, 2.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 2.0, 2.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 2.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 2.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 2.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 2.0, 1.0, 1.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 2.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 2.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 2.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 2.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.1336679321590427, "mean_inference_ms": 0.3895460969891913, "mean_action_processing_ms": 0.02915306354416246, "mean_env_wait_ms": 0.4034218364531293, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 383040, "timesteps_this_iter": 0, "agent_timesteps_total": 1532160, "timers": {"sample_time_ms": 5148.512, "sample_throughput": 978.924, "load_time_ms": 0.151, "load_throughput": 33363781.818, "learn_time_ms": 127.211, "learn_throughput": 39619.357, "update_time_ms": 2.382}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 139.37045288085938, "policy_entropy": 7949.460693359375, "policy_loss": -12.067286431789398, "vf_loss": 19.112069129943848}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 383040, "num_agent_steps_sampled": 1532160, "num_steps_trained": 383040, "num_agent_steps_trained": 1532160, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 764, "training_iteration": 38, "trial_id": "71426_00000", "experiment_id": "84bca2f7b35f43248fca18d21abe2ebf", "date": "2024-06-12_02-52-19", "timestamp": 1718128339, "time_this_iter_s": 10.285530090332031, "time_total_s": 387.8815836906433, "pid": 363902, "hostname": "DESKTOP-LQ219J4", "node_ip": "192.168.46.185", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 20, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 5000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 500, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Base_Model", "custom_model_config": {"env": "rware", "env_args": {"n_agents": 4, "column_height": 1, "max_inactivity_steps": null, "max_steps": 500, "fast_obs": true, "msg_bits": 0, "sensor_range": 1, "shelf_rows": 1, "shelf_columns": 3, "request_queue_size": 4, "reward_type": "RewardType.INDIVIDUAL", "map_name": "customized_map", "map_size": "tiny", "difficulty": "medium"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": true, "force_coop": false, "local_mode": true, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 4, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 100, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64}, "algorithm": "ia2c", "space_obs": "Dict(obs:Box([-100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100.], [100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.], (112,), float32))", "space_act": "Discrete(5)", "num_agents": 4, "episode_limit": 500, "policy_mapping_info": {"all_scenario": {"description": "rware all scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2", "agent_3"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "rware_customized_map", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 10, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.IA2CTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_il.<locals>.<lambda> at 0x7f38082f8310>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "grad_clip": 40.0, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "microbatch_size": null}, "time_since_restore": 387.8815836906433, "timesteps_since_restore": 0, "iterations_since_restore": 38, "perf": {"cpu_util_percent": 4.340000000000001, "ram_util_percent": 42.74666666666666}}
{"episode_reward_max": 7.0, "episode_reward_min": 0.0, "episode_reward_mean": 2.03, "episode_len_mean": 500.0, "episode_media": {}, "episodes_this_iter": 20, "policy_reward_min": {"shared_policy": 0.0}, "policy_reward_max": {"shared_policy": 2.0}, "policy_reward_mean": {"shared_policy": 0.5075}, "custom_metrics": {}, "hist_stats": {"episode_reward": [4.0, 3.0, 0.0, 6.0, 4.0, 2.0, 2.0, 2.0, 1.0, 2.0, 3.0, 6.0, 2.0, 3.0, 0.0, 2.0, 0.0, 2.0, 3.0, 0.0, 3.0, 1.0, 4.0, 1.0, 1.0, 0.0, 2.0, 2.0, 5.0, 1.0, 3.0, 1.0, 1.0, 4.0, 2.0, 2.0, 1.0, 0.0, 1.0, 4.0, 2.0, 3.0, 0.0, 1.0, 0.0, 2.0, 2.0, 2.0, 0.0, 3.0, 0.0, 5.0, 3.0, 1.0, 3.0, 0.0, 0.0, 1.0, 1.0, 2.0, 2.0, 1.0, 3.0, 2.0, 2.0, 2.0, 0.0, 1.0, 2.0, 3.0, 3.0, 2.0, 1.0, 1.0, 1.0, 2.0, 2.0, 4.0, 2.0, 2.0, 4.0, 2.0, 4.0, 2.0, 3.0, 1.0, 1.0, 2.0, 2.0, 0.0, 1.0, 7.0, 3.0, 1.0, 4.0, 3.0, 2.0, 3.0, 1.0, 2.0], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500], "policy_shared_policy_reward": [1.0, 1.0, 0.0, 2.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 2.0, 2.0, 2.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 2.0, 0.0, 1.0, 0.0, 2.0, 1.0, 1.0, 2.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 2.0, 2.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 2.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 2.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 2.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 2.0, 1.0, 1.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 2.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 2.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 2.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 2.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 2.0, 1.0, 0.0, 1.0, 0.0, 2.0, 2.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 2.0, 2.0, 2.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 2.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 2.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.133684497239068, "mean_inference_ms": 0.3896526976849584, "mean_action_processing_ms": 0.029156719704614042, "mean_env_wait_ms": 0.4034939197232738, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 393120, "timesteps_this_iter": 0, "agent_timesteps_total": 1572480, "timers": {"sample_time_ms": 5151.109, "sample_throughput": 978.43, "load_time_ms": 0.152, "load_throughput": 33248336.206, "learn_time_ms": 126.994, "learn_throughput": 39686.91, "update_time_ms": 2.397}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 97.65701293945312, "policy_entropy": 7910.8389892578125, "policy_loss": 0.978759378194809, "vf_loss": 22.66870880126953}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 393120, "num_agent_steps_sampled": 1572480, "num_steps_trained": 393120, "num_agent_steps_trained": 1572480, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 784, "training_iteration": 39, "trial_id": "71426_00000", "experiment_id": "84bca2f7b35f43248fca18d21abe2ebf", "date": "2024-06-12_02-52-29", "timestamp": 1718128349, "time_this_iter_s": 10.308143615722656, "time_total_s": 398.18972730636597, "pid": 363902, "hostname": "DESKTOP-LQ219J4", "node_ip": "192.168.46.185", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 20, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 5000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 500, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Base_Model", "custom_model_config": {"env": "rware", "env_args": {"n_agents": 4, "column_height": 1, "max_inactivity_steps": null, "max_steps": 500, "fast_obs": true, "msg_bits": 0, "sensor_range": 1, "shelf_rows": 1, "shelf_columns": 3, "request_queue_size": 4, "reward_type": "RewardType.INDIVIDUAL", "map_name": "customized_map", "map_size": "tiny", "difficulty": "medium"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": true, "force_coop": false, "local_mode": true, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 4, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 100, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64}, "algorithm": "ia2c", "space_obs": "Dict(obs:Box([-100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100.], [100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.], (112,), float32))", "space_act": "Discrete(5)", "num_agents": 4, "episode_limit": 500, "policy_mapping_info": {"all_scenario": {"description": "rware all scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2", "agent_3"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "rware_customized_map", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 10, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.IA2CTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_il.<locals>.<lambda> at 0x7f380824d1f0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "grad_clip": 40.0, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "microbatch_size": null}, "time_since_restore": 398.18972730636597, "timesteps_since_restore": 0, "iterations_since_restore": 39, "perf": {"cpu_util_percent": 4.42, "ram_util_percent": 43.0}}
{"episode_reward_max": 7.0, "episode_reward_min": 0.0, "episode_reward_mean": 2.1, "episode_len_mean": 500.0, "episode_media": {}, "episodes_this_iter": 20, "policy_reward_min": {"shared_policy": 0.0}, "policy_reward_max": {"shared_policy": 3.0}, "policy_reward_mean": {"shared_policy": 0.525}, "custom_metrics": {}, "hist_stats": {"episode_reward": [3.0, 1.0, 4.0, 1.0, 1.0, 0.0, 2.0, 2.0, 5.0, 1.0, 3.0, 1.0, 1.0, 4.0, 2.0, 2.0, 1.0, 0.0, 1.0, 4.0, 2.0, 3.0, 0.0, 1.0, 0.0, 2.0, 2.0, 2.0, 0.0, 3.0, 0.0, 5.0, 3.0, 1.0, 3.0, 0.0, 0.0, 1.0, 1.0, 2.0, 2.0, 1.0, 3.0, 2.0, 2.0, 2.0, 0.0, 1.0, 2.0, 3.0, 3.0, 2.0, 1.0, 1.0, 1.0, 2.0, 2.0, 4.0, 2.0, 2.0, 4.0, 2.0, 4.0, 2.0, 3.0, 1.0, 1.0, 2.0, 2.0, 0.0, 1.0, 7.0, 3.0, 1.0, 4.0, 3.0, 2.0, 3.0, 1.0, 2.0, 7.0, 1.0, 3.0, 0.0, 2.0, 3.0, 2.0, 1.0, 0.0, 3.0, 2.0, 3.0, 1.0, 3.0, 3.0, 1.0, 4.0, 6.0, 4.0, 5.0], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500], "policy_shared_policy_reward": [1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 2.0, 2.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 2.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 2.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 2.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 2.0, 1.0, 1.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 2.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 2.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 2.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 2.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 2.0, 1.0, 0.0, 1.0, 0.0, 2.0, 2.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 2.0, 2.0, 2.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 2.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 2.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 2.0, 2.0, 1.0, 2.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 2.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 2.0, 1.0, 1.0, 3.0, 2.0, 0.0, 2.0, 0.0, 1.0, 1.0, 2.0, 0.0, 2.0, 1.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.13369213369200528, "mean_inference_ms": 0.38972993319984156, "mean_action_processing_ms": 0.029159129851157362, "mean_env_wait_ms": 0.4035847706423417, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 403200, "timesteps_this_iter": 0, "agent_timesteps_total": 1612800, "timers": {"sample_time_ms": 5147.354, "sample_throughput": 979.144, "load_time_ms": 0.154, "load_throughput": 32799522.358, "learn_time_ms": 126.177, "learn_throughput": 39943.926, "update_time_ms": 2.363}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 134.8881378173828, "policy_entropy": 7938.6844482421875, "policy_loss": -15.623959064483643, "vf_loss": 19.096738576889038}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 403200, "num_agent_steps_sampled": 1612800, "num_steps_trained": 403200, "num_agent_steps_trained": 1612800, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 804, "training_iteration": 40, "trial_id": "71426_00000", "experiment_id": "84bca2f7b35f43248fca18d21abe2ebf", "date": "2024-06-12_02-52-40", "timestamp": 1718128360, "time_this_iter_s": 10.20503306388855, "time_total_s": 408.3947603702545, "pid": 363902, "hostname": "DESKTOP-LQ219J4", "node_ip": "192.168.46.185", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 20, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 5000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 500, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Base_Model", "custom_model_config": {"env": "rware", "env_args": {"n_agents": 4, "column_height": 1, "max_inactivity_steps": null, "max_steps": 500, "fast_obs": true, "msg_bits": 0, "sensor_range": 1, "shelf_rows": 1, "shelf_columns": 3, "request_queue_size": 4, "reward_type": "RewardType.INDIVIDUAL", "map_name": "customized_map", "map_size": "tiny", "difficulty": "medium"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": true, "force_coop": false, "local_mode": true, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 4, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 100, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64}, "algorithm": "ia2c", "space_obs": "Dict(obs:Box([-100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100.], [100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.], (112,), float32))", "space_act": "Discrete(5)", "num_agents": 4, "episode_limit": 500, "policy_mapping_info": {"all_scenario": {"description": "rware all scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2", "agent_3"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "rware_customized_map", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 10, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.IA2CTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_il.<locals>.<lambda> at 0x7f38086c1c10>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "grad_clip": 40.0, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "microbatch_size": null}, "time_since_restore": 408.3947603702545, "timesteps_since_restore": 0, "iterations_since_restore": 40, "perf": {"cpu_util_percent": 4.25, "ram_util_percent": 43.3}}
{"episode_reward_max": 7.0, "episode_reward_min": 0.0, "episode_reward_mean": 2.1, "episode_len_mean": 500.0, "episode_media": {}, "episodes_this_iter": 20, "policy_reward_min": {"shared_policy": 0.0}, "policy_reward_max": {"shared_policy": 3.0}, "policy_reward_mean": {"shared_policy": 0.525}, "custom_metrics": {}, "hist_stats": {"episode_reward": [2.0, 3.0, 0.0, 1.0, 0.0, 2.0, 2.0, 2.0, 0.0, 3.0, 0.0, 5.0, 3.0, 1.0, 3.0, 0.0, 0.0, 1.0, 1.0, 2.0, 2.0, 1.0, 3.0, 2.0, 2.0, 2.0, 0.0, 1.0, 2.0, 3.0, 3.0, 2.0, 1.0, 1.0, 1.0, 2.0, 2.0, 4.0, 2.0, 2.0, 4.0, 2.0, 4.0, 2.0, 3.0, 1.0, 1.0, 2.0, 2.0, 0.0, 1.0, 7.0, 3.0, 1.0, 4.0, 3.0, 2.0, 3.0, 1.0, 2.0, 7.0, 1.0, 3.0, 0.0, 2.0, 3.0, 2.0, 1.0, 0.0, 3.0, 2.0, 3.0, 1.0, 3.0, 3.0, 1.0, 4.0, 6.0, 4.0, 5.0, 2.0, 1.0, 1.0, 1.0, 2.0, 3.0, 3.0, 2.0, 5.0, 1.0, 1.0, 1.0, 5.0, 2.0, 2.0, 2.0, 0.0, 2.0, 2.0, 1.0], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500], "policy_shared_policy_reward": [0.0, 2.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 2.0, 1.0, 1.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 2.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 2.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 2.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 2.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 2.0, 1.0, 0.0, 1.0, 0.0, 2.0, 2.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 2.0, 2.0, 2.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 2.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 2.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 2.0, 2.0, 1.0, 2.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 2.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 2.0, 1.0, 1.0, 3.0, 2.0, 0.0, 2.0, 0.0, 1.0, 1.0, 2.0, 0.0, 2.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 2.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.13368926429294054, "mean_inference_ms": 0.3897941681679278, "mean_action_processing_ms": 0.029161068379653172, "mean_env_wait_ms": 0.40366235440815584, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 413280, "timesteps_this_iter": 0, "agent_timesteps_total": 1653120, "timers": {"sample_time_ms": 5141.109, "sample_throughput": 980.333, "load_time_ms": 0.154, "load_throughput": 32632436.184, "learn_time_ms": 125.88, "learn_throughput": 40038.229, "update_time_ms": 2.379}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 158.03794860839844, "policy_entropy": 7930.552490234375, "policy_loss": 12.092970609664917, "vf_loss": 22.73519277572632}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 413280, "num_agent_steps_sampled": 1653120, "num_steps_trained": 413280, "num_agent_steps_trained": 1653120, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 824, "training_iteration": 41, "trial_id": "71426_00000", "experiment_id": "84bca2f7b35f43248fca18d21abe2ebf", "date": "2024-06-12_02-52-50", "timestamp": 1718128370, "time_this_iter_s": 10.282731056213379, "time_total_s": 418.6774914264679, "pid": 363902, "hostname": "DESKTOP-LQ219J4", "node_ip": "192.168.46.185", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 20, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 5000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 500, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Base_Model", "custom_model_config": {"env": "rware", "env_args": {"n_agents": 4, "column_height": 1, "max_inactivity_steps": null, "max_steps": 500, "fast_obs": true, "msg_bits": 0, "sensor_range": 1, "shelf_rows": 1, "shelf_columns": 3, "request_queue_size": 4, "reward_type": "RewardType.INDIVIDUAL", "map_name": "customized_map", "map_size": "tiny", "difficulty": "medium"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": true, "force_coop": false, "local_mode": true, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 4, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 100, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64}, "algorithm": "ia2c", "space_obs": "Dict(obs:Box([-100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100.], [100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.], (112,), float32))", "space_act": "Discrete(5)", "num_agents": 4, "episode_limit": 500, "policy_mapping_info": {"all_scenario": {"description": "rware all scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2", "agent_3"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "rware_customized_map", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 10, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.IA2CTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_il.<locals>.<lambda> at 0x7f38306aa940>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "grad_clip": 40.0, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "microbatch_size": null}, "time_since_restore": 418.6774914264679, "timesteps_since_restore": 0, "iterations_since_restore": 41, "perf": {"cpu_util_percent": 4.213333333333334, "ram_util_percent": 43.60000000000001}}
{"episode_reward_max": 7.0, "episode_reward_min": 0.0, "episode_reward_mean": 2.23, "episode_len_mean": 500.0, "episode_media": {}, "episodes_this_iter": 20, "policy_reward_min": {"shared_policy": 0.0}, "policy_reward_max": {"shared_policy": 3.0}, "policy_reward_mean": {"shared_policy": 0.5575}, "custom_metrics": {}, "hist_stats": {"episode_reward": [2.0, 1.0, 3.0, 2.0, 2.0, 2.0, 0.0, 1.0, 2.0, 3.0, 3.0, 2.0, 1.0, 1.0, 1.0, 2.0, 2.0, 4.0, 2.0, 2.0, 4.0, 2.0, 4.0, 2.0, 3.0, 1.0, 1.0, 2.0, 2.0, 0.0, 1.0, 7.0, 3.0, 1.0, 4.0, 3.0, 2.0, 3.0, 1.0, 2.0, 7.0, 1.0, 3.0, 0.0, 2.0, 3.0, 2.0, 1.0, 0.0, 3.0, 2.0, 3.0, 1.0, 3.0, 3.0, 1.0, 4.0, 6.0, 4.0, 5.0, 2.0, 1.0, 1.0, 1.0, 2.0, 3.0, 3.0, 2.0, 5.0, 1.0, 1.0, 1.0, 5.0, 2.0, 2.0, 2.0, 0.0, 2.0, 2.0, 1.0, 3.0, 1.0, 1.0, 4.0, 0.0, 6.0, 4.0, 0.0, 1.0, 4.0, 0.0, 0.0, 2.0, 3.0, 5.0, 4.0, 2.0, 0.0, 3.0, 1.0], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500], "policy_shared_policy_reward": [1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 2.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 2.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 2.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 2.0, 1.0, 0.0, 1.0, 0.0, 2.0, 2.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 2.0, 2.0, 2.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 2.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 2.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 2.0, 2.0, 1.0, 2.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 2.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 2.0, 1.0, 1.0, 3.0, 2.0, 0.0, 2.0, 0.0, 1.0, 1.0, 2.0, 0.0, 2.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 2.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 2.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 2.0, 2.0, 1.0, 0.0, 2.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 2.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 2.0, 0.0, 2.0, 0.0, 1.0, 1.0, 2.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.13368869935759034, "mean_inference_ms": 0.38986469326821116, "mean_action_processing_ms": 0.029164409673927638, "mean_env_wait_ms": 0.4037537310798038, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 423360, "timesteps_this_iter": 0, "agent_timesteps_total": 1693440, "timers": {"sample_time_ms": 5147.428, "sample_throughput": 979.13, "load_time_ms": 0.156, "load_throughput": 32382494.118, "learn_time_ms": 125.212, "learn_throughput": 40251.886, "update_time_ms": 2.455}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 113.43549346923828, "policy_entropy": 7915.1744384765625, "policy_loss": -23.171565294265747, "vf_loss": 18.131603240966797}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 423360, "num_agent_steps_sampled": 1693440, "num_steps_trained": 423360, "num_agent_steps_trained": 1693440, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 844, "training_iteration": 42, "trial_id": "71426_00000", "experiment_id": "84bca2f7b35f43248fca18d21abe2ebf", "date": "2024-06-12_02-53-00", "timestamp": 1718128380, "time_this_iter_s": 10.312540054321289, "time_total_s": 428.9900314807892, "pid": 363902, "hostname": "DESKTOP-LQ219J4", "node_ip": "192.168.46.185", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 20, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 5000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 500, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Base_Model", "custom_model_config": {"env": "rware", "env_args": {"n_agents": 4, "column_height": 1, "max_inactivity_steps": null, "max_steps": 500, "fast_obs": true, "msg_bits": 0, "sensor_range": 1, "shelf_rows": 1, "shelf_columns": 3, "request_queue_size": 4, "reward_type": "RewardType.INDIVIDUAL", "map_name": "customized_map", "map_size": "tiny", "difficulty": "medium"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": true, "force_coop": false, "local_mode": true, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 4, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 100, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64}, "algorithm": "ia2c", "space_obs": "Dict(obs:Box([-100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100.], [100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.], (112,), float32))", "space_act": "Discrete(5)", "num_agents": 4, "episode_limit": 500, "policy_mapping_info": {"all_scenario": {"description": "rware all scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2", "agent_3"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "rware_customized_map", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 10, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.IA2CTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_il.<locals>.<lambda> at 0x7f38280b2160>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "grad_clip": 40.0, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "microbatch_size": null}, "time_since_restore": 428.9900314807892, "timesteps_since_restore": 0, "iterations_since_restore": 42, "perf": {"cpu_util_percent": 4.353333333333334, "ram_util_percent": 43.89999999999999}}
{"episode_reward_max": 7.0, "episode_reward_min": 0.0, "episode_reward_mean": 2.32, "episode_len_mean": 500.0, "episode_media": {}, "episodes_this_iter": 20, "policy_reward_min": {"shared_policy": 0.0}, "policy_reward_max": {"shared_policy": 3.0}, "policy_reward_mean": {"shared_policy": 0.58}, "custom_metrics": {}, "hist_stats": {"episode_reward": [4.0, 2.0, 4.0, 2.0, 3.0, 1.0, 1.0, 2.0, 2.0, 0.0, 1.0, 7.0, 3.0, 1.0, 4.0, 3.0, 2.0, 3.0, 1.0, 2.0, 7.0, 1.0, 3.0, 0.0, 2.0, 3.0, 2.0, 1.0, 0.0, 3.0, 2.0, 3.0, 1.0, 3.0, 3.0, 1.0, 4.0, 6.0, 4.0, 5.0, 2.0, 1.0, 1.0, 1.0, 2.0, 3.0, 3.0, 2.0, 5.0, 1.0, 1.0, 1.0, 5.0, 2.0, 2.0, 2.0, 0.0, 2.0, 2.0, 1.0, 3.0, 1.0, 1.0, 4.0, 0.0, 6.0, 4.0, 0.0, 1.0, 4.0, 0.0, 0.0, 2.0, 3.0, 5.0, 4.0, 2.0, 0.0, 3.0, 1.0, 2.0, 4.0, 2.0, 4.0, 1.0, 1.0, 1.0, 4.0, 1.0, 3.0, 1.0, 1.0, 1.0, 3.0, 4.0, 1.0, 3.0, 4.0, 2.0, 4.0], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500], "policy_shared_policy_reward": [1.0, 1.0, 0.0, 2.0, 1.0, 0.0, 1.0, 0.0, 2.0, 2.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 2.0, 2.0, 2.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 2.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 2.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 2.0, 2.0, 1.0, 2.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 2.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 2.0, 1.0, 1.0, 3.0, 2.0, 0.0, 2.0, 0.0, 1.0, 1.0, 2.0, 0.0, 2.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 2.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 2.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 2.0, 2.0, 1.0, 0.0, 2.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 2.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 2.0, 0.0, 2.0, 0.0, 1.0, 1.0, 2.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 2.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 2.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 2.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 2.0, 2.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.1336869633083836, "mean_inference_ms": 0.38993884155893455, "mean_action_processing_ms": 0.029168253406438725, "mean_env_wait_ms": 0.40385699571433215, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 433440, "timesteps_this_iter": 0, "agent_timesteps_total": 1733760, "timers": {"sample_time_ms": 5150.749, "sample_throughput": 978.499, "load_time_ms": 0.168, "load_throughput": 30010352.3, "learn_time_ms": 124.762, "learn_throughput": 40396.881, "update_time_ms": 2.414}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 157.5175018310547, "policy_entropy": 7905.2801513671875, "policy_loss": 35.854929983615875, "vf_loss": 24.767091751098633}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 433440, "num_agent_steps_sampled": 1733760, "num_steps_trained": 433440, "num_agent_steps_trained": 1733760, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 864, "training_iteration": 43, "trial_id": "71426_00000", "experiment_id": "84bca2f7b35f43248fca18d21abe2ebf", "date": "2024-06-12_02-53-11", "timestamp": 1718128391, "time_this_iter_s": 10.326228380203247, "time_total_s": 439.31625986099243, "pid": 363902, "hostname": "DESKTOP-LQ219J4", "node_ip": "192.168.46.185", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 20, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 5000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 500, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Base_Model", "custom_model_config": {"env": "rware", "env_args": {"n_agents": 4, "column_height": 1, "max_inactivity_steps": null, "max_steps": 500, "fast_obs": true, "msg_bits": 0, "sensor_range": 1, "shelf_rows": 1, "shelf_columns": 3, "request_queue_size": 4, "reward_type": "RewardType.INDIVIDUAL", "map_name": "customized_map", "map_size": "tiny", "difficulty": "medium"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": true, "force_coop": false, "local_mode": true, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 4, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 100, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64}, "algorithm": "ia2c", "space_obs": "Dict(obs:Box([-100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100.], [100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.], (112,), float32))", "space_act": "Discrete(5)", "num_agents": 4, "episode_limit": 500, "policy_mapping_info": {"all_scenario": {"description": "rware all scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2", "agent_3"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "rware_customized_map", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 10, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.IA2CTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_il.<locals>.<lambda> at 0x7f38082f8ee0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "grad_clip": 40.0, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "microbatch_size": null}, "time_since_restore": 439.31625986099243, "timesteps_since_restore": 0, "iterations_since_restore": 43, "perf": {"cpu_util_percent": 4.45, "ram_util_percent": 44.15}}
{"episode_reward_max": 7.0, "episode_reward_min": 0.0, "episode_reward_mean": 2.44, "episode_len_mean": 500.0, "episode_media": {}, "episodes_this_iter": 20, "policy_reward_min": {"shared_policy": 0.0}, "policy_reward_max": {"shared_policy": 3.0}, "policy_reward_mean": {"shared_policy": 0.61}, "custom_metrics": {}, "hist_stats": {"episode_reward": [7.0, 1.0, 3.0, 0.0, 2.0, 3.0, 2.0, 1.0, 0.0, 3.0, 2.0, 3.0, 1.0, 3.0, 3.0, 1.0, 4.0, 6.0, 4.0, 5.0, 2.0, 1.0, 1.0, 1.0, 2.0, 3.0, 3.0, 2.0, 5.0, 1.0, 1.0, 1.0, 5.0, 2.0, 2.0, 2.0, 0.0, 2.0, 2.0, 1.0, 3.0, 1.0, 1.0, 4.0, 0.0, 6.0, 4.0, 0.0, 1.0, 4.0, 0.0, 0.0, 2.0, 3.0, 5.0, 4.0, 2.0, 0.0, 3.0, 1.0, 2.0, 4.0, 2.0, 4.0, 1.0, 1.0, 1.0, 4.0, 1.0, 3.0, 1.0, 1.0, 1.0, 3.0, 4.0, 1.0, 3.0, 4.0, 2.0, 4.0, 4.0, 2.0, 3.0, 2.0, 4.0, 6.0, 1.0, 1.0, 5.0, 5.0, 2.0, 2.0, 2.0, 3.0, 6.0, 3.0, 2.0, 3.0, 2.0, 2.0], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500], "policy_shared_policy_reward": [2.0, 2.0, 1.0, 2.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 2.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 2.0, 1.0, 1.0, 3.0, 2.0, 0.0, 2.0, 0.0, 1.0, 1.0, 2.0, 0.0, 2.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 2.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 2.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 2.0, 2.0, 1.0, 0.0, 2.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 2.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 2.0, 0.0, 2.0, 0.0, 1.0, 1.0, 2.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 2.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 2.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 2.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 2.0, 2.0, 0.0, 1.0, 2.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 2.0, 1.0, 1.0, 2.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 2.0, 1.0, 2.0, 0.0, 1.0, 2.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 2.0, 2.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 2.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.13367619065858813, "mean_inference_ms": 0.38997938530134135, "mean_action_processing_ms": 0.029170370023721307, "mean_env_wait_ms": 0.40392812504667847, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 443520, "timesteps_this_iter": 0, "agent_timesteps_total": 1774080, "timers": {"sample_time_ms": 5135.565, "sample_throughput": 981.391, "load_time_ms": 0.173, "load_throughput": 29169714.585, "learn_time_ms": 125.169, "learn_throughput": 40265.41, "update_time_ms": 2.378}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 86.2247314453125, "policy_entropy": 7883.81494140625, "policy_loss": 20.115010261535645, "vf_loss": 23.37971019744873}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 443520, "num_agent_steps_sampled": 1774080, "num_steps_trained": 443520, "num_agent_steps_trained": 1774080, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 884, "training_iteration": 44, "trial_id": "71426_00000", "experiment_id": "84bca2f7b35f43248fca18d21abe2ebf", "date": "2024-06-12_02-53-21", "timestamp": 1718128401, "time_this_iter_s": 10.159793615341187, "time_total_s": 449.4760534763336, "pid": 363902, "hostname": "DESKTOP-LQ219J4", "node_ip": "192.168.46.185", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 20, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 5000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 500, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Base_Model", "custom_model_config": {"env": "rware", "env_args": {"n_agents": 4, "column_height": 1, "max_inactivity_steps": null, "max_steps": 500, "fast_obs": true, "msg_bits": 0, "sensor_range": 1, "shelf_rows": 1, "shelf_columns": 3, "request_queue_size": 4, "reward_type": "RewardType.INDIVIDUAL", "map_name": "customized_map", "map_size": "tiny", "difficulty": "medium"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": true, "force_coop": false, "local_mode": true, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 4, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 100, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64}, "algorithm": "ia2c", "space_obs": "Dict(obs:Box([-100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100.], [100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.], (112,), float32))", "space_act": "Discrete(5)", "num_agents": 4, "episode_limit": 500, "policy_mapping_info": {"all_scenario": {"description": "rware all scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2", "agent_3"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "rware_customized_map", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 10, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.IA2CTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_il.<locals>.<lambda> at 0x7f38081d5dc0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "grad_clip": 40.0, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "microbatch_size": null}, "time_since_restore": 449.4760534763336, "timesteps_since_restore": 0, "iterations_since_restore": 44, "perf": {"cpu_util_percent": 4.640000000000001, "ram_util_percent": 44.486666666666665}}
{"episode_reward_max": 7.0, "episode_reward_min": 0.0, "episode_reward_mean": 2.36, "episode_len_mean": 500.0, "episode_media": {}, "episodes_this_iter": 20, "policy_reward_min": {"shared_policy": 0.0}, "policy_reward_max": {"shared_policy": 3.0}, "policy_reward_mean": {"shared_policy": 0.59}, "custom_metrics": {}, "hist_stats": {"episode_reward": [2.0, 1.0, 1.0, 1.0, 2.0, 3.0, 3.0, 2.0, 5.0, 1.0, 1.0, 1.0, 5.0, 2.0, 2.0, 2.0, 0.0, 2.0, 2.0, 1.0, 3.0, 1.0, 1.0, 4.0, 0.0, 6.0, 4.0, 0.0, 1.0, 4.0, 0.0, 0.0, 2.0, 3.0, 5.0, 4.0, 2.0, 0.0, 3.0, 1.0, 2.0, 4.0, 2.0, 4.0, 1.0, 1.0, 1.0, 4.0, 1.0, 3.0, 1.0, 1.0, 1.0, 3.0, 4.0, 1.0, 3.0, 4.0, 2.0, 4.0, 4.0, 2.0, 3.0, 2.0, 4.0, 6.0, 1.0, 1.0, 5.0, 5.0, 2.0, 2.0, 2.0, 3.0, 6.0, 3.0, 2.0, 3.0, 2.0, 2.0, 1.0, 7.0, 2.0, 2.0, 1.0, 0.0, 3.0, 3.0, 0.0, 3.0, 5.0, 2.0, 2.0, 2.0, 0.0, 5.0, 2.0, 1.0, 2.0, 3.0], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500], "policy_shared_policy_reward": [1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 2.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 2.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 2.0, 2.0, 1.0, 0.0, 2.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 2.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 2.0, 0.0, 2.0, 0.0, 1.0, 1.0, 2.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 2.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 2.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 2.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 2.0, 2.0, 0.0, 1.0, 2.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 2.0, 1.0, 1.0, 2.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 2.0, 1.0, 2.0, 0.0, 1.0, 2.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 2.0, 2.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 2.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 3.0, 1.0, 3.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 2.0, 1.0, 2.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 2.0, 2.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.1336699912902877, "mean_inference_ms": 0.39002646455769935, "mean_action_processing_ms": 0.02917403502312369, "mean_env_wait_ms": 0.4039708136916995, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 453600, "timesteps_this_iter": 0, "agent_timesteps_total": 1814400, "timers": {"sample_time_ms": 5134.383, "sample_throughput": 981.617, "load_time_ms": 0.173, "load_throughput": 29109463.178, "learn_time_ms": 126.572, "learn_throughput": 39819.109, "update_time_ms": 2.396}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 64.75230407714844, "policy_entropy": 7932.482666015625, "policy_loss": -18.341243028640747, "vf_loss": 14.273493528366089}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 453600, "num_agent_steps_sampled": 1814400, "num_steps_trained": 453600, "num_agent_steps_trained": 1814400, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 904, "training_iteration": 45, "trial_id": "71426_00000", "experiment_id": "84bca2f7b35f43248fca18d21abe2ebf", "date": "2024-06-12_02-53-31", "timestamp": 1718128411, "time_this_iter_s": 10.196279764175415, "time_total_s": 459.67233324050903, "pid": 363902, "hostname": "DESKTOP-LQ219J4", "node_ip": "192.168.46.185", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 20, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 5000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 500, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Base_Model", "custom_model_config": {"env": "rware", "env_args": {"n_agents": 4, "column_height": 1, "max_inactivity_steps": null, "max_steps": 500, "fast_obs": true, "msg_bits": 0, "sensor_range": 1, "shelf_rows": 1, "shelf_columns": 3, "request_queue_size": 4, "reward_type": "RewardType.INDIVIDUAL", "map_name": "customized_map", "map_size": "tiny", "difficulty": "medium"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": true, "force_coop": false, "local_mode": true, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 4, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 100, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64}, "algorithm": "ia2c", "space_obs": "Dict(obs:Box([-100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100.], [100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.], (112,), float32))", "space_act": "Discrete(5)", "num_agents": 4, "episode_limit": 500, "policy_mapping_info": {"all_scenario": {"description": "rware all scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2", "agent_3"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "rware_customized_map", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 10, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.IA2CTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_il.<locals>.<lambda> at 0x7f3808645b80>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "grad_clip": 40.0, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "microbatch_size": null}, "time_since_restore": 459.67233324050903, "timesteps_since_restore": 0, "iterations_since_restore": 45, "perf": {"cpu_util_percent": 4.533333333333333, "ram_util_percent": 44.720000000000006}}
{"episode_reward_max": 7.0, "episode_reward_min": 0.0, "episode_reward_mean": 2.51, "episode_len_mean": 500.0, "episode_media": {}, "episodes_this_iter": 20, "policy_reward_min": {"shared_policy": 0.0}, "policy_reward_max": {"shared_policy": 3.0}, "policy_reward_mean": {"shared_policy": 0.6275}, "custom_metrics": {}, "hist_stats": {"episode_reward": [3.0, 1.0, 1.0, 4.0, 0.0, 6.0, 4.0, 0.0, 1.0, 4.0, 0.0, 0.0, 2.0, 3.0, 5.0, 4.0, 2.0, 0.0, 3.0, 1.0, 2.0, 4.0, 2.0, 4.0, 1.0, 1.0, 1.0, 4.0, 1.0, 3.0, 1.0, 1.0, 1.0, 3.0, 4.0, 1.0, 3.0, 4.0, 2.0, 4.0, 4.0, 2.0, 3.0, 2.0, 4.0, 6.0, 1.0, 1.0, 5.0, 5.0, 2.0, 2.0, 2.0, 3.0, 6.0, 3.0, 2.0, 3.0, 2.0, 2.0, 1.0, 7.0, 2.0, 2.0, 1.0, 0.0, 3.0, 3.0, 0.0, 3.0, 5.0, 2.0, 2.0, 2.0, 0.0, 5.0, 2.0, 1.0, 2.0, 3.0, 1.0, 7.0, 3.0, 1.0, 3.0, 2.0, 4.0, 1.0, 4.0, 0.0, 1.0, 4.0, 0.0, 5.0, 1.0, 4.0, 3.0, 5.0, 1.0, 4.0], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500], "policy_shared_policy_reward": [1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 2.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 2.0, 2.0, 1.0, 0.0, 2.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 2.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 2.0, 0.0, 2.0, 0.0, 1.0, 1.0, 2.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 2.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 2.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 2.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 2.0, 2.0, 0.0, 1.0, 2.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 2.0, 1.0, 1.0, 2.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 2.0, 1.0, 2.0, 0.0, 1.0, 2.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 2.0, 2.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 2.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 3.0, 1.0, 3.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 2.0, 1.0, 2.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 2.0, 2.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 2.0, 2.0, 2.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 2.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 2.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 2.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 2.0, 2.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 2.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 2.0, 1.0, 0.0, 0.0, 0.0, 1.0, 2.0, 1.0, 0.0, 1.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.1336664427277113, "mean_inference_ms": 0.3900629053282877, "mean_action_processing_ms": 0.029176383981793695, "mean_env_wait_ms": 0.4039935225188409, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 463680, "timesteps_this_iter": 0, "agent_timesteps_total": 1854720, "timers": {"sample_time_ms": 5131.04, "sample_throughput": 982.257, "load_time_ms": 0.166, "load_throughput": 30355100.747, "learn_time_ms": 142.951, "learn_throughput": 35256.886, "update_time_ms": 2.367}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 219.25613403320312, "policy_entropy": 7955.89892578125, "policy_loss": 21.96065056324005, "vf_loss": 28.06690526008606}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 463680, "num_agent_steps_sampled": 1854720, "num_steps_trained": 463680, "num_agent_steps_trained": 1854720, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 924, "training_iteration": 46, "trial_id": "71426_00000", "experiment_id": "84bca2f7b35f43248fca18d21abe2ebf", "date": "2024-06-12_02-53-41", "timestamp": 1718128421, "time_this_iter_s": 10.396358728408813, "time_total_s": 470.06869196891785, "pid": 363902, "hostname": "DESKTOP-LQ219J4", "node_ip": "192.168.46.185", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 20, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 5000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 500, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Base_Model", "custom_model_config": {"env": "rware", "env_args": {"n_agents": 4, "column_height": 1, "max_inactivity_steps": null, "max_steps": 500, "fast_obs": true, "msg_bits": 0, "sensor_range": 1, "shelf_rows": 1, "shelf_columns": 3, "request_queue_size": 4, "reward_type": "RewardType.INDIVIDUAL", "map_name": "customized_map", "map_size": "tiny", "difficulty": "medium"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": true, "force_coop": false, "local_mode": true, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 4, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 100, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64}, "algorithm": "ia2c", "space_obs": "Dict(obs:Box([-100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100.], [100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.], (112,), float32))", "space_act": "Discrete(5)", "num_agents": 4, "episode_limit": 500, "policy_mapping_info": {"all_scenario": {"description": "rware all scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2", "agent_3"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "rware_customized_map", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 10, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.IA2CTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_il.<locals>.<lambda> at 0x7f380824d3a0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "grad_clip": 40.0, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "microbatch_size": null}, "time_since_restore": 470.06869196891785, "timesteps_since_restore": 0, "iterations_since_restore": 46, "perf": {"cpu_util_percent": 4.285714285714286, "ram_util_percent": 45.0}}
{"episode_reward_max": 9.0, "episode_reward_min": 0.0, "episode_reward_mean": 2.73, "episode_len_mean": 500.0, "episode_media": {}, "episodes_this_iter": 20, "policy_reward_min": {"shared_policy": 0.0}, "policy_reward_max": {"shared_policy": 4.0}, "policy_reward_mean": {"shared_policy": 0.6825}, "custom_metrics": {}, "hist_stats": {"episode_reward": [2.0, 4.0, 2.0, 4.0, 1.0, 1.0, 1.0, 4.0, 1.0, 3.0, 1.0, 1.0, 1.0, 3.0, 4.0, 1.0, 3.0, 4.0, 2.0, 4.0, 4.0, 2.0, 3.0, 2.0, 4.0, 6.0, 1.0, 1.0, 5.0, 5.0, 2.0, 2.0, 2.0, 3.0, 6.0, 3.0, 2.0, 3.0, 2.0, 2.0, 1.0, 7.0, 2.0, 2.0, 1.0, 0.0, 3.0, 3.0, 0.0, 3.0, 5.0, 2.0, 2.0, 2.0, 0.0, 5.0, 2.0, 1.0, 2.0, 3.0, 1.0, 7.0, 3.0, 1.0, 3.0, 2.0, 4.0, 1.0, 4.0, 0.0, 1.0, 4.0, 0.0, 5.0, 1.0, 4.0, 3.0, 5.0, 1.0, 4.0, 2.0, 6.0, 1.0, 6.0, 1.0, 9.0, 1.0, 0.0, 1.0, 3.0, 5.0, 1.0, 2.0, 2.0, 5.0, 6.0, 3.0, 5.0, 3.0, 4.0], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500], "policy_shared_policy_reward": [0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 2.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 2.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 2.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 2.0, 2.0, 0.0, 1.0, 2.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 2.0, 1.0, 1.0, 2.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 2.0, 1.0, 2.0, 0.0, 1.0, 2.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 2.0, 2.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 2.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 3.0, 1.0, 3.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 2.0, 1.0, 2.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 2.0, 2.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 2.0, 2.0, 2.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 2.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 2.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 2.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 2.0, 2.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 2.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 2.0, 1.0, 0.0, 0.0, 0.0, 1.0, 2.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 2.0, 1.0, 2.0, 0.0, 0.0, 0.0, 1.0, 1.0, 2.0, 1.0, 2.0, 0.0, 0.0, 1.0, 0.0, 2.0, 4.0, 2.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 2.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 2.0, 0.0, 2.0, 0.0, 3.0, 3.0, 0.0, 0.0, 0.0, 2.0, 1.0, 2.0, 0.0, 2.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 2.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.13367490670595886, "mean_inference_ms": 0.39012506047825146, "mean_action_processing_ms": 0.029180135594562975, "mean_env_wait_ms": 0.40401593534520475, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 473760, "timesteps_this_iter": 0, "agent_timesteps_total": 1895040, "timers": {"sample_time_ms": 5160.881, "sample_throughput": 976.577, "load_time_ms": 0.175, "load_throughput": 28772685.668, "learn_time_ms": 143.339, "learn_throughput": 35161.397, "update_time_ms": 2.337}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 265.52020263671875, "policy_entropy": 7945.754150390625, "policy_loss": 12.270271301269531, "vf_loss": 35.54915475845337}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 473760, "num_agent_steps_sampled": 1895040, "num_steps_trained": 473760, "num_agent_steps_trained": 1895040, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 944, "training_iteration": 47, "trial_id": "71426_00000", "experiment_id": "84bca2f7b35f43248fca18d21abe2ebf", "date": "2024-06-12_02-53-52", "timestamp": 1718128432, "time_this_iter_s": 10.446116209030151, "time_total_s": 480.514808177948, "pid": 363902, "hostname": "DESKTOP-LQ219J4", "node_ip": "192.168.46.185", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 20, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 5000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 500, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Base_Model", "custom_model_config": {"env": "rware", "env_args": {"n_agents": 4, "column_height": 1, "max_inactivity_steps": null, "max_steps": 500, "fast_obs": true, "msg_bits": 0, "sensor_range": 1, "shelf_rows": 1, "shelf_columns": 3, "request_queue_size": 4, "reward_type": "RewardType.INDIVIDUAL", "map_name": "customized_map", "map_size": "tiny", "difficulty": "medium"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": true, "force_coop": false, "local_mode": true, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 4, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 100, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64}, "algorithm": "ia2c", "space_obs": "Dict(obs:Box([-100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100.], [100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.], (112,), float32))", "space_act": "Discrete(5)", "num_agents": 4, "episode_limit": 500, "policy_mapping_info": {"all_scenario": {"description": "rware all scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2", "agent_3"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "rware_customized_map", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 10, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.IA2CTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_il.<locals>.<lambda> at 0x7f38082f8670>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "grad_clip": 40.0, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "microbatch_size": null}, "time_since_restore": 480.514808177948, "timesteps_since_restore": 0, "iterations_since_restore": 47, "perf": {"cpu_util_percent": 4.6, "ram_util_percent": 45.3}}
{"episode_reward_max": 9.0, "episode_reward_min": 0.0, "episode_reward_mean": 2.74, "episode_len_mean": 500.0, "episode_media": {}, "episodes_this_iter": 20, "policy_reward_min": {"shared_policy": 0.0}, "policy_reward_max": {"shared_policy": 4.0}, "policy_reward_mean": {"shared_policy": 0.685}, "custom_metrics": {}, "hist_stats": {"episode_reward": [4.0, 2.0, 3.0, 2.0, 4.0, 6.0, 1.0, 1.0, 5.0, 5.0, 2.0, 2.0, 2.0, 3.0, 6.0, 3.0, 2.0, 3.0, 2.0, 2.0, 1.0, 7.0, 2.0, 2.0, 1.0, 0.0, 3.0, 3.0, 0.0, 3.0, 5.0, 2.0, 2.0, 2.0, 0.0, 5.0, 2.0, 1.0, 2.0, 3.0, 1.0, 7.0, 3.0, 1.0, 3.0, 2.0, 4.0, 1.0, 4.0, 0.0, 1.0, 4.0, 0.0, 5.0, 1.0, 4.0, 3.0, 5.0, 1.0, 4.0, 2.0, 6.0, 1.0, 6.0, 1.0, 9.0, 1.0, 0.0, 1.0, 3.0, 5.0, 1.0, 2.0, 2.0, 5.0, 6.0, 3.0, 5.0, 3.0, 4.0, 2.0, 2.0, 2.0, 4.0, 7.0, 5.0, 2.0, 2.0, 2.0, 1.0, 3.0, 3.0, 2.0, 2.0, 1.0, 1.0, 0.0, 1.0, 4.0, 2.0], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500], "policy_shared_policy_reward": [1.0, 2.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 2.0, 1.0, 1.0, 2.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 2.0, 1.0, 2.0, 0.0, 1.0, 2.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 2.0, 2.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 2.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 3.0, 1.0, 3.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 2.0, 1.0, 2.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 2.0, 2.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 2.0, 2.0, 2.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 2.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 2.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 2.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 2.0, 2.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 2.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 2.0, 1.0, 0.0, 0.0, 0.0, 1.0, 2.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 2.0, 1.0, 2.0, 0.0, 0.0, 0.0, 1.0, 1.0, 2.0, 1.0, 2.0, 0.0, 0.0, 1.0, 0.0, 2.0, 4.0, 2.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 2.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 2.0, 0.0, 2.0, 0.0, 3.0, 3.0, 0.0, 0.0, 0.0, 2.0, 1.0, 2.0, 0.0, 2.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 2.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 3.0, 0.0, 2.0, 2.0, 2.0, 2.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 2.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 2.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.13368473570369793, "mean_inference_ms": 0.3901811533588085, "mean_action_processing_ms": 0.02918527840011385, "mean_env_wait_ms": 0.40402257324009255, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 483840, "timesteps_this_iter": 0, "agent_timesteps_total": 1935360, "timers": {"sample_time_ms": 5158.184, "sample_throughput": 977.088, "load_time_ms": 0.162, "load_throughput": 31174299.012, "learn_time_ms": 144.294, "learn_throughput": 34928.785, "update_time_ms": 2.466}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 87.36016082763672, "policy_entropy": 7939.5853271484375, "policy_loss": -9.131386697292328, "vf_loss": 20.060971975326538}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 483840, "num_agent_steps_sampled": 1935360, "num_steps_trained": 483840, "num_agent_steps_trained": 1935360, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 964, "training_iteration": 48, "trial_id": "71426_00000", "experiment_id": "84bca2f7b35f43248fca18d21abe2ebf", "date": "2024-06-12_02-54-02", "timestamp": 1718128442, "time_this_iter_s": 10.308529615402222, "time_total_s": 490.8233377933502, "pid": 363902, "hostname": "DESKTOP-LQ219J4", "node_ip": "192.168.46.185", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 20, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 5000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 500, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Base_Model", "custom_model_config": {"env": "rware", "env_args": {"n_agents": 4, "column_height": 1, "max_inactivity_steps": null, "max_steps": 500, "fast_obs": true, "msg_bits": 0, "sensor_range": 1, "shelf_rows": 1, "shelf_columns": 3, "request_queue_size": 4, "reward_type": "RewardType.INDIVIDUAL", "map_name": "customized_map", "map_size": "tiny", "difficulty": "medium"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": true, "force_coop": false, "local_mode": true, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 4, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 100, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64}, "algorithm": "ia2c", "space_obs": "Dict(obs:Box([-100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100.], [100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.], (112,), float32))", "space_act": "Discrete(5)", "num_agents": 4, "episode_limit": 500, "policy_mapping_info": {"all_scenario": {"description": "rware all scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2", "agent_3"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "rware_customized_map", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 10, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.IA2CTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_il.<locals>.<lambda> at 0x7f380824d820>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "grad_clip": 40.0, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "microbatch_size": null}, "time_since_restore": 490.8233377933502, "timesteps_since_restore": 0, "iterations_since_restore": 48, "perf": {"cpu_util_percent": 4.633333333333334, "ram_util_percent": 45.60000000000001}}
{"episode_reward_max": 9.0, "episode_reward_min": 0.0, "episode_reward_mean": 2.72, "episode_len_mean": 500.0, "episode_media": {}, "episodes_this_iter": 20, "policy_reward_min": {"shared_policy": 0.0}, "policy_reward_max": {"shared_policy": 4.0}, "policy_reward_mean": {"shared_policy": 0.68}, "custom_metrics": {}, "hist_stats": {"episode_reward": [1.0, 7.0, 2.0, 2.0, 1.0, 0.0, 3.0, 3.0, 0.0, 3.0, 5.0, 2.0, 2.0, 2.0, 0.0, 5.0, 2.0, 1.0, 2.0, 3.0, 1.0, 7.0, 3.0, 1.0, 3.0, 2.0, 4.0, 1.0, 4.0, 0.0, 1.0, 4.0, 0.0, 5.0, 1.0, 4.0, 3.0, 5.0, 1.0, 4.0, 2.0, 6.0, 1.0, 6.0, 1.0, 9.0, 1.0, 0.0, 1.0, 3.0, 5.0, 1.0, 2.0, 2.0, 5.0, 6.0, 3.0, 5.0, 3.0, 4.0, 2.0, 2.0, 2.0, 4.0, 7.0, 5.0, 2.0, 2.0, 2.0, 1.0, 3.0, 3.0, 2.0, 2.0, 1.0, 1.0, 0.0, 1.0, 4.0, 2.0, 4.0, 1.0, 3.0, 1.0, 3.0, 1.0, 4.0, 2.0, 3.0, 1.0, 2.0, 4.0, 4.0, 4.0, 3.0, 2.0, 4.0, 4.0, 5.0, 3.0], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500], "policy_shared_policy_reward": [0.0, 0.0, 0.0, 1.0, 3.0, 1.0, 3.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 2.0, 1.0, 2.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 2.0, 2.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 2.0, 2.0, 2.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 2.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 2.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 2.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 2.0, 2.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 2.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 2.0, 1.0, 0.0, 0.0, 0.0, 1.0, 2.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 2.0, 1.0, 2.0, 0.0, 0.0, 0.0, 1.0, 1.0, 2.0, 1.0, 2.0, 0.0, 0.0, 1.0, 0.0, 2.0, 4.0, 2.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 2.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 2.0, 0.0, 2.0, 0.0, 3.0, 3.0, 0.0, 0.0, 0.0, 2.0, 1.0, 2.0, 0.0, 2.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 2.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 3.0, 0.0, 2.0, 2.0, 2.0, 2.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 2.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 2.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 2.0, 2.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 2.0, 0.0, 0.0, 0.0, 2.0, 0.0, 2.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 2.0, 0.0, 1.0, 1.0, 2.0, 0.0, 2.0, 1.0, 1.0, 2.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 2.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 2.0, 2.0, 1.0, 2.0, 0.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.1337109024407455, "mean_inference_ms": 0.3902903209928057, "mean_action_processing_ms": 0.029193102364109845, "mean_env_wait_ms": 0.40406978943148786, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 493920, "timesteps_this_iter": 0, "agent_timesteps_total": 1975680, "timers": {"sample_time_ms": 5190.226, "sample_throughput": 971.056, "load_time_ms": 0.159, "load_throughput": 31603067.962, "learn_time_ms": 145.368, "learn_throughput": 34670.719, "update_time_ms": 2.476}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 301.8397216796875, "policy_entropy": 7925.026611328125, "policy_loss": -4.615887641906738, "vf_loss": 32.123878955841064}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 493920, "num_agent_steps_sampled": 1975680, "num_steps_trained": 493920, "num_agent_steps_trained": 1975680, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 984, "training_iteration": 49, "trial_id": "71426_00000", "experiment_id": "84bca2f7b35f43248fca18d21abe2ebf", "date": "2024-06-12_02-54-13", "timestamp": 1718128453, "time_this_iter_s": 10.470619201660156, "time_total_s": 501.2939569950104, "pid": 363902, "hostname": "DESKTOP-LQ219J4", "node_ip": "192.168.46.185", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 20, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 5000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 500, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Base_Model", "custom_model_config": {"env": "rware", "env_args": {"n_agents": 4, "column_height": 1, "max_inactivity_steps": null, "max_steps": 500, "fast_obs": true, "msg_bits": 0, "sensor_range": 1, "shelf_rows": 1, "shelf_columns": 3, "request_queue_size": 4, "reward_type": "RewardType.INDIVIDUAL", "map_name": "customized_map", "map_size": "tiny", "difficulty": "medium"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": true, "force_coop": false, "local_mode": true, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 4, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 100, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64}, "algorithm": "ia2c", "space_obs": "Dict(obs:Box([-100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100.], [100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.], (112,), float32))", "space_act": "Discrete(5)", "num_agents": 4, "episode_limit": 500, "policy_mapping_info": {"all_scenario": {"description": "rware all scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2", "agent_3"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "rware_customized_map", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 10, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.IA2CTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_il.<locals>.<lambda> at 0x7f38082f84c0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "grad_clip": 40.0, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "microbatch_size": null}, "time_since_restore": 501.2939569950104, "timesteps_since_restore": 0, "iterations_since_restore": 49, "perf": {"cpu_util_percent": 4.806666666666666, "ram_util_percent": 45.89999999999999}}
{"episode_reward_max": 9.0, "episode_reward_min": 0.0, "episode_reward_mean": 2.72, "episode_len_mean": 500.0, "episode_media": {}, "episodes_this_iter": 24, "policy_reward_min": {"shared_policy": 0.0}, "policy_reward_max": {"shared_policy": 4.0}, "policy_reward_mean": {"shared_policy": 0.68}, "custom_metrics": {}, "hist_stats": {"episode_reward": [3.0, 2.0, 4.0, 1.0, 4.0, 0.0, 1.0, 4.0, 0.0, 5.0, 1.0, 4.0, 3.0, 5.0, 1.0, 4.0, 2.0, 6.0, 1.0, 6.0, 1.0, 9.0, 1.0, 0.0, 1.0, 3.0, 5.0, 1.0, 2.0, 2.0, 5.0, 6.0, 3.0, 5.0, 3.0, 4.0, 2.0, 2.0, 2.0, 4.0, 7.0, 5.0, 2.0, 2.0, 2.0, 1.0, 3.0, 3.0, 2.0, 2.0, 1.0, 1.0, 0.0, 1.0, 4.0, 2.0, 4.0, 1.0, 3.0, 1.0, 3.0, 1.0, 4.0, 2.0, 3.0, 1.0, 2.0, 4.0, 4.0, 4.0, 3.0, 2.0, 4.0, 4.0, 5.0, 3.0, 1.0, 1.0, 2.0, 4.0, 2.0, 1.0, 1.0, 2.0, 2.0, 2.0, 1.0, 1.0, 4.0, 7.0, 4.0, 2.0, 2.0, 4.0, 2.0, 3.0, 2.0, 5.0, 3.0, 0.0], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500], "policy_shared_policy_reward": [1.0, 0.0, 0.0, 2.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 2.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 2.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 2.0, 2.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 2.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 2.0, 1.0, 0.0, 0.0, 0.0, 1.0, 2.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 2.0, 1.0, 2.0, 0.0, 0.0, 0.0, 1.0, 1.0, 2.0, 1.0, 2.0, 0.0, 0.0, 1.0, 0.0, 2.0, 4.0, 2.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 2.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 2.0, 0.0, 2.0, 0.0, 3.0, 3.0, 0.0, 0.0, 0.0, 2.0, 1.0, 2.0, 0.0, 2.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 2.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 3.0, 0.0, 2.0, 2.0, 2.0, 2.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 2.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 2.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 2.0, 2.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 2.0, 0.0, 0.0, 0.0, 2.0, 0.0, 2.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 2.0, 0.0, 1.0, 1.0, 2.0, 0.0, 2.0, 1.0, 1.0, 2.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 2.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 2.0, 2.0, 1.0, 2.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 2.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 2.0, 1.0, 0.0, 4.0, 3.0, 0.0, 0.0, 1.0, 1.0, 2.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 2.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.13374038157751747, "mean_inference_ms": 0.39039401934534823, "mean_action_processing_ms": 0.0291992917285574, "mean_env_wait_ms": 0.4041806122773208, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 504000, "timesteps_this_iter": 0, "agent_timesteps_total": 2016000, "timers": {"sample_time_ms": 5198.621, "sample_throughput": 969.488, "load_time_ms": 0.161, "load_throughput": 31248029.8, "learn_time_ms": 145.031, "learn_throughput": 34751.237, "update_time_ms": 2.453}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 126.79768371582031, "policy_entropy": 7902.60546875, "policy_loss": -38.68070864677429, "vf_loss": 20.30025625228882}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 504000, "num_agent_steps_sampled": 2016000, "num_steps_trained": 504000, "num_agent_steps_trained": 2016000, "num_steps_trained_this_iter": 0}, "evaluation": {"episode_reward_max": 10.0, "episode_reward_min": 1.0, "episode_reward_mean": 4.4, "episode_len_mean": 500.0, "episode_media": {}, "episodes_this_iter": 10, "policy_reward_min": {"shared_policy": 0.0}, "policy_reward_max": {"shared_policy": 4.0}, "policy_reward_mean": {"shared_policy": 1.1}, "custom_metrics": {}, "hist_stats": {"episode_reward": [10.0, 7.0, 3.0, 6.0, 1.0, 2.0, 5.0, 5.0, 1.0, 4.0], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500], "policy_shared_policy_reward": [3.0, 2.0, 1.0, 4.0, 2.0, 2.0, 0.0, 3.0, 0.0, 2.0, 0.0, 1.0, 1.0, 1.0, 2.0, 2.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 2.0, 0.0, 2.0, 1.0, 2.0, 1.0, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.09068024918880971, "mean_inference_ms": 0.3934417145654122, "mean_action_processing_ms": 0.027808063722948768, "mean_env_wait_ms": 0.38857985391447103, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}}, "done": false, "episodes_total": 1008, "training_iteration": 50, "trial_id": "71426_00000", "experiment_id": "84bca2f7b35f43248fca18d21abe2ebf", "date": "2024-06-12_02-54-27", "timestamp": 1718128467, "time_this_iter_s": 14.79121208190918, "time_total_s": 516.0851690769196, "pid": 363902, "hostname": "DESKTOP-LQ219J4", "node_ip": "192.168.46.185", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 20, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 5000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 500, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Base_Model", "custom_model_config": {"env": "rware", "env_args": {"n_agents": 4, "column_height": 1, "max_inactivity_steps": null, "max_steps": 500, "fast_obs": true, "msg_bits": 0, "sensor_range": 1, "shelf_rows": 1, "shelf_columns": 3, "request_queue_size": 4, "reward_type": "RewardType.INDIVIDUAL", "map_name": "customized_map", "map_size": "tiny", "difficulty": "medium"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": true, "force_coop": false, "local_mode": true, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 4, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 100, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64}, "algorithm": "ia2c", "space_obs": "Dict(obs:Box([-100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100.], [100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.], (112,), float32))", "space_act": "Discrete(5)", "num_agents": 4, "episode_limit": 500, "policy_mapping_info": {"all_scenario": {"description": "rware all scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2", "agent_3"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "rware_customized_map", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 10, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.IA2CTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_il.<locals>.<lambda> at 0x7f3808651c10>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "grad_clip": 40.0, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "microbatch_size": null}, "time_since_restore": 516.0851690769196, "timesteps_since_restore": 0, "iterations_since_restore": 50, "perf": {"cpu_util_percent": 4.585714285714285, "ram_util_percent": 46.266666666666666}}
{"episode_reward_max": 9.0, "episode_reward_min": 0.0, "episode_reward_mean": 2.68, "episode_len_mean": 500.0, "episode_media": {}, "episodes_this_iter": 20, "policy_reward_min": {"shared_policy": 0.0}, "policy_reward_max": {"shared_policy": 4.0}, "policy_reward_mean": {"shared_policy": 0.67}, "custom_metrics": {}, "hist_stats": {"episode_reward": [1.0, 9.0, 1.0, 0.0, 1.0, 3.0, 5.0, 1.0, 2.0, 2.0, 5.0, 6.0, 3.0, 5.0, 3.0, 4.0, 2.0, 2.0, 2.0, 4.0, 7.0, 5.0, 2.0, 2.0, 2.0, 1.0, 3.0, 3.0, 2.0, 2.0, 1.0, 1.0, 0.0, 1.0, 4.0, 2.0, 4.0, 1.0, 3.0, 1.0, 3.0, 1.0, 4.0, 2.0, 3.0, 1.0, 2.0, 4.0, 4.0, 4.0, 3.0, 2.0, 4.0, 4.0, 5.0, 3.0, 1.0, 1.0, 2.0, 4.0, 2.0, 1.0, 1.0, 2.0, 2.0, 2.0, 1.0, 1.0, 4.0, 7.0, 4.0, 2.0, 2.0, 4.0, 2.0, 3.0, 2.0, 5.0, 3.0, 0.0, 2.0, 6.0, 2.0, 0.0, 2.0, 3.0, 1.0, 3.0, 4.0, 0.0, 2.0, 2.0, 4.0, 2.0, 4.0, 7.0, 3.0, 3.0, 1.0, 2.0], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500], "policy_shared_policy_reward": [0.0, 0.0, 1.0, 0.0, 2.0, 4.0, 2.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 2.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 2.0, 0.0, 2.0, 0.0, 3.0, 3.0, 0.0, 0.0, 0.0, 2.0, 1.0, 2.0, 0.0, 2.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 2.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 3.0, 0.0, 2.0, 2.0, 2.0, 2.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 2.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 2.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 2.0, 2.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 2.0, 0.0, 0.0, 0.0, 2.0, 0.0, 2.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 2.0, 0.0, 1.0, 1.0, 2.0, 0.0, 2.0, 1.0, 1.0, 2.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 2.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 2.0, 2.0, 1.0, 2.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 2.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 2.0, 1.0, 0.0, 4.0, 3.0, 0.0, 0.0, 1.0, 1.0, 2.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 2.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 2.0, 2.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 2.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 2.0, 1.0, 1.0, 3.0, 2.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.13376362120421864, "mean_inference_ms": 0.3904780097911413, "mean_action_processing_ms": 0.029204309758959743, "mean_env_wait_ms": 0.404265558204704, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 514080, "timesteps_this_iter": 0, "agent_timesteps_total": 2056320, "timers": {"sample_time_ms": 5645.568, "sample_throughput": 892.736, "load_time_ms": 0.168, "load_throughput": 29976307.657, "learn_time_ms": 127.927, "learn_throughput": 39397.324, "update_time_ms": 2.493}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 120.29936218261719, "policy_entropy": 7858.507568359375, "policy_loss": -50.47370672225952, "vf_loss": 16.890987157821655}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 514080, "num_agent_steps_sampled": 2056320, "num_steps_trained": 514080, "num_agent_steps_trained": 2056320, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 1028, "training_iteration": 51, "trial_id": "71426_00000", "experiment_id": "84bca2f7b35f43248fca18d21abe2ebf", "date": "2024-06-12_02-54-38", "timestamp": 1718128478, "time_this_iter_s": 10.190701246261597, "time_total_s": 526.2758703231812, "pid": 363902, "hostname": "DESKTOP-LQ219J4", "node_ip": "192.168.46.185", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 20, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 5000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 500, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Base_Model", "custom_model_config": {"env": "rware", "env_args": {"n_agents": 4, "column_height": 1, "max_inactivity_steps": null, "max_steps": 500, "fast_obs": true, "msg_bits": 0, "sensor_range": 1, "shelf_rows": 1, "shelf_columns": 3, "request_queue_size": 4, "reward_type": "RewardType.INDIVIDUAL", "map_name": "customized_map", "map_size": "tiny", "difficulty": "medium"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": true, "force_coop": false, "local_mode": true, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 4, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 100, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64}, "algorithm": "ia2c", "space_obs": "Dict(obs:Box([-100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100.], [100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.], (112,), float32))", "space_act": "Discrete(5)", "num_agents": 4, "episode_limit": 500, "policy_mapping_info": {"all_scenario": {"description": "rware all scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2", "agent_3"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "rware_customized_map", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 10, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.IA2CTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_il.<locals>.<lambda> at 0x7f3808651af0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "grad_clip": 40.0, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "microbatch_size": null}, "time_since_restore": 526.2758703231812, "timesteps_since_restore": 0, "iterations_since_restore": 51, "perf": {"cpu_util_percent": 4.753333333333333, "ram_util_percent": 46.46666666666667}}
{"episode_reward_max": 7.0, "episode_reward_min": 0.0, "episode_reward_mean": 2.69, "episode_len_mean": 500.0, "episode_media": {}, "episodes_this_iter": 20, "policy_reward_min": {"shared_policy": 0.0}, "policy_reward_max": {"shared_policy": 4.0}, "policy_reward_mean": {"shared_policy": 0.6725}, "custom_metrics": {}, "hist_stats": {"episode_reward": [7.0, 5.0, 2.0, 2.0, 2.0, 1.0, 3.0, 3.0, 2.0, 2.0, 1.0, 1.0, 0.0, 1.0, 4.0, 2.0, 4.0, 1.0, 3.0, 1.0, 3.0, 1.0, 4.0, 2.0, 3.0, 1.0, 2.0, 4.0, 4.0, 4.0, 3.0, 2.0, 4.0, 4.0, 5.0, 3.0, 1.0, 1.0, 2.0, 4.0, 2.0, 1.0, 1.0, 2.0, 2.0, 2.0, 1.0, 1.0, 4.0, 7.0, 4.0, 2.0, 2.0, 4.0, 2.0, 3.0, 2.0, 5.0, 3.0, 0.0, 2.0, 6.0, 2.0, 0.0, 2.0, 3.0, 1.0, 3.0, 4.0, 0.0, 2.0, 2.0, 4.0, 2.0, 4.0, 7.0, 3.0, 3.0, 1.0, 2.0, 1.0, 1.0, 1.0, 7.0, 1.0, 1.0, 2.0, 4.0, 5.0, 6.0, 5.0, 4.0, 5.0, 2.0, 5.0, 1.0, 5.0, 2.0, 3.0, 1.0], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500], "policy_shared_policy_reward": [3.0, 0.0, 2.0, 2.0, 2.0, 2.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 2.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 2.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 2.0, 2.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 2.0, 0.0, 0.0, 0.0, 2.0, 0.0, 2.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 2.0, 0.0, 1.0, 1.0, 2.0, 0.0, 2.0, 1.0, 1.0, 2.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 2.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 2.0, 2.0, 1.0, 2.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 2.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 2.0, 1.0, 0.0, 4.0, 3.0, 0.0, 0.0, 1.0, 1.0, 2.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 2.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 2.0, 2.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 2.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 2.0, 1.0, 1.0, 3.0, 2.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 2.0, 4.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 2.0, 1.0, 1.0, 1.0, 1.0, 2.0, 1.0, 1.0, 2.0, 2.0, 2.0, 0.0, 1.0, 2.0, 1.0, 1.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 3.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 2.0, 3.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.13377087957424297, "mean_inference_ms": 0.3905253184430798, "mean_action_processing_ms": 0.029205419110586935, "mean_env_wait_ms": 0.4043065811696088, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 524160, "timesteps_this_iter": 0, "agent_timesteps_total": 2096640, "timers": {"sample_time_ms": 5608.815, "sample_throughput": 898.586, "load_time_ms": 0.159, "load_throughput": 31631441.209, "learn_time_ms": 128.042, "learn_throughput": 39361.943, "update_time_ms": 2.52}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 107.2783432006836, "policy_entropy": 7878.6697998046875, "policy_loss": 23.707342863082886, "vf_loss": 29.41657304763794}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 524160, "num_agent_steps_sampled": 2096640, "num_steps_trained": 524160, "num_agent_steps_trained": 2096640, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 1048, "training_iteration": 52, "trial_id": "71426_00000", "experiment_id": "84bca2f7b35f43248fca18d21abe2ebf", "date": "2024-06-12_02-54-48", "timestamp": 1718128488, "time_this_iter_s": 10.249446868896484, "time_total_s": 536.5253171920776, "pid": 363902, "hostname": "DESKTOP-LQ219J4", "node_ip": "192.168.46.185", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 20, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 5000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 500, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Base_Model", "custom_model_config": {"env": "rware", "env_args": {"n_agents": 4, "column_height": 1, "max_inactivity_steps": null, "max_steps": 500, "fast_obs": true, "msg_bits": 0, "sensor_range": 1, "shelf_rows": 1, "shelf_columns": 3, "request_queue_size": 4, "reward_type": "RewardType.INDIVIDUAL", "map_name": "customized_map", "map_size": "tiny", "difficulty": "medium"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": true, "force_coop": false, "local_mode": true, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 4, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 100, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64}, "algorithm": "ia2c", "space_obs": "Dict(obs:Box([-100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100.], [100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.], (112,), float32))", "space_act": "Discrete(5)", "num_agents": 4, "episode_limit": 500, "policy_mapping_info": {"all_scenario": {"description": "rware all scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2", "agent_3"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "rware_customized_map", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 10, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.IA2CTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_il.<locals>.<lambda> at 0x7f3808651ee0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "grad_clip": 40.0, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "microbatch_size": null}, "time_since_restore": 536.5253171920776, "timesteps_since_restore": 0, "iterations_since_restore": 52, "perf": {"cpu_util_percent": 4.571428571428571, "ram_util_percent": 46.74999999999999}}
{"episode_reward_max": 10.0, "episode_reward_min": 0.0, "episode_reward_mean": 2.95, "episode_len_mean": 500.0, "episode_media": {}, "episodes_this_iter": 20, "policy_reward_min": {"shared_policy": 0.0}, "policy_reward_max": {"shared_policy": 4.0}, "policy_reward_mean": {"shared_policy": 0.7375}, "custom_metrics": {}, "hist_stats": {"episode_reward": [3.0, 1.0, 4.0, 2.0, 3.0, 1.0, 2.0, 4.0, 4.0, 4.0, 3.0, 2.0, 4.0, 4.0, 5.0, 3.0, 1.0, 1.0, 2.0, 4.0, 2.0, 1.0, 1.0, 2.0, 2.0, 2.0, 1.0, 1.0, 4.0, 7.0, 4.0, 2.0, 2.0, 4.0, 2.0, 3.0, 2.0, 5.0, 3.0, 0.0, 2.0, 6.0, 2.0, 0.0, 2.0, 3.0, 1.0, 3.0, 4.0, 0.0, 2.0, 2.0, 4.0, 2.0, 4.0, 7.0, 3.0, 3.0, 1.0, 2.0, 1.0, 1.0, 1.0, 7.0, 1.0, 1.0, 2.0, 4.0, 5.0, 6.0, 5.0, 4.0, 5.0, 2.0, 5.0, 1.0, 5.0, 2.0, 3.0, 1.0, 1.0, 2.0, 2.0, 4.0, 1.0, 3.0, 4.0, 1.0, 9.0, 8.0, 4.0, 4.0, 6.0, 3.0, 3.0, 2.0, 1.0, 10.0, 2.0, 3.0], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500], "policy_shared_policy_reward": [1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 2.0, 0.0, 0.0, 0.0, 2.0, 0.0, 2.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 2.0, 0.0, 1.0, 1.0, 2.0, 0.0, 2.0, 1.0, 1.0, 2.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 2.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 2.0, 2.0, 1.0, 2.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 2.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 2.0, 1.0, 0.0, 4.0, 3.0, 0.0, 0.0, 1.0, 1.0, 2.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 2.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 2.0, 2.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 2.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 2.0, 1.0, 1.0, 3.0, 2.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 2.0, 4.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 2.0, 1.0, 1.0, 1.0, 1.0, 2.0, 1.0, 1.0, 2.0, 2.0, 2.0, 0.0, 1.0, 2.0, 1.0, 1.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 3.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 2.0, 3.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 2.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 2.0, 2.0, 0.0, 0.0, 0.0, 1.0, 1.0, 2.0, 3.0, 3.0, 3.0, 1.0, 2.0, 2.0, 0.0, 0.0, 2.0, 2.0, 1.0, 2.0, 1.0, 0.0, 1.0, 2.0, 2.0, 1.0, 2.0, 0.0, 1.0, 0.0, 0.0, 2.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 4.0, 2.0, 3.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 2.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.1337673124741946, "mean_inference_ms": 0.3905378295842307, "mean_action_processing_ms": 0.02920371887679036, "mean_env_wait_ms": 0.4043551305774933, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 534240, "timesteps_this_iter": 0, "agent_timesteps_total": 2136960, "timers": {"sample_time_ms": 5594.679, "sample_throughput": 900.856, "load_time_ms": 0.165, "load_throughput": 30610037.88, "learn_time_ms": 127.273, "learn_throughput": 39599.837, "update_time_ms": 2.438}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 132.38064575195312, "policy_entropy": 7814.4813232421875, "policy_loss": 14.127289295196533, "vf_loss": 35.95252561569214}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 534240, "num_agent_steps_sampled": 2136960, "num_steps_trained": 534240, "num_agent_steps_trained": 2136960, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 1068, "training_iteration": 53, "trial_id": "71426_00000", "experiment_id": "84bca2f7b35f43248fca18d21abe2ebf", "date": "2024-06-12_02-54-58", "timestamp": 1718128498, "time_this_iter_s": 10.15610933303833, "time_total_s": 546.681426525116, "pid": 363902, "hostname": "DESKTOP-LQ219J4", "node_ip": "192.168.46.185", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 20, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 5000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 500, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Base_Model", "custom_model_config": {"env": "rware", "env_args": {"n_agents": 4, "column_height": 1, "max_inactivity_steps": null, "max_steps": 500, "fast_obs": true, "msg_bits": 0, "sensor_range": 1, "shelf_rows": 1, "shelf_columns": 3, "request_queue_size": 4, "reward_type": "RewardType.INDIVIDUAL", "map_name": "customized_map", "map_size": "tiny", "difficulty": "medium"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": true, "force_coop": false, "local_mode": true, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 4, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 100, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64}, "algorithm": "ia2c", "space_obs": "Dict(obs:Box([-100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100.], [100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.], (112,), float32))", "space_act": "Discrete(5)", "num_agents": 4, "episode_limit": 500, "policy_mapping_info": {"all_scenario": {"description": "rware all scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2", "agent_3"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "rware_customized_map", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 10, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.IA2CTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_il.<locals>.<lambda> at 0x7f38086c1c10>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "grad_clip": 40.0, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "microbatch_size": null}, "time_since_restore": 546.681426525116, "timesteps_since_restore": 0, "iterations_since_restore": 53, "perf": {"cpu_util_percent": 4.386666666666667, "ram_util_percent": 47.013333333333335}}
{"episode_reward_max": 10.0, "episode_reward_min": 0.0, "episode_reward_mean": 2.93, "episode_len_mean": 500.0, "episode_media": {}, "episodes_this_iter": 20, "policy_reward_min": {"shared_policy": 0.0}, "policy_reward_max": {"shared_policy": 4.0}, "policy_reward_mean": {"shared_policy": 0.7325}, "custom_metrics": {}, "hist_stats": {"episode_reward": [2.0, 1.0, 1.0, 2.0, 2.0, 2.0, 1.0, 1.0, 4.0, 7.0, 4.0, 2.0, 2.0, 4.0, 2.0, 3.0, 2.0, 5.0, 3.0, 0.0, 2.0, 6.0, 2.0, 0.0, 2.0, 3.0, 1.0, 3.0, 4.0, 0.0, 2.0, 2.0, 4.0, 2.0, 4.0, 7.0, 3.0, 3.0, 1.0, 2.0, 1.0, 1.0, 1.0, 7.0, 1.0, 1.0, 2.0, 4.0, 5.0, 6.0, 5.0, 4.0, 5.0, 2.0, 5.0, 1.0, 5.0, 2.0, 3.0, 1.0, 1.0, 2.0, 2.0, 4.0, 1.0, 3.0, 4.0, 1.0, 9.0, 8.0, 4.0, 4.0, 6.0, 3.0, 3.0, 2.0, 1.0, 10.0, 2.0, 3.0, 2.0, 3.0, 4.0, 5.0, 4.0, 1.0, 2.0, 2.0, 1.0, 4.0, 3.0, 5.0, 3.0, 2.0, 2.0, 2.0, 5.0, 2.0, 2.0, 1.0], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500], "policy_shared_policy_reward": [1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 2.0, 1.0, 0.0, 4.0, 3.0, 0.0, 0.0, 1.0, 1.0, 2.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 2.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 2.0, 2.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 2.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 2.0, 1.0, 1.0, 3.0, 2.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 2.0, 4.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 2.0, 1.0, 1.0, 1.0, 1.0, 2.0, 1.0, 1.0, 2.0, 2.0, 2.0, 0.0, 1.0, 2.0, 1.0, 1.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 3.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 2.0, 3.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 2.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 2.0, 2.0, 0.0, 0.0, 0.0, 1.0, 1.0, 2.0, 3.0, 3.0, 3.0, 1.0, 2.0, 2.0, 0.0, 0.0, 2.0, 2.0, 1.0, 2.0, 1.0, 0.0, 1.0, 2.0, 2.0, 1.0, 2.0, 0.0, 1.0, 0.0, 0.0, 2.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 4.0, 2.0, 3.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 2.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 2.0, 1.0, 2.0, 1.0, 1.0, 1.0, 0.0, 1.0, 2.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 2.0, 1.0, 1.0, 2.0, 1.0, 1.0, 2.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 2.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.13375112672900907, "mean_inference_ms": 0.39051287307945715, "mean_action_processing_ms": 0.02919991199333326, "mean_env_wait_ms": 0.40437233999158984, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 544320, "timesteps_this_iter": 0, "agent_timesteps_total": 2177280, "timers": {"sample_time_ms": 5566.373, "sample_throughput": 905.437, "load_time_ms": 0.166, "load_throughput": 30276843.541, "learn_time_ms": 126.398, "learn_throughput": 39873.991, "update_time_ms": 2.474}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 126.81770324707031, "policy_entropy": 7870.9769287109375, "policy_loss": -10.884747982025146, "vf_loss": 22.16385507583618}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 544320, "num_agent_steps_sampled": 2177280, "num_steps_trained": 544320, "num_agent_steps_trained": 2177280, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 1088, "training_iteration": 54, "trial_id": "71426_00000", "experiment_id": "84bca2f7b35f43248fca18d21abe2ebf", "date": "2024-06-12_02-55-08", "timestamp": 1718128508, "time_this_iter_s": 10.194563627243042, "time_total_s": 556.875990152359, "pid": 363902, "hostname": "DESKTOP-LQ219J4", "node_ip": "192.168.46.185", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 20, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 5000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 500, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Base_Model", "custom_model_config": {"env": "rware", "env_args": {"n_agents": 4, "column_height": 1, "max_inactivity_steps": null, "max_steps": 500, "fast_obs": true, "msg_bits": 0, "sensor_range": 1, "shelf_rows": 1, "shelf_columns": 3, "request_queue_size": 4, "reward_type": "RewardType.INDIVIDUAL", "map_name": "customized_map", "map_size": "tiny", "difficulty": "medium"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": true, "force_coop": false, "local_mode": true, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 4, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 100, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64}, "algorithm": "ia2c", "space_obs": "Dict(obs:Box([-100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100.], [100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.], (112,), float32))", "space_act": "Discrete(5)", "num_agents": 4, "episode_limit": 500, "policy_mapping_info": {"all_scenario": {"description": "rware all scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2", "agent_3"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "rware_customized_map", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 10, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.IA2CTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_il.<locals>.<lambda> at 0x7f3808645b80>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "grad_clip": 40.0, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "microbatch_size": null}, "time_since_restore": 556.875990152359, "timesteps_since_restore": 0, "iterations_since_restore": 54, "perf": {"cpu_util_percent": 4.335714285714286, "ram_util_percent": 47.29999999999999}}
{"episode_reward_max": 10.0, "episode_reward_min": 0.0, "episode_reward_mean": 3.11, "episode_len_mean": 500.0, "episode_media": {}, "episodes_this_iter": 20, "policy_reward_min": {"shared_policy": 0.0}, "policy_reward_max": {"shared_policy": 4.0}, "policy_reward_mean": {"shared_policy": 0.7775}, "custom_metrics": {}, "hist_stats": {"episode_reward": [2.0, 6.0, 2.0, 0.0, 2.0, 3.0, 1.0, 3.0, 4.0, 0.0, 2.0, 2.0, 4.0, 2.0, 4.0, 7.0, 3.0, 3.0, 1.0, 2.0, 1.0, 1.0, 1.0, 7.0, 1.0, 1.0, 2.0, 4.0, 5.0, 6.0, 5.0, 4.0, 5.0, 2.0, 5.0, 1.0, 5.0, 2.0, 3.0, 1.0, 1.0, 2.0, 2.0, 4.0, 1.0, 3.0, 4.0, 1.0, 9.0, 8.0, 4.0, 4.0, 6.0, 3.0, 3.0, 2.0, 1.0, 10.0, 2.0, 3.0, 2.0, 3.0, 4.0, 5.0, 4.0, 1.0, 2.0, 2.0, 1.0, 4.0, 3.0, 5.0, 3.0, 2.0, 2.0, 2.0, 5.0, 2.0, 2.0, 1.0, 4.0, 2.0, 4.0, 1.0, 0.0, 5.0, 4.0, 4.0, 2.0, 7.0, 5.0, 4.0, 3.0, 1.0, 7.0, 5.0, 4.0, 2.0, 1.0, 3.0], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500], "policy_shared_policy_reward": [0.0, 1.0, 1.0, 0.0, 1.0, 2.0, 2.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 2.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 2.0, 1.0, 1.0, 3.0, 2.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 2.0, 4.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 2.0, 1.0, 1.0, 1.0, 1.0, 2.0, 1.0, 1.0, 2.0, 2.0, 2.0, 0.0, 1.0, 2.0, 1.0, 1.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 3.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 2.0, 3.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 2.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 2.0, 2.0, 0.0, 0.0, 0.0, 1.0, 1.0, 2.0, 3.0, 3.0, 3.0, 1.0, 2.0, 2.0, 0.0, 0.0, 2.0, 2.0, 1.0, 2.0, 1.0, 0.0, 1.0, 2.0, 2.0, 1.0, 2.0, 0.0, 1.0, 0.0, 0.0, 2.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 4.0, 2.0, 3.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 2.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 2.0, 1.0, 2.0, 1.0, 1.0, 1.0, 0.0, 1.0, 2.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 2.0, 1.0, 1.0, 2.0, 1.0, 1.0, 2.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 2.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 2.0, 1.0, 0.0, 0.0, 1.0, 1.0, 2.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 3.0, 0.0, 2.0, 0.0, 2.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 3.0, 1.0, 2.0, 1.0, 1.0, 1.0, 1.0, 2.0, 2.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 3.0, 2.0, 0.0, 1.0, 2.0, 2.0, 1.0, 2.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.13373303320429827, "mean_inference_ms": 0.3904941742296113, "mean_action_processing_ms": 0.029200070261762395, "mean_env_wait_ms": 0.40435344581704386, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 554400, "timesteps_this_iter": 0, "agent_timesteps_total": 2217600, "timers": {"sample_time_ms": 5554.028, "sample_throughput": 907.449, "load_time_ms": 0.164, "load_throughput": 30779400.349, "learn_time_ms": 126.264, "learn_throughput": 39916.449, "update_time_ms": 2.532}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 189.9801483154297, "policy_entropy": 7944.35498046875, "policy_loss": -9.462997436523438, "vf_loss": 23.25984811782837}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 554400, "num_agent_steps_sampled": 2217600, "num_steps_trained": 554400, "num_agent_steps_trained": 2217600, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 1108, "training_iteration": 55, "trial_id": "71426_00000", "experiment_id": "84bca2f7b35f43248fca18d21abe2ebf", "date": "2024-06-12_02-55-18", "timestamp": 1718128518, "time_this_iter_s": 10.156605958938599, "time_total_s": 567.0325961112976, "pid": 363902, "hostname": "DESKTOP-LQ219J4", "node_ip": "192.168.46.185", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 20, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 5000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 500, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Base_Model", "custom_model_config": {"env": "rware", "env_args": {"n_agents": 4, "column_height": 1, "max_inactivity_steps": null, "max_steps": 500, "fast_obs": true, "msg_bits": 0, "sensor_range": 1, "shelf_rows": 1, "shelf_columns": 3, "request_queue_size": 4, "reward_type": "RewardType.INDIVIDUAL", "map_name": "customized_map", "map_size": "tiny", "difficulty": "medium"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": true, "force_coop": false, "local_mode": true, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 4, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 100, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64}, "algorithm": "ia2c", "space_obs": "Dict(obs:Box([-100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100.], [100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.], (112,), float32))", "space_act": "Discrete(5)", "num_agents": 4, "episode_limit": 500, "policy_mapping_info": {"all_scenario": {"description": "rware all scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2", "agent_3"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "rware_customized_map", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 10, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.IA2CTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_il.<locals>.<lambda> at 0x7f38086c10d0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "grad_clip": 40.0, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "microbatch_size": null}, "time_since_restore": 567.0325961112976, "timesteps_since_restore": 0, "iterations_since_restore": 55, "perf": {"cpu_util_percent": 4.413333333333333, "ram_util_percent": 47.60000000000001}}
{"episode_reward_max": 10.0, "episode_reward_min": 0.0, "episode_reward_mean": 3.29, "episode_len_mean": 500.0, "episode_media": {}, "episodes_this_iter": 20, "policy_reward_min": {"shared_policy": 0.0}, "policy_reward_max": {"shared_policy": 4.0}, "policy_reward_mean": {"shared_policy": 0.8225}, "custom_metrics": {}, "hist_stats": {"episode_reward": [1.0, 1.0, 1.0, 7.0, 1.0, 1.0, 2.0, 4.0, 5.0, 6.0, 5.0, 4.0, 5.0, 2.0, 5.0, 1.0, 5.0, 2.0, 3.0, 1.0, 1.0, 2.0, 2.0, 4.0, 1.0, 3.0, 4.0, 1.0, 9.0, 8.0, 4.0, 4.0, 6.0, 3.0, 3.0, 2.0, 1.0, 10.0, 2.0, 3.0, 2.0, 3.0, 4.0, 5.0, 4.0, 1.0, 2.0, 2.0, 1.0, 4.0, 3.0, 5.0, 3.0, 2.0, 2.0, 2.0, 5.0, 2.0, 2.0, 1.0, 4.0, 2.0, 4.0, 1.0, 0.0, 5.0, 4.0, 4.0, 2.0, 7.0, 5.0, 4.0, 3.0, 1.0, 7.0, 5.0, 4.0, 2.0, 1.0, 3.0, 9.0, 3.0, 7.0, 2.0, 6.0, 2.0, 2.0, 5.0, 1.0, 1.0, 4.0, 4.0, 3.0, 2.0, 2.0, 1.0, 2.0, 4.0, 3.0, 8.0], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500], "policy_shared_policy_reward": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 2.0, 4.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 2.0, 1.0, 1.0, 1.0, 1.0, 2.0, 1.0, 1.0, 2.0, 2.0, 2.0, 0.0, 1.0, 2.0, 1.0, 1.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 3.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 2.0, 3.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 2.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 2.0, 2.0, 0.0, 0.0, 0.0, 1.0, 1.0, 2.0, 3.0, 3.0, 3.0, 1.0, 2.0, 2.0, 0.0, 0.0, 2.0, 2.0, 1.0, 2.0, 1.0, 0.0, 1.0, 2.0, 2.0, 1.0, 2.0, 0.0, 1.0, 0.0, 0.0, 2.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 4.0, 2.0, 3.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 2.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 2.0, 1.0, 2.0, 1.0, 1.0, 1.0, 0.0, 1.0, 2.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 2.0, 1.0, 1.0, 2.0, 1.0, 1.0, 2.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 2.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 2.0, 1.0, 0.0, 0.0, 1.0, 1.0, 2.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 3.0, 0.0, 2.0, 0.0, 2.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 3.0, 1.0, 2.0, 1.0, 1.0, 1.0, 1.0, 2.0, 2.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 3.0, 2.0, 0.0, 1.0, 2.0, 2.0, 1.0, 2.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 3.0, 4.0, 0.0, 2.0, 0.0, 1.0, 1.0, 1.0, 2.0, 3.0, 0.0, 2.0, 0.0, 1.0, 1.0, 0.0, 2.0, 1.0, 1.0, 2.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 2.0, 1.0, 0.0, 2.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 2.0, 1.0, 2.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 2.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 2.0, 1.0, 0.0, 2.0, 0.0, 1.0, 0.0, 2.0, 3.0, 1.0, 2.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.13370949088816586, "mean_inference_ms": 0.39044901892839207, "mean_action_processing_ms": 0.029197866519348817, "mean_env_wait_ms": 0.4043141596802022, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 564480, "timesteps_this_iter": 0, "agent_timesteps_total": 2257920, "timers": {"sample_time_ms": 5091.133, "sample_throughput": 989.956, "load_time_ms": 0.156, "load_throughput": 32298383.743, "learn_time_ms": 126.826, "learn_throughput": 39739.373, "update_time_ms": 2.499}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 140.44711303710938, "policy_entropy": 7948.6842041015625, "policy_loss": 0.22688674926757812, "vf_loss": 29.508715629577637}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 564480, "num_agent_steps_sampled": 2257920, "num_steps_trained": 564480, "num_agent_steps_trained": 2257920, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 1128, "training_iteration": 56, "trial_id": "71426_00000", "experiment_id": "84bca2f7b35f43248fca18d21abe2ebf", "date": "2024-06-12_02-55-29", "timestamp": 1718128529, "time_this_iter_s": 10.08388066291809, "time_total_s": 577.1164767742157, "pid": 363902, "hostname": "DESKTOP-LQ219J4", "node_ip": "192.168.46.185", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 20, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 5000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 500, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Base_Model", "custom_model_config": {"env": "rware", "env_args": {"n_agents": 4, "column_height": 1, "max_inactivity_steps": null, "max_steps": 500, "fast_obs": true, "msg_bits": 0, "sensor_range": 1, "shelf_rows": 1, "shelf_columns": 3, "request_queue_size": 4, "reward_type": "RewardType.INDIVIDUAL", "map_name": "customized_map", "map_size": "tiny", "difficulty": "medium"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": true, "force_coop": false, "local_mode": true, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 4, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 100, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64}, "algorithm": "ia2c", "space_obs": "Dict(obs:Box([-100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100.], [100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.], (112,), float32))", "space_act": "Discrete(5)", "num_agents": 4, "episode_limit": 500, "policy_mapping_info": {"all_scenario": {"description": "rware all scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2", "agent_3"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "rware_customized_map", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 10, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.IA2CTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_il.<locals>.<lambda> at 0x7f38081d5a60>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "grad_clip": 40.0, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "microbatch_size": null}, "time_since_restore": 577.1164767742157, "timesteps_since_restore": 0, "iterations_since_restore": 56, "perf": {"cpu_util_percent": 4.371428571428572, "ram_util_percent": 47.88571428571428}}
{"episode_reward_max": 10.0, "episode_reward_min": 0.0, "episode_reward_mean": 3.19, "episode_len_mean": 500.0, "episode_media": {}, "episodes_this_iter": 20, "policy_reward_min": {"shared_policy": 0.0}, "policy_reward_max": {"shared_policy": 4.0}, "policy_reward_mean": {"shared_policy": 0.7975}, "custom_metrics": {}, "hist_stats": {"episode_reward": [1.0, 2.0, 2.0, 4.0, 1.0, 3.0, 4.0, 1.0, 9.0, 8.0, 4.0, 4.0, 6.0, 3.0, 3.0, 2.0, 1.0, 10.0, 2.0, 3.0, 2.0, 3.0, 4.0, 5.0, 4.0, 1.0, 2.0, 2.0, 1.0, 4.0, 3.0, 5.0, 3.0, 2.0, 2.0, 2.0, 5.0, 2.0, 2.0, 1.0, 4.0, 2.0, 4.0, 1.0, 0.0, 5.0, 4.0, 4.0, 2.0, 7.0, 5.0, 4.0, 3.0, 1.0, 7.0, 5.0, 4.0, 2.0, 1.0, 3.0, 9.0, 3.0, 7.0, 2.0, 6.0, 2.0, 2.0, 5.0, 1.0, 1.0, 4.0, 4.0, 3.0, 2.0, 2.0, 1.0, 2.0, 4.0, 3.0, 8.0, 1.0, 3.0, 0.0, 3.0, 1.0, 2.0, 3.0, 2.0, 1.0, 1.0, 2.0, 9.0, 2.0, 1.0, 7.0, 2.0, 2.0, 6.0, 2.0, 2.0], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500], "policy_shared_policy_reward": [0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 2.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 2.0, 2.0, 0.0, 0.0, 0.0, 1.0, 1.0, 2.0, 3.0, 3.0, 3.0, 1.0, 2.0, 2.0, 0.0, 0.0, 2.0, 2.0, 1.0, 2.0, 1.0, 0.0, 1.0, 2.0, 2.0, 1.0, 2.0, 0.0, 1.0, 0.0, 0.0, 2.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 4.0, 2.0, 3.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 2.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 2.0, 1.0, 2.0, 1.0, 1.0, 1.0, 0.0, 1.0, 2.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 2.0, 1.0, 1.0, 2.0, 1.0, 1.0, 2.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 2.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 2.0, 1.0, 0.0, 0.0, 1.0, 1.0, 2.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 3.0, 0.0, 2.0, 0.0, 2.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 3.0, 1.0, 2.0, 1.0, 1.0, 1.0, 1.0, 2.0, 2.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 3.0, 2.0, 0.0, 1.0, 2.0, 2.0, 1.0, 2.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 3.0, 4.0, 0.0, 2.0, 0.0, 1.0, 1.0, 1.0, 2.0, 3.0, 0.0, 2.0, 0.0, 1.0, 1.0, 0.0, 2.0, 1.0, 1.0, 2.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 2.0, 1.0, 0.0, 2.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 2.0, 1.0, 2.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 2.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 2.0, 1.0, 0.0, 2.0, 0.0, 1.0, 0.0, 2.0, 3.0, 1.0, 2.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 3.0, 2.0, 2.0, 2.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 3.0, 2.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 2.0, 3.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.13368359135187022, "mean_inference_ms": 0.3903922823197222, "mean_action_processing_ms": 0.029194874223084883, "mean_env_wait_ms": 0.4042467923687925, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 574560, "timesteps_this_iter": 0, "agent_timesteps_total": 2298240, "timers": {"sample_time_ms": 5077.855, "sample_throughput": 992.545, "load_time_ms": 0.158, "load_throughput": 31937289.863, "learn_time_ms": 126.989, "learn_throughput": 39688.519, "update_time_ms": 2.457}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 142.04388427734375, "policy_entropy": 7930.6685791015625, "policy_loss": -19.38331890106201, "vf_loss": 18.244617462158203}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 574560, "num_agent_steps_sampled": 2298240, "num_steps_trained": 574560, "num_agent_steps_trained": 2298240, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 1148, "training_iteration": 57, "trial_id": "71426_00000", "experiment_id": "84bca2f7b35f43248fca18d21abe2ebf", "date": "2024-06-12_02-55-39", "timestamp": 1718128539, "time_this_iter_s": 10.11654257774353, "time_total_s": 587.2330193519592, "pid": 363902, "hostname": "DESKTOP-LQ219J4", "node_ip": "192.168.46.185", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 20, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 5000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 500, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Base_Model", "custom_model_config": {"env": "rware", "env_args": {"n_agents": 4, "column_height": 1, "max_inactivity_steps": null, "max_steps": 500, "fast_obs": true, "msg_bits": 0, "sensor_range": 1, "shelf_rows": 1, "shelf_columns": 3, "request_queue_size": 4, "reward_type": "RewardType.INDIVIDUAL", "map_name": "customized_map", "map_size": "tiny", "difficulty": "medium"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": true, "force_coop": false, "local_mode": true, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 4, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 100, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64}, "algorithm": "ia2c", "space_obs": "Dict(obs:Box([-100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100.], [100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.], (112,), float32))", "space_act": "Discrete(5)", "num_agents": 4, "episode_limit": 500, "policy_mapping_info": {"all_scenario": {"description": "rware all scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2", "agent_3"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "rware_customized_map", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 10, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.IA2CTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_il.<locals>.<lambda> at 0x7f38082f8160>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "grad_clip": 40.0, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "microbatch_size": null}, "time_since_restore": 587.2330193519592, "timesteps_since_restore": 0, "iterations_since_restore": 57, "perf": {"cpu_util_percent": 4.4, "ram_util_percent": 48.213333333333345}}
{"episode_reward_max": 9.0, "episode_reward_min": 0.0, "episode_reward_mean": 3.15, "episode_len_mean": 500.0, "episode_media": {}, "episodes_this_iter": 20, "policy_reward_min": {"shared_policy": 0.0}, "policy_reward_max": {"shared_policy": 4.0}, "policy_reward_mean": {"shared_policy": 0.7875}, "custom_metrics": {}, "hist_stats": {"episode_reward": [2.0, 3.0, 4.0, 5.0, 4.0, 1.0, 2.0, 2.0, 1.0, 4.0, 3.0, 5.0, 3.0, 2.0, 2.0, 2.0, 5.0, 2.0, 2.0, 1.0, 4.0, 2.0, 4.0, 1.0, 0.0, 5.0, 4.0, 4.0, 2.0, 7.0, 5.0, 4.0, 3.0, 1.0, 7.0, 5.0, 4.0, 2.0, 1.0, 3.0, 9.0, 3.0, 7.0, 2.0, 6.0, 2.0, 2.0, 5.0, 1.0, 1.0, 4.0, 4.0, 3.0, 2.0, 2.0, 1.0, 2.0, 4.0, 3.0, 8.0, 1.0, 3.0, 0.0, 3.0, 1.0, 2.0, 3.0, 2.0, 1.0, 1.0, 2.0, 9.0, 2.0, 1.0, 7.0, 2.0, 2.0, 6.0, 2.0, 2.0, 2.0, 3.0, 2.0, 7.0, 4.0, 2.0, 4.0, 4.0, 1.0, 2.0, 5.0, 3.0, 3.0, 4.0, 4.0, 5.0, 1.0, 2.0, 8.0, 3.0], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500], "policy_shared_policy_reward": [1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 2.0, 1.0, 2.0, 1.0, 1.0, 1.0, 0.0, 1.0, 2.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 2.0, 1.0, 1.0, 2.0, 1.0, 1.0, 2.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 2.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 2.0, 1.0, 0.0, 0.0, 1.0, 1.0, 2.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 3.0, 0.0, 2.0, 0.0, 2.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 3.0, 1.0, 2.0, 1.0, 1.0, 1.0, 1.0, 2.0, 2.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 3.0, 2.0, 0.0, 1.0, 2.0, 2.0, 1.0, 2.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 3.0, 4.0, 0.0, 2.0, 0.0, 1.0, 1.0, 1.0, 2.0, 3.0, 0.0, 2.0, 0.0, 1.0, 1.0, 0.0, 2.0, 1.0, 1.0, 2.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 2.0, 1.0, 0.0, 2.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 2.0, 1.0, 2.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 2.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 2.0, 1.0, 0.0, 2.0, 0.0, 1.0, 0.0, 2.0, 3.0, 1.0, 2.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 3.0, 2.0, 2.0, 2.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 3.0, 2.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 2.0, 3.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 2.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 2.0, 2.0, 2.0, 1.0, 1.0, 0.0, 1.0, 2.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 2.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 3.0, 1.0, 1.0, 0.0, 1.0, 2.0, 0.0, 0.0, 0.0, 1.0, 0.0, 2.0, 2.0, 1.0, 1.0, 0.0, 1.0, 0.0, 2.0, 1.0, 1.0, 2.0, 2.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 4.0, 2.0, 1.0, 1.0, 1.0, 1.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.13366506981596535, "mean_inference_ms": 0.3903473476333103, "mean_action_processing_ms": 0.0291929482765449, "mean_env_wait_ms": 0.4041547158728521, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 584640, "timesteps_this_iter": 0, "agent_timesteps_total": 2338560, "timers": {"sample_time_ms": 5075.914, "sample_throughput": 992.925, "load_time_ms": 0.156, "load_throughput": 32318135.086, "learn_time_ms": 127.086, "learn_throughput": 39658.037, "update_time_ms": 2.445}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 186.8671875, "policy_entropy": 7847.005615234375, "policy_loss": 26.997455835342407, "vf_loss": 34.02350902557373}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 584640, "num_agent_steps_sampled": 2338560, "num_steps_trained": 584640, "num_agent_steps_trained": 2338560, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 1168, "training_iteration": 58, "trial_id": "71426_00000", "experiment_id": "84bca2f7b35f43248fca18d21abe2ebf", "date": "2024-06-12_02-55-49", "timestamp": 1718128549, "time_this_iter_s": 10.131585597991943, "time_total_s": 597.3646049499512, "pid": 363902, "hostname": "DESKTOP-LQ219J4", "node_ip": "192.168.46.185", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 20, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 5000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 500, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Base_Model", "custom_model_config": {"env": "rware", "env_args": {"n_agents": 4, "column_height": 1, "max_inactivity_steps": null, "max_steps": 500, "fast_obs": true, "msg_bits": 0, "sensor_range": 1, "shelf_rows": 1, "shelf_columns": 3, "request_queue_size": 4, "reward_type": "RewardType.INDIVIDUAL", "map_name": "customized_map", "map_size": "tiny", "difficulty": "medium"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": true, "force_coop": false, "local_mode": true, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 4, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 100, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64}, "algorithm": "ia2c", "space_obs": "Dict(obs:Box([-100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100.], [100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.], (112,), float32))", "space_act": "Discrete(5)", "num_agents": 4, "episode_limit": 500, "policy_mapping_info": {"all_scenario": {"description": "rware all scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2", "agent_3"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "rware_customized_map", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 10, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.IA2CTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_il.<locals>.<lambda> at 0x7f38281ee430>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "grad_clip": 40.0, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "microbatch_size": null}, "time_since_restore": 597.3646049499512, "timesteps_since_restore": 0, "iterations_since_restore": 58, "perf": {"cpu_util_percent": 4.335714285714285, "ram_util_percent": 48.457142857142856}}
{"episode_reward_max": 10.0, "episode_reward_min": 0.0, "episode_reward_mean": 3.45, "episode_len_mean": 500.0, "episode_media": {}, "episodes_this_iter": 20, "policy_reward_min": {"shared_policy": 0.0}, "policy_reward_max": {"shared_policy": 4.0}, "policy_reward_mean": {"shared_policy": 0.8625}, "custom_metrics": {}, "hist_stats": {"episode_reward": [4.0, 2.0, 4.0, 1.0, 0.0, 5.0, 4.0, 4.0, 2.0, 7.0, 5.0, 4.0, 3.0, 1.0, 7.0, 5.0, 4.0, 2.0, 1.0, 3.0, 9.0, 3.0, 7.0, 2.0, 6.0, 2.0, 2.0, 5.0, 1.0, 1.0, 4.0, 4.0, 3.0, 2.0, 2.0, 1.0, 2.0, 4.0, 3.0, 8.0, 1.0, 3.0, 0.0, 3.0, 1.0, 2.0, 3.0, 2.0, 1.0, 1.0, 2.0, 9.0, 2.0, 1.0, 7.0, 2.0, 2.0, 6.0, 2.0, 2.0, 2.0, 3.0, 2.0, 7.0, 4.0, 2.0, 4.0, 4.0, 1.0, 2.0, 5.0, 3.0, 3.0, 4.0, 4.0, 5.0, 1.0, 2.0, 8.0, 3.0, 4.0, 9.0, 5.0, 3.0, 4.0, 6.0, 2.0, 10.0, 2.0, 7.0, 3.0, 1.0, 2.0, 3.0, 2.0, 8.0, 4.0, 4.0, 4.0, 2.0], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500], "policy_shared_policy_reward": [1.0, 0.0, 1.0, 2.0, 1.0, 0.0, 0.0, 1.0, 1.0, 2.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 3.0, 0.0, 2.0, 0.0, 2.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 3.0, 1.0, 2.0, 1.0, 1.0, 1.0, 1.0, 2.0, 2.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 3.0, 2.0, 0.0, 1.0, 2.0, 2.0, 1.0, 2.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 3.0, 4.0, 0.0, 2.0, 0.0, 1.0, 1.0, 1.0, 2.0, 3.0, 0.0, 2.0, 0.0, 1.0, 1.0, 0.0, 2.0, 1.0, 1.0, 2.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 2.0, 1.0, 0.0, 2.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 2.0, 1.0, 2.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 2.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 2.0, 1.0, 0.0, 2.0, 0.0, 1.0, 0.0, 2.0, 3.0, 1.0, 2.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 3.0, 2.0, 2.0, 2.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 3.0, 2.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 2.0, 3.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 2.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 2.0, 2.0, 2.0, 1.0, 1.0, 0.0, 1.0, 2.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 2.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 3.0, 1.0, 1.0, 0.0, 1.0, 2.0, 0.0, 0.0, 0.0, 1.0, 0.0, 2.0, 2.0, 1.0, 1.0, 0.0, 1.0, 0.0, 2.0, 1.0, 1.0, 2.0, 2.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 4.0, 2.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 3.0, 4.0, 0.0, 2.0, 1.0, 1.0, 2.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 2.0, 0.0, 1.0, 3.0, 0.0, 2.0, 1.0, 0.0, 1.0, 0.0, 1.0, 2.0, 3.0, 3.0, 2.0, 1.0, 1.0, 0.0, 0.0, 3.0, 1.0, 2.0, 1.0, 0.0, 1.0, 2.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 3.0, 0.0, 3.0, 2.0, 1.0, 1.0, 2.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 2.0, 0.0, 1.0, 1.0, 0.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.13364457888173115, "mean_inference_ms": 0.39031717276139666, "mean_action_processing_ms": 0.02919055195382368, "mean_env_wait_ms": 0.40404477396487537, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 594720, "timesteps_this_iter": 0, "agent_timesteps_total": 2378880, "timers": {"sample_time_ms": 5072.218, "sample_throughput": 993.648, "load_time_ms": 0.155, "load_throughput": 32572098.86, "learn_time_ms": 126.659, "learn_throughput": 39791.968, "update_time_ms": 2.397}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 220.34707641601562, "policy_entropy": 7894.06982421875, "policy_loss": -21.60520648956299, "vf_loss": 28.10600185394287}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 594720, "num_agent_steps_sampled": 2378880, "num_steps_trained": 594720, "num_agent_steps_trained": 2378880, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 1188, "training_iteration": 59, "trial_id": "71426_00000", "experiment_id": "84bca2f7b35f43248fca18d21abe2ebf", "date": "2024-06-12_02-55-59", "timestamp": 1718128559, "time_this_iter_s": 10.15999960899353, "time_total_s": 607.5246045589447, "pid": 363902, "hostname": "DESKTOP-LQ219J4", "node_ip": "192.168.46.185", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 20, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 5000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 500, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Base_Model", "custom_model_config": {"env": "rware", "env_args": {"n_agents": 4, "column_height": 1, "max_inactivity_steps": null, "max_steps": 500, "fast_obs": true, "msg_bits": 0, "sensor_range": 1, "shelf_rows": 1, "shelf_columns": 3, "request_queue_size": 4, "reward_type": "RewardType.INDIVIDUAL", "map_name": "customized_map", "map_size": "tiny", "difficulty": "medium"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": true, "force_coop": false, "local_mode": true, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 4, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 100, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64}, "algorithm": "ia2c", "space_obs": "Dict(obs:Box([-100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100.], [100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.], (112,), float32))", "space_act": "Discrete(5)", "num_agents": 4, "episode_limit": 500, "policy_mapping_info": {"all_scenario": {"description": "rware all scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2", "agent_3"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "rware_customized_map", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 10, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.IA2CTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_il.<locals>.<lambda> at 0x7f3808651e50>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "grad_clip": 40.0, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "microbatch_size": null}, "time_since_restore": 607.5246045589447, "timesteps_since_restore": 0, "iterations_since_restore": 59, "perf": {"cpu_util_percent": 4.653333333333332, "ram_util_percent": 48.76666666666666}}
{"episode_reward_max": 10.0, "episode_reward_min": 0.0, "episode_reward_mean": 3.48, "episode_len_mean": 500.0, "episode_media": {}, "episodes_this_iter": 20, "policy_reward_min": {"shared_policy": 0.0}, "policy_reward_max": {"shared_policy": 4.0}, "policy_reward_mean": {"shared_policy": 0.87}, "custom_metrics": {}, "hist_stats": {"episode_reward": [9.0, 3.0, 7.0, 2.0, 6.0, 2.0, 2.0, 5.0, 1.0, 1.0, 4.0, 4.0, 3.0, 2.0, 2.0, 1.0, 2.0, 4.0, 3.0, 8.0, 1.0, 3.0, 0.0, 3.0, 1.0, 2.0, 3.0, 2.0, 1.0, 1.0, 2.0, 9.0, 2.0, 1.0, 7.0, 2.0, 2.0, 6.0, 2.0, 2.0, 2.0, 3.0, 2.0, 7.0, 4.0, 2.0, 4.0, 4.0, 1.0, 2.0, 5.0, 3.0, 3.0, 4.0, 4.0, 5.0, 1.0, 2.0, 8.0, 3.0, 4.0, 9.0, 5.0, 3.0, 4.0, 6.0, 2.0, 10.0, 2.0, 7.0, 3.0, 1.0, 2.0, 3.0, 2.0, 8.0, 4.0, 4.0, 4.0, 2.0, 6.0, 6.0, 5.0, 3.0, 3.0, 2.0, 3.0, 4.0, 3.0, 2.0, 2.0, 2.0, 2.0, 4.0, 3.0, 3.0, 3.0, 9.0, 6.0, 0.0], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500], "policy_shared_policy_reward": [3.0, 4.0, 0.0, 2.0, 0.0, 1.0, 1.0, 1.0, 2.0, 3.0, 0.0, 2.0, 0.0, 1.0, 1.0, 0.0, 2.0, 1.0, 1.0, 2.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 2.0, 1.0, 0.0, 2.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 2.0, 1.0, 2.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 2.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 2.0, 1.0, 0.0, 2.0, 0.0, 1.0, 0.0, 2.0, 3.0, 1.0, 2.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 3.0, 2.0, 2.0, 2.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 3.0, 2.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 2.0, 3.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 2.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 2.0, 2.0, 2.0, 1.0, 1.0, 0.0, 1.0, 2.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 2.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 3.0, 1.0, 1.0, 0.0, 1.0, 2.0, 0.0, 0.0, 0.0, 1.0, 0.0, 2.0, 2.0, 1.0, 1.0, 0.0, 1.0, 0.0, 2.0, 1.0, 1.0, 2.0, 2.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 4.0, 2.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 3.0, 4.0, 0.0, 2.0, 1.0, 1.0, 2.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 2.0, 0.0, 1.0, 3.0, 0.0, 2.0, 1.0, 0.0, 1.0, 0.0, 1.0, 2.0, 3.0, 3.0, 2.0, 1.0, 1.0, 0.0, 0.0, 3.0, 1.0, 2.0, 1.0, 0.0, 1.0, 2.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 3.0, 0.0, 3.0, 2.0, 1.0, 1.0, 2.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 2.0, 0.0, 1.0, 1.0, 0.0, 0.0, 2.0, 2.0, 0.0, 2.0, 1.0, 3.0, 1.0, 1.0, 1.0, 1.0, 1.0, 2.0, 1.0, 1.0, 0.0, 1.0, 2.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 2.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 2.0, 2.0, 3.0, 2.0, 2.0, 0.0, 1.0, 3.0, 0.0, 0.0, 0.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.1336276931023788, "mean_inference_ms": 0.3902955071529472, "mean_action_processing_ms": 0.02918789666760394, "mean_env_wait_ms": 0.40394636888279595, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 604800, "timesteps_this_iter": 0, "agent_timesteps_total": 2419200, "timers": {"sample_time_ms": 5078.046, "sample_throughput": 992.508, "load_time_ms": 0.16, "load_throughput": 31513554.204, "learn_time_ms": 127.028, "learn_throughput": 39676.273, "update_time_ms": 2.365}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 280.70379638671875, "policy_entropy": 7912.8819580078125, "policy_loss": -26.931432723999023, "vf_loss": 30.05520725250244}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 604800, "num_agent_steps_sampled": 2419200, "num_steps_trained": 604800, "num_agent_steps_trained": 2419200, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 1208, "training_iteration": 60, "trial_id": "71426_00000", "experiment_id": "84bca2f7b35f43248fca18d21abe2ebf", "date": "2024-06-12_02-56-09", "timestamp": 1718128569, "time_this_iter_s": 10.216699361801147, "time_total_s": 617.7413039207458, "pid": 363902, "hostname": "DESKTOP-LQ219J4", "node_ip": "192.168.46.185", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 20, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 5000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 500, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Base_Model", "custom_model_config": {"env": "rware", "env_args": {"n_agents": 4, "column_height": 1, "max_inactivity_steps": null, "max_steps": 500, "fast_obs": true, "msg_bits": 0, "sensor_range": 1, "shelf_rows": 1, "shelf_columns": 3, "request_queue_size": 4, "reward_type": "RewardType.INDIVIDUAL", "map_name": "customized_map", "map_size": "tiny", "difficulty": "medium"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": true, "force_coop": false, "local_mode": true, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 4, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 100, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64}, "algorithm": "ia2c", "space_obs": "Dict(obs:Box([-100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100.], [100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.], (112,), float32))", "space_act": "Discrete(5)", "num_agents": 4, "episode_limit": 500, "policy_mapping_info": {"all_scenario": {"description": "rware all scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2", "agent_3"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "rware_customized_map", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 10, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.IA2CTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_il.<locals>.<lambda> at 0x7f38081d5d30>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "grad_clip": 40.0, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "microbatch_size": null}, "time_since_restore": 617.7413039207458, "timesteps_since_restore": 0, "iterations_since_restore": 60, "perf": {"cpu_util_percent": 4.514285714285715, "ram_util_percent": 49.05000000000001}}
{"episode_reward_max": 10.0, "episode_reward_min": 0.0, "episode_reward_mean": 3.46, "episode_len_mean": 500.0, "episode_media": {}, "episodes_this_iter": 20, "policy_reward_min": {"shared_policy": 0.0}, "policy_reward_max": {"shared_policy": 4.0}, "policy_reward_mean": {"shared_policy": 0.865}, "custom_metrics": {}, "hist_stats": {"episode_reward": [1.0, 3.0, 0.0, 3.0, 1.0, 2.0, 3.0, 2.0, 1.0, 1.0, 2.0, 9.0, 2.0, 1.0, 7.0, 2.0, 2.0, 6.0, 2.0, 2.0, 2.0, 3.0, 2.0, 7.0, 4.0, 2.0, 4.0, 4.0, 1.0, 2.0, 5.0, 3.0, 3.0, 4.0, 4.0, 5.0, 1.0, 2.0, 8.0, 3.0, 4.0, 9.0, 5.0, 3.0, 4.0, 6.0, 2.0, 10.0, 2.0, 7.0, 3.0, 1.0, 2.0, 3.0, 2.0, 8.0, 4.0, 4.0, 4.0, 2.0, 6.0, 6.0, 5.0, 3.0, 3.0, 2.0, 3.0, 4.0, 3.0, 2.0, 2.0, 2.0, 2.0, 4.0, 3.0, 3.0, 3.0, 9.0, 6.0, 0.0, 3.0, 2.0, 3.0, 4.0, 4.0, 6.0, 5.0, 4.0, 2.0, 2.0, 4.0, 4.0, 1.0, 6.0, 5.0, 4.0, 4.0, 2.0, 0.0, 4.0], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500], "policy_shared_policy_reward": [1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 3.0, 2.0, 2.0, 2.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 3.0, 2.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 2.0, 3.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 2.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 2.0, 2.0, 2.0, 1.0, 1.0, 0.0, 1.0, 2.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 2.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 3.0, 1.0, 1.0, 0.0, 1.0, 2.0, 0.0, 0.0, 0.0, 1.0, 0.0, 2.0, 2.0, 1.0, 1.0, 0.0, 1.0, 0.0, 2.0, 1.0, 1.0, 2.0, 2.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 4.0, 2.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 3.0, 4.0, 0.0, 2.0, 1.0, 1.0, 2.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 2.0, 0.0, 1.0, 3.0, 0.0, 2.0, 1.0, 0.0, 1.0, 0.0, 1.0, 2.0, 3.0, 3.0, 2.0, 1.0, 1.0, 0.0, 0.0, 3.0, 1.0, 2.0, 1.0, 0.0, 1.0, 2.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 3.0, 0.0, 3.0, 2.0, 1.0, 1.0, 2.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 2.0, 0.0, 1.0, 1.0, 0.0, 0.0, 2.0, 2.0, 0.0, 2.0, 1.0, 3.0, 1.0, 1.0, 1.0, 1.0, 1.0, 2.0, 1.0, 1.0, 0.0, 1.0, 2.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 2.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 2.0, 2.0, 3.0, 2.0, 2.0, 0.0, 1.0, 3.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 2.0, 0.0, 1.0, 1.0, 0.0, 2.0, 1.0, 2.0, 2.0, 1.0, 1.0, 0.0, 2.0, 2.0, 2.0, 0.0, 1.0, 1.0, 0.0, 0.0, 2.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 2.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 2.0, 1.0, 2.0, 1.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0, 0.0, 2.0, 2.0, 0.0, 0.0, 2.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 2.0, 1.0, 1.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.13361496778712106, "mean_inference_ms": 0.3902885573670328, "mean_action_processing_ms": 0.029185441941751034, "mean_env_wait_ms": 0.40387880012370386, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 614880, "timesteps_this_iter": 0, "agent_timesteps_total": 2459520, "timers": {"sample_time_ms": 5091.228, "sample_throughput": 989.938, "load_time_ms": 0.162, "load_throughput": 31142151.09, "learn_time_ms": 127.241, "learn_throughput": 39609.958, "update_time_ms": 2.341}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 153.47555541992188, "policy_entropy": 7877.4862060546875, "policy_loss": -56.60846948623657, "vf_loss": 23.57285213470459}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 614880, "num_agent_steps_sampled": 2459520, "num_steps_trained": 614880, "num_agent_steps_trained": 2459520, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 1228, "training_iteration": 61, "trial_id": "71426_00000", "experiment_id": "84bca2f7b35f43248fca18d21abe2ebf", "date": "2024-06-12_02-56-20", "timestamp": 1718128580, "time_this_iter_s": 10.219384908676147, "time_total_s": 627.960688829422, "pid": 363902, "hostname": "DESKTOP-LQ219J4", "node_ip": "192.168.46.185", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 20, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 5000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 500, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Base_Model", "custom_model_config": {"env": "rware", "env_args": {"n_agents": 4, "column_height": 1, "max_inactivity_steps": null, "max_steps": 500, "fast_obs": true, "msg_bits": 0, "sensor_range": 1, "shelf_rows": 1, "shelf_columns": 3, "request_queue_size": 4, "reward_type": "RewardType.INDIVIDUAL", "map_name": "customized_map", "map_size": "tiny", "difficulty": "medium"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": true, "force_coop": false, "local_mode": true, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 4, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 100, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64}, "algorithm": "ia2c", "space_obs": "Dict(obs:Box([-100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100.], [100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.], (112,), float32))", "space_act": "Discrete(5)", "num_agents": 4, "episode_limit": 500, "policy_mapping_info": {"all_scenario": {"description": "rware all scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2", "agent_3"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "rware_customized_map", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 10, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.IA2CTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_il.<locals>.<lambda> at 0x7f380824d8b0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "grad_clip": 40.0, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "microbatch_size": null}, "time_since_restore": 627.960688829422, "timesteps_since_restore": 0, "iterations_since_restore": 61, "perf": {"cpu_util_percent": 4.486666666666666, "ram_util_percent": 49.29999999999998}}
{"episode_reward_max": 10.0, "episode_reward_min": 0.0, "episode_reward_mean": 3.71, "episode_len_mean": 500.0, "episode_media": {}, "episodes_this_iter": 20, "policy_reward_min": {"shared_policy": 0.0}, "policy_reward_max": {"shared_policy": 4.0}, "policy_reward_mean": {"shared_policy": 0.9275}, "custom_metrics": {}, "hist_stats": {"episode_reward": [2.0, 3.0, 2.0, 7.0, 4.0, 2.0, 4.0, 4.0, 1.0, 2.0, 5.0, 3.0, 3.0, 4.0, 4.0, 5.0, 1.0, 2.0, 8.0, 3.0, 4.0, 9.0, 5.0, 3.0, 4.0, 6.0, 2.0, 10.0, 2.0, 7.0, 3.0, 1.0, 2.0, 3.0, 2.0, 8.0, 4.0, 4.0, 4.0, 2.0, 6.0, 6.0, 5.0, 3.0, 3.0, 2.0, 3.0, 4.0, 3.0, 2.0, 2.0, 2.0, 2.0, 4.0, 3.0, 3.0, 3.0, 9.0, 6.0, 0.0, 3.0, 2.0, 3.0, 4.0, 4.0, 6.0, 5.0, 4.0, 2.0, 2.0, 4.0, 4.0, 1.0, 6.0, 5.0, 4.0, 4.0, 2.0, 0.0, 4.0, 3.0, 4.0, 4.0, 1.0, 1.0, 2.0, 8.0, 4.0, 4.0, 5.0, 8.0, 2.0, 6.0, 5.0, 3.0, 2.0, 3.0, 9.0, 1.0, 2.0], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500], "policy_shared_policy_reward": [0.0, 1.0, 1.0, 0.0, 0.0, 2.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 2.0, 2.0, 2.0, 1.0, 1.0, 0.0, 1.0, 2.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 2.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 3.0, 1.0, 1.0, 0.0, 1.0, 2.0, 0.0, 0.0, 0.0, 1.0, 0.0, 2.0, 2.0, 1.0, 1.0, 0.0, 1.0, 0.0, 2.0, 1.0, 1.0, 2.0, 2.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 4.0, 2.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 3.0, 4.0, 0.0, 2.0, 1.0, 1.0, 2.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 2.0, 0.0, 1.0, 3.0, 0.0, 2.0, 1.0, 0.0, 1.0, 0.0, 1.0, 2.0, 3.0, 3.0, 2.0, 1.0, 1.0, 0.0, 0.0, 3.0, 1.0, 2.0, 1.0, 0.0, 1.0, 2.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 3.0, 0.0, 3.0, 2.0, 1.0, 1.0, 2.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 2.0, 0.0, 1.0, 1.0, 0.0, 0.0, 2.0, 2.0, 0.0, 2.0, 1.0, 3.0, 1.0, 1.0, 1.0, 1.0, 1.0, 2.0, 1.0, 1.0, 0.0, 1.0, 2.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 2.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 2.0, 2.0, 3.0, 2.0, 2.0, 0.0, 1.0, 3.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 2.0, 0.0, 1.0, 1.0, 0.0, 2.0, 1.0, 2.0, 2.0, 1.0, 1.0, 0.0, 2.0, 2.0, 2.0, 0.0, 1.0, 1.0, 0.0, 0.0, 2.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 2.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 2.0, 1.0, 2.0, 1.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0, 0.0, 2.0, 2.0, 0.0, 0.0, 2.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 2.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 2.0, 0.0, 2.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 2.0, 2.0, 1.0, 3.0, 2.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 2.0, 1.0, 2.0, 1.0, 1.0, 2.0, 1.0, 2.0, 3.0, 1.0, 0.0, 1.0, 0.0, 1.0, 2.0, 1.0, 2.0, 2.0, 1.0, 0.0, 2.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 2.0, 4.0, 1.0, 1.0, 3.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.13360984900303788, "mean_inference_ms": 0.3903014066890198, "mean_action_processing_ms": 0.029184144422556898, "mean_env_wait_ms": 0.4038428685469269, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 624960, "timesteps_this_iter": 0, "agent_timesteps_total": 2499840, "timers": {"sample_time_ms": 5109.972, "sample_throughput": 986.307, "load_time_ms": 0.161, "load_throughput": 31275768.842, "learn_time_ms": 126.831, "learn_throughput": 39737.864, "update_time_ms": 2.317}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 308.89898681640625, "policy_entropy": 7861.4910888671875, "policy_loss": -67.69972372055054, "vf_loss": 30.39766812324524}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 624960, "num_agent_steps_sampled": 2499840, "num_steps_trained": 624960, "num_agent_steps_trained": 2499840, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 1248, "training_iteration": 62, "trial_id": "71426_00000", "experiment_id": "84bca2f7b35f43248fca18d21abe2ebf", "date": "2024-06-12_02-56-30", "timestamp": 1718128590, "time_this_iter_s": 10.292195558547974, "time_total_s": 638.25288438797, "pid": 363902, "hostname": "DESKTOP-LQ219J4", "node_ip": "192.168.46.185", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 20, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 5000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 500, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Base_Model", "custom_model_config": {"env": "rware", "env_args": {"n_agents": 4, "column_height": 1, "max_inactivity_steps": null, "max_steps": 500, "fast_obs": true, "msg_bits": 0, "sensor_range": 1, "shelf_rows": 1, "shelf_columns": 3, "request_queue_size": 4, "reward_type": "RewardType.INDIVIDUAL", "map_name": "customized_map", "map_size": "tiny", "difficulty": "medium"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": true, "force_coop": false, "local_mode": true, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 4, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 100, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64}, "algorithm": "ia2c", "space_obs": "Dict(obs:Box([-100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100.], [100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.], (112,), float32))", "space_act": "Discrete(5)", "num_agents": 4, "episode_limit": 500, "policy_mapping_info": {"all_scenario": {"description": "rware all scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2", "agent_3"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "rware_customized_map", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 10, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.IA2CTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_il.<locals>.<lambda> at 0x7f38280b2310>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "grad_clip": 40.0, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "microbatch_size": null}, "time_since_restore": 638.25288438797, "timesteps_since_restore": 0, "iterations_since_restore": 62, "perf": {"cpu_util_percent": 4.8928571428571415, "ram_util_percent": 49.75714285714285}}
{"episode_reward_max": 10.0, "episode_reward_min": 0.0, "episode_reward_mean": 3.75, "episode_len_mean": 500.0, "episode_media": {}, "episodes_this_iter": 20, "policy_reward_min": {"shared_policy": 0.0}, "policy_reward_max": {"shared_policy": 4.0}, "policy_reward_mean": {"shared_policy": 0.9375}, "custom_metrics": {}, "hist_stats": {"episode_reward": [4.0, 9.0, 5.0, 3.0, 4.0, 6.0, 2.0, 10.0, 2.0, 7.0, 3.0, 1.0, 2.0, 3.0, 2.0, 8.0, 4.0, 4.0, 4.0, 2.0, 6.0, 6.0, 5.0, 3.0, 3.0, 2.0, 3.0, 4.0, 3.0, 2.0, 2.0, 2.0, 2.0, 4.0, 3.0, 3.0, 3.0, 9.0, 6.0, 0.0, 3.0, 2.0, 3.0, 4.0, 4.0, 6.0, 5.0, 4.0, 2.0, 2.0, 4.0, 4.0, 1.0, 6.0, 5.0, 4.0, 4.0, 2.0, 0.0, 4.0, 3.0, 4.0, 4.0, 1.0, 1.0, 2.0, 8.0, 4.0, 4.0, 5.0, 8.0, 2.0, 6.0, 5.0, 3.0, 2.0, 3.0, 9.0, 1.0, 2.0, 7.0, 8.0, 5.0, 5.0, 4.0, 3.0, 5.0, 3.0, 3.0, 6.0, 3.0, 2.0, 3.0, 3.0, 2.0, 0.0, 3.0, 4.0, 3.0, 1.0], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500], "policy_shared_policy_reward": [1.0, 1.0, 1.0, 1.0, 3.0, 4.0, 0.0, 2.0, 1.0, 1.0, 2.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 2.0, 0.0, 1.0, 3.0, 0.0, 2.0, 1.0, 0.0, 1.0, 0.0, 1.0, 2.0, 3.0, 3.0, 2.0, 1.0, 1.0, 0.0, 0.0, 3.0, 1.0, 2.0, 1.0, 0.0, 1.0, 2.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 3.0, 0.0, 3.0, 2.0, 1.0, 1.0, 2.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 2.0, 0.0, 1.0, 1.0, 0.0, 0.0, 2.0, 2.0, 0.0, 2.0, 1.0, 3.0, 1.0, 1.0, 1.0, 1.0, 1.0, 2.0, 1.0, 1.0, 0.0, 1.0, 2.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 2.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 2.0, 2.0, 3.0, 2.0, 2.0, 0.0, 1.0, 3.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 2.0, 0.0, 1.0, 1.0, 0.0, 2.0, 1.0, 2.0, 2.0, 1.0, 1.0, 0.0, 2.0, 2.0, 2.0, 0.0, 1.0, 1.0, 0.0, 0.0, 2.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 2.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 2.0, 1.0, 2.0, 1.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0, 0.0, 2.0, 2.0, 0.0, 0.0, 2.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 2.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 2.0, 0.0, 2.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 2.0, 2.0, 1.0, 3.0, 2.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 2.0, 1.0, 2.0, 1.0, 1.0, 2.0, 1.0, 2.0, 3.0, 1.0, 0.0, 1.0, 0.0, 1.0, 2.0, 1.0, 2.0, 2.0, 1.0, 0.0, 2.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 2.0, 4.0, 1.0, 1.0, 3.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 2.0, 1.0, 3.0, 1.0, 1.0, 3.0, 1.0, 3.0, 2.0, 1.0, 1.0, 1.0, 0.0, 2.0, 2.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 3.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 2.0, 1.0, 0.0, 0.0, 2.0, 2.0, 2.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 2.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 2.0, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.1336050179187365, "mean_inference_ms": 0.39031287085273747, "mean_action_processing_ms": 0.029183185473416223, "mean_env_wait_ms": 0.403842513409945, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 635040, "timesteps_this_iter": 0, "agent_timesteps_total": 2540160, "timers": {"sample_time_ms": 5120.445, "sample_throughput": 984.29, "load_time_ms": 0.164, "load_throughput": 30801824.508, "learn_time_ms": 127.199, "learn_throughput": 39623.011, "update_time_ms": 2.277}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 363.916748046875, "policy_entropy": 7859.651611328125, "policy_loss": -34.65489864349365, "vf_loss": 23.471423864364624}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 635040, "num_agent_steps_sampled": 2540160, "num_steps_trained": 635040, "num_agent_steps_trained": 2540160, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 1268, "training_iteration": 63, "trial_id": "71426_00000", "experiment_id": "84bca2f7b35f43248fca18d21abe2ebf", "date": "2024-06-12_02-56-40", "timestamp": 1718128600, "time_this_iter_s": 10.236514568328857, "time_total_s": 648.4893989562988, "pid": 363902, "hostname": "DESKTOP-LQ219J4", "node_ip": "192.168.46.185", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 20, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 5000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 500, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Base_Model", "custom_model_config": {"env": "rware", "env_args": {"n_agents": 4, "column_height": 1, "max_inactivity_steps": null, "max_steps": 500, "fast_obs": true, "msg_bits": 0, "sensor_range": 1, "shelf_rows": 1, "shelf_columns": 3, "request_queue_size": 4, "reward_type": "RewardType.INDIVIDUAL", "map_name": "customized_map", "map_size": "tiny", "difficulty": "medium"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": true, "force_coop": false, "local_mode": true, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 4, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 100, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64}, "algorithm": "ia2c", "space_obs": "Dict(obs:Box([-100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100.], [100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.], (112,), float32))", "space_act": "Discrete(5)", "num_agents": 4, "episode_limit": 500, "policy_mapping_info": {"all_scenario": {"description": "rware all scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2", "agent_3"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "rware_customized_map", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 10, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.IA2CTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_il.<locals>.<lambda> at 0x7f38081d5d30>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "grad_clip": 40.0, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "microbatch_size": null}, "time_since_restore": 648.4893989562988, "timesteps_since_restore": 0, "iterations_since_restore": 63, "perf": {"cpu_util_percent": 4.573333333333333, "ram_util_percent": 49.96}}
{"episode_reward_max": 10.0, "episode_reward_min": 0.0, "episode_reward_mean": 3.51, "episode_len_mean": 500.0, "episode_media": {}, "episodes_this_iter": 20, "policy_reward_min": {"shared_policy": 0.0}, "policy_reward_max": {"shared_policy": 4.0}, "policy_reward_mean": {"shared_policy": 0.8775}, "custom_metrics": {}, "hist_stats": {"episode_reward": [6.0, 6.0, 5.0, 3.0, 3.0, 2.0, 3.0, 4.0, 3.0, 2.0, 2.0, 2.0, 2.0, 4.0, 3.0, 3.0, 3.0, 9.0, 6.0, 0.0, 3.0, 2.0, 3.0, 4.0, 4.0, 6.0, 5.0, 4.0, 2.0, 2.0, 4.0, 4.0, 1.0, 6.0, 5.0, 4.0, 4.0, 2.0, 0.0, 4.0, 3.0, 4.0, 4.0, 1.0, 1.0, 2.0, 8.0, 4.0, 4.0, 5.0, 8.0, 2.0, 6.0, 5.0, 3.0, 2.0, 3.0, 9.0, 1.0, 2.0, 7.0, 8.0, 5.0, 5.0, 4.0, 3.0, 5.0, 3.0, 3.0, 6.0, 3.0, 2.0, 3.0, 3.0, 2.0, 0.0, 3.0, 4.0, 3.0, 1.0, 1.0, 0.0, 10.0, 4.0, 4.0, 2.0, 1.0, 7.0, 5.0, 4.0, 2.0, 2.0, 4.0, 2.0, 4.0, 1.0, 3.0, 2.0, 2.0, 1.0], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500], "policy_shared_policy_reward": [2.0, 2.0, 0.0, 2.0, 1.0, 3.0, 1.0, 1.0, 1.0, 1.0, 1.0, 2.0, 1.0, 1.0, 0.0, 1.0, 2.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 2.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 2.0, 2.0, 3.0, 2.0, 2.0, 0.0, 1.0, 3.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 2.0, 0.0, 1.0, 1.0, 0.0, 2.0, 1.0, 2.0, 2.0, 1.0, 1.0, 0.0, 2.0, 2.0, 2.0, 0.0, 1.0, 1.0, 0.0, 0.0, 2.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 2.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 2.0, 1.0, 2.0, 1.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0, 0.0, 2.0, 2.0, 0.0, 0.0, 2.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 2.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 2.0, 0.0, 2.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 2.0, 2.0, 1.0, 3.0, 2.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 2.0, 1.0, 2.0, 1.0, 1.0, 2.0, 1.0, 2.0, 3.0, 1.0, 0.0, 1.0, 0.0, 1.0, 2.0, 1.0, 2.0, 2.0, 1.0, 0.0, 2.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 2.0, 4.0, 1.0, 1.0, 3.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 2.0, 1.0, 3.0, 1.0, 1.0, 3.0, 1.0, 3.0, 2.0, 1.0, 1.0, 1.0, 0.0, 2.0, 2.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 3.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 2.0, 1.0, 0.0, 0.0, 2.0, 2.0, 2.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 2.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 2.0, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.0, 3.0, 2.0, 2.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 2.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 3.0, 2.0, 1.0, 1.0, 0.0, 1.0, 2.0, 2.0, 1.0, 2.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 2.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 2.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.13360595690815116, "mean_inference_ms": 0.3903216065108049, "mean_action_processing_ms": 0.0291833323593183, "mean_env_wait_ms": 0.4038599550486078, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 645120, "timesteps_this_iter": 0, "agent_timesteps_total": 2580480, "timers": {"sample_time_ms": 5127.616, "sample_throughput": 982.913, "load_time_ms": 0.166, "load_throughput": 30429382.698, "learn_time_ms": 128.449, "learn_throughput": 39237.425, "update_time_ms": 2.297}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 168.6932373046875, "policy_entropy": 7887.6171875, "policy_loss": 19.85215139389038, "vf_loss": 25.177225589752197}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 645120, "num_agent_steps_sampled": 2580480, "num_steps_trained": 645120, "num_agent_steps_trained": 2580480, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 1288, "training_iteration": 64, "trial_id": "71426_00000", "experiment_id": "84bca2f7b35f43248fca18d21abe2ebf", "date": "2024-06-12_02-56-50", "timestamp": 1718128610, "time_this_iter_s": 10.24370789527893, "time_total_s": 658.7331068515778, "pid": 363902, "hostname": "DESKTOP-LQ219J4", "node_ip": "192.168.46.185", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 20, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 5000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 500, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Base_Model", "custom_model_config": {"env": "rware", "env_args": {"n_agents": 4, "column_height": 1, "max_inactivity_steps": null, "max_steps": 500, "fast_obs": true, "msg_bits": 0, "sensor_range": 1, "shelf_rows": 1, "shelf_columns": 3, "request_queue_size": 4, "reward_type": "RewardType.INDIVIDUAL", "map_name": "customized_map", "map_size": "tiny", "difficulty": "medium"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": true, "force_coop": false, "local_mode": true, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 4, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 100, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64}, "algorithm": "ia2c", "space_obs": "Dict(obs:Box([-100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100.], [100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.], (112,), float32))", "space_act": "Discrete(5)", "num_agents": 4, "episode_limit": 500, "policy_mapping_info": {"all_scenario": {"description": "rware all scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2", "agent_3"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "rware_customized_map", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 10, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.IA2CTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_il.<locals>.<lambda> at 0x7f3808645160>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "grad_clip": 40.0, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "microbatch_size": null}, "time_since_restore": 658.7331068515778, "timesteps_since_restore": 0, "iterations_since_restore": 64, "perf": {"cpu_util_percent": 5.193333333333332, "ram_util_percent": 50.39999999999999}}
{"episode_reward_max": 10.0, "episode_reward_min": 0.0, "episode_reward_mean": 3.57, "episode_len_mean": 500.0, "episode_media": {}, "episodes_this_iter": 20, "policy_reward_min": {"shared_policy": 0.0}, "policy_reward_max": {"shared_policy": 4.0}, "policy_reward_mean": {"shared_policy": 0.8925}, "custom_metrics": {}, "hist_stats": {"episode_reward": [3.0, 2.0, 3.0, 4.0, 4.0, 6.0, 5.0, 4.0, 2.0, 2.0, 4.0, 4.0, 1.0, 6.0, 5.0, 4.0, 4.0, 2.0, 0.0, 4.0, 3.0, 4.0, 4.0, 1.0, 1.0, 2.0, 8.0, 4.0, 4.0, 5.0, 8.0, 2.0, 6.0, 5.0, 3.0, 2.0, 3.0, 9.0, 1.0, 2.0, 7.0, 8.0, 5.0, 5.0, 4.0, 3.0, 5.0, 3.0, 3.0, 6.0, 3.0, 2.0, 3.0, 3.0, 2.0, 0.0, 3.0, 4.0, 3.0, 1.0, 1.0, 0.0, 10.0, 4.0, 4.0, 2.0, 1.0, 7.0, 5.0, 4.0, 2.0, 2.0, 4.0, 2.0, 4.0, 1.0, 3.0, 2.0, 2.0, 1.0, 4.0, 9.0, 4.0, 1.0, 2.0, 0.0, 2.0, 3.0, 5.0, 5.0, 8.0, 8.0, 4.0, 2.0, 1.0, 6.0, 6.0, 1.0, 4.0, 2.0], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500], "policy_shared_policy_reward": [1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 2.0, 0.0, 1.0, 1.0, 0.0, 2.0, 1.0, 2.0, 2.0, 1.0, 1.0, 0.0, 2.0, 2.0, 2.0, 0.0, 1.0, 1.0, 0.0, 0.0, 2.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 2.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 2.0, 1.0, 2.0, 1.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0, 0.0, 2.0, 2.0, 0.0, 0.0, 2.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 2.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 2.0, 0.0, 2.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 2.0, 2.0, 1.0, 3.0, 2.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 2.0, 1.0, 2.0, 1.0, 1.0, 2.0, 1.0, 2.0, 3.0, 1.0, 0.0, 1.0, 0.0, 1.0, 2.0, 1.0, 2.0, 2.0, 1.0, 0.0, 2.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 2.0, 4.0, 1.0, 1.0, 3.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 2.0, 1.0, 3.0, 1.0, 1.0, 3.0, 1.0, 3.0, 2.0, 1.0, 1.0, 1.0, 0.0, 2.0, 2.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 3.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 2.0, 1.0, 0.0, 0.0, 2.0, 2.0, 2.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 2.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 2.0, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.0, 3.0, 2.0, 2.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 2.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 3.0, 2.0, 1.0, 1.0, 0.0, 1.0, 2.0, 2.0, 1.0, 2.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 2.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 2.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 2.0, 2.0, 2.0, 3.0, 0.0, 1.0, 1.0, 2.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 2.0, 2.0, 1.0, 2.0, 0.0, 1.0, 2.0, 2.0, 0.0, 2.0, 2.0, 2.0, 2.0, 3.0, 4.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 2.0, 1.0, 0.0, 3.0, 2.0, 0.0, 1.0, 3.0, 1.0, 0.0, 0.0, 0.0, 2.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.13360715533997475, "mean_inference_ms": 0.39033396378005164, "mean_action_processing_ms": 0.029185343679804077, "mean_env_wait_ms": 0.4038761529424971, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 655200, "timesteps_this_iter": 0, "agent_timesteps_total": 2620800, "timers": {"sample_time_ms": 5131.272, "sample_throughput": 982.213, "load_time_ms": 0.164, "load_throughput": 30743589.529, "learn_time_ms": 128.298, "learn_throughput": 39283.471, "update_time_ms": 2.288}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 152.34976196289062, "policy_entropy": 7894.7481689453125, "policy_loss": 12.794639468193054, "vf_loss": 26.693461894989014}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 655200, "num_agent_steps_sampled": 2620800, "num_steps_trained": 655200, "num_agent_steps_trained": 2620800, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 1308, "training_iteration": 65, "trial_id": "71426_00000", "experiment_id": "84bca2f7b35f43248fca18d21abe2ebf", "date": "2024-06-12_02-57-01", "timestamp": 1718128621, "time_this_iter_s": 10.241047620773315, "time_total_s": 668.9741544723511, "pid": 363902, "hostname": "DESKTOP-LQ219J4", "node_ip": "192.168.46.185", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 20, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 5000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 500, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Base_Model", "custom_model_config": {"env": "rware", "env_args": {"n_agents": 4, "column_height": 1, "max_inactivity_steps": null, "max_steps": 500, "fast_obs": true, "msg_bits": 0, "sensor_range": 1, "shelf_rows": 1, "shelf_columns": 3, "request_queue_size": 4, "reward_type": "RewardType.INDIVIDUAL", "map_name": "customized_map", "map_size": "tiny", "difficulty": "medium"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": true, "force_coop": false, "local_mode": true, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 4, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 100, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64}, "algorithm": "ia2c", "space_obs": "Dict(obs:Box([-100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100.], [100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.], (112,), float32))", "space_act": "Discrete(5)", "num_agents": 4, "episode_limit": 500, "policy_mapping_info": {"all_scenario": {"description": "rware all scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2", "agent_3"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "rware_customized_map", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 10, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.IA2CTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_il.<locals>.<lambda> at 0x7f38086c11f0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "grad_clip": 40.0, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "microbatch_size": null}, "time_since_restore": 668.9741544723511, "timesteps_since_restore": 0, "iterations_since_restore": 65, "perf": {"cpu_util_percent": 4.521428571428571, "ram_util_percent": 50.70000000000001}}
{"episode_reward_max": 10.0, "episode_reward_min": 0.0, "episode_reward_mean": 3.66, "episode_len_mean": 500.0, "episode_media": {}, "episodes_this_iter": 20, "policy_reward_min": {"shared_policy": 0.0}, "policy_reward_max": {"shared_policy": 4.0}, "policy_reward_mean": {"shared_policy": 0.915}, "custom_metrics": {}, "hist_stats": {"episode_reward": [3.0, 4.0, 4.0, 1.0, 1.0, 2.0, 8.0, 4.0, 4.0, 5.0, 8.0, 2.0, 6.0, 5.0, 3.0, 2.0, 3.0, 9.0, 1.0, 2.0, 7.0, 8.0, 5.0, 5.0, 4.0, 3.0, 5.0, 3.0, 3.0, 6.0, 3.0, 2.0, 3.0, 3.0, 2.0, 0.0, 3.0, 4.0, 3.0, 1.0, 1.0, 0.0, 10.0, 4.0, 4.0, 2.0, 1.0, 7.0, 5.0, 4.0, 2.0, 2.0, 4.0, 2.0, 4.0, 1.0, 3.0, 2.0, 2.0, 1.0, 4.0, 9.0, 4.0, 1.0, 2.0, 0.0, 2.0, 3.0, 5.0, 5.0, 8.0, 8.0, 4.0, 2.0, 1.0, 6.0, 6.0, 1.0, 4.0, 2.0, 5.0, 3.0, 4.0, 1.0, 3.0, 4.0, 4.0, 1.0, 3.0, 1.0, 6.0, 4.0, 5.0, 4.0, 6.0, 7.0, 3.0, 3.0, 6.0, 5.0], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500], "policy_shared_policy_reward": [1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 2.0, 0.0, 2.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 2.0, 2.0, 1.0, 3.0, 2.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 2.0, 1.0, 2.0, 1.0, 1.0, 2.0, 1.0, 2.0, 3.0, 1.0, 0.0, 1.0, 0.0, 1.0, 2.0, 1.0, 2.0, 2.0, 1.0, 0.0, 2.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 2.0, 4.0, 1.0, 1.0, 3.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 2.0, 1.0, 3.0, 1.0, 1.0, 3.0, 1.0, 3.0, 2.0, 1.0, 1.0, 1.0, 0.0, 2.0, 2.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 3.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 2.0, 1.0, 0.0, 0.0, 2.0, 2.0, 2.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 2.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 2.0, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.0, 3.0, 2.0, 2.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 2.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 3.0, 2.0, 1.0, 1.0, 0.0, 1.0, 2.0, 2.0, 1.0, 2.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 2.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 2.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 2.0, 2.0, 2.0, 3.0, 0.0, 1.0, 1.0, 2.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 2.0, 2.0, 1.0, 2.0, 0.0, 1.0, 2.0, 2.0, 0.0, 2.0, 2.0, 2.0, 2.0, 3.0, 4.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 2.0, 1.0, 0.0, 3.0, 2.0, 0.0, 1.0, 3.0, 1.0, 0.0, 0.0, 0.0, 2.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 2.0, 0.0, 2.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 2.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 2.0, 0.0, 0.0, 0.0, 1.0, 1.0, 2.0, 1.0, 1.0, 0.0, 2.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 2.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 2.0, 2.0, 1.0, 1.0, 1.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0, 1.0, 2.0, 0.0, 1.0, 2.0, 1.0, 1.0, 2.0, 2.0, 3.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 2.0, 2.0, 2.0, 2.0, 1.0, 0.0, 2.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.13360226268561223, "mean_inference_ms": 0.39033141947592265, "mean_action_processing_ms": 0.029185465077348996, "mean_env_wait_ms": 0.40388185757427464, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 665280, "timesteps_this_iter": 0, "agent_timesteps_total": 2661120, "timers": {"sample_time_ms": 5120.164, "sample_throughput": 984.343, "load_time_ms": 0.163, "load_throughput": 30932531.694, "learn_time_ms": 127.87, "learn_throughput": 39414.976, "update_time_ms": 2.327}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 136.72744750976562, "policy_entropy": 7837.2479248046875, "policy_loss": -7.191649943590164, "vf_loss": 27.94440531730652}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 665280, "num_agent_steps_sampled": 2661120, "num_steps_trained": 665280, "num_agent_steps_trained": 2661120, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 1328, "training_iteration": 66, "trial_id": "71426_00000", "experiment_id": "84bca2f7b35f43248fca18d21abe2ebf", "date": "2024-06-12_02-57-11", "timestamp": 1718128631, "time_this_iter_s": 10.102810621261597, "time_total_s": 679.0769650936127, "pid": 363902, "hostname": "DESKTOP-LQ219J4", "node_ip": "192.168.46.185", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 20, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 5000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 500, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Base_Model", "custom_model_config": {"env": "rware", "env_args": {"n_agents": 4, "column_height": 1, "max_inactivity_steps": null, "max_steps": 500, "fast_obs": true, "msg_bits": 0, "sensor_range": 1, "shelf_rows": 1, "shelf_columns": 3, "request_queue_size": 4, "reward_type": "RewardType.INDIVIDUAL", "map_name": "customized_map", "map_size": "tiny", "difficulty": "medium"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": true, "force_coop": false, "local_mode": true, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 4, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 100, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64}, "algorithm": "ia2c", "space_obs": "Dict(obs:Box([-100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100.], [100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.], (112,), float32))", "space_act": "Discrete(5)", "num_agents": 4, "episode_limit": 500, "policy_mapping_info": {"all_scenario": {"description": "rware all scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2", "agent_3"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "rware_customized_map", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 10, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.IA2CTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_il.<locals>.<lambda> at 0x7f380824d8b0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "grad_clip": 40.0, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "microbatch_size": null}, "time_since_restore": 679.0769650936127, "timesteps_since_restore": 0, "iterations_since_restore": 66, "perf": {"cpu_util_percent": 4.493333333333334, "ram_util_percent": 51.0}}
{"episode_reward_max": 10.0, "episode_reward_min": 0.0, "episode_reward_mean": 3.7, "episode_len_mean": 500.0, "episode_media": {}, "episodes_this_iter": 20, "policy_reward_min": {"shared_policy": 0.0}, "policy_reward_max": {"shared_policy": 4.0}, "policy_reward_mean": {"shared_policy": 0.925}, "custom_metrics": {}, "hist_stats": {"episode_reward": [7.0, 8.0, 5.0, 5.0, 4.0, 3.0, 5.0, 3.0, 3.0, 6.0, 3.0, 2.0, 3.0, 3.0, 2.0, 0.0, 3.0, 4.0, 3.0, 1.0, 1.0, 0.0, 10.0, 4.0, 4.0, 2.0, 1.0, 7.0, 5.0, 4.0, 2.0, 2.0, 4.0, 2.0, 4.0, 1.0, 3.0, 2.0, 2.0, 1.0, 4.0, 9.0, 4.0, 1.0, 2.0, 0.0, 2.0, 3.0, 5.0, 5.0, 8.0, 8.0, 4.0, 2.0, 1.0, 6.0, 6.0, 1.0, 4.0, 2.0, 5.0, 3.0, 4.0, 1.0, 3.0, 4.0, 4.0, 1.0, 3.0, 1.0, 6.0, 4.0, 5.0, 4.0, 6.0, 7.0, 3.0, 3.0, 6.0, 5.0, 6.0, 3.0, 2.0, 3.0, 2.0, 3.0, 4.0, 2.0, 2.0, 2.0, 4.0, 4.0, 6.0, 6.0, 10.0, 2.0, 7.0, 2.0, 3.0, 8.0], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500], "policy_shared_policy_reward": [2.0, 1.0, 3.0, 1.0, 1.0, 3.0, 1.0, 3.0, 2.0, 1.0, 1.0, 1.0, 0.0, 2.0, 2.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 3.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 2.0, 1.0, 0.0, 0.0, 2.0, 2.0, 2.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 2.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 2.0, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.0, 3.0, 2.0, 2.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 2.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 3.0, 2.0, 1.0, 1.0, 0.0, 1.0, 2.0, 2.0, 1.0, 2.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 2.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 2.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 2.0, 2.0, 2.0, 3.0, 0.0, 1.0, 1.0, 2.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 2.0, 2.0, 1.0, 2.0, 0.0, 1.0, 2.0, 2.0, 0.0, 2.0, 2.0, 2.0, 2.0, 3.0, 4.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 2.0, 1.0, 0.0, 3.0, 2.0, 0.0, 1.0, 3.0, 1.0, 0.0, 0.0, 0.0, 2.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 2.0, 0.0, 2.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 2.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 2.0, 0.0, 0.0, 0.0, 1.0, 1.0, 2.0, 1.0, 1.0, 0.0, 2.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 2.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 2.0, 2.0, 1.0, 1.0, 1.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0, 1.0, 2.0, 0.0, 1.0, 2.0, 1.0, 1.0, 2.0, 2.0, 3.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 2.0, 2.0, 2.0, 2.0, 1.0, 0.0, 2.0, 1.0, 1.0, 2.0, 2.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 2.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 2.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 2.0, 0.0, 1.0, 0.0, 1.0, 0.0, 2.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 2.0, 1.0, 2.0, 1.0, 2.0, 2.0, 1.0, 1.0, 2.0, 2.0, 4.0, 2.0, 2.0, 1.0, 0.0, 0.0, 1.0, 1.0, 3.0, 2.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 2.0, 0.0, 3.0, 3.0, 1.0, 1.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.13359093146716083, "mean_inference_ms": 0.39031087976451984, "mean_action_processing_ms": 0.02918511830829775, "mean_env_wait_ms": 0.4038817776619679, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 675360, "timesteps_this_iter": 0, "agent_timesteps_total": 2701440, "timers": {"sample_time_ms": 5109.993, "sample_throughput": 986.303, "load_time_ms": 0.162, "load_throughput": 31055225.738, "learn_time_ms": 127.962, "learn_throughput": 39386.651, "update_time_ms": 2.319}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 194.9639892578125, "policy_entropy": 7848.901611328125, "policy_loss": 17.581152200698853, "vf_loss": 25.77664613723755}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 675360, "num_agent_steps_sampled": 2701440, "num_steps_trained": 675360, "num_agent_steps_trained": 2701440, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 1348, "training_iteration": 67, "trial_id": "71426_00000", "experiment_id": "84bca2f7b35f43248fca18d21abe2ebf", "date": "2024-06-12_02-57-21", "timestamp": 1718128641, "time_this_iter_s": 10.201130867004395, "time_total_s": 689.2780959606171, "pid": 363902, "hostname": "DESKTOP-LQ219J4", "node_ip": "192.168.46.185", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 20, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 5000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 500, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Base_Model", "custom_model_config": {"env": "rware", "env_args": {"n_agents": 4, "column_height": 1, "max_inactivity_steps": null, "max_steps": 500, "fast_obs": true, "msg_bits": 0, "sensor_range": 1, "shelf_rows": 1, "shelf_columns": 3, "request_queue_size": 4, "reward_type": "RewardType.INDIVIDUAL", "map_name": "customized_map", "map_size": "tiny", "difficulty": "medium"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": true, "force_coop": false, "local_mode": true, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 4, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 100, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64}, "algorithm": "ia2c", "space_obs": "Dict(obs:Box([-100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100.], [100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.], (112,), float32))", "space_act": "Discrete(5)", "num_agents": 4, "episode_limit": 500, "policy_mapping_info": {"all_scenario": {"description": "rware all scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2", "agent_3"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "rware_customized_map", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 10, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.IA2CTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_il.<locals>.<lambda> at 0x7f38082f8550>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "grad_clip": 40.0, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "microbatch_size": null}, "time_since_restore": 689.2780959606171, "timesteps_since_restore": 0, "iterations_since_restore": 67, "perf": {"cpu_util_percent": 4.457142857142856, "ram_util_percent": 51.29285714285713}}
{"episode_reward_max": 10.0, "episode_reward_min": 0.0, "episode_reward_mean": 3.62, "episode_len_mean": 500.0, "episode_media": {}, "episodes_this_iter": 20, "policy_reward_min": {"shared_policy": 0.0}, "policy_reward_max": {"shared_policy": 4.0}, "policy_reward_mean": {"shared_policy": 0.905}, "custom_metrics": {}, "hist_stats": {"episode_reward": [1.0, 0.0, 10.0, 4.0, 4.0, 2.0, 1.0, 7.0, 5.0, 4.0, 2.0, 2.0, 4.0, 2.0, 4.0, 1.0, 3.0, 2.0, 2.0, 1.0, 4.0, 9.0, 4.0, 1.0, 2.0, 0.0, 2.0, 3.0, 5.0, 5.0, 8.0, 8.0, 4.0, 2.0, 1.0, 6.0, 6.0, 1.0, 4.0, 2.0, 5.0, 3.0, 4.0, 1.0, 3.0, 4.0, 4.0, 1.0, 3.0, 1.0, 6.0, 4.0, 5.0, 4.0, 6.0, 7.0, 3.0, 3.0, 6.0, 5.0, 6.0, 3.0, 2.0, 3.0, 2.0, 3.0, 4.0, 2.0, 2.0, 2.0, 4.0, 4.0, 6.0, 6.0, 10.0, 2.0, 7.0, 2.0, 3.0, 8.0, 2.0, 2.0, 6.0, 8.0, 3.0, 2.0, 6.0, 3.0, 1.0, 1.0, 3.0, 6.0, 2.0, 3.0, 7.0, 3.0, 3.0, 1.0, 2.0, 1.0], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500], "policy_shared_policy_reward": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.0, 3.0, 2.0, 2.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 2.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 3.0, 2.0, 1.0, 1.0, 0.0, 1.0, 2.0, 2.0, 1.0, 2.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 2.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 2.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 2.0, 2.0, 2.0, 3.0, 0.0, 1.0, 1.0, 2.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 2.0, 2.0, 1.0, 2.0, 0.0, 1.0, 2.0, 2.0, 0.0, 2.0, 2.0, 2.0, 2.0, 3.0, 4.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 2.0, 1.0, 0.0, 3.0, 2.0, 0.0, 1.0, 3.0, 1.0, 0.0, 0.0, 0.0, 2.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 2.0, 0.0, 2.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 2.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 2.0, 0.0, 0.0, 0.0, 1.0, 1.0, 2.0, 1.0, 1.0, 0.0, 2.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 2.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 2.0, 2.0, 1.0, 1.0, 1.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0, 1.0, 2.0, 0.0, 1.0, 2.0, 1.0, 1.0, 2.0, 2.0, 3.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 2.0, 2.0, 2.0, 2.0, 1.0, 0.0, 2.0, 1.0, 1.0, 2.0, 2.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 2.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 2.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 2.0, 0.0, 1.0, 0.0, 1.0, 0.0, 2.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 2.0, 1.0, 2.0, 1.0, 2.0, 2.0, 1.0, 1.0, 2.0, 2.0, 4.0, 2.0, 2.0, 1.0, 0.0, 0.0, 1.0, 1.0, 3.0, 2.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 2.0, 0.0, 3.0, 3.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 2.0, 2.0, 2.0, 1.0, 3.0, 2.0, 1.0, 2.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 2.0, 2.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 2.0, 1.0, 2.0, 3.0, 1.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 2.0, 1.0, 0.0, 2.0, 2.0, 1.0, 2.0, 0.0, 1.0, 1.0, 1.0, 0.0, 2.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.1335912635543164, "mean_inference_ms": 0.39032465210389833, "mean_action_processing_ms": 0.02918636573037395, "mean_env_wait_ms": 0.40387520315152203, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 685440, "timesteps_this_iter": 0, "agent_timesteps_total": 2741760, "timers": {"sample_time_ms": 5125.374, "sample_throughput": 983.343, "load_time_ms": 0.165, "load_throughput": 30508431.462, "learn_time_ms": 127.245, "learn_throughput": 39608.712, "update_time_ms": 2.395}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 202.7513427734375, "policy_entropy": 7927.9559326171875, "policy_loss": -26.050294399261475, "vf_loss": 22.956207752227783}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 685440, "num_agent_steps_sampled": 2741760, "num_steps_trained": 685440, "num_agent_steps_trained": 2741760, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 1368, "training_iteration": 68, "trial_id": "71426_00000", "experiment_id": "84bca2f7b35f43248fca18d21abe2ebf", "date": "2024-06-12_02-57-31", "timestamp": 1718128651, "time_this_iter_s": 10.390332221984863, "time_total_s": 699.6684281826019, "pid": 363902, "hostname": "DESKTOP-LQ219J4", "node_ip": "192.168.46.185", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 20, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 5000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 500, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Base_Model", "custom_model_config": {"env": "rware", "env_args": {"n_agents": 4, "column_height": 1, "max_inactivity_steps": null, "max_steps": 500, "fast_obs": true, "msg_bits": 0, "sensor_range": 1, "shelf_rows": 1, "shelf_columns": 3, "request_queue_size": 4, "reward_type": "RewardType.INDIVIDUAL", "map_name": "customized_map", "map_size": "tiny", "difficulty": "medium"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": true, "force_coop": false, "local_mode": true, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 4, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 100, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64}, "algorithm": "ia2c", "space_obs": "Dict(obs:Box([-100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100.], [100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.], (112,), float32))", "space_act": "Discrete(5)", "num_agents": 4, "episode_limit": 500, "policy_mapping_info": {"all_scenario": {"description": "rware all scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2", "agent_3"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "rware_customized_map", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 10, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.IA2CTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_il.<locals>.<lambda> at 0x7f3808645160>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "grad_clip": 40.0, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "microbatch_size": null}, "time_since_restore": 699.6684281826019, "timesteps_since_restore": 0, "iterations_since_restore": 68, "perf": {"cpu_util_percent": 4.420000000000001, "ram_util_percent": 51.55333333333335}}
{"episode_reward_max": 12.0, "episode_reward_min": 0.0, "episode_reward_mean": 3.94, "episode_len_mean": 500.0, "episode_media": {}, "episodes_this_iter": 20, "policy_reward_min": {"shared_policy": 0.0}, "policy_reward_max": {"shared_policy": 5.0}, "policy_reward_mean": {"shared_policy": 0.985}, "custom_metrics": {}, "hist_stats": {"episode_reward": [4.0, 9.0, 4.0, 1.0, 2.0, 0.0, 2.0, 3.0, 5.0, 5.0, 8.0, 8.0, 4.0, 2.0, 1.0, 6.0, 6.0, 1.0, 4.0, 2.0, 5.0, 3.0, 4.0, 1.0, 3.0, 4.0, 4.0, 1.0, 3.0, 1.0, 6.0, 4.0, 5.0, 4.0, 6.0, 7.0, 3.0, 3.0, 6.0, 5.0, 6.0, 3.0, 2.0, 3.0, 2.0, 3.0, 4.0, 2.0, 2.0, 2.0, 4.0, 4.0, 6.0, 6.0, 10.0, 2.0, 7.0, 2.0, 3.0, 8.0, 2.0, 2.0, 6.0, 8.0, 3.0, 2.0, 6.0, 3.0, 1.0, 1.0, 3.0, 6.0, 2.0, 3.0, 7.0, 3.0, 3.0, 1.0, 2.0, 1.0, 2.0, 4.0, 3.0, 8.0, 5.0, 2.0, 4.0, 4.0, 6.0, 2.0, 4.0, 4.0, 5.0, 2.0, 2.0, 5.0, 3.0, 12.0, 8.0, 8.0], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500], "policy_shared_policy_reward": [1.0, 1.0, 1.0, 1.0, 2.0, 2.0, 2.0, 3.0, 0.0, 1.0, 1.0, 2.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 2.0, 2.0, 1.0, 2.0, 0.0, 1.0, 2.0, 2.0, 0.0, 2.0, 2.0, 2.0, 2.0, 3.0, 4.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 2.0, 1.0, 0.0, 3.0, 2.0, 0.0, 1.0, 3.0, 1.0, 0.0, 0.0, 0.0, 2.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 2.0, 0.0, 2.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 2.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 2.0, 0.0, 0.0, 0.0, 1.0, 1.0, 2.0, 1.0, 1.0, 0.0, 2.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 2.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 2.0, 2.0, 1.0, 1.0, 1.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0, 1.0, 2.0, 0.0, 1.0, 2.0, 1.0, 1.0, 2.0, 2.0, 3.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 2.0, 2.0, 2.0, 2.0, 1.0, 0.0, 2.0, 1.0, 1.0, 2.0, 2.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 2.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 2.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 2.0, 0.0, 1.0, 0.0, 1.0, 0.0, 2.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 2.0, 1.0, 2.0, 1.0, 2.0, 2.0, 1.0, 1.0, 2.0, 2.0, 4.0, 2.0, 2.0, 1.0, 0.0, 0.0, 1.0, 1.0, 3.0, 2.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 2.0, 0.0, 3.0, 3.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 2.0, 2.0, 2.0, 1.0, 3.0, 2.0, 1.0, 2.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 2.0, 2.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 2.0, 1.0, 2.0, 3.0, 1.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 2.0, 1.0, 0.0, 2.0, 2.0, 1.0, 2.0, 0.0, 1.0, 1.0, 1.0, 0.0, 2.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 2.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 2.0, 2.0, 3.0, 2.0, 1.0, 3.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 2.0, 1.0, 1.0, 0.0, 2.0, 1.0, 1.0, 2.0, 2.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 2.0, 1.0, 1.0, 2.0, 0.0, 1.0, 2.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 2.0, 0.0, 3.0, 0.0, 0.0, 2.0, 0.0, 2.0, 0.0, 1.0, 1.0, 5.0, 4.0, 2.0, 0.0, 2.0, 2.0, 4.0, 2.0, 3.0, 1.0, 2.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.13358838873517165, "mean_inference_ms": 0.3903253338069092, "mean_action_processing_ms": 0.02918707825339596, "mean_env_wait_ms": 0.40385314145359, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 695520, "timesteps_this_iter": 0, "agent_timesteps_total": 2782080, "timers": {"sample_time_ms": 5115.213, "sample_throughput": 985.296, "load_time_ms": 0.161, "load_throughput": 31243411.41, "learn_time_ms": 126.598, "learn_throughput": 39810.913, "update_time_ms": 2.392}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 315.2751159667969, "policy_entropy": 7882.8028564453125, "policy_loss": 43.31654214859009, "vf_loss": 32.81312656402588}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 695520, "num_agent_steps_sampled": 2782080, "num_steps_trained": 695520, "num_agent_steps_trained": 2782080, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 1388, "training_iteration": 69, "trial_id": "71426_00000", "experiment_id": "84bca2f7b35f43248fca18d21abe2ebf", "date": "2024-06-12_02-57-41", "timestamp": 1718128661, "time_this_iter_s": 10.135791301727295, "time_total_s": 709.8042194843292, "pid": 363902, "hostname": "DESKTOP-LQ219J4", "node_ip": "192.168.46.185", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 20, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 5000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 500, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Base_Model", "custom_model_config": {"env": "rware", "env_args": {"n_agents": 4, "column_height": 1, "max_inactivity_steps": null, "max_steps": 500, "fast_obs": true, "msg_bits": 0, "sensor_range": 1, "shelf_rows": 1, "shelf_columns": 3, "request_queue_size": 4, "reward_type": "RewardType.INDIVIDUAL", "map_name": "customized_map", "map_size": "tiny", "difficulty": "medium"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": true, "force_coop": false, "local_mode": true, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 4, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 100, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64}, "algorithm": "ia2c", "space_obs": "Dict(obs:Box([-100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100.], [100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.], (112,), float32))", "space_act": "Discrete(5)", "num_agents": 4, "episode_limit": 500, "policy_mapping_info": {"all_scenario": {"description": "rware all scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2", "agent_3"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "rware_customized_map", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 10, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.IA2CTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_il.<locals>.<lambda> at 0x7f380824d310>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "grad_clip": 40.0, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "microbatch_size": null}, "time_since_restore": 709.8042194843292, "timesteps_since_restore": 0, "iterations_since_restore": 69, "perf": {"cpu_util_percent": 4.386666666666667, "ram_util_percent": 51.819999999999986}}
{"episode_reward_max": 12.0, "episode_reward_min": 0.0, "episode_reward_mean": 3.81, "episode_len_mean": 500.0, "episode_media": {}, "episodes_this_iter": 20, "policy_reward_min": {"shared_policy": 0.0}, "policy_reward_max": {"shared_policy": 5.0}, "policy_reward_mean": {"shared_policy": 0.9525}, "custom_metrics": {}, "hist_stats": {"episode_reward": [5.0, 3.0, 4.0, 1.0, 3.0, 4.0, 4.0, 1.0, 3.0, 1.0, 6.0, 4.0, 5.0, 4.0, 6.0, 7.0, 3.0, 3.0, 6.0, 5.0, 6.0, 3.0, 2.0, 3.0, 2.0, 3.0, 4.0, 2.0, 2.0, 2.0, 4.0, 4.0, 6.0, 6.0, 10.0, 2.0, 7.0, 2.0, 3.0, 8.0, 2.0, 2.0, 6.0, 8.0, 3.0, 2.0, 6.0, 3.0, 1.0, 1.0, 3.0, 6.0, 2.0, 3.0, 7.0, 3.0, 3.0, 1.0, 2.0, 1.0, 2.0, 4.0, 3.0, 8.0, 5.0, 2.0, 4.0, 4.0, 6.0, 2.0, 4.0, 4.0, 5.0, 2.0, 2.0, 5.0, 3.0, 12.0, 8.0, 8.0, 3.0, 1.0, 0.0, 3.0, 5.0, 2.0, 5.0, 3.0, 4.0, 3.0, 3.0, 2.0, 1.0, 4.0, 7.0, 7.0, 4.0, 2.0, 2.0, 3.0], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500], "policy_shared_policy_reward": [2.0, 0.0, 2.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 2.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 2.0, 0.0, 0.0, 0.0, 1.0, 1.0, 2.0, 1.0, 1.0, 0.0, 2.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 2.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 2.0, 2.0, 1.0, 1.0, 1.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0, 1.0, 2.0, 0.0, 1.0, 2.0, 1.0, 1.0, 2.0, 2.0, 3.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 2.0, 2.0, 2.0, 2.0, 1.0, 0.0, 2.0, 1.0, 1.0, 2.0, 2.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 2.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 2.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 2.0, 0.0, 1.0, 0.0, 1.0, 0.0, 2.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 2.0, 1.0, 2.0, 1.0, 2.0, 2.0, 1.0, 1.0, 2.0, 2.0, 4.0, 2.0, 2.0, 1.0, 0.0, 0.0, 1.0, 1.0, 3.0, 2.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 2.0, 0.0, 3.0, 3.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 2.0, 2.0, 2.0, 1.0, 3.0, 2.0, 1.0, 2.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 2.0, 2.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 2.0, 1.0, 2.0, 3.0, 1.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 2.0, 1.0, 0.0, 2.0, 2.0, 1.0, 2.0, 0.0, 1.0, 1.0, 1.0, 0.0, 2.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 2.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 2.0, 2.0, 3.0, 2.0, 1.0, 3.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 2.0, 1.0, 1.0, 0.0, 2.0, 1.0, 1.0, 2.0, 2.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 2.0, 1.0, 1.0, 2.0, 0.0, 1.0, 2.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 2.0, 0.0, 3.0, 0.0, 0.0, 2.0, 0.0, 2.0, 0.0, 1.0, 1.0, 5.0, 4.0, 2.0, 0.0, 2.0, 2.0, 4.0, 2.0, 3.0, 1.0, 2.0, 0.0, 0.0, 2.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 2.0, 1.0, 2.0, 0.0, 0.0, 1.0, 0.0, 1.0, 2.0, 2.0, 0.0, 1.0, 0.0, 2.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 2.0, 0.0, 2.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 2.0, 2.0, 2.0, 2.0, 2.0, 1.0, 2.0, 1.0, 2.0, 2.0, 1.0, 1.0, 0.0, 2.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 2.0, 1.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.1335866531483648, "mean_inference_ms": 0.390327515269907, "mean_action_processing_ms": 0.029185641391126227, "mean_env_wait_ms": 0.40382634198980083, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 705600, "timesteps_this_iter": 0, "agent_timesteps_total": 2822400, "timers": {"sample_time_ms": 5111.93, "sample_throughput": 985.929, "load_time_ms": 0.158, "load_throughput": 31821906.006, "learn_time_ms": 126.02, "learn_throughput": 39993.53, "update_time_ms": 2.407}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 182.52159118652344, "policy_entropy": 7889.540771484375, "policy_loss": 25.10915780067444, "vf_loss": 25.33111047744751}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 705600, "num_agent_steps_sampled": 2822400, "num_steps_trained": 705600, "num_agent_steps_trained": 2822400, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 1408, "training_iteration": 70, "trial_id": "71426_00000", "experiment_id": "84bca2f7b35f43248fca18d21abe2ebf", "date": "2024-06-12_02-57-52", "timestamp": 1718128672, "time_this_iter_s": 10.213468074798584, "time_total_s": 720.0176875591278, "pid": 363902, "hostname": "DESKTOP-LQ219J4", "node_ip": "192.168.46.185", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 20, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 5000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 500, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Base_Model", "custom_model_config": {"env": "rware", "env_args": {"n_agents": 4, "column_height": 1, "max_inactivity_steps": null, "max_steps": 500, "fast_obs": true, "msg_bits": 0, "sensor_range": 1, "shelf_rows": 1, "shelf_columns": 3, "request_queue_size": 4, "reward_type": "RewardType.INDIVIDUAL", "map_name": "customized_map", "map_size": "tiny", "difficulty": "medium"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": true, "force_coop": false, "local_mode": true, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 4, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 100, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64}, "algorithm": "ia2c", "space_obs": "Dict(obs:Box([-100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100.], [100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.], (112,), float32))", "space_act": "Discrete(5)", "num_agents": 4, "episode_limit": 500, "policy_mapping_info": {"all_scenario": {"description": "rware all scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2", "agent_3"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "rware_customized_map", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 10, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.IA2CTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_il.<locals>.<lambda> at 0x7f380824d040>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "grad_clip": 40.0, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "microbatch_size": null}, "time_since_restore": 720.0176875591278, "timesteps_since_restore": 0, "iterations_since_restore": 70, "perf": {"cpu_util_percent": 4.528571428571428, "ram_util_percent": 52.10000000000001}}
{"episode_reward_max": 12.0, "episode_reward_min": 0.0, "episode_reward_mean": 3.71, "episode_len_mean": 500.0, "episode_media": {}, "episodes_this_iter": 20, "policy_reward_min": {"shared_policy": 0.0}, "policy_reward_max": {"shared_policy": 5.0}, "policy_reward_mean": {"shared_policy": 0.9275}, "custom_metrics": {}, "hist_stats": {"episode_reward": [6.0, 3.0, 2.0, 3.0, 2.0, 3.0, 4.0, 2.0, 2.0, 2.0, 4.0, 4.0, 6.0, 6.0, 10.0, 2.0, 7.0, 2.0, 3.0, 8.0, 2.0, 2.0, 6.0, 8.0, 3.0, 2.0, 6.0, 3.0, 1.0, 1.0, 3.0, 6.0, 2.0, 3.0, 7.0, 3.0, 3.0, 1.0, 2.0, 1.0, 2.0, 4.0, 3.0, 8.0, 5.0, 2.0, 4.0, 4.0, 6.0, 2.0, 4.0, 4.0, 5.0, 2.0, 2.0, 5.0, 3.0, 12.0, 8.0, 8.0, 3.0, 1.0, 0.0, 3.0, 5.0, 2.0, 5.0, 3.0, 4.0, 3.0, 3.0, 2.0, 1.0, 4.0, 7.0, 7.0, 4.0, 2.0, 2.0, 3.0, 3.0, 5.0, 5.0, 2.0, 3.0, 1.0, 3.0, 2.0, 5.0, 5.0, 6.0, 1.0, 2.0, 4.0, 1.0, 3.0, 2.0, 2.0, 9.0, 4.0], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500], "policy_shared_policy_reward": [1.0, 1.0, 2.0, 2.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 2.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 2.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 2.0, 0.0, 1.0, 0.0, 1.0, 0.0, 2.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 2.0, 1.0, 2.0, 1.0, 2.0, 2.0, 1.0, 1.0, 2.0, 2.0, 4.0, 2.0, 2.0, 1.0, 0.0, 0.0, 1.0, 1.0, 3.0, 2.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 2.0, 0.0, 3.0, 3.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 2.0, 2.0, 2.0, 1.0, 3.0, 2.0, 1.0, 2.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 2.0, 2.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 2.0, 1.0, 2.0, 3.0, 1.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 2.0, 1.0, 0.0, 2.0, 2.0, 1.0, 2.0, 0.0, 1.0, 1.0, 1.0, 0.0, 2.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 2.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 2.0, 2.0, 3.0, 2.0, 1.0, 3.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 2.0, 1.0, 1.0, 0.0, 2.0, 1.0, 1.0, 2.0, 2.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 2.0, 1.0, 1.0, 2.0, 0.0, 1.0, 2.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 2.0, 0.0, 3.0, 0.0, 0.0, 2.0, 0.0, 2.0, 0.0, 1.0, 1.0, 5.0, 4.0, 2.0, 0.0, 2.0, 2.0, 4.0, 2.0, 3.0, 1.0, 2.0, 0.0, 0.0, 2.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 2.0, 1.0, 2.0, 0.0, 0.0, 1.0, 0.0, 1.0, 2.0, 2.0, 0.0, 1.0, 0.0, 2.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 2.0, 0.0, 2.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 2.0, 2.0, 2.0, 2.0, 2.0, 1.0, 2.0, 1.0, 2.0, 2.0, 1.0, 1.0, 0.0, 2.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 2.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 2.0, 0.0, 2.0, 2.0, 1.0, 0.0, 2.0, 1.0, 1.0, 0.0, 0.0, 0.0, 2.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 2.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0, 3.0, 1.0, 2.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 2.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 2.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 5.0, 1.0, 1.0, 2.0, 2.0, 0.0, 1.0, 1.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.1335931693112533, "mean_inference_ms": 0.39035015012156365, "mean_action_processing_ms": 0.029185758149727598, "mean_env_wait_ms": 0.4038183982477537, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 715680, "timesteps_this_iter": 0, "agent_timesteps_total": 2862720, "timers": {"sample_time_ms": 5129.19, "sample_throughput": 982.611, "load_time_ms": 0.16, "load_throughput": 31490082.169, "learn_time_ms": 126.045, "learn_throughput": 39985.67, "update_time_ms": 2.378}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 126.04701232910156, "policy_entropy": 7822.666015625, "policy_loss": -11.808350563049316, "vf_loss": 23.56631088256836}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 715680, "num_agent_steps_sampled": 2862720, "num_steps_trained": 715680, "num_agent_steps_trained": 2862720, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 1428, "training_iteration": 71, "trial_id": "71426_00000", "experiment_id": "84bca2f7b35f43248fca18d21abe2ebf", "date": "2024-06-12_02-58-02", "timestamp": 1718128682, "time_this_iter_s": 10.275724411010742, "time_total_s": 730.2934119701385, "pid": 363902, "hostname": "DESKTOP-LQ219J4", "node_ip": "192.168.46.185", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 20, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 5000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 500, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Base_Model", "custom_model_config": {"env": "rware", "env_args": {"n_agents": 4, "column_height": 1, "max_inactivity_steps": null, "max_steps": 500, "fast_obs": true, "msg_bits": 0, "sensor_range": 1, "shelf_rows": 1, "shelf_columns": 3, "request_queue_size": 4, "reward_type": "RewardType.INDIVIDUAL", "map_name": "customized_map", "map_size": "tiny", "difficulty": "medium"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": true, "force_coop": false, "local_mode": true, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 4, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 100, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64}, "algorithm": "ia2c", "space_obs": "Dict(obs:Box([-100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100.], [100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.], (112,), float32))", "space_act": "Discrete(5)", "num_agents": 4, "episode_limit": 500, "policy_mapping_info": {"all_scenario": {"description": "rware all scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2", "agent_3"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "rware_customized_map", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 10, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.IA2CTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_il.<locals>.<lambda> at 0x7f38086c1d30>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "grad_clip": 40.0, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "microbatch_size": null}, "time_since_restore": 730.2934119701385, "timesteps_since_restore": 0, "iterations_since_restore": 71, "perf": {"cpu_util_percent": 4.373333333333333, "ram_util_percent": 52.39999999999999}}
{"episode_reward_max": 12.0, "episode_reward_min": 0.0, "episode_reward_mean": 3.72, "episode_len_mean": 500.0, "episode_media": {}, "episodes_this_iter": 20, "policy_reward_min": {"shared_policy": 0.0}, "policy_reward_max": {"shared_policy": 5.0}, "policy_reward_mean": {"shared_policy": 0.93}, "custom_metrics": {}, "hist_stats": {"episode_reward": [2.0, 2.0, 6.0, 8.0, 3.0, 2.0, 6.0, 3.0, 1.0, 1.0, 3.0, 6.0, 2.0, 3.0, 7.0, 3.0, 3.0, 1.0, 2.0, 1.0, 2.0, 4.0, 3.0, 8.0, 5.0, 2.0, 4.0, 4.0, 6.0, 2.0, 4.0, 4.0, 5.0, 2.0, 2.0, 5.0, 3.0, 12.0, 8.0, 8.0, 3.0, 1.0, 0.0, 3.0, 5.0, 2.0, 5.0, 3.0, 4.0, 3.0, 3.0, 2.0, 1.0, 4.0, 7.0, 7.0, 4.0, 2.0, 2.0, 3.0, 3.0, 5.0, 5.0, 2.0, 3.0, 1.0, 3.0, 2.0, 5.0, 5.0, 6.0, 1.0, 2.0, 4.0, 1.0, 3.0, 2.0, 2.0, 9.0, 4.0, 6.0, 2.0, 4.0, 3.0, 5.0, 2.0, 8.0, 3.0, 2.0, 3.0, 4.0, 8.0, 7.0, 3.0, 3.0, 5.0, 9.0, 1.0, 3.0, 1.0], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500], "policy_shared_policy_reward": [0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 2.0, 2.0, 2.0, 1.0, 3.0, 2.0, 1.0, 2.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 2.0, 2.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 2.0, 1.0, 2.0, 3.0, 1.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 2.0, 1.0, 0.0, 2.0, 2.0, 1.0, 2.0, 0.0, 1.0, 1.0, 1.0, 0.0, 2.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 2.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 2.0, 2.0, 3.0, 2.0, 1.0, 3.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 2.0, 1.0, 1.0, 0.0, 2.0, 1.0, 1.0, 2.0, 2.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 2.0, 1.0, 1.0, 2.0, 0.0, 1.0, 2.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 2.0, 0.0, 3.0, 0.0, 0.0, 2.0, 0.0, 2.0, 0.0, 1.0, 1.0, 5.0, 4.0, 2.0, 0.0, 2.0, 2.0, 4.0, 2.0, 3.0, 1.0, 2.0, 0.0, 0.0, 2.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 2.0, 1.0, 2.0, 0.0, 0.0, 1.0, 0.0, 1.0, 2.0, 2.0, 0.0, 1.0, 0.0, 2.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 2.0, 0.0, 2.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 2.0, 2.0, 2.0, 2.0, 2.0, 1.0, 2.0, 1.0, 2.0, 2.0, 1.0, 1.0, 0.0, 2.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 2.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 2.0, 0.0, 2.0, 2.0, 1.0, 0.0, 2.0, 1.0, 1.0, 0.0, 0.0, 0.0, 2.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 2.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0, 3.0, 1.0, 2.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 2.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 2.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 5.0, 1.0, 1.0, 2.0, 2.0, 0.0, 1.0, 1.0, 1.0, 1.0, 2.0, 2.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 2.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 2.0, 0.0, 1.0, 1.0, 0.0, 2.0, 1.0, 2.0, 3.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 3.0, 1.0, 3.0, 2.0, 1.0, 3.0, 1.0, 2.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 2.0, 2.0, 4.0, 1.0, 0.0, 4.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.13360881478780487, "mean_inference_ms": 0.3903993813947102, "mean_action_processing_ms": 0.029186522657242905, "mean_env_wait_ms": 0.403825540163716, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 725760, "timesteps_this_iter": 0, "agent_timesteps_total": 2903040, "timers": {"sample_time_ms": 5150.714, "sample_throughput": 978.505, "load_time_ms": 0.163, "load_throughput": 30950647.379, "learn_time_ms": 129.992, "learn_throughput": 38771.643, "update_time_ms": 2.408}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 435.4329528808594, "policy_entropy": 7889.3929443359375, "policy_loss": -26.874282836914062, "vf_loss": 23.152576208114624}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 725760, "num_agent_steps_sampled": 2903040, "num_steps_trained": 725760, "num_agent_steps_trained": 2903040, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 1448, "training_iteration": 72, "trial_id": "71426_00000", "experiment_id": "84bca2f7b35f43248fca18d21abe2ebf", "date": "2024-06-12_02-58-12", "timestamp": 1718128692, "time_this_iter_s": 10.44594931602478, "time_total_s": 740.7393612861633, "pid": 363902, "hostname": "DESKTOP-LQ219J4", "node_ip": "192.168.46.185", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 20, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 5000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 500, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Base_Model", "custom_model_config": {"env": "rware", "env_args": {"n_agents": 4, "column_height": 1, "max_inactivity_steps": null, "max_steps": 500, "fast_obs": true, "msg_bits": 0, "sensor_range": 1, "shelf_rows": 1, "shelf_columns": 3, "request_queue_size": 4, "reward_type": "RewardType.INDIVIDUAL", "map_name": "customized_map", "map_size": "tiny", "difficulty": "medium"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": true, "force_coop": false, "local_mode": true, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 4, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 100, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64}, "algorithm": "ia2c", "space_obs": "Dict(obs:Box([-100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100.], [100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.], (112,), float32))", "space_act": "Discrete(5)", "num_agents": 4, "episode_limit": 500, "policy_mapping_info": {"all_scenario": {"description": "rware all scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2", "agent_3"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "rware_customized_map", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 10, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.IA2CTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_il.<locals>.<lambda> at 0x7f38280b24c0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "grad_clip": 40.0, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "microbatch_size": null}, "time_since_restore": 740.7393612861633, "timesteps_since_restore": 0, "iterations_since_restore": 72, "perf": {"cpu_util_percent": 5.38, "ram_util_percent": 52.91333333333333}}
{"episode_reward_max": 12.0, "episode_reward_min": 0.0, "episode_reward_mean": 4.01, "episode_len_mean": 500.0, "episode_media": {}, "episodes_this_iter": 20, "policy_reward_min": {"shared_policy": 0.0}, "policy_reward_max": {"shared_policy": 5.0}, "policy_reward_mean": {"shared_policy": 1.0025}, "custom_metrics": {}, "hist_stats": {"episode_reward": [2.0, 4.0, 3.0, 8.0, 5.0, 2.0, 4.0, 4.0, 6.0, 2.0, 4.0, 4.0, 5.0, 2.0, 2.0, 5.0, 3.0, 12.0, 8.0, 8.0, 3.0, 1.0, 0.0, 3.0, 5.0, 2.0, 5.0, 3.0, 4.0, 3.0, 3.0, 2.0, 1.0, 4.0, 7.0, 7.0, 4.0, 2.0, 2.0, 3.0, 3.0, 5.0, 5.0, 2.0, 3.0, 1.0, 3.0, 2.0, 5.0, 5.0, 6.0, 1.0, 2.0, 4.0, 1.0, 3.0, 2.0, 2.0, 9.0, 4.0, 6.0, 2.0, 4.0, 3.0, 5.0, 2.0, 8.0, 3.0, 2.0, 3.0, 4.0, 8.0, 7.0, 3.0, 3.0, 5.0, 9.0, 1.0, 3.0, 1.0, 2.0, 6.0, 5.0, 3.0, 7.0, 8.0, 3.0, 8.0, 2.0, 4.0, 7.0, 2.0, 8.0, 4.0, 1.0, 0.0, 7.0, 5.0, 10.0, 2.0], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500], "policy_shared_policy_reward": [0.0, 1.0, 1.0, 0.0, 2.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 2.0, 2.0, 3.0, 2.0, 1.0, 3.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 2.0, 1.0, 1.0, 0.0, 2.0, 1.0, 1.0, 2.0, 2.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 2.0, 1.0, 1.0, 2.0, 0.0, 1.0, 2.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 2.0, 0.0, 3.0, 0.0, 0.0, 2.0, 0.0, 2.0, 0.0, 1.0, 1.0, 5.0, 4.0, 2.0, 0.0, 2.0, 2.0, 4.0, 2.0, 3.0, 1.0, 2.0, 0.0, 0.0, 2.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 2.0, 1.0, 2.0, 0.0, 0.0, 1.0, 0.0, 1.0, 2.0, 2.0, 0.0, 1.0, 0.0, 2.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 2.0, 0.0, 2.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 2.0, 2.0, 2.0, 2.0, 2.0, 1.0, 2.0, 1.0, 2.0, 2.0, 1.0, 1.0, 0.0, 2.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 2.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 2.0, 0.0, 2.0, 2.0, 1.0, 0.0, 2.0, 1.0, 1.0, 0.0, 0.0, 0.0, 2.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 2.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0, 3.0, 1.0, 2.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 2.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 2.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 5.0, 1.0, 1.0, 2.0, 2.0, 0.0, 1.0, 1.0, 1.0, 1.0, 2.0, 2.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 2.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 2.0, 0.0, 1.0, 1.0, 0.0, 2.0, 1.0, 2.0, 3.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 3.0, 1.0, 3.0, 2.0, 1.0, 3.0, 1.0, 2.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 2.0, 2.0, 4.0, 1.0, 0.0, 4.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 2.0, 1.0, 2.0, 1.0, 2.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 3.0, 3.0, 0.0, 1.0, 2.0, 2.0, 3.0, 0.0, 1.0, 1.0, 1.0, 4.0, 2.0, 1.0, 1.0, 2.0, 0.0, 0.0, 0.0, 2.0, 0.0, 1.0, 1.0, 2.0, 1.0, 2.0, 2.0, 0.0, 0.0, 1.0, 1.0, 2.0, 1.0, 2.0, 3.0, 2.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.0, 2.0, 2.0, 0.0, 1.0, 1.0, 1.0, 2.0, 2.0, 2.0, 2.0, 4.0, 1.0, 0.0, 0.0, 1.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.1336135126090042, "mean_inference_ms": 0.3904192222710505, "mean_action_processing_ms": 0.0291853975084019, "mean_env_wait_ms": 0.4038371218402287, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 735840, "timesteps_this_iter": 0, "agent_timesteps_total": 2943360, "timers": {"sample_time_ms": 5139.638, "sample_throughput": 980.614, "load_time_ms": 0.162, "load_throughput": 31165107.121, "learn_time_ms": 132.682, "learn_throughput": 37985.419, "update_time_ms": 2.357}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 140.70172119140625, "policy_entropy": 7882.925048828125, "policy_loss": -5.934570789337158, "vf_loss": 33.55090665817261}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 735840, "num_agent_steps_sampled": 2943360, "num_steps_trained": 735840, "num_agent_steps_trained": 2943360, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 1468, "training_iteration": 73, "trial_id": "71426_00000", "experiment_id": "84bca2f7b35f43248fca18d21abe2ebf", "date": "2024-06-12_02-58-23", "timestamp": 1718128703, "time_this_iter_s": 10.275386810302734, "time_total_s": 751.0147480964661, "pid": 363902, "hostname": "DESKTOP-LQ219J4", "node_ip": "192.168.46.185", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 20, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 5000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 500, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Base_Model", "custom_model_config": {"env": "rware", "env_args": {"n_agents": 4, "column_height": 1, "max_inactivity_steps": null, "max_steps": 500, "fast_obs": true, "msg_bits": 0, "sensor_range": 1, "shelf_rows": 1, "shelf_columns": 3, "request_queue_size": 4, "reward_type": "RewardType.INDIVIDUAL", "map_name": "customized_map", "map_size": "tiny", "difficulty": "medium"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": true, "force_coop": false, "local_mode": true, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 4, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 100, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64}, "algorithm": "ia2c", "space_obs": "Dict(obs:Box([-100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100.], [100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.], (112,), float32))", "space_act": "Discrete(5)", "num_agents": 4, "episode_limit": 500, "policy_mapping_info": {"all_scenario": {"description": "rware all scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2", "agent_3"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "rware_customized_map", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 10, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.IA2CTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_il.<locals>.<lambda> at 0x7f380824d430>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "grad_clip": 40.0, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "microbatch_size": null}, "time_since_restore": 751.0147480964661, "timesteps_since_restore": 0, "iterations_since_restore": 73, "perf": {"cpu_util_percent": 4.678571428571429, "ram_util_percent": 53.29999999999999}}
{"episode_reward_max": 12.0, "episode_reward_min": 0.0, "episode_reward_mean": 4.09, "episode_len_mean": 500.0, "episode_media": {}, "episodes_this_iter": 20, "policy_reward_min": {"shared_policy": 0.0}, "policy_reward_max": {"shared_policy": 5.0}, "policy_reward_mean": {"shared_policy": 1.0225}, "custom_metrics": {}, "hist_stats": {"episode_reward": [3.0, 1.0, 0.0, 3.0, 5.0, 2.0, 5.0, 3.0, 4.0, 3.0, 3.0, 2.0, 1.0, 4.0, 7.0, 7.0, 4.0, 2.0, 2.0, 3.0, 3.0, 5.0, 5.0, 2.0, 3.0, 1.0, 3.0, 2.0, 5.0, 5.0, 6.0, 1.0, 2.0, 4.0, 1.0, 3.0, 2.0, 2.0, 9.0, 4.0, 6.0, 2.0, 4.0, 3.0, 5.0, 2.0, 8.0, 3.0, 2.0, 3.0, 4.0, 8.0, 7.0, 3.0, 3.0, 5.0, 9.0, 1.0, 3.0, 1.0, 2.0, 6.0, 5.0, 3.0, 7.0, 8.0, 3.0, 8.0, 2.0, 4.0, 7.0, 2.0, 8.0, 4.0, 1.0, 0.0, 7.0, 5.0, 10.0, 2.0, 4.0, 5.0, 4.0, 5.0, 12.0, 6.0, 4.0, 0.0, 2.0, 11.0, 5.0, 3.0, 6.0, 3.0, 2.0, 5.0, 10.0, 4.0, 5.0, 5.0], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500], "policy_shared_policy_reward": [0.0, 0.0, 2.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 2.0, 1.0, 2.0, 0.0, 0.0, 1.0, 0.0, 1.0, 2.0, 2.0, 0.0, 1.0, 0.0, 2.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 2.0, 0.0, 2.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 2.0, 2.0, 2.0, 2.0, 2.0, 1.0, 2.0, 1.0, 2.0, 2.0, 1.0, 1.0, 0.0, 2.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 2.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 2.0, 0.0, 2.0, 2.0, 1.0, 0.0, 2.0, 1.0, 1.0, 0.0, 0.0, 0.0, 2.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 2.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0, 3.0, 1.0, 2.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 2.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 2.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 5.0, 1.0, 1.0, 2.0, 2.0, 0.0, 1.0, 1.0, 1.0, 1.0, 2.0, 2.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 2.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 2.0, 0.0, 1.0, 1.0, 0.0, 2.0, 1.0, 2.0, 3.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 3.0, 1.0, 3.0, 2.0, 1.0, 3.0, 1.0, 2.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 2.0, 2.0, 4.0, 1.0, 0.0, 4.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 2.0, 1.0, 2.0, 1.0, 2.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 3.0, 3.0, 0.0, 1.0, 2.0, 2.0, 3.0, 0.0, 1.0, 1.0, 1.0, 4.0, 2.0, 1.0, 1.0, 2.0, 0.0, 0.0, 0.0, 2.0, 0.0, 1.0, 1.0, 2.0, 1.0, 2.0, 2.0, 0.0, 0.0, 1.0, 1.0, 2.0, 1.0, 2.0, 3.0, 2.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.0, 2.0, 2.0, 0.0, 1.0, 1.0, 1.0, 2.0, 2.0, 2.0, 2.0, 4.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 2.0, 0.0, 3.0, 2.0, 1.0, 1.0, 0.0, 2.0, 1.0, 2.0, 0.0, 1.0, 4.0, 3.0, 4.0, 1.0, 2.0, 2.0, 1.0, 1.0, 1.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 2.0, 3.0, 2.0, 4.0, 1.0, 2.0, 0.0, 2.0, 1.0, 0.0, 1.0, 1.0, 1.0, 2.0, 2.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 2.0, 1.0, 1.0, 1.0, 2.0, 3.0, 2.0, 3.0, 1.0, 2.0, 1.0, 0.0, 2.0, 1.0, 1.0, 1.0, 1.0, 1.0, 2.0, 1.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.13361985895511008, "mean_inference_ms": 0.3904394459289119, "mean_action_processing_ms": 0.02918459612866352, "mean_env_wait_ms": 0.4038591431066141, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 745920, "timesteps_this_iter": 0, "agent_timesteps_total": 2983680, "timers": {"sample_time_ms": 5146.935, "sample_throughput": 979.223, "load_time_ms": 0.165, "load_throughput": 30614470.905, "learn_time_ms": 134.956, "learn_throughput": 37345.544, "update_time_ms": 2.383}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 484.09381103515625, "policy_entropy": 7840.58740234375, "policy_loss": 86.60505199432373, "vf_loss": 52.741915225982666}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 745920, "num_agent_steps_sampled": 2983680, "num_steps_trained": 745920, "num_agent_steps_trained": 2983680, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 1488, "training_iteration": 74, "trial_id": "71426_00000", "experiment_id": "84bca2f7b35f43248fca18d21abe2ebf", "date": "2024-06-12_02-58-33", "timestamp": 1718128713, "time_this_iter_s": 10.206002712249756, "time_total_s": 761.2207508087158, "pid": 363902, "hostname": "DESKTOP-LQ219J4", "node_ip": "192.168.46.185", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 20, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 5000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 500, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Base_Model", "custom_model_config": {"env": "rware", "env_args": {"n_agents": 4, "column_height": 1, "max_inactivity_steps": null, "max_steps": 500, "fast_obs": true, "msg_bits": 0, "sensor_range": 1, "shelf_rows": 1, "shelf_columns": 3, "request_queue_size": 4, "reward_type": "RewardType.INDIVIDUAL", "map_name": "customized_map", "map_size": "tiny", "difficulty": "medium"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": true, "force_coop": false, "local_mode": true, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 4, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 100, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64}, "algorithm": "ia2c", "space_obs": "Dict(obs:Box([-100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100.], [100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.], (112,), float32))", "space_act": "Discrete(5)", "num_agents": 4, "episode_limit": 500, "policy_mapping_info": {"all_scenario": {"description": "rware all scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2", "agent_3"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "rware_customized_map", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 10, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.IA2CTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_il.<locals>.<lambda> at 0x7f38280b2160>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "grad_clip": 40.0, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "microbatch_size": null}, "time_since_restore": 761.2207508087158, "timesteps_since_restore": 0, "iterations_since_restore": 74, "perf": {"cpu_util_percent": 4.593333333333333, "ram_util_percent": 53.56666666666668}}
{"episode_reward_max": 12.0, "episode_reward_min": 0.0, "episode_reward_mean": 4.37, "episode_len_mean": 500.0, "episode_media": {}, "episodes_this_iter": 24, "policy_reward_min": {"shared_policy": 0.0}, "policy_reward_max": {"shared_policy": 5.0}, "policy_reward_mean": {"shared_policy": 1.0925}, "custom_metrics": {}, "hist_stats": {"episode_reward": [3.0, 1.0, 3.0, 2.0, 5.0, 5.0, 6.0, 1.0, 2.0, 4.0, 1.0, 3.0, 2.0, 2.0, 9.0, 4.0, 6.0, 2.0, 4.0, 3.0, 5.0, 2.0, 8.0, 3.0, 2.0, 3.0, 4.0, 8.0, 7.0, 3.0, 3.0, 5.0, 9.0, 1.0, 3.0, 1.0, 2.0, 6.0, 5.0, 3.0, 7.0, 8.0, 3.0, 8.0, 2.0, 4.0, 7.0, 2.0, 8.0, 4.0, 1.0, 0.0, 7.0, 5.0, 10.0, 2.0, 4.0, 5.0, 4.0, 5.0, 12.0, 6.0, 4.0, 0.0, 2.0, 11.0, 5.0, 3.0, 6.0, 3.0, 2.0, 5.0, 10.0, 4.0, 5.0, 5.0, 9.0, 6.0, 2.0, 6.0, 9.0, 9.0, 8.0, 7.0, 1.0, 5.0, 3.0, 2.0, 1.0, 8.0, 1.0, 2.0, 3.0, 3.0, 2.0, 3.0, 2.0, 6.0, 6.0, 3.0], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500], "policy_shared_policy_reward": [0.0, 2.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 2.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0, 3.0, 1.0, 2.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 2.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 2.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 5.0, 1.0, 1.0, 2.0, 2.0, 0.0, 1.0, 1.0, 1.0, 1.0, 2.0, 2.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 2.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 2.0, 0.0, 1.0, 1.0, 0.0, 2.0, 1.0, 2.0, 3.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 3.0, 1.0, 3.0, 2.0, 1.0, 3.0, 1.0, 2.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 2.0, 2.0, 4.0, 1.0, 0.0, 4.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 2.0, 1.0, 2.0, 1.0, 2.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 3.0, 3.0, 0.0, 1.0, 2.0, 2.0, 3.0, 0.0, 1.0, 1.0, 1.0, 4.0, 2.0, 1.0, 1.0, 2.0, 0.0, 0.0, 0.0, 2.0, 0.0, 1.0, 1.0, 2.0, 1.0, 2.0, 2.0, 0.0, 0.0, 1.0, 1.0, 2.0, 1.0, 2.0, 3.0, 2.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.0, 2.0, 2.0, 0.0, 1.0, 1.0, 1.0, 2.0, 2.0, 2.0, 2.0, 4.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 2.0, 0.0, 3.0, 2.0, 1.0, 1.0, 0.0, 2.0, 1.0, 2.0, 0.0, 1.0, 4.0, 3.0, 4.0, 1.0, 2.0, 2.0, 1.0, 1.0, 1.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 2.0, 3.0, 2.0, 4.0, 1.0, 2.0, 0.0, 2.0, 1.0, 0.0, 1.0, 1.0, 1.0, 2.0, 2.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 2.0, 1.0, 1.0, 1.0, 2.0, 3.0, 2.0, 3.0, 1.0, 2.0, 1.0, 0.0, 2.0, 1.0, 1.0, 1.0, 1.0, 1.0, 2.0, 1.0, 2.0, 3.0, 2.0, 2.0, 1.0, 1.0, 3.0, 1.0, 0.0, 0.0, 1.0, 1.0, 2.0, 1.0, 1.0, 2.0, 1.0, 3.0, 2.0, 3.0, 2.0, 1.0, 3.0, 3.0, 2.0, 3.0, 1.0, 2.0, 2.0, 2.0, 0.0, 3.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 2.0, 1.0, 3.0, 2.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 2.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 2.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 3.0, 1.0, 1.0, 3.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.1336233414573953, "mean_inference_ms": 0.3904589879434292, "mean_action_processing_ms": 0.029183391047480703, "mean_env_wait_ms": 0.4038778450206483, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 756000, "timesteps_this_iter": 0, "agent_timesteps_total": 3024000, "timers": {"sample_time_ms": 5164.135, "sample_throughput": 975.962, "load_time_ms": 0.167, "load_throughput": 30263839.885, "learn_time_ms": 135.851, "learn_throughput": 37099.352, "update_time_ms": 2.406}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 192.25082397460938, "policy_entropy": 7821.39306640625, "policy_loss": 1.5162765979766846, "vf_loss": 32.7365026473999}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 756000, "num_agent_steps_sampled": 3024000, "num_steps_trained": 756000, "num_agent_steps_trained": 3024000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 1512, "training_iteration": 75, "trial_id": "71426_00000", "experiment_id": "84bca2f7b35f43248fca18d21abe2ebf", "date": "2024-06-12_02-58-43", "timestamp": 1718128723, "time_this_iter_s": 10.373265504837036, "time_total_s": 771.5940163135529, "pid": 363902, "hostname": "DESKTOP-LQ219J4", "node_ip": "192.168.46.185", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 20, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 5000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 500, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Base_Model", "custom_model_config": {"env": "rware", "env_args": {"n_agents": 4, "column_height": 1, "max_inactivity_steps": null, "max_steps": 500, "fast_obs": true, "msg_bits": 0, "sensor_range": 1, "shelf_rows": 1, "shelf_columns": 3, "request_queue_size": 4, "reward_type": "RewardType.INDIVIDUAL", "map_name": "customized_map", "map_size": "tiny", "difficulty": "medium"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": true, "force_coop": false, "local_mode": true, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 4, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 100, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64}, "algorithm": "ia2c", "space_obs": "Dict(obs:Box([-100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100.], [100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.], (112,), float32))", "space_act": "Discrete(5)", "num_agents": 4, "episode_limit": 500, "policy_mapping_info": {"all_scenario": {"description": "rware all scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2", "agent_3"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "rware_customized_map", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 10, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.IA2CTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_il.<locals>.<lambda> at 0x7f380824d550>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "grad_clip": 40.0, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "microbatch_size": null}, "time_since_restore": 771.5940163135529, "timesteps_since_restore": 0, "iterations_since_restore": 75, "perf": {"cpu_util_percent": 5.0200000000000005, "ram_util_percent": 53.69333333333335}}
{"episode_reward_max": 12.0, "episode_reward_min": 0.0, "episode_reward_mean": 4.75, "episode_len_mean": 500.0, "episode_media": {}, "episodes_this_iter": 20, "policy_reward_min": {"shared_policy": 0.0}, "policy_reward_max": {"shared_policy": 4.0}, "policy_reward_mean": {"shared_policy": 1.1875}, "custom_metrics": {}, "hist_stats": {"episode_reward": [5.0, 2.0, 8.0, 3.0, 2.0, 3.0, 4.0, 8.0, 7.0, 3.0, 3.0, 5.0, 9.0, 1.0, 3.0, 1.0, 2.0, 6.0, 5.0, 3.0, 7.0, 8.0, 3.0, 8.0, 2.0, 4.0, 7.0, 2.0, 8.0, 4.0, 1.0, 0.0, 7.0, 5.0, 10.0, 2.0, 4.0, 5.0, 4.0, 5.0, 12.0, 6.0, 4.0, 0.0, 2.0, 11.0, 5.0, 3.0, 6.0, 3.0, 2.0, 5.0, 10.0, 4.0, 5.0, 5.0, 9.0, 6.0, 2.0, 6.0, 9.0, 9.0, 8.0, 7.0, 1.0, 5.0, 3.0, 2.0, 1.0, 8.0, 1.0, 2.0, 3.0, 3.0, 2.0, 3.0, 2.0, 6.0, 6.0, 3.0, 9.0, 7.0, 6.0, 9.0, 4.0, 9.0, 8.0, 3.0, 5.0, 1.0, 4.0, 4.0, 3.0, 5.0, 4.0, 5.0, 2.0, 5.0, 7.0, 6.0], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500], "policy_shared_policy_reward": [1.0, 1.0, 1.0, 2.0, 0.0, 1.0, 1.0, 0.0, 2.0, 1.0, 2.0, 3.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 3.0, 1.0, 3.0, 2.0, 1.0, 3.0, 1.0, 2.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 2.0, 2.0, 4.0, 1.0, 0.0, 4.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 2.0, 1.0, 2.0, 1.0, 2.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 3.0, 3.0, 0.0, 1.0, 2.0, 2.0, 3.0, 0.0, 1.0, 1.0, 1.0, 4.0, 2.0, 1.0, 1.0, 2.0, 0.0, 0.0, 0.0, 2.0, 0.0, 1.0, 1.0, 2.0, 1.0, 2.0, 2.0, 0.0, 0.0, 1.0, 1.0, 2.0, 1.0, 2.0, 3.0, 2.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.0, 2.0, 2.0, 0.0, 1.0, 1.0, 1.0, 2.0, 2.0, 2.0, 2.0, 4.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 2.0, 0.0, 3.0, 2.0, 1.0, 1.0, 0.0, 2.0, 1.0, 2.0, 0.0, 1.0, 4.0, 3.0, 4.0, 1.0, 2.0, 2.0, 1.0, 1.0, 1.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 2.0, 3.0, 2.0, 4.0, 1.0, 2.0, 0.0, 2.0, 1.0, 0.0, 1.0, 1.0, 1.0, 2.0, 2.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 2.0, 1.0, 1.0, 1.0, 2.0, 3.0, 2.0, 3.0, 1.0, 2.0, 1.0, 0.0, 2.0, 1.0, 1.0, 1.0, 1.0, 1.0, 2.0, 1.0, 2.0, 3.0, 2.0, 2.0, 1.0, 1.0, 3.0, 1.0, 0.0, 0.0, 1.0, 1.0, 2.0, 1.0, 1.0, 2.0, 1.0, 3.0, 2.0, 3.0, 2.0, 1.0, 3.0, 3.0, 2.0, 3.0, 1.0, 2.0, 2.0, 2.0, 0.0, 3.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 2.0, 1.0, 3.0, 2.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 2.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 2.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 3.0, 1.0, 1.0, 3.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 3.0, 3.0, 2.0, 1.0, 1.0, 2.0, 3.0, 1.0, 2.0, 0.0, 2.0, 2.0, 1.0, 2.0, 2.0, 4.0, 0.0, 1.0, 2.0, 1.0, 4.0, 2.0, 2.0, 1.0, 2.0, 2.0, 3.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 3.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 2.0, 1.0, 0.0, 1.0, 0.0, 2.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 2.0, 2.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 2.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 2.0, 1.0, 1.0, 3.0, 1.0, 2.0, 1.0, 1.0, 1.0, 3.0, 1.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.13362881410774752, "mean_inference_ms": 0.39047998647443793, "mean_action_processing_ms": 0.02918481576064401, "mean_env_wait_ms": 0.40389620262067555, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 766080, "timesteps_this_iter": 0, "agent_timesteps_total": 3064320, "timers": {"sample_time_ms": 5158.476, "sample_throughput": 977.033, "load_time_ms": 0.169, "load_throughput": 29744325.538, "learn_time_ms": 136.485, "learn_throughput": 36927.224, "update_time_ms": 2.443}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 238.28610229492188, "policy_entropy": 7853.555419921875, "policy_loss": 16.223577439785004, "vf_loss": 32.004183769226074}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 766080, "num_agent_steps_sampled": 3064320, "num_steps_trained": 766080, "num_agent_steps_trained": 3064320, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 1532, "training_iteration": 76, "trial_id": "71426_00000", "experiment_id": "84bca2f7b35f43248fca18d21abe2ebf", "date": "2024-06-12_02-58-54", "timestamp": 1718128734, "time_this_iter_s": 10.213998079299927, "time_total_s": 781.8080143928528, "pid": 363902, "hostname": "DESKTOP-LQ219J4", "node_ip": "192.168.46.185", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 20, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 5000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 500, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Base_Model", "custom_model_config": {"env": "rware", "env_args": {"n_agents": 4, "column_height": 1, "max_inactivity_steps": null, "max_steps": 500, "fast_obs": true, "msg_bits": 0, "sensor_range": 1, "shelf_rows": 1, "shelf_columns": 3, "request_queue_size": 4, "reward_type": "RewardType.INDIVIDUAL", "map_name": "customized_map", "map_size": "tiny", "difficulty": "medium"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": true, "force_coop": false, "local_mode": true, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 4, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 100, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64}, "algorithm": "ia2c", "space_obs": "Dict(obs:Box([-100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100.], [100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.], (112,), float32))", "space_act": "Discrete(5)", "num_agents": 4, "episode_limit": 500, "policy_mapping_info": {"all_scenario": {"description": "rware all scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2", "agent_3"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "rware_customized_map", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 10, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.IA2CTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_il.<locals>.<lambda> at 0x7f380824d790>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "grad_clip": 40.0, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "microbatch_size": null}, "time_since_restore": 781.8080143928528, "timesteps_since_restore": 0, "iterations_since_restore": 76, "perf": {"cpu_util_percent": 4.664285714285714, "ram_util_percent": 53.92142857142857}}
{"episode_reward_max": 12.0, "episode_reward_min": 0.0, "episode_reward_mean": 4.89, "episode_len_mean": 500.0, "episode_media": {}, "episodes_this_iter": 20, "policy_reward_min": {"shared_policy": 0.0}, "policy_reward_max": {"shared_policy": 4.0}, "policy_reward_mean": {"shared_policy": 1.2225}, "custom_metrics": {}, "hist_stats": {"episode_reward": [7.0, 8.0, 3.0, 8.0, 2.0, 4.0, 7.0, 2.0, 8.0, 4.0, 1.0, 0.0, 7.0, 5.0, 10.0, 2.0, 4.0, 5.0, 4.0, 5.0, 12.0, 6.0, 4.0, 0.0, 2.0, 11.0, 5.0, 3.0, 6.0, 3.0, 2.0, 5.0, 10.0, 4.0, 5.0, 5.0, 9.0, 6.0, 2.0, 6.0, 9.0, 9.0, 8.0, 7.0, 1.0, 5.0, 3.0, 2.0, 1.0, 8.0, 1.0, 2.0, 3.0, 3.0, 2.0, 3.0, 2.0, 6.0, 6.0, 3.0, 9.0, 7.0, 6.0, 9.0, 4.0, 9.0, 8.0, 3.0, 5.0, 1.0, 4.0, 4.0, 3.0, 5.0, 4.0, 5.0, 2.0, 5.0, 7.0, 6.0, 3.0, 5.0, 5.0, 4.0, 9.0, 0.0, 7.0, 8.0, 4.0, 2.0, 3.0, 10.0, 5.0, 4.0, 3.0, 5.0, 6.0, 3.0, 7.0, 4.0], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500], "policy_shared_policy_reward": [1.0, 3.0, 3.0, 0.0, 1.0, 2.0, 2.0, 3.0, 0.0, 1.0, 1.0, 1.0, 4.0, 2.0, 1.0, 1.0, 2.0, 0.0, 0.0, 0.0, 2.0, 0.0, 1.0, 1.0, 2.0, 1.0, 2.0, 2.0, 0.0, 0.0, 1.0, 1.0, 2.0, 1.0, 2.0, 3.0, 2.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.0, 2.0, 2.0, 0.0, 1.0, 1.0, 1.0, 2.0, 2.0, 2.0, 2.0, 4.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 2.0, 0.0, 3.0, 2.0, 1.0, 1.0, 0.0, 2.0, 1.0, 2.0, 0.0, 1.0, 4.0, 3.0, 4.0, 1.0, 2.0, 2.0, 1.0, 1.0, 1.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 2.0, 3.0, 2.0, 4.0, 1.0, 2.0, 0.0, 2.0, 1.0, 0.0, 1.0, 1.0, 1.0, 2.0, 2.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 2.0, 1.0, 1.0, 1.0, 2.0, 3.0, 2.0, 3.0, 1.0, 2.0, 1.0, 0.0, 2.0, 1.0, 1.0, 1.0, 1.0, 1.0, 2.0, 1.0, 2.0, 3.0, 2.0, 2.0, 1.0, 1.0, 3.0, 1.0, 0.0, 0.0, 1.0, 1.0, 2.0, 1.0, 1.0, 2.0, 1.0, 3.0, 2.0, 3.0, 2.0, 1.0, 3.0, 3.0, 2.0, 3.0, 1.0, 2.0, 2.0, 2.0, 0.0, 3.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 2.0, 1.0, 3.0, 2.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 2.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 2.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 3.0, 1.0, 1.0, 3.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 3.0, 3.0, 2.0, 1.0, 1.0, 2.0, 3.0, 1.0, 2.0, 0.0, 2.0, 2.0, 1.0, 2.0, 2.0, 4.0, 0.0, 1.0, 2.0, 1.0, 4.0, 2.0, 2.0, 1.0, 2.0, 2.0, 3.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 3.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 2.0, 1.0, 0.0, 1.0, 0.0, 2.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 2.0, 2.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 2.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 2.0, 1.0, 1.0, 3.0, 1.0, 2.0, 1.0, 1.0, 1.0, 3.0, 1.0, 1.0, 0.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0, 1.0, 1.0, 2.0, 1.0, 0.0, 3.0, 0.0, 1.0, 2.0, 2.0, 4.0, 1.0, 0.0, 0.0, 0.0, 0.0, 2.0, 1.0, 3.0, 1.0, 3.0, 1.0, 3.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 4.0, 2.0, 2.0, 2.0, 3.0, 2.0, 0.0, 0.0, 0.0, 1.0, 2.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 2.0, 1.0, 1.0, 2.0, 1.0, 1.0, 2.0, 0.0, 2.0, 1.0, 0.0, 1.0, 1.0, 2.0, 3.0, 1.0, 1.0, 0.0, 2.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.13362992761875506, "mean_inference_ms": 0.39048699439924783, "mean_action_processing_ms": 0.02918771743753572, "mean_env_wait_ms": 0.40392005606297315, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 776160, "timesteps_this_iter": 0, "agent_timesteps_total": 3104640, "timers": {"sample_time_ms": 5143.756, "sample_throughput": 979.829, "load_time_ms": 0.167, "load_throughput": 30125826.08, "learn_time_ms": 133.03, "learn_throughput": 37886.188, "update_time_ms": 2.446}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 227.4494171142578, "policy_entropy": 7866.0162353515625, "policy_loss": -20.30023282766342, "vf_loss": 28.79060411453247}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 776160, "num_agent_steps_sampled": 3104640, "num_steps_trained": 776160, "num_agent_steps_trained": 3104640, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 1552, "training_iteration": 77, "trial_id": "71426_00000", "experiment_id": "84bca2f7b35f43248fca18d21abe2ebf", "date": "2024-06-12_02-59-04", "timestamp": 1718128744, "time_this_iter_s": 10.267654657363892, "time_total_s": 792.0756690502167, "pid": 363902, "hostname": "DESKTOP-LQ219J4", "node_ip": "192.168.46.185", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 20, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 5000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 500, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Base_Model", "custom_model_config": {"env": "rware", "env_args": {"n_agents": 4, "column_height": 1, "max_inactivity_steps": null, "max_steps": 500, "fast_obs": true, "msg_bits": 0, "sensor_range": 1, "shelf_rows": 1, "shelf_columns": 3, "request_queue_size": 4, "reward_type": "RewardType.INDIVIDUAL", "map_name": "customized_map", "map_size": "tiny", "difficulty": "medium"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": true, "force_coop": false, "local_mode": true, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 4, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 100, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64}, "algorithm": "ia2c", "space_obs": "Dict(obs:Box([-100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100.], [100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.], (112,), float32))", "space_act": "Discrete(5)", "num_agents": 4, "episode_limit": 500, "policy_mapping_info": {"all_scenario": {"description": "rware all scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2", "agent_3"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "rware_customized_map", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 10, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.IA2CTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_il.<locals>.<lambda> at 0x7f38082f8ee0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "grad_clip": 40.0, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "microbatch_size": null}, "time_since_restore": 792.0756690502167, "timesteps_since_restore": 0, "iterations_since_restore": 77, "perf": {"cpu_util_percent": 4.680000000000001, "ram_util_percent": 54.013333333333335}}
{"episode_reward_max": 13.0, "episode_reward_min": 0.0, "episode_reward_mean": 4.96, "episode_len_mean": 500.0, "episode_media": {}, "episodes_this_iter": 20, "policy_reward_min": {"shared_policy": 0.0}, "policy_reward_max": {"shared_policy": 5.0}, "policy_reward_mean": {"shared_policy": 1.24}, "custom_metrics": {}, "hist_stats": {"episode_reward": [12.0, 6.0, 4.0, 0.0, 2.0, 11.0, 5.0, 3.0, 6.0, 3.0, 2.0, 5.0, 10.0, 4.0, 5.0, 5.0, 9.0, 6.0, 2.0, 6.0, 9.0, 9.0, 8.0, 7.0, 1.0, 5.0, 3.0, 2.0, 1.0, 8.0, 1.0, 2.0, 3.0, 3.0, 2.0, 3.0, 2.0, 6.0, 6.0, 3.0, 9.0, 7.0, 6.0, 9.0, 4.0, 9.0, 8.0, 3.0, 5.0, 1.0, 4.0, 4.0, 3.0, 5.0, 4.0, 5.0, 2.0, 5.0, 7.0, 6.0, 3.0, 5.0, 5.0, 4.0, 9.0, 0.0, 7.0, 8.0, 4.0, 2.0, 3.0, 10.0, 5.0, 4.0, 3.0, 5.0, 6.0, 3.0, 7.0, 4.0, 4.0, 2.0, 8.0, 4.0, 9.0, 4.0, 8.0, 4.0, 13.0, 3.0, 2.0, 5.0, 4.0, 4.0, 4.0, 4.0, 2.0, 9.0, 5.0, 5.0], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500], "policy_shared_policy_reward": [1.0, 4.0, 3.0, 4.0, 1.0, 2.0, 2.0, 1.0, 1.0, 1.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 2.0, 3.0, 2.0, 4.0, 1.0, 2.0, 0.0, 2.0, 1.0, 0.0, 1.0, 1.0, 1.0, 2.0, 2.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 2.0, 1.0, 1.0, 1.0, 2.0, 3.0, 2.0, 3.0, 1.0, 2.0, 1.0, 0.0, 2.0, 1.0, 1.0, 1.0, 1.0, 1.0, 2.0, 1.0, 2.0, 3.0, 2.0, 2.0, 1.0, 1.0, 3.0, 1.0, 0.0, 0.0, 1.0, 1.0, 2.0, 1.0, 1.0, 2.0, 1.0, 3.0, 2.0, 3.0, 2.0, 1.0, 3.0, 3.0, 2.0, 3.0, 1.0, 2.0, 2.0, 2.0, 0.0, 3.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 2.0, 1.0, 3.0, 2.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 2.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 2.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 3.0, 1.0, 1.0, 3.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 3.0, 3.0, 2.0, 1.0, 1.0, 2.0, 3.0, 1.0, 2.0, 0.0, 2.0, 2.0, 1.0, 2.0, 2.0, 4.0, 0.0, 1.0, 2.0, 1.0, 4.0, 2.0, 2.0, 1.0, 2.0, 2.0, 3.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 3.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 2.0, 1.0, 0.0, 1.0, 0.0, 2.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 2.0, 2.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 2.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 2.0, 1.0, 1.0, 3.0, 1.0, 2.0, 1.0, 1.0, 1.0, 3.0, 1.0, 1.0, 0.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0, 1.0, 1.0, 2.0, 1.0, 0.0, 3.0, 0.0, 1.0, 2.0, 2.0, 4.0, 1.0, 0.0, 0.0, 0.0, 0.0, 2.0, 1.0, 3.0, 1.0, 3.0, 1.0, 3.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 4.0, 2.0, 2.0, 2.0, 3.0, 2.0, 0.0, 0.0, 0.0, 1.0, 2.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 2.0, 1.0, 1.0, 2.0, 1.0, 1.0, 2.0, 0.0, 2.0, 1.0, 0.0, 1.0, 1.0, 2.0, 3.0, 1.0, 1.0, 0.0, 2.0, 0.0, 2.0, 0.0, 2.0, 1.0, 1.0, 0.0, 0.0, 1.0, 2.0, 4.0, 1.0, 1.0, 1.0, 1.0, 1.0, 2.0, 3.0, 2.0, 2.0, 1.0, 1.0, 1.0, 1.0, 1.0, 3.0, 2.0, 2.0, 1.0, 2.0, 0.0, 1.0, 5.0, 4.0, 1.0, 3.0, 2.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 2.0, 1.0, 1.0, 1.0, 2.0, 0.0, 1.0, 1.0, 1.0, 1.0, 2.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 2.0, 2.0, 3.0, 2.0, 1.0, 2.0, 2.0, 0.0, 3.0, 0.0, 1.0, 1.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.13364291016685445, "mean_inference_ms": 0.3905249971829501, "mean_action_processing_ms": 0.029193016266186103, "mean_env_wait_ms": 0.403966837149133, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 786240, "timesteps_this_iter": 0, "agent_timesteps_total": 3144960, "timers": {"sample_time_ms": 5171.498, "sample_throughput": 974.573, "load_time_ms": 0.163, "load_throughput": 30937058.627, "learn_time_ms": 130.607, "learn_throughput": 38589.075, "update_time_ms": 2.468}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 269.04156494140625, "policy_entropy": 7761.597900390625, "policy_loss": 38.86395215988159, "vf_loss": 41.32082939147949}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 786240, "num_agent_steps_sampled": 3144960, "num_steps_trained": 786240, "num_agent_steps_trained": 3144960, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 1572, "training_iteration": 78, "trial_id": "71426_00000", "experiment_id": "84bca2f7b35f43248fca18d21abe2ebf", "date": "2024-06-12_02-59-14", "timestamp": 1718128754, "time_this_iter_s": 10.55294942855835, "time_total_s": 802.628618478775, "pid": 363902, "hostname": "DESKTOP-LQ219J4", "node_ip": "192.168.46.185", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 20, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 5000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 500, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Base_Model", "custom_model_config": {"env": "rware", "env_args": {"n_agents": 4, "column_height": 1, "max_inactivity_steps": null, "max_steps": 500, "fast_obs": true, "msg_bits": 0, "sensor_range": 1, "shelf_rows": 1, "shelf_columns": 3, "request_queue_size": 4, "reward_type": "RewardType.INDIVIDUAL", "map_name": "customized_map", "map_size": "tiny", "difficulty": "medium"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": true, "force_coop": false, "local_mode": true, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 4, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 100, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64}, "algorithm": "ia2c", "space_obs": "Dict(obs:Box([-100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100.], [100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.], (112,), float32))", "space_act": "Discrete(5)", "num_agents": 4, "episode_limit": 500, "policy_mapping_info": {"all_scenario": {"description": "rware all scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2", "agent_3"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "rware_customized_map", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 10, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.IA2CTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_il.<locals>.<lambda> at 0x7f380824d430>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "grad_clip": 40.0, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "microbatch_size": null}, "time_since_restore": 802.628618478775, "timesteps_since_restore": 0, "iterations_since_restore": 78, "perf": {"cpu_util_percent": 4.66, "ram_util_percent": 54.43333333333332}}
{"episode_reward_max": 13.0, "episode_reward_min": 0.0, "episode_reward_mean": 5.03, "episode_len_mean": 500.0, "episode_media": {}, "episodes_this_iter": 20, "policy_reward_min": {"shared_policy": 0.0}, "policy_reward_max": {"shared_policy": 5.0}, "policy_reward_mean": {"shared_policy": 1.2575}, "custom_metrics": {}, "hist_stats": {"episode_reward": [9.0, 9.0, 8.0, 7.0, 1.0, 5.0, 3.0, 2.0, 1.0, 8.0, 1.0, 2.0, 3.0, 3.0, 2.0, 3.0, 2.0, 6.0, 6.0, 3.0, 9.0, 7.0, 6.0, 9.0, 4.0, 9.0, 8.0, 3.0, 5.0, 1.0, 4.0, 4.0, 3.0, 5.0, 4.0, 5.0, 2.0, 5.0, 7.0, 6.0, 3.0, 5.0, 5.0, 4.0, 9.0, 0.0, 7.0, 8.0, 4.0, 2.0, 3.0, 10.0, 5.0, 4.0, 3.0, 5.0, 6.0, 3.0, 7.0, 4.0, 4.0, 2.0, 8.0, 4.0, 9.0, 4.0, 8.0, 4.0, 13.0, 3.0, 2.0, 5.0, 4.0, 4.0, 4.0, 4.0, 2.0, 9.0, 5.0, 5.0, 7.0, 11.0, 4.0, 12.0, 8.0, 3.0, 2.0, 6.0, 5.0, 6.0, 3.0, 5.0, 7.0, 9.0, 6.0, 2.0, 5.0, 5.0, 5.0, 2.0], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500], "policy_shared_policy_reward": [1.0, 3.0, 2.0, 3.0, 2.0, 1.0, 3.0, 3.0, 2.0, 3.0, 1.0, 2.0, 2.0, 2.0, 0.0, 3.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 2.0, 1.0, 3.0, 2.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 2.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 2.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 3.0, 1.0, 1.0, 3.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 3.0, 3.0, 2.0, 1.0, 1.0, 2.0, 3.0, 1.0, 2.0, 0.0, 2.0, 2.0, 1.0, 2.0, 2.0, 4.0, 0.0, 1.0, 2.0, 1.0, 4.0, 2.0, 2.0, 1.0, 2.0, 2.0, 3.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 3.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 2.0, 1.0, 0.0, 1.0, 0.0, 2.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 2.0, 2.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 2.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 2.0, 1.0, 1.0, 3.0, 1.0, 2.0, 1.0, 1.0, 1.0, 3.0, 1.0, 1.0, 0.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0, 1.0, 1.0, 2.0, 1.0, 0.0, 3.0, 0.0, 1.0, 2.0, 2.0, 4.0, 1.0, 0.0, 0.0, 0.0, 0.0, 2.0, 1.0, 3.0, 1.0, 3.0, 1.0, 3.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 4.0, 2.0, 2.0, 2.0, 3.0, 2.0, 0.0, 0.0, 0.0, 1.0, 2.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 2.0, 1.0, 1.0, 2.0, 1.0, 1.0, 2.0, 0.0, 2.0, 1.0, 0.0, 1.0, 1.0, 2.0, 3.0, 1.0, 1.0, 0.0, 2.0, 0.0, 2.0, 0.0, 2.0, 1.0, 1.0, 0.0, 0.0, 1.0, 2.0, 4.0, 1.0, 1.0, 1.0, 1.0, 1.0, 2.0, 3.0, 2.0, 2.0, 1.0, 1.0, 1.0, 1.0, 1.0, 3.0, 2.0, 2.0, 1.0, 2.0, 0.0, 1.0, 5.0, 4.0, 1.0, 3.0, 2.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 2.0, 1.0, 1.0, 1.0, 2.0, 0.0, 1.0, 1.0, 1.0, 1.0, 2.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 2.0, 2.0, 3.0, 2.0, 1.0, 2.0, 2.0, 0.0, 3.0, 0.0, 1.0, 1.0, 2.0, 2.0, 1.0, 2.0, 4.0, 1.0, 4.0, 2.0, 1.0, 1.0, 1.0, 1.0, 3.0, 5.0, 2.0, 2.0, 3.0, 1.0, 0.0, 4.0, 0.0, 0.0, 1.0, 2.0, 1.0, 1.0, 0.0, 0.0, 2.0, 2.0, 1.0, 1.0, 2.0, 1.0, 0.0, 2.0, 1.0, 2.0, 3.0, 0.0, 0.0, 1.0, 2.0, 0.0, 0.0, 3.0, 1.0, 1.0, 3.0, 1.0, 2.0, 1.0, 2.0, 1.0, 2.0, 4.0, 1.0, 1.0, 2.0, 2.0, 1.0, 0.0, 0.0, 1.0, 3.0, 1.0, 1.0, 0.0, 1.0, 1.0, 2.0, 1.0, 2.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.13366385190492655, "mean_inference_ms": 0.3905818663015006, "mean_action_processing_ms": 0.029198882209292884, "mean_env_wait_ms": 0.40401859338799995, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 796320, "timesteps_this_iter": 0, "agent_timesteps_total": 3185280, "timers": {"sample_time_ms": 5191.05, "sample_throughput": 970.902, "load_time_ms": 0.163, "load_throughput": 30982400.938, "learn_time_ms": 127.989, "learn_throughput": 39378.441, "update_time_ms": 2.464}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 193.22483825683594, "policy_entropy": 7658.1292724609375, "policy_loss": -1.671164631843567, "vf_loss": 42.78561496734619}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 796320, "num_agent_steps_sampled": 3185280, "num_steps_trained": 796320, "num_agent_steps_trained": 3185280, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 1592, "training_iteration": 79, "trial_id": "71426_00000", "experiment_id": "84bca2f7b35f43248fca18d21abe2ebf", "date": "2024-06-12_02-59-25", "timestamp": 1718128765, "time_this_iter_s": 10.395560503005981, "time_total_s": 813.024178981781, "pid": 363902, "hostname": "DESKTOP-LQ219J4", "node_ip": "192.168.46.185", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 20, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 5000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 500, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Base_Model", "custom_model_config": {"env": "rware", "env_args": {"n_agents": 4, "column_height": 1, "max_inactivity_steps": null, "max_steps": 500, "fast_obs": true, "msg_bits": 0, "sensor_range": 1, "shelf_rows": 1, "shelf_columns": 3, "request_queue_size": 4, "reward_type": "RewardType.INDIVIDUAL", "map_name": "customized_map", "map_size": "tiny", "difficulty": "medium"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": true, "force_coop": false, "local_mode": true, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 4, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 100, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64}, "algorithm": "ia2c", "space_obs": "Dict(obs:Box([-100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100.], [100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.], (112,), float32))", "space_act": "Discrete(5)", "num_agents": 4, "episode_limit": 500, "policy_mapping_info": {"all_scenario": {"description": "rware all scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2", "agent_3"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "rware_customized_map", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 10, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.IA2CTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_il.<locals>.<lambda> at 0x7f38086c1e50>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "grad_clip": 40.0, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "microbatch_size": null}, "time_since_restore": 813.024178981781, "timesteps_since_restore": 0, "iterations_since_restore": 79, "perf": {"cpu_util_percent": 4.473333333333333, "ram_util_percent": 54.66666666666668}}
{"episode_reward_max": 13.0, "episode_reward_min": 0.0, "episode_reward_mean": 5.13, "episode_len_mean": 500.0, "episode_media": {}, "episodes_this_iter": 20, "policy_reward_min": {"shared_policy": 0.0}, "policy_reward_max": {"shared_policy": 5.0}, "policy_reward_mean": {"shared_policy": 1.2825}, "custom_metrics": {}, "hist_stats": {"episode_reward": [9.0, 7.0, 6.0, 9.0, 4.0, 9.0, 8.0, 3.0, 5.0, 1.0, 4.0, 4.0, 3.0, 5.0, 4.0, 5.0, 2.0, 5.0, 7.0, 6.0, 3.0, 5.0, 5.0, 4.0, 9.0, 0.0, 7.0, 8.0, 4.0, 2.0, 3.0, 10.0, 5.0, 4.0, 3.0, 5.0, 6.0, 3.0, 7.0, 4.0, 4.0, 2.0, 8.0, 4.0, 9.0, 4.0, 8.0, 4.0, 13.0, 3.0, 2.0, 5.0, 4.0, 4.0, 4.0, 4.0, 2.0, 9.0, 5.0, 5.0, 7.0, 11.0, 4.0, 12.0, 8.0, 3.0, 2.0, 6.0, 5.0, 6.0, 3.0, 5.0, 7.0, 9.0, 6.0, 2.0, 5.0, 5.0, 5.0, 2.0, 5.0, 12.0, 2.0, 3.0, 7.0, 4.0, 7.0, 3.0, 9.0, 3.0, 3.0, 4.0, 4.0, 6.0, 2.0, 6.0, 5.0, 2.0, 3.0, 4.0], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500], "policy_shared_policy_reward": [3.0, 3.0, 2.0, 1.0, 1.0, 2.0, 3.0, 1.0, 2.0, 0.0, 2.0, 2.0, 1.0, 2.0, 2.0, 4.0, 0.0, 1.0, 2.0, 1.0, 4.0, 2.0, 2.0, 1.0, 2.0, 2.0, 3.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 3.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 2.0, 1.0, 0.0, 1.0, 0.0, 2.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 2.0, 2.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 2.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 2.0, 1.0, 1.0, 3.0, 1.0, 2.0, 1.0, 1.0, 1.0, 3.0, 1.0, 1.0, 0.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0, 1.0, 1.0, 2.0, 1.0, 0.0, 3.0, 0.0, 1.0, 2.0, 2.0, 4.0, 1.0, 0.0, 0.0, 0.0, 0.0, 2.0, 1.0, 3.0, 1.0, 3.0, 1.0, 3.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 4.0, 2.0, 2.0, 2.0, 3.0, 2.0, 0.0, 0.0, 0.0, 1.0, 2.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 2.0, 1.0, 1.0, 2.0, 1.0, 1.0, 2.0, 0.0, 2.0, 1.0, 0.0, 1.0, 1.0, 2.0, 3.0, 1.0, 1.0, 0.0, 2.0, 0.0, 2.0, 0.0, 2.0, 1.0, 1.0, 0.0, 0.0, 1.0, 2.0, 4.0, 1.0, 1.0, 1.0, 1.0, 1.0, 2.0, 3.0, 2.0, 2.0, 1.0, 1.0, 1.0, 1.0, 1.0, 3.0, 2.0, 2.0, 1.0, 2.0, 0.0, 1.0, 5.0, 4.0, 1.0, 3.0, 2.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 2.0, 1.0, 1.0, 1.0, 2.0, 0.0, 1.0, 1.0, 1.0, 1.0, 2.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 2.0, 2.0, 3.0, 2.0, 1.0, 2.0, 2.0, 0.0, 3.0, 0.0, 1.0, 1.0, 2.0, 2.0, 1.0, 2.0, 4.0, 1.0, 4.0, 2.0, 1.0, 1.0, 1.0, 1.0, 3.0, 5.0, 2.0, 2.0, 3.0, 1.0, 0.0, 4.0, 0.0, 0.0, 1.0, 2.0, 1.0, 1.0, 0.0, 0.0, 2.0, 2.0, 1.0, 1.0, 2.0, 1.0, 0.0, 2.0, 1.0, 2.0, 3.0, 0.0, 0.0, 1.0, 2.0, 0.0, 0.0, 3.0, 1.0, 1.0, 3.0, 1.0, 2.0, 1.0, 2.0, 1.0, 2.0, 4.0, 1.0, 1.0, 2.0, 2.0, 1.0, 0.0, 0.0, 1.0, 3.0, 1.0, 1.0, 0.0, 1.0, 1.0, 2.0, 1.0, 2.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 2.0, 2.0, 0.0, 1.0, 3.0, 3.0, 3.0, 3.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 2.0, 1.0, 2.0, 2.0, 1.0, 1.0, 0.0, 2.0, 1.0, 2.0, 2.0, 2.0, 1.0, 1.0, 1.0, 0.0, 2.0, 2.0, 3.0, 2.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 2.0, 0.0, 2.0, 1.0, 1.0, 0.0, 2.0, 3.0, 1.0, 0.0, 1.0, 1.0, 0.0, 2.0, 2.0, 1.0, 1.0, 1.0, 1.0, 2.0, 1.0, 0.0, 0.0, 2.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 2.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.13369609241245403, "mean_inference_ms": 0.3906568996965294, "mean_action_processing_ms": 0.029206549089505464, "mean_env_wait_ms": 0.4040998283981337, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 806400, "timesteps_this_iter": 0, "agent_timesteps_total": 3225600, "timers": {"sample_time_ms": 5189.319, "sample_throughput": 971.226, "load_time_ms": 0.165, "load_throughput": 30460075.159, "learn_time_ms": 127.645, "learn_throughput": 39484.628, "update_time_ms": 2.451}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 216.76492309570312, "policy_entropy": 7804.9503173828125, "policy_loss": -30.781188249588013, "vf_loss": 29.63070583343506}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 806400, "num_agent_steps_sampled": 3225600, "num_steps_trained": 806400, "num_agent_steps_trained": 3225600, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 1612, "training_iteration": 80, "trial_id": "71426_00000", "experiment_id": "84bca2f7b35f43248fca18d21abe2ebf", "date": "2024-06-12_02-59-35", "timestamp": 1718128775, "time_this_iter_s": 10.37316083908081, "time_total_s": 823.3973398208618, "pid": 363902, "hostname": "DESKTOP-LQ219J4", "node_ip": "192.168.46.185", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 20, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 5000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 500, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Base_Model", "custom_model_config": {"env": "rware", "env_args": {"n_agents": 4, "column_height": 1, "max_inactivity_steps": null, "max_steps": 500, "fast_obs": true, "msg_bits": 0, "sensor_range": 1, "shelf_rows": 1, "shelf_columns": 3, "request_queue_size": 4, "reward_type": "RewardType.INDIVIDUAL", "map_name": "customized_map", "map_size": "tiny", "difficulty": "medium"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": true, "force_coop": false, "local_mode": true, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 4, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 100, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64}, "algorithm": "ia2c", "space_obs": "Dict(obs:Box([-100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100.], [100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.], (112,), float32))", "space_act": "Discrete(5)", "num_agents": 4, "episode_limit": 500, "policy_mapping_info": {"all_scenario": {"description": "rware all scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2", "agent_3"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "rware_customized_map", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 10, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.IA2CTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_il.<locals>.<lambda> at 0x7f380824d8b0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "grad_clip": 40.0, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "microbatch_size": null}, "time_since_restore": 823.3973398208618, "timesteps_since_restore": 0, "iterations_since_restore": 80, "perf": {"cpu_util_percent": 4.433333333333334, "ram_util_percent": 54.93999999999999}}
{"episode_reward_max": 13.0, "episode_reward_min": 0.0, "episode_reward_mean": 5.07, "episode_len_mean": 500.0, "episode_media": {}, "episodes_this_iter": 20, "policy_reward_min": {"shared_policy": 0.0}, "policy_reward_max": {"shared_policy": 5.0}, "policy_reward_mean": {"shared_policy": 1.2675}, "custom_metrics": {}, "hist_stats": {"episode_reward": [3.0, 5.0, 5.0, 4.0, 9.0, 0.0, 7.0, 8.0, 4.0, 2.0, 3.0, 10.0, 5.0, 4.0, 3.0, 5.0, 6.0, 3.0, 7.0, 4.0, 4.0, 2.0, 8.0, 4.0, 9.0, 4.0, 8.0, 4.0, 13.0, 3.0, 2.0, 5.0, 4.0, 4.0, 4.0, 4.0, 2.0, 9.0, 5.0, 5.0, 7.0, 11.0, 4.0, 12.0, 8.0, 3.0, 2.0, 6.0, 5.0, 6.0, 3.0, 5.0, 7.0, 9.0, 6.0, 2.0, 5.0, 5.0, 5.0, 2.0, 5.0, 12.0, 2.0, 3.0, 7.0, 4.0, 7.0, 3.0, 9.0, 3.0, 3.0, 4.0, 4.0, 6.0, 2.0, 6.0, 5.0, 2.0, 3.0, 4.0, 11.0, 6.0, 3.0, 5.0, 3.0, 8.0, 13.0, 2.0, 4.0, 2.0, 8.0, 2.0, 3.0, 3.0, 6.0, 5.0, 3.0, 5.0, 2.0, 6.0], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500], "policy_shared_policy_reward": [1.0, 0.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0, 1.0, 1.0, 2.0, 1.0, 0.0, 3.0, 0.0, 1.0, 2.0, 2.0, 4.0, 1.0, 0.0, 0.0, 0.0, 0.0, 2.0, 1.0, 3.0, 1.0, 3.0, 1.0, 3.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 4.0, 2.0, 2.0, 2.0, 3.0, 2.0, 0.0, 0.0, 0.0, 1.0, 2.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 2.0, 1.0, 1.0, 2.0, 1.0, 1.0, 2.0, 0.0, 2.0, 1.0, 0.0, 1.0, 1.0, 2.0, 3.0, 1.0, 1.0, 0.0, 2.0, 0.0, 2.0, 0.0, 2.0, 1.0, 1.0, 0.0, 0.0, 1.0, 2.0, 4.0, 1.0, 1.0, 1.0, 1.0, 1.0, 2.0, 3.0, 2.0, 2.0, 1.0, 1.0, 1.0, 1.0, 1.0, 3.0, 2.0, 2.0, 1.0, 2.0, 0.0, 1.0, 5.0, 4.0, 1.0, 3.0, 2.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 2.0, 1.0, 1.0, 1.0, 2.0, 0.0, 1.0, 1.0, 1.0, 1.0, 2.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 2.0, 2.0, 3.0, 2.0, 1.0, 2.0, 2.0, 0.0, 3.0, 0.0, 1.0, 1.0, 2.0, 2.0, 1.0, 2.0, 4.0, 1.0, 4.0, 2.0, 1.0, 1.0, 1.0, 1.0, 3.0, 5.0, 2.0, 2.0, 3.0, 1.0, 0.0, 4.0, 0.0, 0.0, 1.0, 2.0, 1.0, 1.0, 0.0, 0.0, 2.0, 2.0, 1.0, 1.0, 2.0, 1.0, 0.0, 2.0, 1.0, 2.0, 3.0, 0.0, 0.0, 1.0, 2.0, 0.0, 0.0, 3.0, 1.0, 1.0, 3.0, 1.0, 2.0, 1.0, 2.0, 1.0, 2.0, 4.0, 1.0, 1.0, 2.0, 2.0, 1.0, 0.0, 0.0, 1.0, 3.0, 1.0, 1.0, 0.0, 1.0, 1.0, 2.0, 1.0, 2.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 2.0, 2.0, 0.0, 1.0, 3.0, 3.0, 3.0, 3.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 2.0, 1.0, 2.0, 2.0, 1.0, 1.0, 0.0, 2.0, 1.0, 2.0, 2.0, 2.0, 1.0, 1.0, 1.0, 0.0, 2.0, 2.0, 3.0, 2.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 2.0, 0.0, 2.0, 1.0, 1.0, 0.0, 2.0, 3.0, 1.0, 0.0, 1.0, 1.0, 0.0, 2.0, 2.0, 1.0, 1.0, 1.0, 1.0, 2.0, 1.0, 0.0, 0.0, 2.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 2.0, 0.0, 4.0, 2.0, 3.0, 2.0, 2.0, 2.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 2.0, 2.0, 0.0, 1.0, 1.0, 0.0, 1.0, 2.0, 2.0, 1.0, 3.0, 1.0, 4.0, 3.0, 5.0, 1.0, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 2.0, 1.0, 1.0, 0.0, 0.0, 3.0, 1.0, 2.0, 2.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 2.0, 1.0, 2.0, 1.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 2.0, 0.0, 2.0, 1.0, 1.0, 0.0, 0.0, 1.0, 2.0, 1.0, 2.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.13372053295686834, "mean_inference_ms": 0.3907137134931525, "mean_action_processing_ms": 0.029210632033226033, "mean_env_wait_ms": 0.40414959018109653, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 816480, "timesteps_this_iter": 0, "agent_timesteps_total": 3265920, "timers": {"sample_time_ms": 5190.294, "sample_throughput": 971.043, "load_time_ms": 0.165, "load_throughput": 30618905.214, "learn_time_ms": 127.23, "learn_throughput": 39613.321, "update_time_ms": 2.43}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 270.82470703125, "policy_entropy": 7894.326416015625, "policy_loss": -67.15964460372925, "vf_loss": 33.83032035827637}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 816480, "num_agent_steps_sampled": 3265920, "num_steps_trained": 816480, "num_agent_steps_trained": 3265920, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 1632, "training_iteration": 81, "trial_id": "71426_00000", "experiment_id": "84bca2f7b35f43248fca18d21abe2ebf", "date": "2024-06-12_02-59-45", "timestamp": 1718128785, "time_this_iter_s": 10.230262041091919, "time_total_s": 833.6276018619537, "pid": 363902, "hostname": "DESKTOP-LQ219J4", "node_ip": "192.168.46.185", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 20, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 5000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 500, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Base_Model", "custom_model_config": {"env": "rware", "env_args": {"n_agents": 4, "column_height": 1, "max_inactivity_steps": null, "max_steps": 500, "fast_obs": true, "msg_bits": 0, "sensor_range": 1, "shelf_rows": 1, "shelf_columns": 3, "request_queue_size": 4, "reward_type": "RewardType.INDIVIDUAL", "map_name": "customized_map", "map_size": "tiny", "difficulty": "medium"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": true, "force_coop": false, "local_mode": true, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 4, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 100, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64}, "algorithm": "ia2c", "space_obs": "Dict(obs:Box([-100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100.], [100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.], (112,), float32))", "space_act": "Discrete(5)", "num_agents": 4, "episode_limit": 500, "policy_mapping_info": {"all_scenario": {"description": "rware all scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2", "agent_3"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "rware_customized_map", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 10, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.IA2CTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_il.<locals>.<lambda> at 0x7f380824d4c0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "grad_clip": 40.0, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "microbatch_size": null}, "time_since_restore": 833.6276018619537, "timesteps_since_restore": 0, "iterations_since_restore": 81, "perf": {"cpu_util_percent": 4.364285714285714, "ram_util_percent": 55.21428571428572}}
{"episode_reward_max": 13.0, "episode_reward_min": 2.0, "episode_reward_mean": 5.03, "episode_len_mean": 500.0, "episode_media": {}, "episodes_this_iter": 20, "policy_reward_min": {"shared_policy": 0.0}, "policy_reward_max": {"shared_policy": 5.0}, "policy_reward_mean": {"shared_policy": 1.2575}, "custom_metrics": {}, "hist_stats": {"episode_reward": [4.0, 2.0, 8.0, 4.0, 9.0, 4.0, 8.0, 4.0, 13.0, 3.0, 2.0, 5.0, 4.0, 4.0, 4.0, 4.0, 2.0, 9.0, 5.0, 5.0, 7.0, 11.0, 4.0, 12.0, 8.0, 3.0, 2.0, 6.0, 5.0, 6.0, 3.0, 5.0, 7.0, 9.0, 6.0, 2.0, 5.0, 5.0, 5.0, 2.0, 5.0, 12.0, 2.0, 3.0, 7.0, 4.0, 7.0, 3.0, 9.0, 3.0, 3.0, 4.0, 4.0, 6.0, 2.0, 6.0, 5.0, 2.0, 3.0, 4.0, 11.0, 6.0, 3.0, 5.0, 3.0, 8.0, 13.0, 2.0, 4.0, 2.0, 8.0, 2.0, 3.0, 3.0, 6.0, 5.0, 3.0, 5.0, 2.0, 6.0, 3.0, 3.0, 7.0, 10.0, 3.0, 7.0, 3.0, 5.0, 4.0, 5.0, 6.0, 3.0, 2.0, 4.0, 6.0, 3.0, 3.0, 8.0, 6.0, 2.0], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500], "policy_shared_policy_reward": [0.0, 2.0, 0.0, 2.0, 1.0, 1.0, 0.0, 0.0, 1.0, 2.0, 4.0, 1.0, 1.0, 1.0, 1.0, 1.0, 2.0, 3.0, 2.0, 2.0, 1.0, 1.0, 1.0, 1.0, 1.0, 3.0, 2.0, 2.0, 1.0, 2.0, 0.0, 1.0, 5.0, 4.0, 1.0, 3.0, 2.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 2.0, 1.0, 1.0, 1.0, 2.0, 0.0, 1.0, 1.0, 1.0, 1.0, 2.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 2.0, 2.0, 3.0, 2.0, 1.0, 2.0, 2.0, 0.0, 3.0, 0.0, 1.0, 1.0, 2.0, 2.0, 1.0, 2.0, 4.0, 1.0, 4.0, 2.0, 1.0, 1.0, 1.0, 1.0, 3.0, 5.0, 2.0, 2.0, 3.0, 1.0, 0.0, 4.0, 0.0, 0.0, 1.0, 2.0, 1.0, 1.0, 0.0, 0.0, 2.0, 2.0, 1.0, 1.0, 2.0, 1.0, 0.0, 2.0, 1.0, 2.0, 3.0, 0.0, 0.0, 1.0, 2.0, 0.0, 0.0, 3.0, 1.0, 1.0, 3.0, 1.0, 2.0, 1.0, 2.0, 1.0, 2.0, 4.0, 1.0, 1.0, 2.0, 2.0, 1.0, 0.0, 0.0, 1.0, 3.0, 1.0, 1.0, 0.0, 1.0, 1.0, 2.0, 1.0, 2.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 2.0, 2.0, 0.0, 1.0, 3.0, 3.0, 3.0, 3.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 2.0, 1.0, 2.0, 2.0, 1.0, 1.0, 0.0, 2.0, 1.0, 2.0, 2.0, 2.0, 1.0, 1.0, 1.0, 0.0, 2.0, 2.0, 3.0, 2.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 2.0, 0.0, 2.0, 1.0, 1.0, 0.0, 2.0, 3.0, 1.0, 0.0, 1.0, 1.0, 0.0, 2.0, 2.0, 1.0, 1.0, 1.0, 1.0, 2.0, 1.0, 0.0, 0.0, 2.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 2.0, 0.0, 4.0, 2.0, 3.0, 2.0, 2.0, 2.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 2.0, 2.0, 0.0, 1.0, 1.0, 0.0, 1.0, 2.0, 2.0, 1.0, 3.0, 1.0, 4.0, 3.0, 5.0, 1.0, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 2.0, 1.0, 1.0, 0.0, 0.0, 3.0, 1.0, 2.0, 2.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 2.0, 1.0, 2.0, 1.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 2.0, 0.0, 2.0, 1.0, 1.0, 0.0, 0.0, 1.0, 2.0, 1.0, 2.0, 0.0, 1.0, 2.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 3.0, 1.0, 2.0, 2.0, 5.0, 2.0, 1.0, 0.0, 0.0, 1.0, 2.0, 2.0, 1.0, 2.0, 2.0, 1.0, 0.0, 1.0, 1.0, 3.0, 0.0, 1.0, 1.0, 1.0, 2.0, 0.0, 1.0, 1.0, 1.0, 2.0, 1.0, 1.0, 3.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 2.0, 2.0, 1.0, 2.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 2.0, 2.0, 4.0, 0.0, 2.0, 0.0, 1.0, 3.0, 0.0, 1.0, 1.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.13374264696430743, "mean_inference_ms": 0.39076769132713773, "mean_action_processing_ms": 0.029212486057993495, "mean_env_wait_ms": 0.4041823062543368, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 826560, "timesteps_this_iter": 0, "agent_timesteps_total": 3306240, "timers": {"sample_time_ms": 5180.659, "sample_throughput": 972.849, "load_time_ms": 0.163, "load_throughput": 30964248.074, "learn_time_ms": 126.529, "learn_throughput": 39832.675, "update_time_ms": 2.471}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 315.3601989746094, "policy_entropy": 7902.76416015625, "policy_loss": -9.505971908569336, "vf_loss": 41.397772789001465}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 826560, "num_agent_steps_sampled": 3306240, "num_steps_trained": 826560, "num_agent_steps_trained": 3306240, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 1652, "training_iteration": 82, "trial_id": "71426_00000", "experiment_id": "84bca2f7b35f43248fca18d21abe2ebf", "date": "2024-06-12_02-59-56", "timestamp": 1718128796, "time_this_iter_s": 10.16590404510498, "time_total_s": 843.7935059070587, "pid": 363902, "hostname": "DESKTOP-LQ219J4", "node_ip": "192.168.46.185", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 20, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 5000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 500, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Base_Model", "custom_model_config": {"env": "rware", "env_args": {"n_agents": 4, "column_height": 1, "max_inactivity_steps": null, "max_steps": 500, "fast_obs": true, "msg_bits": 0, "sensor_range": 1, "shelf_rows": 1, "shelf_columns": 3, "request_queue_size": 4, "reward_type": "RewardType.INDIVIDUAL", "map_name": "customized_map", "map_size": "tiny", "difficulty": "medium"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": true, "force_coop": false, "local_mode": true, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 4, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 100, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64}, "algorithm": "ia2c", "space_obs": "Dict(obs:Box([-100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100.], [100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.], (112,), float32))", "space_act": "Discrete(5)", "num_agents": 4, "episode_limit": 500, "policy_mapping_info": {"all_scenario": {"description": "rware all scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2", "agent_3"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "rware_customized_map", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 10, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.IA2CTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_il.<locals>.<lambda> at 0x7f38086c1e50>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "grad_clip": 40.0, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "microbatch_size": null}, "time_since_restore": 843.7935059070587, "timesteps_since_restore": 0, "iterations_since_restore": 82, "perf": {"cpu_util_percent": 4.6466666666666665, "ram_util_percent": 55.5}}
{"episode_reward_max": 13.0, "episode_reward_min": 2.0, "episode_reward_mean": 4.88, "episode_len_mean": 500.0, "episode_media": {}, "episodes_this_iter": 20, "policy_reward_min": {"shared_policy": 0.0}, "policy_reward_max": {"shared_policy": 5.0}, "policy_reward_mean": {"shared_policy": 1.22}, "custom_metrics": {}, "hist_stats": {"episode_reward": [7.0, 11.0, 4.0, 12.0, 8.0, 3.0, 2.0, 6.0, 5.0, 6.0, 3.0, 5.0, 7.0, 9.0, 6.0, 2.0, 5.0, 5.0, 5.0, 2.0, 5.0, 12.0, 2.0, 3.0, 7.0, 4.0, 7.0, 3.0, 9.0, 3.0, 3.0, 4.0, 4.0, 6.0, 2.0, 6.0, 5.0, 2.0, 3.0, 4.0, 11.0, 6.0, 3.0, 5.0, 3.0, 8.0, 13.0, 2.0, 4.0, 2.0, 8.0, 2.0, 3.0, 3.0, 6.0, 5.0, 3.0, 5.0, 2.0, 6.0, 3.0, 3.0, 7.0, 10.0, 3.0, 7.0, 3.0, 5.0, 4.0, 5.0, 6.0, 3.0, 2.0, 4.0, 6.0, 3.0, 3.0, 8.0, 6.0, 2.0, 3.0, 5.0, 5.0, 5.0, 4.0, 3.0, 12.0, 8.0, 2.0, 2.0, 2.0, 5.0, 3.0, 2.0, 2.0, 3.0, 5.0, 3.0, 5.0, 9.0], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500], "policy_shared_policy_reward": [2.0, 2.0, 1.0, 2.0, 4.0, 1.0, 4.0, 2.0, 1.0, 1.0, 1.0, 1.0, 3.0, 5.0, 2.0, 2.0, 3.0, 1.0, 0.0, 4.0, 0.0, 0.0, 1.0, 2.0, 1.0, 1.0, 0.0, 0.0, 2.0, 2.0, 1.0, 1.0, 2.0, 1.0, 0.0, 2.0, 1.0, 2.0, 3.0, 0.0, 0.0, 1.0, 2.0, 0.0, 0.0, 3.0, 1.0, 1.0, 3.0, 1.0, 2.0, 1.0, 2.0, 1.0, 2.0, 4.0, 1.0, 1.0, 2.0, 2.0, 1.0, 0.0, 0.0, 1.0, 3.0, 1.0, 1.0, 0.0, 1.0, 1.0, 2.0, 1.0, 2.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 2.0, 2.0, 0.0, 1.0, 3.0, 3.0, 3.0, 3.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 2.0, 1.0, 2.0, 2.0, 1.0, 1.0, 0.0, 2.0, 1.0, 2.0, 2.0, 2.0, 1.0, 1.0, 1.0, 0.0, 2.0, 2.0, 3.0, 2.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 2.0, 0.0, 2.0, 1.0, 1.0, 0.0, 2.0, 3.0, 1.0, 0.0, 1.0, 1.0, 0.0, 2.0, 2.0, 1.0, 1.0, 1.0, 1.0, 2.0, 1.0, 0.0, 0.0, 2.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 2.0, 0.0, 4.0, 2.0, 3.0, 2.0, 2.0, 2.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 2.0, 2.0, 0.0, 1.0, 1.0, 0.0, 1.0, 2.0, 2.0, 1.0, 3.0, 1.0, 4.0, 3.0, 5.0, 1.0, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 2.0, 1.0, 1.0, 0.0, 0.0, 3.0, 1.0, 2.0, 2.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 2.0, 1.0, 2.0, 1.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 2.0, 0.0, 2.0, 1.0, 1.0, 0.0, 0.0, 1.0, 2.0, 1.0, 2.0, 0.0, 1.0, 2.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 3.0, 1.0, 2.0, 2.0, 5.0, 2.0, 1.0, 0.0, 0.0, 1.0, 2.0, 2.0, 1.0, 2.0, 2.0, 1.0, 0.0, 1.0, 1.0, 3.0, 0.0, 1.0, 1.0, 1.0, 2.0, 0.0, 1.0, 1.0, 1.0, 2.0, 1.0, 1.0, 3.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 2.0, 2.0, 1.0, 2.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 2.0, 2.0, 4.0, 0.0, 2.0, 0.0, 1.0, 3.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 2.0, 1.0, 2.0, 1.0, 0.0, 2.0, 2.0, 1.0, 0.0, 2.0, 1.0, 1.0, 2.0, 0.0, 1.0, 1.0, 1.0, 0.0, 4.0, 2.0, 3.0, 3.0, 0.0, 2.0, 2.0, 4.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 2.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 2.0, 1.0, 0.0, 1.0, 0.0, 2.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0, 0.0, 1.0, 2.0, 0.0, 3.0, 0.0, 1.0, 3.0, 2.0, 3.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.13375141652854117, "mean_inference_ms": 0.39079165293016144, "mean_action_processing_ms": 0.02921226061831234, "mean_env_wait_ms": 0.40418028956178753, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 836640, "timesteps_this_iter": 0, "agent_timesteps_total": 3346560, "timers": {"sample_time_ms": 5145.317, "sample_throughput": 979.531, "load_time_ms": 0.16, "load_throughput": 31443242.838, "learn_time_ms": 125.891, "learn_throughput": 40034.529, "update_time_ms": 2.456}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 225.68792724609375, "policy_entropy": 7881.64013671875, "policy_loss": -29.61562407016754, "vf_loss": 31.89337396621704}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 836640, "num_agent_steps_sampled": 3346560, "num_steps_trained": 836640, "num_agent_steps_trained": 3346560, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 1672, "training_iteration": 83, "trial_id": "71426_00000", "experiment_id": "84bca2f7b35f43248fca18d21abe2ebf", "date": "2024-06-12_03-00-06", "timestamp": 1718128806, "time_this_iter_s": 10.209803342819214, "time_total_s": 854.0033092498779, "pid": 363902, "hostname": "DESKTOP-LQ219J4", "node_ip": "192.168.46.185", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 20, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 5000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 500, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Base_Model", "custom_model_config": {"env": "rware", "env_args": {"n_agents": 4, "column_height": 1, "max_inactivity_steps": null, "max_steps": 500, "fast_obs": true, "msg_bits": 0, "sensor_range": 1, "shelf_rows": 1, "shelf_columns": 3, "request_queue_size": 4, "reward_type": "RewardType.INDIVIDUAL", "map_name": "customized_map", "map_size": "tiny", "difficulty": "medium"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": true, "force_coop": false, "local_mode": true, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 4, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 100, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64}, "algorithm": "ia2c", "space_obs": "Dict(obs:Box([-100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100.], [100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.], (112,), float32))", "space_act": "Discrete(5)", "num_agents": 4, "episode_limit": 500, "policy_mapping_info": {"all_scenario": {"description": "rware all scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2", "agent_3"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "rware_customized_map", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 10, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.IA2CTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_il.<locals>.<lambda> at 0x7f3808651940>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "grad_clip": 40.0, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "microbatch_size": null}, "time_since_restore": 854.0033092498779, "timesteps_since_restore": 0, "iterations_since_restore": 83, "perf": {"cpu_util_percent": 4.764285714285714, "ram_util_percent": 55.79999999999999}}
{"episode_reward_max": 14.0, "episode_reward_min": 1.0, "episode_reward_mean": 4.78, "episode_len_mean": 500.0, "episode_media": {}, "episodes_this_iter": 20, "policy_reward_min": {"shared_policy": 0.0}, "policy_reward_max": {"shared_policy": 6.0}, "policy_reward_mean": {"shared_policy": 1.195}, "custom_metrics": {}, "hist_stats": {"episode_reward": [5.0, 12.0, 2.0, 3.0, 7.0, 4.0, 7.0, 3.0, 9.0, 3.0, 3.0, 4.0, 4.0, 6.0, 2.0, 6.0, 5.0, 2.0, 3.0, 4.0, 11.0, 6.0, 3.0, 5.0, 3.0, 8.0, 13.0, 2.0, 4.0, 2.0, 8.0, 2.0, 3.0, 3.0, 6.0, 5.0, 3.0, 5.0, 2.0, 6.0, 3.0, 3.0, 7.0, 10.0, 3.0, 7.0, 3.0, 5.0, 4.0, 5.0, 6.0, 3.0, 2.0, 4.0, 6.0, 3.0, 3.0, 8.0, 6.0, 2.0, 3.0, 5.0, 5.0, 5.0, 4.0, 3.0, 12.0, 8.0, 2.0, 2.0, 2.0, 5.0, 3.0, 2.0, 2.0, 3.0, 5.0, 3.0, 5.0, 9.0, 7.0, 3.0, 6.0, 4.0, 5.0, 7.0, 3.0, 8.0, 4.0, 4.0, 2.0, 5.0, 14.0, 3.0, 5.0, 1.0, 3.0, 5.0, 7.0, 7.0], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500], "policy_shared_policy_reward": [2.0, 2.0, 0.0, 1.0, 3.0, 3.0, 3.0, 3.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 2.0, 1.0, 2.0, 2.0, 1.0, 1.0, 0.0, 2.0, 1.0, 2.0, 2.0, 2.0, 1.0, 1.0, 1.0, 0.0, 2.0, 2.0, 3.0, 2.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 2.0, 0.0, 2.0, 1.0, 1.0, 0.0, 2.0, 3.0, 1.0, 0.0, 1.0, 1.0, 0.0, 2.0, 2.0, 1.0, 1.0, 1.0, 1.0, 2.0, 1.0, 0.0, 0.0, 2.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 2.0, 0.0, 4.0, 2.0, 3.0, 2.0, 2.0, 2.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 2.0, 2.0, 0.0, 1.0, 1.0, 0.0, 1.0, 2.0, 2.0, 1.0, 3.0, 1.0, 4.0, 3.0, 5.0, 1.0, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 2.0, 1.0, 1.0, 0.0, 0.0, 3.0, 1.0, 2.0, 2.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 2.0, 1.0, 2.0, 1.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 2.0, 0.0, 2.0, 1.0, 1.0, 0.0, 0.0, 1.0, 2.0, 1.0, 2.0, 0.0, 1.0, 2.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 3.0, 1.0, 2.0, 2.0, 5.0, 2.0, 1.0, 0.0, 0.0, 1.0, 2.0, 2.0, 1.0, 2.0, 2.0, 1.0, 0.0, 1.0, 1.0, 3.0, 0.0, 1.0, 1.0, 1.0, 2.0, 0.0, 1.0, 1.0, 1.0, 2.0, 1.0, 1.0, 3.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 2.0, 2.0, 1.0, 2.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 2.0, 2.0, 4.0, 0.0, 2.0, 0.0, 1.0, 3.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 2.0, 1.0, 2.0, 1.0, 0.0, 2.0, 2.0, 1.0, 0.0, 2.0, 1.0, 1.0, 2.0, 0.0, 1.0, 1.0, 1.0, 0.0, 4.0, 2.0, 3.0, 3.0, 0.0, 2.0, 2.0, 4.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 2.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 2.0, 1.0, 0.0, 1.0, 0.0, 2.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0, 0.0, 1.0, 2.0, 0.0, 3.0, 0.0, 1.0, 3.0, 2.0, 3.0, 1.0, 1.0, 1.0, 4.0, 0.0, 0.0, 2.0, 1.0, 3.0, 1.0, 1.0, 1.0, 0.0, 2.0, 1.0, 1.0, 1.0, 1.0, 1.0, 2.0, 2.0, 3.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 2.0, 2.0, 1.0, 3.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 2.0, 2.0, 1.0, 3.0, 6.0, 1.0, 4.0, 1.0, 1.0, 0.0, 1.0, 1.0, 2.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0, 1.0, 3.0, 1.0, 2.0, 3.0, 1.0, 2.0, 1.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.1337550620682482, "mean_inference_ms": 0.39079678050974787, "mean_action_processing_ms": 0.029210934889780268, "mean_env_wait_ms": 0.4041728152673433, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 846720, "timesteps_this_iter": 0, "agent_timesteps_total": 3386880, "timers": {"sample_time_ms": 5130.133, "sample_throughput": 982.431, "load_time_ms": 0.154, "load_throughput": 32657642.762, "learn_time_ms": 125.444, "learn_throughput": 40177.364, "update_time_ms": 2.433}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 127.1511459350586, "policy_entropy": 7811.3037109375, "policy_loss": -51.31546115875244, "vf_loss": 36.277095317840576}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 846720, "num_agent_steps_sampled": 3386880, "num_steps_trained": 846720, "num_agent_steps_trained": 3386880, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 1692, "training_iteration": 84, "trial_id": "71426_00000", "experiment_id": "84bca2f7b35f43248fca18d21abe2ebf", "date": "2024-06-12_03-00-16", "timestamp": 1718128816, "time_this_iter_s": 10.246196746826172, "time_total_s": 864.2495059967041, "pid": 363902, "hostname": "DESKTOP-LQ219J4", "node_ip": "192.168.46.185", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 20, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 5000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 500, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Base_Model", "custom_model_config": {"env": "rware", "env_args": {"n_agents": 4, "column_height": 1, "max_inactivity_steps": null, "max_steps": 500, "fast_obs": true, "msg_bits": 0, "sensor_range": 1, "shelf_rows": 1, "shelf_columns": 3, "request_queue_size": 4, "reward_type": "RewardType.INDIVIDUAL", "map_name": "customized_map", "map_size": "tiny", "difficulty": "medium"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": true, "force_coop": false, "local_mode": true, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 4, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 100, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64}, "algorithm": "ia2c", "space_obs": "Dict(obs:Box([-100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100.], [100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.], (112,), float32))", "space_act": "Discrete(5)", "num_agents": 4, "episode_limit": 500, "policy_mapping_info": {"all_scenario": {"description": "rware all scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2", "agent_3"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "rware_customized_map", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 10, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.IA2CTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_il.<locals>.<lambda> at 0x7f3808651820>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "grad_clip": 40.0, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "microbatch_size": null}, "time_since_restore": 864.2495059967041, "timesteps_since_restore": 0, "iterations_since_restore": 84, "perf": {"cpu_util_percent": 4.513333333333333, "ram_util_percent": 56.10000000000001}}
{"episode_reward_max": 16.0, "episode_reward_min": 1.0, "episode_reward_mean": 5.33, "episode_len_mean": 500.0, "episode_media": {}, "episodes_this_iter": 20, "policy_reward_min": {"shared_policy": 0.0}, "policy_reward_max": {"shared_policy": 6.0}, "policy_reward_mean": {"shared_policy": 1.3325}, "custom_metrics": {}, "hist_stats": {"episode_reward": [11.0, 6.0, 3.0, 5.0, 3.0, 8.0, 13.0, 2.0, 4.0, 2.0, 8.0, 2.0, 3.0, 3.0, 6.0, 5.0, 3.0, 5.0, 2.0, 6.0, 3.0, 3.0, 7.0, 10.0, 3.0, 7.0, 3.0, 5.0, 4.0, 5.0, 6.0, 3.0, 2.0, 4.0, 6.0, 3.0, 3.0, 8.0, 6.0, 2.0, 3.0, 5.0, 5.0, 5.0, 4.0, 3.0, 12.0, 8.0, 2.0, 2.0, 2.0, 5.0, 3.0, 2.0, 2.0, 3.0, 5.0, 3.0, 5.0, 9.0, 7.0, 3.0, 6.0, 4.0, 5.0, 7.0, 3.0, 8.0, 4.0, 4.0, 2.0, 5.0, 14.0, 3.0, 5.0, 1.0, 3.0, 5.0, 7.0, 7.0, 2.0, 10.0, 9.0, 12.0, 16.0, 5.0, 7.0, 11.0, 6.0, 11.0, 5.0, 6.0, 4.0, 8.0, 3.0, 9.0, 12.0, 1.0, 6.0, 6.0], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500], "policy_shared_policy_reward": [4.0, 2.0, 3.0, 2.0, 2.0, 2.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 2.0, 2.0, 0.0, 1.0, 1.0, 0.0, 1.0, 2.0, 2.0, 1.0, 3.0, 1.0, 4.0, 3.0, 5.0, 1.0, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 2.0, 1.0, 1.0, 0.0, 0.0, 3.0, 1.0, 2.0, 2.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 2.0, 1.0, 2.0, 1.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 2.0, 0.0, 2.0, 1.0, 1.0, 0.0, 0.0, 1.0, 2.0, 1.0, 2.0, 0.0, 1.0, 2.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 3.0, 1.0, 2.0, 2.0, 5.0, 2.0, 1.0, 0.0, 0.0, 1.0, 2.0, 2.0, 1.0, 2.0, 2.0, 1.0, 0.0, 1.0, 1.0, 3.0, 0.0, 1.0, 1.0, 1.0, 2.0, 0.0, 1.0, 1.0, 1.0, 2.0, 1.0, 1.0, 3.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 2.0, 2.0, 1.0, 2.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 2.0, 2.0, 4.0, 0.0, 2.0, 0.0, 1.0, 3.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 2.0, 1.0, 2.0, 1.0, 0.0, 2.0, 2.0, 1.0, 0.0, 2.0, 1.0, 1.0, 2.0, 0.0, 1.0, 1.0, 1.0, 0.0, 4.0, 2.0, 3.0, 3.0, 0.0, 2.0, 2.0, 4.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 2.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 2.0, 1.0, 0.0, 1.0, 0.0, 2.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0, 0.0, 1.0, 2.0, 0.0, 3.0, 0.0, 1.0, 3.0, 2.0, 3.0, 1.0, 1.0, 1.0, 4.0, 0.0, 0.0, 2.0, 1.0, 3.0, 1.0, 1.0, 1.0, 0.0, 2.0, 1.0, 1.0, 1.0, 1.0, 1.0, 2.0, 2.0, 3.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 2.0, 2.0, 1.0, 3.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 2.0, 2.0, 1.0, 3.0, 6.0, 1.0, 4.0, 1.0, 1.0, 0.0, 1.0, 1.0, 2.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0, 1.0, 3.0, 1.0, 2.0, 3.0, 1.0, 2.0, 1.0, 1.0, 0.0, 0.0, 1.0, 2.0, 3.0, 2.0, 3.0, 2.0, 2.0, 3.0, 2.0, 5.0, 3.0, 2.0, 2.0, 4.0, 5.0, 4.0, 3.0, 1.0, 1.0, 1.0, 2.0, 2.0, 2.0, 1.0, 2.0, 4.0, 3.0, 3.0, 1.0, 3.0, 0.0, 2.0, 1.0, 2.0, 3.0, 3.0, 3.0, 2.0, 2.0, 1.0, 0.0, 2.0, 2.0, 2.0, 0.0, 1.0, 1.0, 1.0, 1.0, 3.0, 2.0, 2.0, 1.0, 1.0, 2.0, 0.0, 0.0, 2.0, 3.0, 3.0, 1.0, 3.0, 4.0, 1.0, 4.0, 0.0, 1.0, 0.0, 0.0, 2.0, 1.0, 2.0, 1.0, 2.0, 2.0, 2.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.1337508745490391, "mean_inference_ms": 0.3907884439981026, "mean_action_processing_ms": 0.029209513220383673, "mean_env_wait_ms": 0.40415447066695864, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 856800, "timesteps_this_iter": 0, "agent_timesteps_total": 3427200, "timers": {"sample_time_ms": 5114.085, "sample_throughput": 985.514, "load_time_ms": 0.162, "load_throughput": 31123810.601, "learn_time_ms": 125.76, "learn_throughput": 40076.478, "update_time_ms": 2.476}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 434.4789123535156, "policy_entropy": 7725.078125, "policy_loss": 24.678607940673828, "vf_loss": 62.39834690093994}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 856800, "num_agent_steps_sampled": 3427200, "num_steps_trained": 856800, "num_agent_steps_trained": 3427200, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 1712, "training_iteration": 85, "trial_id": "71426_00000", "experiment_id": "84bca2f7b35f43248fca18d21abe2ebf", "date": "2024-06-12_03-00-26", "timestamp": 1718128826, "time_this_iter_s": 10.220808506011963, "time_total_s": 874.4703145027161, "pid": 363902, "hostname": "DESKTOP-LQ219J4", "node_ip": "192.168.46.185", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 20, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 5000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 500, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Base_Model", "custom_model_config": {"env": "rware", "env_args": {"n_agents": 4, "column_height": 1, "max_inactivity_steps": null, "max_steps": 500, "fast_obs": true, "msg_bits": 0, "sensor_range": 1, "shelf_rows": 1, "shelf_columns": 3, "request_queue_size": 4, "reward_type": "RewardType.INDIVIDUAL", "map_name": "customized_map", "map_size": "tiny", "difficulty": "medium"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": true, "force_coop": false, "local_mode": true, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 4, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 100, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64}, "algorithm": "ia2c", "space_obs": "Dict(obs:Box([-100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100.], [100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.], (112,), float32))", "space_act": "Discrete(5)", "num_agents": 4, "episode_limit": 500, "policy_mapping_info": {"all_scenario": {"description": "rware all scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2", "agent_3"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "rware_customized_map", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 10, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.IA2CTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_il.<locals>.<lambda> at 0x7f38082f8160>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "grad_clip": 40.0, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "microbatch_size": null}, "time_since_restore": 874.4703145027161, "timesteps_since_restore": 0, "iterations_since_restore": 85, "perf": {"cpu_util_percent": 4.453333333333333, "ram_util_percent": 56.353333333333325}}
{"episode_reward_max": 16.0, "episode_reward_min": 1.0, "episode_reward_mean": 5.49, "episode_len_mean": 500.0, "episode_media": {}, "episodes_this_iter": 20, "policy_reward_min": {"shared_policy": 0.0}, "policy_reward_max": {"shared_policy": 6.0}, "policy_reward_mean": {"shared_policy": 1.3725}, "custom_metrics": {}, "hist_stats": {"episode_reward": [3.0, 3.0, 7.0, 10.0, 3.0, 7.0, 3.0, 5.0, 4.0, 5.0, 6.0, 3.0, 2.0, 4.0, 6.0, 3.0, 3.0, 8.0, 6.0, 2.0, 3.0, 5.0, 5.0, 5.0, 4.0, 3.0, 12.0, 8.0, 2.0, 2.0, 2.0, 5.0, 3.0, 2.0, 2.0, 3.0, 5.0, 3.0, 5.0, 9.0, 7.0, 3.0, 6.0, 4.0, 5.0, 7.0, 3.0, 8.0, 4.0, 4.0, 2.0, 5.0, 14.0, 3.0, 5.0, 1.0, 3.0, 5.0, 7.0, 7.0, 2.0, 10.0, 9.0, 12.0, 16.0, 5.0, 7.0, 11.0, 6.0, 11.0, 5.0, 6.0, 4.0, 8.0, 3.0, 9.0, 12.0, 1.0, 6.0, 6.0, 3.0, 7.0, 6.0, 6.0, 3.0, 4.0, 14.0, 2.0, 3.0, 6.0, 5.0, 7.0, 7.0, 2.0, 9.0, 5.0, 12.0, 4.0, 4.0, 7.0], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500], "policy_shared_policy_reward": [0.0, 1.0, 2.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 3.0, 1.0, 2.0, 2.0, 5.0, 2.0, 1.0, 0.0, 0.0, 1.0, 2.0, 2.0, 1.0, 2.0, 2.0, 1.0, 0.0, 1.0, 1.0, 3.0, 0.0, 1.0, 1.0, 1.0, 2.0, 0.0, 1.0, 1.0, 1.0, 2.0, 1.0, 1.0, 3.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 2.0, 2.0, 1.0, 2.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 2.0, 2.0, 4.0, 0.0, 2.0, 0.0, 1.0, 3.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 2.0, 1.0, 2.0, 1.0, 0.0, 2.0, 2.0, 1.0, 0.0, 2.0, 1.0, 1.0, 2.0, 0.0, 1.0, 1.0, 1.0, 0.0, 4.0, 2.0, 3.0, 3.0, 0.0, 2.0, 2.0, 4.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 2.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 2.0, 1.0, 0.0, 1.0, 0.0, 2.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0, 0.0, 1.0, 2.0, 0.0, 3.0, 0.0, 1.0, 3.0, 2.0, 3.0, 1.0, 1.0, 1.0, 4.0, 0.0, 0.0, 2.0, 1.0, 3.0, 1.0, 1.0, 1.0, 0.0, 2.0, 1.0, 1.0, 1.0, 1.0, 1.0, 2.0, 2.0, 3.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 2.0, 2.0, 1.0, 3.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 2.0, 2.0, 1.0, 3.0, 6.0, 1.0, 4.0, 1.0, 1.0, 0.0, 1.0, 1.0, 2.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0, 1.0, 3.0, 1.0, 2.0, 3.0, 1.0, 2.0, 1.0, 1.0, 0.0, 0.0, 1.0, 2.0, 3.0, 2.0, 3.0, 2.0, 2.0, 3.0, 2.0, 5.0, 3.0, 2.0, 2.0, 4.0, 5.0, 4.0, 3.0, 1.0, 1.0, 1.0, 2.0, 2.0, 2.0, 1.0, 2.0, 4.0, 3.0, 3.0, 1.0, 3.0, 0.0, 2.0, 1.0, 2.0, 3.0, 3.0, 3.0, 2.0, 2.0, 1.0, 0.0, 2.0, 2.0, 2.0, 0.0, 1.0, 1.0, 1.0, 1.0, 3.0, 2.0, 2.0, 1.0, 1.0, 2.0, 0.0, 0.0, 2.0, 3.0, 3.0, 1.0, 3.0, 4.0, 1.0, 4.0, 0.0, 1.0, 0.0, 0.0, 2.0, 1.0, 2.0, 1.0, 2.0, 2.0, 2.0, 0.0, 0.0, 1.0, 2.0, 0.0, 2.0, 2.0, 1.0, 2.0, 2.0, 2.0, 1.0, 1.0, 0.0, 1.0, 3.0, 2.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 4.0, 2.0, 4.0, 4.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 3.0, 1.0, 1.0, 0.0, 3.0, 1.0, 1.0, 2.0, 1.0, 2.0, 2.0, 0.0, 4.0, 2.0, 1.0, 1.0, 1.0, 0.0, 0.0, 2.0, 1.0, 3.0, 3.0, 0.0, 2.0, 2.0, 1.0, 3.0, 5.0, 2.0, 2.0, 0.0, 1.0, 2.0, 1.0, 2.0, 1.0, 0.0, 1.0, 3.0, 0.0, 1.0, 3.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.1337486501919037, "mean_inference_ms": 0.3907859613289341, "mean_action_processing_ms": 0.029208615928909953, "mean_env_wait_ms": 0.4041514271429951, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 866880, "timesteps_this_iter": 0, "agent_timesteps_total": 3467520, "timers": {"sample_time_ms": 5127.281, "sample_throughput": 982.977, "load_time_ms": 0.162, "load_throughput": 31032431.239, "learn_time_ms": 126.145, "learn_throughput": 39953.952, "update_time_ms": 2.472}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 166.63185119628906, "policy_entropy": 7786.22509765625, "policy_loss": -104.40387988090515, "vf_loss": 40.172269344329834}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 866880, "num_agent_steps_sampled": 3467520, "num_steps_trained": 866880, "num_agent_steps_trained": 3467520, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 1732, "training_iteration": 86, "trial_id": "71426_00000", "experiment_id": "84bca2f7b35f43248fca18d21abe2ebf", "date": "2024-06-12_03-00-37", "timestamp": 1718128837, "time_this_iter_s": 10.350373268127441, "time_total_s": 884.8206877708435, "pid": 363902, "hostname": "DESKTOP-LQ219J4", "node_ip": "192.168.46.185", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 20, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 5000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 500, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Base_Model", "custom_model_config": {"env": "rware", "env_args": {"n_agents": 4, "column_height": 1, "max_inactivity_steps": null, "max_steps": 500, "fast_obs": true, "msg_bits": 0, "sensor_range": 1, "shelf_rows": 1, "shelf_columns": 3, "request_queue_size": 4, "reward_type": "RewardType.INDIVIDUAL", "map_name": "customized_map", "map_size": "tiny", "difficulty": "medium"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": true, "force_coop": false, "local_mode": true, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 4, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 100, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64}, "algorithm": "ia2c", "space_obs": "Dict(obs:Box([-100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100.], [100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.], (112,), float32))", "space_act": "Discrete(5)", "num_agents": 4, "episode_limit": 500, "policy_mapping_info": {"all_scenario": {"description": "rware all scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2", "agent_3"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "rware_customized_map", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 10, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.IA2CTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_il.<locals>.<lambda> at 0x7f382806e940>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "grad_clip": 40.0, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "microbatch_size": null}, "time_since_restore": 884.8206877708435, "timesteps_since_restore": 0, "iterations_since_restore": 86, "perf": {"cpu_util_percent": 4.521428571428571, "ram_util_percent": 56.60000000000001}}
{"episode_reward_max": 16.0, "episode_reward_min": 0.0, "episode_reward_mean": 5.51, "episode_len_mean": 500.0, "episode_media": {}, "episodes_this_iter": 20, "policy_reward_min": {"shared_policy": 0.0}, "policy_reward_max": {"shared_policy": 6.0}, "policy_reward_mean": {"shared_policy": 1.3775}, "custom_metrics": {}, "hist_stats": {"episode_reward": [3.0, 5.0, 5.0, 5.0, 4.0, 3.0, 12.0, 8.0, 2.0, 2.0, 2.0, 5.0, 3.0, 2.0, 2.0, 3.0, 5.0, 3.0, 5.0, 9.0, 7.0, 3.0, 6.0, 4.0, 5.0, 7.0, 3.0, 8.0, 4.0, 4.0, 2.0, 5.0, 14.0, 3.0, 5.0, 1.0, 3.0, 5.0, 7.0, 7.0, 2.0, 10.0, 9.0, 12.0, 16.0, 5.0, 7.0, 11.0, 6.0, 11.0, 5.0, 6.0, 4.0, 8.0, 3.0, 9.0, 12.0, 1.0, 6.0, 6.0, 3.0, 7.0, 6.0, 6.0, 3.0, 4.0, 14.0, 2.0, 3.0, 6.0, 5.0, 7.0, 7.0, 2.0, 9.0, 5.0, 12.0, 4.0, 4.0, 7.0, 1.0, 8.0, 5.0, 2.0, 0.0, 6.0, 6.0, 4.0, 7.0, 2.0, 7.0, 9.0, 2.0, 4.0, 4.0, 7.0, 8.0, 6.0, 6.0, 1.0], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500], "policy_shared_policy_reward": [1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 2.0, 1.0, 2.0, 1.0, 0.0, 2.0, 2.0, 1.0, 0.0, 2.0, 1.0, 1.0, 2.0, 0.0, 1.0, 1.0, 1.0, 0.0, 4.0, 2.0, 3.0, 3.0, 0.0, 2.0, 2.0, 4.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 2.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 2.0, 1.0, 0.0, 1.0, 0.0, 2.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0, 0.0, 1.0, 2.0, 0.0, 3.0, 0.0, 1.0, 3.0, 2.0, 3.0, 1.0, 1.0, 1.0, 4.0, 0.0, 0.0, 2.0, 1.0, 3.0, 1.0, 1.0, 1.0, 0.0, 2.0, 1.0, 1.0, 1.0, 1.0, 1.0, 2.0, 2.0, 3.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 2.0, 2.0, 1.0, 3.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 2.0, 2.0, 1.0, 3.0, 6.0, 1.0, 4.0, 1.0, 1.0, 0.0, 1.0, 1.0, 2.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0, 1.0, 3.0, 1.0, 2.0, 3.0, 1.0, 2.0, 1.0, 1.0, 0.0, 0.0, 1.0, 2.0, 3.0, 2.0, 3.0, 2.0, 2.0, 3.0, 2.0, 5.0, 3.0, 2.0, 2.0, 4.0, 5.0, 4.0, 3.0, 1.0, 1.0, 1.0, 2.0, 2.0, 2.0, 1.0, 2.0, 4.0, 3.0, 3.0, 1.0, 3.0, 0.0, 2.0, 1.0, 2.0, 3.0, 3.0, 3.0, 2.0, 2.0, 1.0, 0.0, 2.0, 2.0, 2.0, 0.0, 1.0, 1.0, 1.0, 1.0, 3.0, 2.0, 2.0, 1.0, 1.0, 2.0, 0.0, 0.0, 2.0, 3.0, 3.0, 1.0, 3.0, 4.0, 1.0, 4.0, 0.0, 1.0, 0.0, 0.0, 2.0, 1.0, 2.0, 1.0, 2.0, 2.0, 2.0, 0.0, 0.0, 1.0, 2.0, 0.0, 2.0, 2.0, 1.0, 2.0, 2.0, 2.0, 1.0, 1.0, 0.0, 1.0, 3.0, 2.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 4.0, 2.0, 4.0, 4.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 3.0, 1.0, 1.0, 0.0, 3.0, 1.0, 1.0, 2.0, 1.0, 2.0, 2.0, 0.0, 4.0, 2.0, 1.0, 1.0, 1.0, 0.0, 0.0, 2.0, 1.0, 3.0, 3.0, 0.0, 2.0, 2.0, 1.0, 3.0, 5.0, 2.0, 2.0, 0.0, 1.0, 2.0, 1.0, 2.0, 1.0, 0.0, 1.0, 3.0, 0.0, 1.0, 3.0, 1.0, 0.0, 0.0, 0.0, 2.0, 3.0, 2.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 2.0, 1.0, 2.0, 1.0, 2.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0, 1.0, 3.0, 1.0, 2.0, 1.0, 0.0, 1.0, 0.0, 1.0, 3.0, 1.0, 1.0, 2.0, 2.0, 2.0, 2.0, 3.0, 1.0, 0.0, 1.0, 0.0, 2.0, 1.0, 0.0, 1.0, 0.0, 2.0, 1.0, 1.0, 1.0, 2.0, 3.0, 1.0, 1.0, 2.0, 3.0, 2.0, 2.0, 1.0, 1.0, 2.0, 0.0, 2.0, 2.0, 2.0, 0.0, 0.0, 1.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.13374483980714125, "mean_inference_ms": 0.39077509505776853, "mean_action_processing_ms": 0.029207175929746695, "mean_env_wait_ms": 0.40415221706187937, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 876960, "timesteps_this_iter": 0, "agent_timesteps_total": 3507840, "timers": {"sample_time_ms": 5122.739, "sample_throughput": 983.849, "load_time_ms": 0.165, "load_throughput": 30482036.28, "learn_time_ms": 126.63, "learn_throughput": 39800.884, "update_time_ms": 2.417}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 151.65643310546875, "policy_entropy": 7849.908203125, "policy_loss": -69.66054725646973, "vf_loss": 36.55621409416199}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 876960, "num_agent_steps_sampled": 3507840, "num_steps_trained": 876960, "num_agent_steps_trained": 3507840, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 1752, "training_iteration": 87, "trial_id": "71426_00000", "experiment_id": "84bca2f7b35f43248fca18d21abe2ebf", "date": "2024-06-12_03-00-47", "timestamp": 1718128847, "time_this_iter_s": 10.128436803817749, "time_total_s": 894.9491245746613, "pid": 363902, "hostname": "DESKTOP-LQ219J4", "node_ip": "192.168.46.185", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 20, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 5000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 500, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Base_Model", "custom_model_config": {"env": "rware", "env_args": {"n_agents": 4, "column_height": 1, "max_inactivity_steps": null, "max_steps": 500, "fast_obs": true, "msg_bits": 0, "sensor_range": 1, "shelf_rows": 1, "shelf_columns": 3, "request_queue_size": 4, "reward_type": "RewardType.INDIVIDUAL", "map_name": "customized_map", "map_size": "tiny", "difficulty": "medium"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": true, "force_coop": false, "local_mode": true, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 4, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 100, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64}, "algorithm": "ia2c", "space_obs": "Dict(obs:Box([-100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100.], [100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.], (112,), float32))", "space_act": "Discrete(5)", "num_agents": 4, "episode_limit": 500, "policy_mapping_info": {"all_scenario": {"description": "rware all scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2", "agent_3"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "rware_customized_map", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 10, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.IA2CTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_il.<locals>.<lambda> at 0x7f380824d550>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "grad_clip": 40.0, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "microbatch_size": null}, "time_since_restore": 894.9491245746613, "timesteps_since_restore": 0, "iterations_since_restore": 87, "perf": {"cpu_util_percent": 4.486666666666667, "ram_util_percent": 56.89999999999999}}
{"episode_reward_max": 16.0, "episode_reward_min": 0.0, "episode_reward_mean": 5.83, "episode_len_mean": 500.0, "episode_media": {}, "episodes_this_iter": 20, "policy_reward_min": {"shared_policy": 0.0}, "policy_reward_max": {"shared_policy": 6.0}, "policy_reward_mean": {"shared_policy": 1.4575}, "custom_metrics": {}, "hist_stats": {"episode_reward": [7.0, 3.0, 6.0, 4.0, 5.0, 7.0, 3.0, 8.0, 4.0, 4.0, 2.0, 5.0, 14.0, 3.0, 5.0, 1.0, 3.0, 5.0, 7.0, 7.0, 2.0, 10.0, 9.0, 12.0, 16.0, 5.0, 7.0, 11.0, 6.0, 11.0, 5.0, 6.0, 4.0, 8.0, 3.0, 9.0, 12.0, 1.0, 6.0, 6.0, 3.0, 7.0, 6.0, 6.0, 3.0, 4.0, 14.0, 2.0, 3.0, 6.0, 5.0, 7.0, 7.0, 2.0, 9.0, 5.0, 12.0, 4.0, 4.0, 7.0, 1.0, 8.0, 5.0, 2.0, 0.0, 6.0, 6.0, 4.0, 7.0, 2.0, 7.0, 9.0, 2.0, 4.0, 4.0, 7.0, 8.0, 6.0, 6.0, 1.0, 3.0, 5.0, 4.0, 2.0, 9.0, 14.0, 9.0, 12.0, 4.0, 5.0, 7.0, 2.0, 9.0, 10.0, 3.0, 10.0, 4.0, 5.0, 1.0, 2.0], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500], "policy_shared_policy_reward": [1.0, 1.0, 1.0, 4.0, 0.0, 0.0, 2.0, 1.0, 3.0, 1.0, 1.0, 1.0, 0.0, 2.0, 1.0, 1.0, 1.0, 1.0, 1.0, 2.0, 2.0, 3.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 2.0, 2.0, 1.0, 3.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 2.0, 2.0, 1.0, 3.0, 6.0, 1.0, 4.0, 1.0, 1.0, 0.0, 1.0, 1.0, 2.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0, 1.0, 3.0, 1.0, 2.0, 3.0, 1.0, 2.0, 1.0, 1.0, 0.0, 0.0, 1.0, 2.0, 3.0, 2.0, 3.0, 2.0, 2.0, 3.0, 2.0, 5.0, 3.0, 2.0, 2.0, 4.0, 5.0, 4.0, 3.0, 1.0, 1.0, 1.0, 2.0, 2.0, 2.0, 1.0, 2.0, 4.0, 3.0, 3.0, 1.0, 3.0, 0.0, 2.0, 1.0, 2.0, 3.0, 3.0, 3.0, 2.0, 2.0, 1.0, 0.0, 2.0, 2.0, 2.0, 0.0, 1.0, 1.0, 1.0, 1.0, 3.0, 2.0, 2.0, 1.0, 1.0, 2.0, 0.0, 0.0, 2.0, 3.0, 3.0, 1.0, 3.0, 4.0, 1.0, 4.0, 0.0, 1.0, 0.0, 0.0, 2.0, 1.0, 2.0, 1.0, 2.0, 2.0, 2.0, 0.0, 0.0, 1.0, 2.0, 0.0, 2.0, 2.0, 1.0, 2.0, 2.0, 2.0, 1.0, 1.0, 0.0, 1.0, 3.0, 2.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 4.0, 2.0, 4.0, 4.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 3.0, 1.0, 1.0, 0.0, 3.0, 1.0, 1.0, 2.0, 1.0, 2.0, 2.0, 0.0, 4.0, 2.0, 1.0, 1.0, 1.0, 0.0, 0.0, 2.0, 1.0, 3.0, 3.0, 0.0, 2.0, 2.0, 1.0, 3.0, 5.0, 2.0, 2.0, 0.0, 1.0, 2.0, 1.0, 2.0, 1.0, 0.0, 1.0, 3.0, 0.0, 1.0, 3.0, 1.0, 0.0, 0.0, 0.0, 2.0, 3.0, 2.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 2.0, 1.0, 2.0, 1.0, 2.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0, 1.0, 3.0, 1.0, 2.0, 1.0, 0.0, 1.0, 0.0, 1.0, 3.0, 1.0, 1.0, 2.0, 2.0, 2.0, 2.0, 3.0, 1.0, 0.0, 1.0, 0.0, 2.0, 1.0, 0.0, 1.0, 0.0, 2.0, 1.0, 1.0, 1.0, 2.0, 3.0, 1.0, 1.0, 2.0, 3.0, 2.0, 2.0, 1.0, 1.0, 2.0, 0.0, 2.0, 2.0, 2.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 2.0, 1.0, 2.0, 0.0, 0.0, 2.0, 1.0, 1.0, 0.0, 0.0, 2.0, 2.0, 3.0, 2.0, 2.0, 5.0, 5.0, 2.0, 2.0, 2.0, 2.0, 3.0, 4.0, 1.0, 3.0, 4.0, 1.0, 1.0, 2.0, 0.0, 0.0, 1.0, 3.0, 1.0, 1.0, 1.0, 3.0, 2.0, 0.0, 1.0, 1.0, 0.0, 2.0, 1.0, 3.0, 3.0, 4.0, 1.0, 5.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 4.0, 2.0, 3.0, 2.0, 0.0, 1.0, 1.0, 2.0, 1.0, 0.0, 2.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.1337418288933993, "mean_inference_ms": 0.3907639209276222, "mean_action_processing_ms": 0.029205988238671307, "mean_env_wait_ms": 0.4041595350631904, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 887040, "timesteps_this_iter": 0, "agent_timesteps_total": 3548160, "timers": {"sample_time_ms": 5127.11, "sample_throughput": 983.01, "load_time_ms": 0.167, "load_throughput": 30229218.018, "learn_time_ms": 127.104, "learn_throughput": 39652.547, "update_time_ms": 2.421}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 212.6502227783203, "policy_entropy": 7853.8641357421875, "policy_loss": 13.538550853729248, "vf_loss": 45.69131565093994}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 887040, "num_agent_steps_sampled": 3548160, "num_steps_trained": 887040, "num_agent_steps_trained": 3548160, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 1772, "training_iteration": 88, "trial_id": "71426_00000", "experiment_id": "84bca2f7b35f43248fca18d21abe2ebf", "date": "2024-06-12_03-00-57", "timestamp": 1718128857, "time_this_iter_s": 10.249685525894165, "time_total_s": 905.1988101005554, "pid": 363902, "hostname": "DESKTOP-LQ219J4", "node_ip": "192.168.46.185", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 20, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 5000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 500, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Base_Model", "custom_model_config": {"env": "rware", "env_args": {"n_agents": 4, "column_height": 1, "max_inactivity_steps": null, "max_steps": 500, "fast_obs": true, "msg_bits": 0, "sensor_range": 1, "shelf_rows": 1, "shelf_columns": 3, "request_queue_size": 4, "reward_type": "RewardType.INDIVIDUAL", "map_name": "customized_map", "map_size": "tiny", "difficulty": "medium"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": true, "force_coop": false, "local_mode": true, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 4, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 100, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64}, "algorithm": "ia2c", "space_obs": "Dict(obs:Box([-100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100.], [100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.], (112,), float32))", "space_act": "Discrete(5)", "num_agents": 4, "episode_limit": 500, "policy_mapping_info": {"all_scenario": {"description": "rware all scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2", "agent_3"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "rware_customized_map", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 10, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.IA2CTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_il.<locals>.<lambda> at 0x7f38086518b0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "grad_clip": 40.0, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "microbatch_size": null}, "time_since_restore": 905.1988101005554, "timesteps_since_restore": 0, "iterations_since_restore": 88, "perf": {"cpu_util_percent": 4.5, "ram_util_percent": 57.200000000000024}}
{"episode_reward_max": 18.0, "episode_reward_min": 0.0, "episode_reward_mean": 6.1, "episode_len_mean": 500.0, "episode_media": {}, "episodes_this_iter": 20, "policy_reward_min": {"shared_policy": 0.0}, "policy_reward_max": {"shared_policy": 6.0}, "policy_reward_mean": {"shared_policy": 1.525}, "custom_metrics": {}, "hist_stats": {"episode_reward": [2.0, 10.0, 9.0, 12.0, 16.0, 5.0, 7.0, 11.0, 6.0, 11.0, 5.0, 6.0, 4.0, 8.0, 3.0, 9.0, 12.0, 1.0, 6.0, 6.0, 3.0, 7.0, 6.0, 6.0, 3.0, 4.0, 14.0, 2.0, 3.0, 6.0, 5.0, 7.0, 7.0, 2.0, 9.0, 5.0, 12.0, 4.0, 4.0, 7.0, 1.0, 8.0, 5.0, 2.0, 0.0, 6.0, 6.0, 4.0, 7.0, 2.0, 7.0, 9.0, 2.0, 4.0, 4.0, 7.0, 8.0, 6.0, 6.0, 1.0, 3.0, 5.0, 4.0, 2.0, 9.0, 14.0, 9.0, 12.0, 4.0, 5.0, 7.0, 2.0, 9.0, 10.0, 3.0, 10.0, 4.0, 5.0, 1.0, 2.0, 5.0, 2.0, 6.0, 5.0, 9.0, 11.0, 5.0, 5.0, 11.0, 4.0, 1.0, 4.0, 8.0, 18.0, 2.0, 6.0, 4.0, 9.0, 8.0, 7.0], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500], "policy_shared_policy_reward": [1.0, 0.0, 0.0, 1.0, 2.0, 3.0, 2.0, 3.0, 2.0, 2.0, 3.0, 2.0, 5.0, 3.0, 2.0, 2.0, 4.0, 5.0, 4.0, 3.0, 1.0, 1.0, 1.0, 2.0, 2.0, 2.0, 1.0, 2.0, 4.0, 3.0, 3.0, 1.0, 3.0, 0.0, 2.0, 1.0, 2.0, 3.0, 3.0, 3.0, 2.0, 2.0, 1.0, 0.0, 2.0, 2.0, 2.0, 0.0, 1.0, 1.0, 1.0, 1.0, 3.0, 2.0, 2.0, 1.0, 1.0, 2.0, 0.0, 0.0, 2.0, 3.0, 3.0, 1.0, 3.0, 4.0, 1.0, 4.0, 0.0, 1.0, 0.0, 0.0, 2.0, 1.0, 2.0, 1.0, 2.0, 2.0, 2.0, 0.0, 0.0, 1.0, 2.0, 0.0, 2.0, 2.0, 1.0, 2.0, 2.0, 2.0, 1.0, 1.0, 0.0, 1.0, 3.0, 2.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 4.0, 2.0, 4.0, 4.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 3.0, 1.0, 1.0, 0.0, 3.0, 1.0, 1.0, 2.0, 1.0, 2.0, 2.0, 0.0, 4.0, 2.0, 1.0, 1.0, 1.0, 0.0, 0.0, 2.0, 1.0, 3.0, 3.0, 0.0, 2.0, 2.0, 1.0, 3.0, 5.0, 2.0, 2.0, 0.0, 1.0, 2.0, 1.0, 2.0, 1.0, 0.0, 1.0, 3.0, 0.0, 1.0, 3.0, 1.0, 0.0, 0.0, 0.0, 2.0, 3.0, 2.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 2.0, 1.0, 2.0, 1.0, 2.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0, 1.0, 3.0, 1.0, 2.0, 1.0, 0.0, 1.0, 0.0, 1.0, 3.0, 1.0, 1.0, 2.0, 2.0, 2.0, 2.0, 3.0, 1.0, 0.0, 1.0, 0.0, 2.0, 1.0, 0.0, 1.0, 0.0, 2.0, 1.0, 1.0, 1.0, 2.0, 3.0, 1.0, 1.0, 2.0, 3.0, 2.0, 2.0, 1.0, 1.0, 2.0, 0.0, 2.0, 2.0, 2.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 2.0, 1.0, 2.0, 0.0, 0.0, 2.0, 1.0, 1.0, 0.0, 0.0, 2.0, 2.0, 3.0, 2.0, 2.0, 5.0, 5.0, 2.0, 2.0, 2.0, 2.0, 3.0, 4.0, 1.0, 3.0, 4.0, 1.0, 1.0, 2.0, 0.0, 0.0, 1.0, 3.0, 1.0, 1.0, 1.0, 3.0, 2.0, 0.0, 1.0, 1.0, 0.0, 2.0, 1.0, 3.0, 3.0, 4.0, 1.0, 5.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 4.0, 2.0, 3.0, 2.0, 0.0, 1.0, 1.0, 2.0, 1.0, 0.0, 2.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 2.0, 1.0, 1.0, 0.0, 1.0, 0.0, 2.0, 1.0, 1.0, 2.0, 0.0, 1.0, 2.0, 2.0, 2.0, 2.0, 3.0, 2.0, 2.0, 3.0, 2.0, 4.0, 2.0, 0.0, 1.0, 2.0, 1.0, 1.0, 2.0, 1.0, 3.0, 2.0, 2.0, 4.0, 2.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 3.0, 1.0, 2.0, 2.0, 5.0, 2.0, 6.0, 5.0, 1.0, 0.0, 1.0, 0.0, 2.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0, 1.0, 2.0, 3.0, 3.0, 1.0, 2.0, 3.0, 2.0, 1.0, 2.0, 2.0, 1.0, 2.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.13373704066260333, "mean_inference_ms": 0.3907498835605124, "mean_action_processing_ms": 0.02920471143613258, "mean_env_wait_ms": 0.4041545862813032, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 897120, "timesteps_this_iter": 0, "agent_timesteps_total": 3588480, "timers": {"sample_time_ms": 5120.878, "sample_throughput": 984.206, "load_time_ms": 0.172, "load_throughput": 29360128.0, "learn_time_ms": 128.114, "learn_throughput": 39340.026, "update_time_ms": 2.428}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 475.2249755859375, "policy_entropy": 7773.154541015625, "policy_loss": 94.4375432729721, "vf_loss": 66.850510597229}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 897120, "num_agent_steps_sampled": 3588480, "num_steps_trained": 897120, "num_agent_steps_trained": 3588480, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 1792, "training_iteration": 89, "trial_id": "71426_00000", "experiment_id": "84bca2f7b35f43248fca18d21abe2ebf", "date": "2024-06-12_03-01-07", "timestamp": 1718128867, "time_this_iter_s": 10.184092998504639, "time_total_s": 915.3829030990601, "pid": 363902, "hostname": "DESKTOP-LQ219J4", "node_ip": "192.168.46.185", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 20, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 5000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 500, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Base_Model", "custom_model_config": {"env": "rware", "env_args": {"n_agents": 4, "column_height": 1, "max_inactivity_steps": null, "max_steps": 500, "fast_obs": true, "msg_bits": 0, "sensor_range": 1, "shelf_rows": 1, "shelf_columns": 3, "request_queue_size": 4, "reward_type": "RewardType.INDIVIDUAL", "map_name": "customized_map", "map_size": "tiny", "difficulty": "medium"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": true, "force_coop": false, "local_mode": true, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 4, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 100, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64}, "algorithm": "ia2c", "space_obs": "Dict(obs:Box([-100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100.], [100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.], (112,), float32))", "space_act": "Discrete(5)", "num_agents": 4, "episode_limit": 500, "policy_mapping_info": {"all_scenario": {"description": "rware all scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2", "agent_3"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "rware_customized_map", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 10, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.IA2CTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_il.<locals>.<lambda> at 0x7f382806ea60>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "grad_clip": 40.0, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "microbatch_size": null}, "time_since_restore": 915.3829030990601, "timesteps_since_restore": 0, "iterations_since_restore": 89, "perf": {"cpu_util_percent": 4.48, "ram_util_percent": 57.44666666666667}}
{"episode_reward_max": 18.0, "episode_reward_min": 0.0, "episode_reward_mean": 5.8, "episode_len_mean": 500.0, "episode_media": {}, "episodes_this_iter": 20, "policy_reward_min": {"shared_policy": 0.0}, "policy_reward_max": {"shared_policy": 6.0}, "policy_reward_mean": {"shared_policy": 1.45}, "custom_metrics": {}, "hist_stats": {"episode_reward": [3.0, 7.0, 6.0, 6.0, 3.0, 4.0, 14.0, 2.0, 3.0, 6.0, 5.0, 7.0, 7.0, 2.0, 9.0, 5.0, 12.0, 4.0, 4.0, 7.0, 1.0, 8.0, 5.0, 2.0, 0.0, 6.0, 6.0, 4.0, 7.0, 2.0, 7.0, 9.0, 2.0, 4.0, 4.0, 7.0, 8.0, 6.0, 6.0, 1.0, 3.0, 5.0, 4.0, 2.0, 9.0, 14.0, 9.0, 12.0, 4.0, 5.0, 7.0, 2.0, 9.0, 10.0, 3.0, 10.0, 4.0, 5.0, 1.0, 2.0, 5.0, 2.0, 6.0, 5.0, 9.0, 11.0, 5.0, 5.0, 11.0, 4.0, 1.0, 4.0, 8.0, 18.0, 2.0, 6.0, 4.0, 9.0, 8.0, 7.0, 4.0, 9.0, 3.0, 7.0, 9.0, 5.0, 4.0, 3.0, 8.0, 4.0, 4.0, 10.0, 2.0, 4.0, 7.0, 7.0, 2.0, 10.0, 5.0, 12.0], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500], "policy_shared_policy_reward": [0.0, 1.0, 2.0, 0.0, 2.0, 2.0, 1.0, 2.0, 2.0, 2.0, 1.0, 1.0, 0.0, 1.0, 3.0, 2.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 4.0, 2.0, 4.0, 4.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 3.0, 1.0, 1.0, 0.0, 3.0, 1.0, 1.0, 2.0, 1.0, 2.0, 2.0, 0.0, 4.0, 2.0, 1.0, 1.0, 1.0, 0.0, 0.0, 2.0, 1.0, 3.0, 3.0, 0.0, 2.0, 2.0, 1.0, 3.0, 5.0, 2.0, 2.0, 0.0, 1.0, 2.0, 1.0, 2.0, 1.0, 0.0, 1.0, 3.0, 0.0, 1.0, 3.0, 1.0, 0.0, 0.0, 0.0, 2.0, 3.0, 2.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 2.0, 1.0, 2.0, 1.0, 2.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0, 1.0, 3.0, 1.0, 2.0, 1.0, 0.0, 1.0, 0.0, 1.0, 3.0, 1.0, 1.0, 2.0, 2.0, 2.0, 2.0, 3.0, 1.0, 0.0, 1.0, 0.0, 2.0, 1.0, 0.0, 1.0, 0.0, 2.0, 1.0, 1.0, 1.0, 2.0, 3.0, 1.0, 1.0, 2.0, 3.0, 2.0, 2.0, 1.0, 1.0, 2.0, 0.0, 2.0, 2.0, 2.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 2.0, 1.0, 2.0, 0.0, 0.0, 2.0, 1.0, 1.0, 0.0, 0.0, 2.0, 2.0, 3.0, 2.0, 2.0, 5.0, 5.0, 2.0, 2.0, 2.0, 2.0, 3.0, 4.0, 1.0, 3.0, 4.0, 1.0, 1.0, 2.0, 0.0, 0.0, 1.0, 3.0, 1.0, 1.0, 1.0, 3.0, 2.0, 0.0, 1.0, 1.0, 0.0, 2.0, 1.0, 3.0, 3.0, 4.0, 1.0, 5.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 4.0, 2.0, 3.0, 2.0, 0.0, 1.0, 1.0, 2.0, 1.0, 0.0, 2.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 2.0, 1.0, 1.0, 0.0, 1.0, 0.0, 2.0, 1.0, 1.0, 2.0, 0.0, 1.0, 2.0, 2.0, 2.0, 2.0, 3.0, 2.0, 2.0, 3.0, 2.0, 4.0, 2.0, 0.0, 1.0, 2.0, 1.0, 1.0, 2.0, 1.0, 3.0, 2.0, 2.0, 4.0, 2.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 3.0, 1.0, 2.0, 2.0, 5.0, 2.0, 6.0, 5.0, 1.0, 0.0, 1.0, 0.0, 2.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0, 1.0, 2.0, 3.0, 3.0, 1.0, 2.0, 3.0, 2.0, 1.0, 2.0, 2.0, 1.0, 2.0, 1.0, 1.0, 0.0, 2.0, 3.0, 2.0, 3.0, 1.0, 1.0, 0.0, 1.0, 1.0, 2.0, 2.0, 2.0, 1.0, 2.0, 4.0, 1.0, 2.0, 2.0, 2.0, 0.0, 1.0, 1.0, 0.0, 1.0, 2.0, 2.0, 1.0, 0.0, 0.0, 3.0, 0.0, 3.0, 2.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 4.0, 2.0, 2.0, 2.0, 0.0, 0.0, 1.0, 1.0, 1.0, 2.0, 1.0, 0.0, 2.0, 0.0, 1.0, 4.0, 3.0, 2.0, 0.0, 2.0, 0.0, 1.0, 1.0, 0.0, 1.0, 3.0, 3.0, 3.0, 1.0, 2.0, 1.0, 1.0, 2.0, 2.0, 3.0, 5.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.13373415198906236, "mean_inference_ms": 0.3907426163428346, "mean_action_processing_ms": 0.029203704648370205, "mean_env_wait_ms": 0.4041482504494245, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 907200, "timesteps_this_iter": 0, "agent_timesteps_total": 3628800, "timers": {"sample_time_ms": 5124.669, "sample_throughput": 983.478, "load_time_ms": 0.16, "load_throughput": 31504161.192, "learn_time_ms": 127.673, "learn_throughput": 39475.847, "update_time_ms": 2.362}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 262.40093994140625, "policy_entropy": 7706.729736328125, "policy_loss": 46.96605634689331, "vf_loss": 57.35887813568115}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 907200, "num_agent_steps_sampled": 3628800, "num_steps_trained": 907200, "num_agent_steps_trained": 3628800, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 1812, "training_iteration": 90, "trial_id": "71426_00000", "experiment_id": "84bca2f7b35f43248fca18d21abe2ebf", "date": "2024-06-12_03-01-18", "timestamp": 1718128878, "time_this_iter_s": 10.248603582382202, "time_total_s": 925.6315066814423, "pid": 363902, "hostname": "DESKTOP-LQ219J4", "node_ip": "192.168.46.185", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 20, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 5000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 500, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Base_Model", "custom_model_config": {"env": "rware", "env_args": {"n_agents": 4, "column_height": 1, "max_inactivity_steps": null, "max_steps": 500, "fast_obs": true, "msg_bits": 0, "sensor_range": 1, "shelf_rows": 1, "shelf_columns": 3, "request_queue_size": 4, "reward_type": "RewardType.INDIVIDUAL", "map_name": "customized_map", "map_size": "tiny", "difficulty": "medium"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": true, "force_coop": false, "local_mode": true, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 4, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 100, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64}, "algorithm": "ia2c", "space_obs": "Dict(obs:Box([-100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100.], [100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.], (112,), float32))", "space_act": "Discrete(5)", "num_agents": 4, "episode_limit": 500, "policy_mapping_info": {"all_scenario": {"description": "rware all scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2", "agent_3"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "rware_customized_map", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 10, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.IA2CTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_il.<locals>.<lambda> at 0x7f380824d940>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "grad_clip": 40.0, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "microbatch_size": null}, "time_since_restore": 925.6315066814423, "timesteps_since_restore": 0, "iterations_since_restore": 90, "perf": {"cpu_util_percent": 4.6066666666666665, "ram_util_percent": 57.759999999999984}}
{"episode_reward_max": 18.0, "episode_reward_min": 0.0, "episode_reward_mean": 5.74, "episode_len_mean": 500.0, "episode_media": {}, "episodes_this_iter": 20, "policy_reward_min": {"shared_policy": 0.0}, "policy_reward_max": {"shared_policy": 6.0}, "policy_reward_mean": {"shared_policy": 1.435}, "custom_metrics": {}, "hist_stats": {"episode_reward": [1.0, 8.0, 5.0, 2.0, 0.0, 6.0, 6.0, 4.0, 7.0, 2.0, 7.0, 9.0, 2.0, 4.0, 4.0, 7.0, 8.0, 6.0, 6.0, 1.0, 3.0, 5.0, 4.0, 2.0, 9.0, 14.0, 9.0, 12.0, 4.0, 5.0, 7.0, 2.0, 9.0, 10.0, 3.0, 10.0, 4.0, 5.0, 1.0, 2.0, 5.0, 2.0, 6.0, 5.0, 9.0, 11.0, 5.0, 5.0, 11.0, 4.0, 1.0, 4.0, 8.0, 18.0, 2.0, 6.0, 4.0, 9.0, 8.0, 7.0, 4.0, 9.0, 3.0, 7.0, 9.0, 5.0, 4.0, 3.0, 8.0, 4.0, 4.0, 10.0, 2.0, 4.0, 7.0, 7.0, 2.0, 10.0, 5.0, 12.0, 9.0, 3.0, 11.0, 6.0, 3.0, 11.0, 8.0, 5.0, 2.0, 1.0, 11.0, 5.0, 1.0, 5.0, 4.0, 2.0, 8.0, 6.0, 6.0, 3.0], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500], "policy_shared_policy_reward": [1.0, 0.0, 0.0, 0.0, 2.0, 3.0, 2.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 2.0, 1.0, 2.0, 1.0, 2.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0, 1.0, 3.0, 1.0, 2.0, 1.0, 0.0, 1.0, 0.0, 1.0, 3.0, 1.0, 1.0, 2.0, 2.0, 2.0, 2.0, 3.0, 1.0, 0.0, 1.0, 0.0, 2.0, 1.0, 0.0, 1.0, 0.0, 2.0, 1.0, 1.0, 1.0, 2.0, 3.0, 1.0, 1.0, 2.0, 3.0, 2.0, 2.0, 1.0, 1.0, 2.0, 0.0, 2.0, 2.0, 2.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 2.0, 1.0, 2.0, 0.0, 0.0, 2.0, 1.0, 1.0, 0.0, 0.0, 2.0, 2.0, 3.0, 2.0, 2.0, 5.0, 5.0, 2.0, 2.0, 2.0, 2.0, 3.0, 4.0, 1.0, 3.0, 4.0, 1.0, 1.0, 2.0, 0.0, 0.0, 1.0, 3.0, 1.0, 1.0, 1.0, 3.0, 2.0, 0.0, 1.0, 1.0, 0.0, 2.0, 1.0, 3.0, 3.0, 4.0, 1.0, 5.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 4.0, 2.0, 3.0, 2.0, 0.0, 1.0, 1.0, 2.0, 1.0, 0.0, 2.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 2.0, 1.0, 1.0, 0.0, 1.0, 0.0, 2.0, 1.0, 1.0, 2.0, 0.0, 1.0, 2.0, 2.0, 2.0, 2.0, 3.0, 2.0, 2.0, 3.0, 2.0, 4.0, 2.0, 0.0, 1.0, 2.0, 1.0, 1.0, 2.0, 1.0, 3.0, 2.0, 2.0, 4.0, 2.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 3.0, 1.0, 2.0, 2.0, 5.0, 2.0, 6.0, 5.0, 1.0, 0.0, 1.0, 0.0, 2.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0, 1.0, 2.0, 3.0, 3.0, 1.0, 2.0, 3.0, 2.0, 1.0, 2.0, 2.0, 1.0, 2.0, 1.0, 1.0, 0.0, 2.0, 3.0, 2.0, 3.0, 1.0, 1.0, 0.0, 1.0, 1.0, 2.0, 2.0, 2.0, 1.0, 2.0, 4.0, 1.0, 2.0, 2.0, 2.0, 0.0, 1.0, 1.0, 0.0, 1.0, 2.0, 2.0, 1.0, 0.0, 0.0, 3.0, 0.0, 3.0, 2.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 4.0, 2.0, 2.0, 2.0, 0.0, 0.0, 1.0, 1.0, 1.0, 2.0, 1.0, 0.0, 2.0, 0.0, 1.0, 4.0, 3.0, 2.0, 0.0, 2.0, 0.0, 1.0, 1.0, 0.0, 1.0, 3.0, 3.0, 3.0, 1.0, 2.0, 1.0, 1.0, 2.0, 2.0, 3.0, 5.0, 3.0, 2.0, 1.0, 3.0, 1.0, 0.0, 1.0, 1.0, 4.0, 4.0, 0.0, 3.0, 2.0, 1.0, 1.0, 2.0, 1.0, 0.0, 1.0, 1.0, 1.0, 5.0, 3.0, 2.0, 2.0, 3.0, 1.0, 2.0, 1.0, 1.0, 1.0, 2.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 3.0, 1.0, 3.0, 4.0, 2.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 2.0, 3.0, 0.0, 3.0, 2.0, 2.0, 0.0, 2.0, 1.0, 2.0, 2.0, 1.0, 0.0, 1.0, 2.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.13372863115146114, "mean_inference_ms": 0.3907273874629435, "mean_action_processing_ms": 0.029202045839436908, "mean_env_wait_ms": 0.40413032141362715, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 917280, "timesteps_this_iter": 0, "agent_timesteps_total": 3669120, "timers": {"sample_time_ms": 5110.47, "sample_throughput": 986.211, "load_time_ms": 0.158, "load_throughput": 31985613.799, "learn_time_ms": 127.355, "learn_throughput": 39574.521, "update_time_ms": 2.358}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 265.68621826171875, "policy_entropy": 7836.9139404296875, "policy_loss": -46.70483207702637, "vf_loss": 30.516505479812622}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 917280, "num_agent_steps_sampled": 3669120, "num_steps_trained": 917280, "num_agent_steps_trained": 3669120, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 1832, "training_iteration": 91, "trial_id": "71426_00000", "experiment_id": "84bca2f7b35f43248fca18d21abe2ebf", "date": "2024-06-12_03-01-28", "timestamp": 1718128888, "time_this_iter_s": 10.222462177276611, "time_total_s": 935.8539688587189, "pid": 363902, "hostname": "DESKTOP-LQ219J4", "node_ip": "192.168.46.185", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 20, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 5000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 500, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Base_Model", "custom_model_config": {"env": "rware", "env_args": {"n_agents": 4, "column_height": 1, "max_inactivity_steps": null, "max_steps": 500, "fast_obs": true, "msg_bits": 0, "sensor_range": 1, "shelf_rows": 1, "shelf_columns": 3, "request_queue_size": 4, "reward_type": "RewardType.INDIVIDUAL", "map_name": "customized_map", "map_size": "tiny", "difficulty": "medium"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": true, "force_coop": false, "local_mode": true, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 4, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 100, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64}, "algorithm": "ia2c", "space_obs": "Dict(obs:Box([-100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100.], [100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.], (112,), float32))", "space_act": "Discrete(5)", "num_agents": 4, "episode_limit": 500, "policy_mapping_info": {"all_scenario": {"description": "rware all scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2", "agent_3"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "rware_customized_map", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 10, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.IA2CTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_il.<locals>.<lambda> at 0x7f3808645b80>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "grad_clip": 40.0, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "microbatch_size": null}, "time_since_restore": 935.8539688587189, "timesteps_since_restore": 0, "iterations_since_restore": 91, "perf": {"cpu_util_percent": 4.671428571428571, "ram_util_percent": 58.0}}
{"episode_reward_max": 18.0, "episode_reward_min": 1.0, "episode_reward_mean": 6.14, "episode_len_mean": 500.0, "episode_media": {}, "episodes_this_iter": 20, "policy_reward_min": {"shared_policy": 0.0}, "policy_reward_max": {"shared_policy": 6.0}, "policy_reward_mean": {"shared_policy": 1.535}, "custom_metrics": {}, "hist_stats": {"episode_reward": [3.0, 5.0, 4.0, 2.0, 9.0, 14.0, 9.0, 12.0, 4.0, 5.0, 7.0, 2.0, 9.0, 10.0, 3.0, 10.0, 4.0, 5.0, 1.0, 2.0, 5.0, 2.0, 6.0, 5.0, 9.0, 11.0, 5.0, 5.0, 11.0, 4.0, 1.0, 4.0, 8.0, 18.0, 2.0, 6.0, 4.0, 9.0, 8.0, 7.0, 4.0, 9.0, 3.0, 7.0, 9.0, 5.0, 4.0, 3.0, 8.0, 4.0, 4.0, 10.0, 2.0, 4.0, 7.0, 7.0, 2.0, 10.0, 5.0, 12.0, 9.0, 3.0, 11.0, 6.0, 3.0, 11.0, 8.0, 5.0, 2.0, 1.0, 11.0, 5.0, 1.0, 5.0, 4.0, 2.0, 8.0, 6.0, 6.0, 3.0, 6.0, 11.0, 5.0, 6.0, 13.0, 6.0, 7.0, 12.0, 11.0, 5.0, 9.0, 5.0, 6.0, 7.0, 4.0, 6.0, 2.0, 7.0, 4.0, 3.0], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500], "policy_shared_policy_reward": [1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 2.0, 1.0, 2.0, 0.0, 0.0, 2.0, 1.0, 1.0, 0.0, 0.0, 2.0, 2.0, 3.0, 2.0, 2.0, 5.0, 5.0, 2.0, 2.0, 2.0, 2.0, 3.0, 4.0, 1.0, 3.0, 4.0, 1.0, 1.0, 2.0, 0.0, 0.0, 1.0, 3.0, 1.0, 1.0, 1.0, 3.0, 2.0, 0.0, 1.0, 1.0, 0.0, 2.0, 1.0, 3.0, 3.0, 4.0, 1.0, 5.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 4.0, 2.0, 3.0, 2.0, 0.0, 1.0, 1.0, 2.0, 1.0, 0.0, 2.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 2.0, 1.0, 1.0, 0.0, 1.0, 0.0, 2.0, 1.0, 1.0, 2.0, 0.0, 1.0, 2.0, 2.0, 2.0, 2.0, 3.0, 2.0, 2.0, 3.0, 2.0, 4.0, 2.0, 0.0, 1.0, 2.0, 1.0, 1.0, 2.0, 1.0, 3.0, 2.0, 2.0, 4.0, 2.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 3.0, 1.0, 2.0, 2.0, 5.0, 2.0, 6.0, 5.0, 1.0, 0.0, 1.0, 0.0, 2.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0, 1.0, 2.0, 3.0, 3.0, 1.0, 2.0, 3.0, 2.0, 1.0, 2.0, 2.0, 1.0, 2.0, 1.0, 1.0, 0.0, 2.0, 3.0, 2.0, 3.0, 1.0, 1.0, 0.0, 1.0, 1.0, 2.0, 2.0, 2.0, 1.0, 2.0, 4.0, 1.0, 2.0, 2.0, 2.0, 0.0, 1.0, 1.0, 0.0, 1.0, 2.0, 2.0, 1.0, 0.0, 0.0, 3.0, 0.0, 3.0, 2.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 4.0, 2.0, 2.0, 2.0, 0.0, 0.0, 1.0, 1.0, 1.0, 2.0, 1.0, 0.0, 2.0, 0.0, 1.0, 4.0, 3.0, 2.0, 0.0, 2.0, 0.0, 1.0, 1.0, 0.0, 1.0, 3.0, 3.0, 3.0, 1.0, 2.0, 1.0, 1.0, 2.0, 2.0, 3.0, 5.0, 3.0, 2.0, 1.0, 3.0, 1.0, 0.0, 1.0, 1.0, 4.0, 4.0, 0.0, 3.0, 2.0, 1.0, 1.0, 2.0, 1.0, 0.0, 1.0, 1.0, 1.0, 5.0, 3.0, 2.0, 2.0, 3.0, 1.0, 2.0, 1.0, 1.0, 1.0, 2.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 3.0, 1.0, 3.0, 4.0, 2.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 2.0, 3.0, 0.0, 3.0, 2.0, 2.0, 0.0, 2.0, 1.0, 2.0, 2.0, 1.0, 0.0, 1.0, 2.0, 0.0, 2.0, 2.0, 1.0, 1.0, 3.0, 3.0, 3.0, 2.0, 1.0, 1.0, 2.0, 1.0, 1.0, 2.0, 1.0, 2.0, 4.0, 3.0, 4.0, 2.0, 1.0, 1.0, 2.0, 2.0, 3.0, 1.0, 2.0, 1.0, 2.0, 5.0, 2.0, 3.0, 1.0, 4.0, 3.0, 3.0, 2.0, 1.0, 1.0, 1.0, 3.0, 2.0, 3.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0, 3.0, 1.0, 1.0, 2.0, 1.0, 2.0, 2.0, 1.0, 1.0, 1.0, 1.0, 1.0, 2.0, 2.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 2.0, 2.0, 2.0, 0.0, 1.0, 1.0, 2.0, 0.0, 1.0, 2.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.1337252305665919, "mean_inference_ms": 0.3907254428008004, "mean_action_processing_ms": 0.029201482992279634, "mean_env_wait_ms": 0.4041175555592421, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 927360, "timesteps_this_iter": 0, "agent_timesteps_total": 3709440, "timers": {"sample_time_ms": 5120.163, "sample_throughput": 984.344, "load_time_ms": 0.156, "load_throughput": 32283586.072, "learn_time_ms": 127.835, "learn_throughput": 39425.87, "update_time_ms": 2.362}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 333.8828125, "policy_entropy": 7800.109130859375, "policy_loss": 29.026837825775146, "vf_loss": 58.85378932952881}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 927360, "num_agent_steps_sampled": 3709440, "num_steps_trained": 927360, "num_agent_steps_trained": 3709440, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 1852, "training_iteration": 92, "trial_id": "71426_00000", "experiment_id": "84bca2f7b35f43248fca18d21abe2ebf", "date": "2024-06-12_03-01-38", "timestamp": 1718128898, "time_this_iter_s": 10.225271463394165, "time_total_s": 946.079240322113, "pid": 363902, "hostname": "DESKTOP-LQ219J4", "node_ip": "192.168.46.185", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 20, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 5000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 500, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Base_Model", "custom_model_config": {"env": "rware", "env_args": {"n_agents": 4, "column_height": 1, "max_inactivity_steps": null, "max_steps": 500, "fast_obs": true, "msg_bits": 0, "sensor_range": 1, "shelf_rows": 1, "shelf_columns": 3, "request_queue_size": 4, "reward_type": "RewardType.INDIVIDUAL", "map_name": "customized_map", "map_size": "tiny", "difficulty": "medium"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": true, "force_coop": false, "local_mode": true, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 4, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 100, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64}, "algorithm": "ia2c", "space_obs": "Dict(obs:Box([-100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100.], [100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.], (112,), float32))", "space_act": "Discrete(5)", "num_agents": 4, "episode_limit": 500, "policy_mapping_info": {"all_scenario": {"description": "rware all scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2", "agent_3"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "rware_customized_map", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 10, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.IA2CTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_il.<locals>.<lambda> at 0x7f380824d4c0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "grad_clip": 40.0, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "microbatch_size": null}, "time_since_restore": 946.079240322113, "timesteps_since_restore": 0, "iterations_since_restore": 92, "perf": {"cpu_util_percent": 4.346666666666666, "ram_util_percent": 58.299999999999976}}
{"episode_reward_max": 18.0, "episode_reward_min": 1.0, "episode_reward_mean": 6.23, "episode_len_mean": 500.0, "episode_media": {}, "episodes_this_iter": 20, "policy_reward_min": {"shared_policy": 0.0}, "policy_reward_max": {"shared_policy": 6.0}, "policy_reward_mean": {"shared_policy": 1.5575}, "custom_metrics": {}, "hist_stats": {"episode_reward": [5.0, 2.0, 6.0, 5.0, 9.0, 11.0, 5.0, 5.0, 11.0, 4.0, 1.0, 4.0, 8.0, 18.0, 2.0, 6.0, 4.0, 9.0, 8.0, 7.0, 4.0, 9.0, 3.0, 7.0, 9.0, 5.0, 4.0, 3.0, 8.0, 4.0, 4.0, 10.0, 2.0, 4.0, 7.0, 7.0, 2.0, 10.0, 5.0, 12.0, 9.0, 3.0, 11.0, 6.0, 3.0, 11.0, 8.0, 5.0, 2.0, 1.0, 11.0, 5.0, 1.0, 5.0, 4.0, 2.0, 8.0, 6.0, 6.0, 3.0, 6.0, 11.0, 5.0, 6.0, 13.0, 6.0, 7.0, 12.0, 11.0, 5.0, 9.0, 5.0, 6.0, 7.0, 4.0, 6.0, 2.0, 7.0, 4.0, 3.0, 6.0, 8.0, 6.0, 6.0, 6.0, 6.0, 4.0, 5.0, 8.0, 3.0, 6.0, 7.0, 10.0, 4.0, 6.0, 9.0, 8.0, 6.0, 9.0, 6.0], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500], "policy_shared_policy_reward": [1.0, 1.0, 2.0, 1.0, 1.0, 0.0, 1.0, 0.0, 2.0, 1.0, 1.0, 2.0, 0.0, 1.0, 2.0, 2.0, 2.0, 2.0, 3.0, 2.0, 2.0, 3.0, 2.0, 4.0, 2.0, 0.0, 1.0, 2.0, 1.0, 1.0, 2.0, 1.0, 3.0, 2.0, 2.0, 4.0, 2.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 3.0, 1.0, 2.0, 2.0, 5.0, 2.0, 6.0, 5.0, 1.0, 0.0, 1.0, 0.0, 2.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0, 1.0, 2.0, 3.0, 3.0, 1.0, 2.0, 3.0, 2.0, 1.0, 2.0, 2.0, 1.0, 2.0, 1.0, 1.0, 0.0, 2.0, 3.0, 2.0, 3.0, 1.0, 1.0, 0.0, 1.0, 1.0, 2.0, 2.0, 2.0, 1.0, 2.0, 4.0, 1.0, 2.0, 2.0, 2.0, 0.0, 1.0, 1.0, 0.0, 1.0, 2.0, 2.0, 1.0, 0.0, 0.0, 3.0, 0.0, 3.0, 2.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 4.0, 2.0, 2.0, 2.0, 0.0, 0.0, 1.0, 1.0, 1.0, 2.0, 1.0, 0.0, 2.0, 0.0, 1.0, 4.0, 3.0, 2.0, 0.0, 2.0, 0.0, 1.0, 1.0, 0.0, 1.0, 3.0, 3.0, 3.0, 1.0, 2.0, 1.0, 1.0, 2.0, 2.0, 3.0, 5.0, 3.0, 2.0, 1.0, 3.0, 1.0, 0.0, 1.0, 1.0, 4.0, 4.0, 0.0, 3.0, 2.0, 1.0, 1.0, 2.0, 1.0, 0.0, 1.0, 1.0, 1.0, 5.0, 3.0, 2.0, 2.0, 3.0, 1.0, 2.0, 1.0, 1.0, 1.0, 2.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 3.0, 1.0, 3.0, 4.0, 2.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 2.0, 3.0, 0.0, 3.0, 2.0, 2.0, 0.0, 2.0, 1.0, 2.0, 2.0, 1.0, 0.0, 1.0, 2.0, 0.0, 2.0, 2.0, 1.0, 1.0, 3.0, 3.0, 3.0, 2.0, 1.0, 1.0, 2.0, 1.0, 1.0, 2.0, 1.0, 2.0, 4.0, 3.0, 4.0, 2.0, 1.0, 1.0, 2.0, 2.0, 3.0, 1.0, 2.0, 1.0, 2.0, 5.0, 2.0, 3.0, 1.0, 4.0, 3.0, 3.0, 2.0, 1.0, 1.0, 1.0, 3.0, 2.0, 3.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0, 3.0, 1.0, 1.0, 2.0, 1.0, 2.0, 2.0, 1.0, 1.0, 1.0, 1.0, 1.0, 2.0, 2.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 2.0, 2.0, 2.0, 0.0, 1.0, 1.0, 2.0, 0.0, 1.0, 2.0, 0.0, 1.0, 1.0, 2.0, 2.0, 2.0, 3.0, 2.0, 1.0, 1.0, 2.0, 2.0, 1.0, 1.0, 1.0, 3.0, 1.0, 2.0, 1.0, 1.0, 2.0, 1.0, 1.0, 2.0, 2.0, 0.0, 2.0, 2.0, 0.0, 2.0, 2.0, 0.0, 1.0, 4.0, 1.0, 1.0, 2.0, 1.0, 0.0, 1.0, 1.0, 2.0, 2.0, 1.0, 1.0, 0.0, 4.0, 1.0, 2.0, 1.0, 3.0, 3.0, 3.0, 0.0, 2.0, 1.0, 1.0, 1.0, 1.0, 3.0, 1.0, 2.0, 2.0, 2.0, 3.0, 3.0, 2.0, 1.0, 2.0, 2.0, 0.0, 2.0, 2.0, 4.0, 3.0, 1.0, 1.0, 2.0, 2.0, 1.0, 1.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.13372165142527007, "mean_inference_ms": 0.39071928566956404, "mean_action_processing_ms": 0.02920059681736664, "mean_env_wait_ms": 0.40410195726773734, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 937440, "timesteps_this_iter": 0, "agent_timesteps_total": 3749760, "timers": {"sample_time_ms": 5116.824, "sample_throughput": 984.986, "load_time_ms": 0.159, "load_throughput": 31778851.714, "learn_time_ms": 128.135, "learn_throughput": 39333.401, "update_time_ms": 2.374}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 408.97760009765625, "policy_entropy": 7746.6776123046875, "policy_loss": -14.710384368896484, "vf_loss": 54.15894412994385}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 937440, "num_agent_steps_sampled": 3749760, "num_steps_trained": 937440, "num_agent_steps_trained": 3749760, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 1872, "training_iteration": 93, "trial_id": "71426_00000", "experiment_id": "84bca2f7b35f43248fca18d21abe2ebf", "date": "2024-06-12_03-01-48", "timestamp": 1718128908, "time_this_iter_s": 10.214319467544556, "time_total_s": 956.2935597896576, "pid": 363902, "hostname": "DESKTOP-LQ219J4", "node_ip": "192.168.46.185", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 20, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 5000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 500, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Base_Model", "custom_model_config": {"env": "rware", "env_args": {"n_agents": 4, "column_height": 1, "max_inactivity_steps": null, "max_steps": 500, "fast_obs": true, "msg_bits": 0, "sensor_range": 1, "shelf_rows": 1, "shelf_columns": 3, "request_queue_size": 4, "reward_type": "RewardType.INDIVIDUAL", "map_name": "customized_map", "map_size": "tiny", "difficulty": "medium"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": true, "force_coop": false, "local_mode": true, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 4, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 100, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64}, "algorithm": "ia2c", "space_obs": "Dict(obs:Box([-100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100.], [100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.], (112,), float32))", "space_act": "Discrete(5)", "num_agents": 4, "episode_limit": 500, "policy_mapping_info": {"all_scenario": {"description": "rware all scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2", "agent_3"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "rware_customized_map", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 10, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.IA2CTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_il.<locals>.<lambda> at 0x7f38081d59d0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "grad_clip": 40.0, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "microbatch_size": null}, "time_since_restore": 956.2935597896576, "timesteps_since_restore": 0, "iterations_since_restore": 93, "perf": {"cpu_util_percent": 4.328571428571428, "ram_util_percent": 58.53571428571429}}
{"episode_reward_max": 13.0, "episode_reward_min": 1.0, "episode_reward_mean": 6.22, "episode_len_mean": 500.0, "episode_media": {}, "episodes_this_iter": 20, "policy_reward_min": {"shared_policy": 0.0}, "policy_reward_max": {"shared_policy": 5.0}, "policy_reward_mean": {"shared_policy": 1.555}, "custom_metrics": {}, "hist_stats": {"episode_reward": [4.0, 9.0, 3.0, 7.0, 9.0, 5.0, 4.0, 3.0, 8.0, 4.0, 4.0, 10.0, 2.0, 4.0, 7.0, 7.0, 2.0, 10.0, 5.0, 12.0, 9.0, 3.0, 11.0, 6.0, 3.0, 11.0, 8.0, 5.0, 2.0, 1.0, 11.0, 5.0, 1.0, 5.0, 4.0, 2.0, 8.0, 6.0, 6.0, 3.0, 6.0, 11.0, 5.0, 6.0, 13.0, 6.0, 7.0, 12.0, 11.0, 5.0, 9.0, 5.0, 6.0, 7.0, 4.0, 6.0, 2.0, 7.0, 4.0, 3.0, 6.0, 8.0, 6.0, 6.0, 6.0, 6.0, 4.0, 5.0, 8.0, 3.0, 6.0, 7.0, 10.0, 4.0, 6.0, 9.0, 8.0, 6.0, 9.0, 6.0, 9.0, 5.0, 13.0, 6.0, 10.0, 7.0, 4.0, 4.0, 7.0, 3.0, 5.0, 3.0, 2.0, 6.0, 3.0, 11.0, 4.0, 5.0, 9.0, 13.0], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500], "policy_shared_policy_reward": [1.0, 1.0, 0.0, 2.0, 3.0, 2.0, 3.0, 1.0, 1.0, 0.0, 1.0, 1.0, 2.0, 2.0, 2.0, 1.0, 2.0, 4.0, 1.0, 2.0, 2.0, 2.0, 0.0, 1.0, 1.0, 0.0, 1.0, 2.0, 2.0, 1.0, 0.0, 0.0, 3.0, 0.0, 3.0, 2.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 4.0, 2.0, 2.0, 2.0, 0.0, 0.0, 1.0, 1.0, 1.0, 2.0, 1.0, 0.0, 2.0, 0.0, 1.0, 4.0, 3.0, 2.0, 0.0, 2.0, 0.0, 1.0, 1.0, 0.0, 1.0, 3.0, 3.0, 3.0, 1.0, 2.0, 1.0, 1.0, 2.0, 2.0, 3.0, 5.0, 3.0, 2.0, 1.0, 3.0, 1.0, 0.0, 1.0, 1.0, 4.0, 4.0, 0.0, 3.0, 2.0, 1.0, 1.0, 2.0, 1.0, 0.0, 1.0, 1.0, 1.0, 5.0, 3.0, 2.0, 2.0, 3.0, 1.0, 2.0, 1.0, 1.0, 1.0, 2.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 3.0, 1.0, 3.0, 4.0, 2.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 2.0, 3.0, 0.0, 3.0, 2.0, 2.0, 0.0, 2.0, 1.0, 2.0, 2.0, 1.0, 0.0, 1.0, 2.0, 0.0, 2.0, 2.0, 1.0, 1.0, 3.0, 3.0, 3.0, 2.0, 1.0, 1.0, 2.0, 1.0, 1.0, 2.0, 1.0, 2.0, 4.0, 3.0, 4.0, 2.0, 1.0, 1.0, 2.0, 2.0, 3.0, 1.0, 2.0, 1.0, 2.0, 5.0, 2.0, 3.0, 1.0, 4.0, 3.0, 3.0, 2.0, 1.0, 1.0, 1.0, 3.0, 2.0, 3.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0, 3.0, 1.0, 1.0, 2.0, 1.0, 2.0, 2.0, 1.0, 1.0, 1.0, 1.0, 1.0, 2.0, 2.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 2.0, 2.0, 2.0, 0.0, 1.0, 1.0, 2.0, 0.0, 1.0, 2.0, 0.0, 1.0, 1.0, 2.0, 2.0, 2.0, 3.0, 2.0, 1.0, 1.0, 2.0, 2.0, 1.0, 1.0, 1.0, 3.0, 1.0, 2.0, 1.0, 1.0, 2.0, 1.0, 1.0, 2.0, 2.0, 0.0, 2.0, 2.0, 0.0, 2.0, 2.0, 0.0, 1.0, 4.0, 1.0, 1.0, 2.0, 1.0, 0.0, 1.0, 1.0, 2.0, 2.0, 1.0, 1.0, 0.0, 4.0, 1.0, 2.0, 1.0, 3.0, 3.0, 3.0, 0.0, 2.0, 1.0, 1.0, 1.0, 1.0, 3.0, 1.0, 2.0, 2.0, 2.0, 3.0, 3.0, 2.0, 1.0, 2.0, 2.0, 0.0, 2.0, 2.0, 4.0, 3.0, 1.0, 1.0, 2.0, 2.0, 1.0, 1.0, 3.0, 3.0, 1.0, 2.0, 0.0, 2.0, 2.0, 1.0, 3.0, 5.0, 1.0, 4.0, 1.0, 2.0, 1.0, 2.0, 3.0, 1.0, 3.0, 3.0, 1.0, 2.0, 1.0, 3.0, 1.0, 1.0, 0.0, 2.0, 0.0, 1.0, 2.0, 1.0, 3.0, 2.0, 1.0, 1.0, 0.0, 2.0, 0.0, 1.0, 1.0, 1.0, 1.0, 2.0, 0.0, 0.0, 1.0, 2.0, 1.0, 0.0, 0.0, 1.0, 2.0, 1.0, 0.0, 3.0, 1.0, 0.0, 1.0, 1.0, 3.0, 3.0, 4.0, 1.0, 1.0, 2.0, 1.0, 0.0, 1.0, 2.0, 1.0, 1.0, 2.0, 2.0, 3.0, 2.0, 5.0, 3.0, 4.0, 1.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.13372047035637738, "mean_inference_ms": 0.39072258244162605, "mean_action_processing_ms": 0.029201258318602225, "mean_env_wait_ms": 0.40411187905599105, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 947520, "timesteps_this_iter": 0, "agent_timesteps_total": 3790080, "timers": {"sample_time_ms": 5134.684, "sample_throughput": 981.56, "load_time_ms": 0.158, "load_throughput": 31817116.436, "learn_time_ms": 127.111, "learn_throughput": 39650.449, "update_time_ms": 2.354}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 150.218505859375, "policy_entropy": 7791.2418212890625, "policy_loss": -27.441522002220154, "vf_loss": 38.773786544799805}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 947520, "num_agent_steps_sampled": 3790080, "num_steps_trained": 947520, "num_agent_steps_trained": 3790080, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 1892, "training_iteration": 94, "trial_id": "71426_00000", "experiment_id": "84bca2f7b35f43248fca18d21abe2ebf", "date": "2024-06-12_03-01-59", "timestamp": 1718128919, "time_this_iter_s": 10.358267545700073, "time_total_s": 966.6518273353577, "pid": 363902, "hostname": "DESKTOP-LQ219J4", "node_ip": "192.168.46.185", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 20, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 5000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 500, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Base_Model", "custom_model_config": {"env": "rware", "env_args": {"n_agents": 4, "column_height": 1, "max_inactivity_steps": null, "max_steps": 500, "fast_obs": true, "msg_bits": 0, "sensor_range": 1, "shelf_rows": 1, "shelf_columns": 3, "request_queue_size": 4, "reward_type": "RewardType.INDIVIDUAL", "map_name": "customized_map", "map_size": "tiny", "difficulty": "medium"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": true, "force_coop": false, "local_mode": true, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 4, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 100, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64}, "algorithm": "ia2c", "space_obs": "Dict(obs:Box([-100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100.], [100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.], (112,), float32))", "space_act": "Discrete(5)", "num_agents": 4, "episode_limit": 500, "policy_mapping_info": {"all_scenario": {"description": "rware all scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2", "agent_3"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "rware_customized_map", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 10, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.IA2CTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_il.<locals>.<lambda> at 0x7f38082f8e50>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "grad_clip": 40.0, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "microbatch_size": null}, "time_since_restore": 966.6518273353577, "timesteps_since_restore": 0, "iterations_since_restore": 94, "perf": {"cpu_util_percent": 4.760000000000001, "ram_util_percent": 58.799999999999976}}
{"episode_reward_max": 13.0, "episode_reward_min": 1.0, "episode_reward_mean": 6.25, "episode_len_mean": 500.0, "episode_media": {}, "episodes_this_iter": 20, "policy_reward_min": {"shared_policy": 0.0}, "policy_reward_max": {"shared_policy": 5.0}, "policy_reward_mean": {"shared_policy": 1.5625}, "custom_metrics": {}, "hist_stats": {"episode_reward": [9.0, 3.0, 11.0, 6.0, 3.0, 11.0, 8.0, 5.0, 2.0, 1.0, 11.0, 5.0, 1.0, 5.0, 4.0, 2.0, 8.0, 6.0, 6.0, 3.0, 6.0, 11.0, 5.0, 6.0, 13.0, 6.0, 7.0, 12.0, 11.0, 5.0, 9.0, 5.0, 6.0, 7.0, 4.0, 6.0, 2.0, 7.0, 4.0, 3.0, 6.0, 8.0, 6.0, 6.0, 6.0, 6.0, 4.0, 5.0, 8.0, 3.0, 6.0, 7.0, 10.0, 4.0, 6.0, 9.0, 8.0, 6.0, 9.0, 6.0, 9.0, 5.0, 13.0, 6.0, 10.0, 7.0, 4.0, 4.0, 7.0, 3.0, 5.0, 3.0, 2.0, 6.0, 3.0, 11.0, 4.0, 5.0, 9.0, 13.0, 7.0, 5.0, 6.0, 7.0, 7.0, 3.0, 4.0, 9.0, 6.0, 6.0, 5.0, 6.0, 9.0, 10.0, 3.0, 2.0, 6.0, 4.0, 12.0, 5.0], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500], "policy_shared_policy_reward": [3.0, 2.0, 1.0, 3.0, 1.0, 0.0, 1.0, 1.0, 4.0, 4.0, 0.0, 3.0, 2.0, 1.0, 1.0, 2.0, 1.0, 0.0, 1.0, 1.0, 1.0, 5.0, 3.0, 2.0, 2.0, 3.0, 1.0, 2.0, 1.0, 1.0, 1.0, 2.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 3.0, 1.0, 3.0, 4.0, 2.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 2.0, 3.0, 0.0, 3.0, 2.0, 2.0, 0.0, 2.0, 1.0, 2.0, 2.0, 1.0, 0.0, 1.0, 2.0, 0.0, 2.0, 2.0, 1.0, 1.0, 3.0, 3.0, 3.0, 2.0, 1.0, 1.0, 2.0, 1.0, 1.0, 2.0, 1.0, 2.0, 4.0, 3.0, 4.0, 2.0, 1.0, 1.0, 2.0, 2.0, 3.0, 1.0, 2.0, 1.0, 2.0, 5.0, 2.0, 3.0, 1.0, 4.0, 3.0, 3.0, 2.0, 1.0, 1.0, 1.0, 3.0, 2.0, 3.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0, 3.0, 1.0, 1.0, 2.0, 1.0, 2.0, 2.0, 1.0, 1.0, 1.0, 1.0, 1.0, 2.0, 2.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 2.0, 2.0, 2.0, 0.0, 1.0, 1.0, 2.0, 0.0, 1.0, 2.0, 0.0, 1.0, 1.0, 2.0, 2.0, 2.0, 3.0, 2.0, 1.0, 1.0, 2.0, 2.0, 1.0, 1.0, 1.0, 3.0, 1.0, 2.0, 1.0, 1.0, 2.0, 1.0, 1.0, 2.0, 2.0, 0.0, 2.0, 2.0, 0.0, 2.0, 2.0, 0.0, 1.0, 4.0, 1.0, 1.0, 2.0, 1.0, 0.0, 1.0, 1.0, 2.0, 2.0, 1.0, 1.0, 0.0, 4.0, 1.0, 2.0, 1.0, 3.0, 3.0, 3.0, 0.0, 2.0, 1.0, 1.0, 1.0, 1.0, 3.0, 1.0, 2.0, 2.0, 2.0, 3.0, 3.0, 2.0, 1.0, 2.0, 2.0, 0.0, 2.0, 2.0, 4.0, 3.0, 1.0, 1.0, 2.0, 2.0, 1.0, 1.0, 3.0, 3.0, 1.0, 2.0, 0.0, 2.0, 2.0, 1.0, 3.0, 5.0, 1.0, 4.0, 1.0, 2.0, 1.0, 2.0, 3.0, 1.0, 3.0, 3.0, 1.0, 2.0, 1.0, 3.0, 1.0, 1.0, 0.0, 2.0, 0.0, 1.0, 2.0, 1.0, 3.0, 2.0, 1.0, 1.0, 0.0, 2.0, 0.0, 1.0, 1.0, 1.0, 1.0, 2.0, 0.0, 0.0, 1.0, 2.0, 1.0, 0.0, 0.0, 1.0, 2.0, 1.0, 0.0, 3.0, 1.0, 0.0, 1.0, 1.0, 3.0, 3.0, 4.0, 1.0, 1.0, 2.0, 1.0, 0.0, 1.0, 2.0, 1.0, 1.0, 2.0, 2.0, 3.0, 2.0, 5.0, 3.0, 4.0, 1.0, 2.0, 3.0, 1.0, 1.0, 1.0, 1.0, 1.0, 2.0, 2.0, 0.0, 2.0, 2.0, 2.0, 1.0, 2.0, 2.0, 1.0, 2.0, 2.0, 2.0, 1.0, 1.0, 0.0, 1.0, 0.0, 2.0, 1.0, 1.0, 2.0, 3.0, 1.0, 3.0, 1.0, 1.0, 2.0, 2.0, 1.0, 2.0, 2.0, 1.0, 1.0, 2.0, 0.0, 2.0, 1.0, 1.0, 2.0, 2.0, 1.0, 3.0, 2.0, 3.0, 2.0, 3.0, 1.0, 4.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 3.0, 1.0, 1.0, 0.0, 2.0, 1.0, 1.0, 3.0, 1.0, 4.0, 4.0, 2.0, 1.0, 1.0, 1.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.1337208302195769, "mean_inference_ms": 0.3907262038756645, "mean_action_processing_ms": 0.029201916085824606, "mean_env_wait_ms": 0.4041198510427229, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 957600, "timesteps_this_iter": 0, "agent_timesteps_total": 3830400, "timers": {"sample_time_ms": 5134.29, "sample_throughput": 981.635, "load_time_ms": 0.159, "load_throughput": 31702597.72, "learn_time_ms": 127.195, "learn_throughput": 39624.333, "update_time_ms": 2.405}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 343.8476867675781, "policy_entropy": 7832.975830078125, "policy_loss": 22.546863555908203, "vf_loss": 53.62693214416504}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 957600, "num_agent_steps_sampled": 3830400, "num_steps_trained": 957600, "num_agent_steps_trained": 3830400, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 1912, "training_iteration": 95, "trial_id": "71426_00000", "experiment_id": "84bca2f7b35f43248fca18d21abe2ebf", "date": "2024-06-12_03-02-09", "timestamp": 1718128929, "time_this_iter_s": 10.255039930343628, "time_total_s": 976.9068672657013, "pid": 363902, "hostname": "DESKTOP-LQ219J4", "node_ip": "192.168.46.185", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 20, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 5000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 500, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Base_Model", "custom_model_config": {"env": "rware", "env_args": {"n_agents": 4, "column_height": 1, "max_inactivity_steps": null, "max_steps": 500, "fast_obs": true, "msg_bits": 0, "sensor_range": 1, "shelf_rows": 1, "shelf_columns": 3, "request_queue_size": 4, "reward_type": "RewardType.INDIVIDUAL", "map_name": "customized_map", "map_size": "tiny", "difficulty": "medium"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": true, "force_coop": false, "local_mode": true, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 4, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 100, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64}, "algorithm": "ia2c", "space_obs": "Dict(obs:Box([-100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100.], [100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.], (112,), float32))", "space_act": "Discrete(5)", "num_agents": 4, "episode_limit": 500, "policy_mapping_info": {"all_scenario": {"description": "rware all scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2", "agent_3"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "rware_customized_map", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 10, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.IA2CTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_il.<locals>.<lambda> at 0x7f38082f8d30>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "grad_clip": 40.0, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "microbatch_size": null}, "time_since_restore": 976.9068672657013, "timesteps_since_restore": 0, "iterations_since_restore": 95, "perf": {"cpu_util_percent": 4.693333333333333, "ram_util_percent": 59.10000000000001}}
{"episode_reward_max": 13.0, "episode_reward_min": 2.0, "episode_reward_mean": 6.38, "episode_len_mean": 500.0, "episode_media": {}, "episodes_this_iter": 20, "policy_reward_min": {"shared_policy": 0.0}, "policy_reward_max": {"shared_policy": 5.0}, "policy_reward_mean": {"shared_policy": 1.595}, "custom_metrics": {}, "hist_stats": {"episode_reward": [6.0, 11.0, 5.0, 6.0, 13.0, 6.0, 7.0, 12.0, 11.0, 5.0, 9.0, 5.0, 6.0, 7.0, 4.0, 6.0, 2.0, 7.0, 4.0, 3.0, 6.0, 8.0, 6.0, 6.0, 6.0, 6.0, 4.0, 5.0, 8.0, 3.0, 6.0, 7.0, 10.0, 4.0, 6.0, 9.0, 8.0, 6.0, 9.0, 6.0, 9.0, 5.0, 13.0, 6.0, 10.0, 7.0, 4.0, 4.0, 7.0, 3.0, 5.0, 3.0, 2.0, 6.0, 3.0, 11.0, 4.0, 5.0, 9.0, 13.0, 7.0, 5.0, 6.0, 7.0, 7.0, 3.0, 4.0, 9.0, 6.0, 6.0, 5.0, 6.0, 9.0, 10.0, 3.0, 2.0, 6.0, 4.0, 12.0, 5.0, 4.0, 11.0, 2.0, 10.0, 3.0, 11.0, 9.0, 6.0, 8.0, 3.0, 7.0, 6.0, 4.0, 4.0, 4.0, 3.0, 5.0, 10.0, 3.0, 10.0], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500], "policy_shared_policy_reward": [2.0, 2.0, 1.0, 1.0, 3.0, 3.0, 3.0, 2.0, 1.0, 1.0, 2.0, 1.0, 1.0, 2.0, 1.0, 2.0, 4.0, 3.0, 4.0, 2.0, 1.0, 1.0, 2.0, 2.0, 3.0, 1.0, 2.0, 1.0, 2.0, 5.0, 2.0, 3.0, 1.0, 4.0, 3.0, 3.0, 2.0, 1.0, 1.0, 1.0, 3.0, 2.0, 3.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0, 3.0, 1.0, 1.0, 2.0, 1.0, 2.0, 2.0, 1.0, 1.0, 1.0, 1.0, 1.0, 2.0, 2.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 2.0, 2.0, 2.0, 0.0, 1.0, 1.0, 2.0, 0.0, 1.0, 2.0, 0.0, 1.0, 1.0, 2.0, 2.0, 2.0, 3.0, 2.0, 1.0, 1.0, 2.0, 2.0, 1.0, 1.0, 1.0, 3.0, 1.0, 2.0, 1.0, 1.0, 2.0, 1.0, 1.0, 2.0, 2.0, 0.0, 2.0, 2.0, 0.0, 2.0, 2.0, 0.0, 1.0, 4.0, 1.0, 1.0, 2.0, 1.0, 0.0, 1.0, 1.0, 2.0, 2.0, 1.0, 1.0, 0.0, 4.0, 1.0, 2.0, 1.0, 3.0, 3.0, 3.0, 0.0, 2.0, 1.0, 1.0, 1.0, 1.0, 3.0, 1.0, 2.0, 2.0, 2.0, 3.0, 3.0, 2.0, 1.0, 2.0, 2.0, 0.0, 2.0, 2.0, 4.0, 3.0, 1.0, 1.0, 2.0, 2.0, 1.0, 1.0, 3.0, 3.0, 1.0, 2.0, 0.0, 2.0, 2.0, 1.0, 3.0, 5.0, 1.0, 4.0, 1.0, 2.0, 1.0, 2.0, 3.0, 1.0, 3.0, 3.0, 1.0, 2.0, 1.0, 3.0, 1.0, 1.0, 0.0, 2.0, 0.0, 1.0, 2.0, 1.0, 3.0, 2.0, 1.0, 1.0, 0.0, 2.0, 0.0, 1.0, 1.0, 1.0, 1.0, 2.0, 0.0, 0.0, 1.0, 2.0, 1.0, 0.0, 0.0, 1.0, 2.0, 1.0, 0.0, 3.0, 1.0, 0.0, 1.0, 1.0, 3.0, 3.0, 4.0, 1.0, 1.0, 2.0, 1.0, 0.0, 1.0, 2.0, 1.0, 1.0, 2.0, 2.0, 3.0, 2.0, 5.0, 3.0, 4.0, 1.0, 2.0, 3.0, 1.0, 1.0, 1.0, 1.0, 1.0, 2.0, 2.0, 0.0, 2.0, 2.0, 2.0, 1.0, 2.0, 2.0, 1.0, 2.0, 2.0, 2.0, 1.0, 1.0, 0.0, 1.0, 0.0, 2.0, 1.0, 1.0, 2.0, 3.0, 1.0, 3.0, 1.0, 1.0, 2.0, 2.0, 1.0, 2.0, 2.0, 1.0, 1.0, 2.0, 0.0, 2.0, 1.0, 1.0, 2.0, 2.0, 1.0, 3.0, 2.0, 3.0, 2.0, 3.0, 1.0, 4.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 3.0, 1.0, 1.0, 0.0, 2.0, 1.0, 1.0, 3.0, 1.0, 4.0, 4.0, 2.0, 1.0, 1.0, 1.0, 0.0, 1.0, 2.0, 1.0, 4.0, 2.0, 4.0, 1.0, 1.0, 0.0, 1.0, 0.0, 3.0, 3.0, 2.0, 2.0, 2.0, 1.0, 0.0, 0.0, 3.0, 3.0, 3.0, 2.0, 2.0, 3.0, 2.0, 2.0, 3.0, 0.0, 1.0, 2.0, 1.0, 2.0, 2.0, 3.0, 0.0, 0.0, 1.0, 2.0, 2.0, 1.0, 2.0, 2.0, 1.0, 1.0, 2.0, 2.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 2.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 2.0, 1.0, 1.0, 2.0, 4.0, 2.0, 2.0, 1.0, 2.0, 0.0, 0.0, 3.0, 3.0, 2.0, 2.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.1337258866328498, "mean_inference_ms": 0.3907392531226319, "mean_action_processing_ms": 0.02920312473356116, "mean_env_wait_ms": 0.4041403756501532, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 967680, "timesteps_this_iter": 0, "agent_timesteps_total": 3870720, "timers": {"sample_time_ms": 5148.898, "sample_throughput": 978.85, "load_time_ms": 0.158, "load_throughput": 31879493.53, "learn_time_ms": 127.025, "learn_throughput": 39677.301, "update_time_ms": 2.402}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 341.22100830078125, "policy_entropy": 7801.3045654296875, "policy_loss": -20.922091007232666, "vf_loss": 37.052128314971924}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 967680, "num_agent_steps_sampled": 3870720, "num_steps_trained": 967680, "num_agent_steps_trained": 3870720, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 1932, "training_iteration": 96, "trial_id": "71426_00000", "experiment_id": "84bca2f7b35f43248fca18d21abe2ebf", "date": "2024-06-12_03-02-19", "timestamp": 1718128939, "time_this_iter_s": 10.361701488494873, "time_total_s": 987.2685687541962, "pid": 363902, "hostname": "DESKTOP-LQ219J4", "node_ip": "192.168.46.185", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 20, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 5000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 500, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Base_Model", "custom_model_config": {"env": "rware", "env_args": {"n_agents": 4, "column_height": 1, "max_inactivity_steps": null, "max_steps": 500, "fast_obs": true, "msg_bits": 0, "sensor_range": 1, "shelf_rows": 1, "shelf_columns": 3, "request_queue_size": 4, "reward_type": "RewardType.INDIVIDUAL", "map_name": "customized_map", "map_size": "tiny", "difficulty": "medium"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": true, "force_coop": false, "local_mode": true, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 4, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 100, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64}, "algorithm": "ia2c", "space_obs": "Dict(obs:Box([-100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100.], [100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.], (112,), float32))", "space_act": "Discrete(5)", "num_agents": 4, "episode_limit": 500, "policy_mapping_info": {"all_scenario": {"description": "rware all scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2", "agent_3"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "rware_customized_map", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 10, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.IA2CTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_il.<locals>.<lambda> at 0x7f380824d280>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "grad_clip": 40.0, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "microbatch_size": null}, "time_since_restore": 987.2685687541962, "timesteps_since_restore": 0, "iterations_since_restore": 96, "perf": {"cpu_util_percent": 4.486666666666666, "ram_util_percent": 59.419999999999995}}
{"episode_reward_max": 14.0, "episode_reward_min": 1.0, "episode_reward_mean": 6.24, "episode_len_mean": 500.0, "episode_media": {}, "episodes_this_iter": 20, "policy_reward_min": {"shared_policy": 0.0}, "policy_reward_max": {"shared_policy": 5.0}, "policy_reward_mean": {"shared_policy": 1.56}, "custom_metrics": {}, "hist_stats": {"episode_reward": [6.0, 8.0, 6.0, 6.0, 6.0, 6.0, 4.0, 5.0, 8.0, 3.0, 6.0, 7.0, 10.0, 4.0, 6.0, 9.0, 8.0, 6.0, 9.0, 6.0, 9.0, 5.0, 13.0, 6.0, 10.0, 7.0, 4.0, 4.0, 7.0, 3.0, 5.0, 3.0, 2.0, 6.0, 3.0, 11.0, 4.0, 5.0, 9.0, 13.0, 7.0, 5.0, 6.0, 7.0, 7.0, 3.0, 4.0, 9.0, 6.0, 6.0, 5.0, 6.0, 9.0, 10.0, 3.0, 2.0, 6.0, 4.0, 12.0, 5.0, 4.0, 11.0, 2.0, 10.0, 3.0, 11.0, 9.0, 6.0, 8.0, 3.0, 7.0, 6.0, 4.0, 4.0, 4.0, 3.0, 5.0, 10.0, 3.0, 10.0, 6.0, 6.0, 4.0, 10.0, 5.0, 3.0, 9.0, 14.0, 5.0, 1.0, 6.0, 3.0, 5.0, 4.0, 8.0, 7.0, 8.0, 6.0, 6.0, 5.0], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500], "policy_shared_policy_reward": [1.0, 1.0, 2.0, 2.0, 2.0, 3.0, 2.0, 1.0, 1.0, 2.0, 2.0, 1.0, 1.0, 1.0, 3.0, 1.0, 2.0, 1.0, 1.0, 2.0, 1.0, 1.0, 2.0, 2.0, 0.0, 2.0, 2.0, 0.0, 2.0, 2.0, 0.0, 1.0, 4.0, 1.0, 1.0, 2.0, 1.0, 0.0, 1.0, 1.0, 2.0, 2.0, 1.0, 1.0, 0.0, 4.0, 1.0, 2.0, 1.0, 3.0, 3.0, 3.0, 0.0, 2.0, 1.0, 1.0, 1.0, 1.0, 3.0, 1.0, 2.0, 2.0, 2.0, 3.0, 3.0, 2.0, 1.0, 2.0, 2.0, 0.0, 2.0, 2.0, 4.0, 3.0, 1.0, 1.0, 2.0, 2.0, 1.0, 1.0, 3.0, 3.0, 1.0, 2.0, 0.0, 2.0, 2.0, 1.0, 3.0, 5.0, 1.0, 4.0, 1.0, 2.0, 1.0, 2.0, 3.0, 1.0, 3.0, 3.0, 1.0, 2.0, 1.0, 3.0, 1.0, 1.0, 0.0, 2.0, 0.0, 1.0, 2.0, 1.0, 3.0, 2.0, 1.0, 1.0, 0.0, 2.0, 0.0, 1.0, 1.0, 1.0, 1.0, 2.0, 0.0, 0.0, 1.0, 2.0, 1.0, 0.0, 0.0, 1.0, 2.0, 1.0, 0.0, 3.0, 1.0, 0.0, 1.0, 1.0, 3.0, 3.0, 4.0, 1.0, 1.0, 2.0, 1.0, 0.0, 1.0, 2.0, 1.0, 1.0, 2.0, 2.0, 3.0, 2.0, 5.0, 3.0, 4.0, 1.0, 2.0, 3.0, 1.0, 1.0, 1.0, 1.0, 1.0, 2.0, 2.0, 0.0, 2.0, 2.0, 2.0, 1.0, 2.0, 2.0, 1.0, 2.0, 2.0, 2.0, 1.0, 1.0, 0.0, 1.0, 0.0, 2.0, 1.0, 1.0, 2.0, 3.0, 1.0, 3.0, 1.0, 1.0, 2.0, 2.0, 1.0, 2.0, 2.0, 1.0, 1.0, 2.0, 0.0, 2.0, 1.0, 1.0, 2.0, 2.0, 1.0, 3.0, 2.0, 3.0, 2.0, 3.0, 1.0, 4.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 3.0, 1.0, 1.0, 0.0, 2.0, 1.0, 1.0, 3.0, 1.0, 4.0, 4.0, 2.0, 1.0, 1.0, 1.0, 0.0, 1.0, 2.0, 1.0, 4.0, 2.0, 4.0, 1.0, 1.0, 0.0, 1.0, 0.0, 3.0, 3.0, 2.0, 2.0, 2.0, 1.0, 0.0, 0.0, 3.0, 3.0, 3.0, 2.0, 2.0, 3.0, 2.0, 2.0, 3.0, 0.0, 1.0, 2.0, 1.0, 2.0, 2.0, 3.0, 0.0, 0.0, 1.0, 2.0, 2.0, 1.0, 2.0, 2.0, 1.0, 1.0, 2.0, 2.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 2.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 2.0, 1.0, 1.0, 2.0, 4.0, 2.0, 2.0, 1.0, 2.0, 0.0, 0.0, 3.0, 3.0, 2.0, 2.0, 2.0, 3.0, 0.0, 1.0, 2.0, 1.0, 2.0, 1.0, 2.0, 0.0, 0.0, 2.0, 3.0, 3.0, 3.0, 1.0, 0.0, 1.0, 2.0, 2.0, 1.0, 1.0, 1.0, 0.0, 2.0, 2.0, 2.0, 3.0, 4.0, 3.0, 3.0, 4.0, 1.0, 1.0, 2.0, 1.0, 0.0, 0.0, 1.0, 0.0, 3.0, 1.0, 1.0, 1.0, 1.0, 0.0, 2.0, 0.0, 1.0, 2.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 2.0, 2.0, 2.0, 2.0, 3.0, 2.0, 2.0, 0.0, 2.0, 1.0, 4.0, 1.0, 2.0, 1.0, 1.0, 2.0, 2.0, 1.0, 2.0, 1.0, 2.0, 1.0, 1.0, 1.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.13373694094893282, "mean_inference_ms": 0.39076268226552857, "mean_action_processing_ms": 0.029204672805818906, "mean_env_wait_ms": 0.4041769571928536, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 977760, "timesteps_this_iter": 0, "agent_timesteps_total": 3911040, "timers": {"sample_time_ms": 5165.083, "sample_throughput": 975.783, "load_time_ms": 0.158, "load_throughput": 31821906.006, "learn_time_ms": 126.433, "learn_throughput": 39862.901, "update_time_ms": 2.383}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 321.65545654296875, "policy_entropy": 7809.0816650390625, "policy_loss": -49.6978714466095, "vf_loss": 30.442984580993652}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 977760, "num_agent_steps_sampled": 3911040, "num_steps_trained": 977760, "num_agent_steps_trained": 3911040, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 1952, "training_iteration": 97, "trial_id": "71426_00000", "experiment_id": "84bca2f7b35f43248fca18d21abe2ebf", "date": "2024-06-12_03-02-30", "timestamp": 1718128950, "time_this_iter_s": 10.384367227554321, "time_total_s": 997.6529359817505, "pid": 363902, "hostname": "DESKTOP-LQ219J4", "node_ip": "192.168.46.185", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 20, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 5000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 500, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Base_Model", "custom_model_config": {"env": "rware", "env_args": {"n_agents": 4, "column_height": 1, "max_inactivity_steps": null, "max_steps": 500, "fast_obs": true, "msg_bits": 0, "sensor_range": 1, "shelf_rows": 1, "shelf_columns": 3, "request_queue_size": 4, "reward_type": "RewardType.INDIVIDUAL", "map_name": "customized_map", "map_size": "tiny", "difficulty": "medium"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": true, "force_coop": false, "local_mode": true, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 4, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 100, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64}, "algorithm": "ia2c", "space_obs": "Dict(obs:Box([-100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100.], [100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.], (112,), float32))", "space_act": "Discrete(5)", "num_agents": 4, "episode_limit": 500, "policy_mapping_info": {"all_scenario": {"description": "rware all scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2", "agent_3"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "rware_customized_map", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 10, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.IA2CTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_il.<locals>.<lambda> at 0x7f38086c1d30>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "grad_clip": 40.0, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "microbatch_size": null}, "time_since_restore": 997.6529359817505, "timesteps_since_restore": 0, "iterations_since_restore": 97, "perf": {"cpu_util_percent": 4.421428571428572, "ram_util_percent": 59.65000000000002}}
{"episode_reward_max": 17.0, "episode_reward_min": 0.0, "episode_reward_mean": 6.27, "episode_len_mean": 500.0, "episode_media": {}, "episodes_this_iter": 20, "policy_reward_min": {"shared_policy": 0.0}, "policy_reward_max": {"shared_policy": 6.0}, "policy_reward_mean": {"shared_policy": 1.5675}, "custom_metrics": {}, "hist_stats": {"episode_reward": [9.0, 5.0, 13.0, 6.0, 10.0, 7.0, 4.0, 4.0, 7.0, 3.0, 5.0, 3.0, 2.0, 6.0, 3.0, 11.0, 4.0, 5.0, 9.0, 13.0, 7.0, 5.0, 6.0, 7.0, 7.0, 3.0, 4.0, 9.0, 6.0, 6.0, 5.0, 6.0, 9.0, 10.0, 3.0, 2.0, 6.0, 4.0, 12.0, 5.0, 4.0, 11.0, 2.0, 10.0, 3.0, 11.0, 9.0, 6.0, 8.0, 3.0, 7.0, 6.0, 4.0, 4.0, 4.0, 3.0, 5.0, 10.0, 3.0, 10.0, 6.0, 6.0, 4.0, 10.0, 5.0, 3.0, 9.0, 14.0, 5.0, 1.0, 6.0, 3.0, 5.0, 4.0, 8.0, 7.0, 8.0, 6.0, 6.0, 5.0, 9.0, 4.0, 17.0, 11.0, 8.0, 4.0, 2.0, 3.0, 10.0, 5.0, 3.0, 8.0, 5.0, 7.0, 0.0, 5.0, 6.0, 7.0, 15.0, 3.0], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500], "policy_shared_policy_reward": [3.0, 3.0, 1.0, 2.0, 0.0, 2.0, 2.0, 1.0, 3.0, 5.0, 1.0, 4.0, 1.0, 2.0, 1.0, 2.0, 3.0, 1.0, 3.0, 3.0, 1.0, 2.0, 1.0, 3.0, 1.0, 1.0, 0.0, 2.0, 0.0, 1.0, 2.0, 1.0, 3.0, 2.0, 1.0, 1.0, 0.0, 2.0, 0.0, 1.0, 1.0, 1.0, 1.0, 2.0, 0.0, 0.0, 1.0, 2.0, 1.0, 0.0, 0.0, 1.0, 2.0, 1.0, 0.0, 3.0, 1.0, 0.0, 1.0, 1.0, 3.0, 3.0, 4.0, 1.0, 1.0, 2.0, 1.0, 0.0, 1.0, 2.0, 1.0, 1.0, 2.0, 2.0, 3.0, 2.0, 5.0, 3.0, 4.0, 1.0, 2.0, 3.0, 1.0, 1.0, 1.0, 1.0, 1.0, 2.0, 2.0, 0.0, 2.0, 2.0, 2.0, 1.0, 2.0, 2.0, 1.0, 2.0, 2.0, 2.0, 1.0, 1.0, 0.0, 1.0, 0.0, 2.0, 1.0, 1.0, 2.0, 3.0, 1.0, 3.0, 1.0, 1.0, 2.0, 2.0, 1.0, 2.0, 2.0, 1.0, 1.0, 2.0, 0.0, 2.0, 1.0, 1.0, 2.0, 2.0, 1.0, 3.0, 2.0, 3.0, 2.0, 3.0, 1.0, 4.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 3.0, 1.0, 1.0, 0.0, 2.0, 1.0, 1.0, 3.0, 1.0, 4.0, 4.0, 2.0, 1.0, 1.0, 1.0, 0.0, 1.0, 2.0, 1.0, 4.0, 2.0, 4.0, 1.0, 1.0, 0.0, 1.0, 0.0, 3.0, 3.0, 2.0, 2.0, 2.0, 1.0, 0.0, 0.0, 3.0, 3.0, 3.0, 2.0, 2.0, 3.0, 2.0, 2.0, 3.0, 0.0, 1.0, 2.0, 1.0, 2.0, 2.0, 3.0, 0.0, 0.0, 1.0, 2.0, 2.0, 1.0, 2.0, 2.0, 1.0, 1.0, 2.0, 2.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 2.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 2.0, 1.0, 1.0, 2.0, 4.0, 2.0, 2.0, 1.0, 2.0, 0.0, 0.0, 3.0, 3.0, 2.0, 2.0, 2.0, 3.0, 0.0, 1.0, 2.0, 1.0, 2.0, 1.0, 2.0, 0.0, 0.0, 2.0, 3.0, 3.0, 3.0, 1.0, 0.0, 1.0, 2.0, 2.0, 1.0, 1.0, 1.0, 0.0, 2.0, 2.0, 2.0, 3.0, 4.0, 3.0, 3.0, 4.0, 1.0, 1.0, 2.0, 1.0, 0.0, 0.0, 1.0, 0.0, 3.0, 1.0, 1.0, 1.0, 1.0, 0.0, 2.0, 0.0, 1.0, 2.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 2.0, 2.0, 2.0, 2.0, 3.0, 2.0, 2.0, 0.0, 2.0, 1.0, 4.0, 1.0, 2.0, 1.0, 1.0, 2.0, 2.0, 1.0, 2.0, 1.0, 2.0, 1.0, 1.0, 1.0, 3.0, 4.0, 1.0, 1.0, 1.0, 1.0, 2.0, 0.0, 5.0, 6.0, 3.0, 3.0, 2.0, 4.0, 4.0, 1.0, 1.0, 2.0, 3.0, 2.0, 0.0, 2.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 3.0, 2.0, 2.0, 3.0, 1.0, 2.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 2.0, 1.0, 3.0, 2.0, 0.0, 2.0, 1.0, 2.0, 2.0, 1.0, 1.0, 3.0, 0.0, 0.0, 0.0, 0.0, 1.0, 2.0, 1.0, 1.0, 1.0, 1.0, 2.0, 2.0, 3.0, 3.0, 1.0, 0.0, 4.0, 2.0, 5.0, 4.0, 1.0, 1.0, 0.0, 1.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.1337533121492145, "mean_inference_ms": 0.3908017282169636, "mean_action_processing_ms": 0.029207110165829615, "mean_env_wait_ms": 0.4042262427780377, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 987840, "timesteps_this_iter": 0, "agent_timesteps_total": 3951360, "timers": {"sample_time_ms": 5181.928, "sample_throughput": 972.611, "load_time_ms": 0.158, "load_throughput": 31918001.148, "learn_time_ms": 126.297, "learn_throughput": 39905.824, "update_time_ms": 2.418}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 215.5596923828125, "policy_entropy": 7775.45556640625, "policy_loss": -54.465524673461914, "vf_loss": 46.52003288269043}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 987840, "num_agent_steps_sampled": 3951360, "num_steps_trained": 987840, "num_agent_steps_trained": 3951360, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 1972, "training_iteration": 98, "trial_id": "71426_00000", "experiment_id": "84bca2f7b35f43248fca18d21abe2ebf", "date": "2024-06-12_03-02-40", "timestamp": 1718128960, "time_this_iter_s": 10.389355182647705, "time_total_s": 1008.0422911643982, "pid": 363902, "hostname": "DESKTOP-LQ219J4", "node_ip": "192.168.46.185", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 20, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 5000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 500, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Base_Model", "custom_model_config": {"env": "rware", "env_args": {"n_agents": 4, "column_height": 1, "max_inactivity_steps": null, "max_steps": 500, "fast_obs": true, "msg_bits": 0, "sensor_range": 1, "shelf_rows": 1, "shelf_columns": 3, "request_queue_size": 4, "reward_type": "RewardType.INDIVIDUAL", "map_name": "customized_map", "map_size": "tiny", "difficulty": "medium"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": true, "force_coop": false, "local_mode": true, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 4, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 100, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64}, "algorithm": "ia2c", "space_obs": "Dict(obs:Box([-100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100.], [100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.], (112,), float32))", "space_act": "Discrete(5)", "num_agents": 4, "episode_limit": 500, "policy_mapping_info": {"all_scenario": {"description": "rware all scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2", "agent_3"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "rware_customized_map", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 10, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.IA2CTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_il.<locals>.<lambda> at 0x7f38082f8430>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "grad_clip": 40.0, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "microbatch_size": null}, "time_since_restore": 1008.0422911643982, "timesteps_since_restore": 0, "iterations_since_restore": 98, "perf": {"cpu_util_percent": 4.499999999999999, "ram_util_percent": 59.89999999999999}}
{"episode_reward_max": 17.0, "episode_reward_min": 0.0, "episode_reward_mean": 6.39, "episode_len_mean": 500.0, "episode_media": {}, "episodes_this_iter": 20, "policy_reward_min": {"shared_policy": 0.0}, "policy_reward_max": {"shared_policy": 6.0}, "policy_reward_mean": {"shared_policy": 1.5975}, "custom_metrics": {}, "hist_stats": {"episode_reward": [7.0, 5.0, 6.0, 7.0, 7.0, 3.0, 4.0, 9.0, 6.0, 6.0, 5.0, 6.0, 9.0, 10.0, 3.0, 2.0, 6.0, 4.0, 12.0, 5.0, 4.0, 11.0, 2.0, 10.0, 3.0, 11.0, 9.0, 6.0, 8.0, 3.0, 7.0, 6.0, 4.0, 4.0, 4.0, 3.0, 5.0, 10.0, 3.0, 10.0, 6.0, 6.0, 4.0, 10.0, 5.0, 3.0, 9.0, 14.0, 5.0, 1.0, 6.0, 3.0, 5.0, 4.0, 8.0, 7.0, 8.0, 6.0, 6.0, 5.0, 9.0, 4.0, 17.0, 11.0, 8.0, 4.0, 2.0, 3.0, 10.0, 5.0, 3.0, 8.0, 5.0, 7.0, 0.0, 5.0, 6.0, 7.0, 15.0, 3.0, 7.0, 9.0, 9.0, 6.0, 5.0, 4.0, 6.0, 8.0, 7.0, 12.0, 0.0, 4.0, 4.0, 3.0, 17.0, 11.0, 8.0, 6.0, 8.0, 7.0], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500], "policy_shared_policy_reward": [2.0, 3.0, 1.0, 1.0, 1.0, 1.0, 1.0, 2.0, 2.0, 0.0, 2.0, 2.0, 2.0, 1.0, 2.0, 2.0, 1.0, 2.0, 2.0, 2.0, 1.0, 1.0, 0.0, 1.0, 0.0, 2.0, 1.0, 1.0, 2.0, 3.0, 1.0, 3.0, 1.0, 1.0, 2.0, 2.0, 1.0, 2.0, 2.0, 1.0, 1.0, 2.0, 0.0, 2.0, 1.0, 1.0, 2.0, 2.0, 1.0, 3.0, 2.0, 3.0, 2.0, 3.0, 1.0, 4.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 3.0, 1.0, 1.0, 0.0, 2.0, 1.0, 1.0, 3.0, 1.0, 4.0, 4.0, 2.0, 1.0, 1.0, 1.0, 0.0, 1.0, 2.0, 1.0, 4.0, 2.0, 4.0, 1.0, 1.0, 0.0, 1.0, 0.0, 3.0, 3.0, 2.0, 2.0, 2.0, 1.0, 0.0, 0.0, 3.0, 3.0, 3.0, 2.0, 2.0, 3.0, 2.0, 2.0, 3.0, 0.0, 1.0, 2.0, 1.0, 2.0, 2.0, 3.0, 0.0, 0.0, 1.0, 2.0, 2.0, 1.0, 2.0, 2.0, 1.0, 1.0, 2.0, 2.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 2.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 2.0, 1.0, 1.0, 2.0, 4.0, 2.0, 2.0, 1.0, 2.0, 0.0, 0.0, 3.0, 3.0, 2.0, 2.0, 2.0, 3.0, 0.0, 1.0, 2.0, 1.0, 2.0, 1.0, 2.0, 0.0, 0.0, 2.0, 3.0, 3.0, 3.0, 1.0, 0.0, 1.0, 2.0, 2.0, 1.0, 1.0, 1.0, 0.0, 2.0, 2.0, 2.0, 3.0, 4.0, 3.0, 3.0, 4.0, 1.0, 1.0, 2.0, 1.0, 0.0, 0.0, 1.0, 0.0, 3.0, 1.0, 1.0, 1.0, 1.0, 0.0, 2.0, 0.0, 1.0, 2.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 2.0, 2.0, 2.0, 2.0, 3.0, 2.0, 2.0, 0.0, 2.0, 1.0, 4.0, 1.0, 2.0, 1.0, 1.0, 2.0, 2.0, 1.0, 2.0, 1.0, 2.0, 1.0, 1.0, 1.0, 3.0, 4.0, 1.0, 1.0, 1.0, 1.0, 2.0, 0.0, 5.0, 6.0, 3.0, 3.0, 2.0, 4.0, 4.0, 1.0, 1.0, 2.0, 3.0, 2.0, 0.0, 2.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 3.0, 2.0, 2.0, 3.0, 1.0, 2.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 2.0, 1.0, 3.0, 2.0, 0.0, 2.0, 1.0, 2.0, 2.0, 1.0, 1.0, 3.0, 0.0, 0.0, 0.0, 0.0, 1.0, 2.0, 1.0, 1.0, 1.0, 1.0, 2.0, 2.0, 3.0, 3.0, 1.0, 0.0, 4.0, 2.0, 5.0, 4.0, 1.0, 1.0, 0.0, 1.0, 2.0, 3.0, 1.0, 1.0, 1.0, 0.0, 4.0, 4.0, 3.0, 2.0, 2.0, 2.0, 1.0, 2.0, 1.0, 2.0, 1.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0, 1.0, 1.0, 2.0, 1.0, 2.0, 1.0, 1.0, 3.0, 3.0, 2.0, 2.0, 1.0, 2.0, 3.0, 3.0, 4.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 2.0, 1.0, 0.0, 2.0, 2.0, 0.0, 1.0, 0.0, 1.0, 1.0, 3.0, 5.0, 4.0, 5.0, 4.0, 3.0, 2.0, 2.0, 2.0, 2.0, 3.0, 1.0, 2.0, 2.0, 1.0, 1.0, 2.0, 2.0, 2.0, 2.0, 2.0, 1.0, 2.0, 2.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.13377054984976294, "mean_inference_ms": 0.39084015201740885, "mean_action_processing_ms": 0.02920803780036521, "mean_env_wait_ms": 0.40425682255513634, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 997920, "timesteps_this_iter": 0, "agent_timesteps_total": 3991680, "timers": {"sample_time_ms": 5174.658, "sample_throughput": 973.977, "load_time_ms": 0.16, "load_throughput": 31415206.063, "learn_time_ms": 127.997, "learn_throughput": 39375.822, "update_time_ms": 2.423}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 245.71142578125, "policy_entropy": 7632.279052734375, "policy_loss": 10.796823263168335, "vf_loss": 58.9696569442749}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 997920, "num_agent_steps_sampled": 3991680, "num_steps_trained": 997920, "num_agent_steps_trained": 3991680, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 1992, "training_iteration": 99, "trial_id": "71426_00000", "experiment_id": "84bca2f7b35f43248fca18d21abe2ebf", "date": "2024-06-12_03-02-50", "timestamp": 1718128970, "time_this_iter_s": 10.28997015953064, "time_total_s": 1018.3322613239288, "pid": 363902, "hostname": "DESKTOP-LQ219J4", "node_ip": "192.168.46.185", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 20, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 5000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 500, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Base_Model", "custom_model_config": {"env": "rware", "env_args": {"n_agents": 4, "column_height": 1, "max_inactivity_steps": null, "max_steps": 500, "fast_obs": true, "msg_bits": 0, "sensor_range": 1, "shelf_rows": 1, "shelf_columns": 3, "request_queue_size": 4, "reward_type": "RewardType.INDIVIDUAL", "map_name": "customized_map", "map_size": "tiny", "difficulty": "medium"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": true, "force_coop": false, "local_mode": true, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 4, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 100, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64}, "algorithm": "ia2c", "space_obs": "Dict(obs:Box([-100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100.], [100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.], (112,), float32))", "space_act": "Discrete(5)", "num_agents": 4, "episode_limit": 500, "policy_mapping_info": {"all_scenario": {"description": "rware all scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2", "agent_3"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "rware_customized_map", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 10, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.IA2CTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_il.<locals>.<lambda> at 0x7f382806e9d0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "grad_clip": 40.0, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "microbatch_size": null}, "time_since_restore": 1018.3322613239288, "timesteps_since_restore": 0, "iterations_since_restore": 99, "perf": {"cpu_util_percent": 4.7, "ram_util_percent": 60.200000000000024}}
{"episode_reward_max": 18.0, "episode_reward_min": 0.0, "episode_reward_mean": 6.86, "episode_len_mean": 500.0, "episode_media": {}, "episodes_this_iter": 24, "policy_reward_min": {"shared_policy": 0.0}, "policy_reward_max": {"shared_policy": 6.0}, "policy_reward_mean": {"shared_policy": 1.715}, "custom_metrics": {}, "hist_stats": {"episode_reward": [3.0, 11.0, 9.0, 6.0, 8.0, 3.0, 7.0, 6.0, 4.0, 4.0, 4.0, 3.0, 5.0, 10.0, 3.0, 10.0, 6.0, 6.0, 4.0, 10.0, 5.0, 3.0, 9.0, 14.0, 5.0, 1.0, 6.0, 3.0, 5.0, 4.0, 8.0, 7.0, 8.0, 6.0, 6.0, 5.0, 9.0, 4.0, 17.0, 11.0, 8.0, 4.0, 2.0, 3.0, 10.0, 5.0, 3.0, 8.0, 5.0, 7.0, 0.0, 5.0, 6.0, 7.0, 15.0, 3.0, 7.0, 9.0, 9.0, 6.0, 5.0, 4.0, 6.0, 8.0, 7.0, 12.0, 0.0, 4.0, 4.0, 3.0, 17.0, 11.0, 8.0, 6.0, 8.0, 7.0, 8.0, 9.0, 11.0, 11.0, 5.0, 0.0, 15.0, 5.0, 10.0, 11.0, 4.0, 18.0, 4.0, 7.0, 9.0, 5.0, 10.0, 14.0, 6.0, 9.0, 6.0, 4.0, 9.0, 6.0], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500], "policy_shared_policy_reward": [2.0, 1.0, 0.0, 0.0, 3.0, 3.0, 3.0, 2.0, 2.0, 3.0, 2.0, 2.0, 3.0, 0.0, 1.0, 2.0, 1.0, 2.0, 2.0, 3.0, 0.0, 0.0, 1.0, 2.0, 2.0, 1.0, 2.0, 2.0, 1.0, 1.0, 2.0, 2.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 2.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 2.0, 1.0, 1.0, 2.0, 4.0, 2.0, 2.0, 1.0, 2.0, 0.0, 0.0, 3.0, 3.0, 2.0, 2.0, 2.0, 3.0, 0.0, 1.0, 2.0, 1.0, 2.0, 1.0, 2.0, 0.0, 0.0, 2.0, 3.0, 3.0, 3.0, 1.0, 0.0, 1.0, 2.0, 2.0, 1.0, 1.0, 1.0, 0.0, 2.0, 2.0, 2.0, 3.0, 4.0, 3.0, 3.0, 4.0, 1.0, 1.0, 2.0, 1.0, 0.0, 0.0, 1.0, 0.0, 3.0, 1.0, 1.0, 1.0, 1.0, 0.0, 2.0, 0.0, 1.0, 2.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 2.0, 2.0, 2.0, 2.0, 3.0, 2.0, 2.0, 0.0, 2.0, 1.0, 4.0, 1.0, 2.0, 1.0, 1.0, 2.0, 2.0, 1.0, 2.0, 1.0, 2.0, 1.0, 1.0, 1.0, 3.0, 4.0, 1.0, 1.0, 1.0, 1.0, 2.0, 0.0, 5.0, 6.0, 3.0, 3.0, 2.0, 4.0, 4.0, 1.0, 1.0, 2.0, 3.0, 2.0, 0.0, 2.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 3.0, 2.0, 2.0, 3.0, 1.0, 2.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 2.0, 1.0, 3.0, 2.0, 0.0, 2.0, 1.0, 2.0, 2.0, 1.0, 1.0, 3.0, 0.0, 0.0, 0.0, 0.0, 1.0, 2.0, 1.0, 1.0, 1.0, 1.0, 2.0, 2.0, 3.0, 3.0, 1.0, 0.0, 4.0, 2.0, 5.0, 4.0, 1.0, 1.0, 0.0, 1.0, 2.0, 3.0, 1.0, 1.0, 1.0, 0.0, 4.0, 4.0, 3.0, 2.0, 2.0, 2.0, 1.0, 2.0, 1.0, 2.0, 1.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0, 1.0, 1.0, 2.0, 1.0, 2.0, 1.0, 1.0, 3.0, 3.0, 2.0, 2.0, 1.0, 2.0, 3.0, 3.0, 4.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 2.0, 1.0, 0.0, 2.0, 2.0, 0.0, 1.0, 0.0, 1.0, 1.0, 3.0, 5.0, 4.0, 5.0, 4.0, 3.0, 2.0, 2.0, 2.0, 2.0, 3.0, 1.0, 2.0, 2.0, 1.0, 1.0, 2.0, 2.0, 2.0, 2.0, 2.0, 1.0, 2.0, 2.0, 3.0, 2.0, 2.0, 1.0, 2.0, 2.0, 4.0, 1.0, 2.0, 3.0, 3.0, 3.0, 1.0, 3.0, 4.0, 3.0, 1.0, 1.0, 1.0, 2.0, 0.0, 0.0, 0.0, 0.0, 4.0, 3.0, 5.0, 3.0, 1.0, 1.0, 1.0, 2.0, 2.0, 1.0, 2.0, 5.0, 2.0, 3.0, 3.0, 3.0, 1.0, 1.0, 2.0, 0.0, 2.0, 4.0, 6.0, 6.0, 1.0, 1.0, 1.0, 1.0, 1.0, 2.0, 3.0, 1.0, 2.0, 3.0, 3.0, 1.0, 1.0, 1.0, 1.0, 2.0, 2.0, 4.0, 3.0, 1.0, 2.0, 4.0, 4.0, 4.0, 2.0, 2.0, 0.0, 2.0, 2.0, 3.0, 2.0, 2.0, 1.0, 0.0, 3.0, 2.0, 1.0, 0.0, 1.0, 2.0, 0.0, 4.0, 2.0, 3.0, 2.0, 1.0, 1.0, 2.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.133777103713741, "mean_inference_ms": 0.3908508543088376, "mean_action_processing_ms": 0.02920383003097526, "mean_env_wait_ms": 0.4042933705969445, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 1008000, "timesteps_this_iter": 0, "agent_timesteps_total": 4032000, "timers": {"sample_time_ms": 5173.533, "sample_throughput": 974.189, "load_time_ms": 0.158, "load_throughput": 31855473.418, "learn_time_ms": 128.351, "learn_throughput": 39267.25, "update_time_ms": 2.39}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 311.2551574707031, "policy_entropy": 7706.515869140625, "policy_loss": -13.510727882385254, "vf_loss": 60.470375061035156}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 1008000, "num_agent_steps_sampled": 4032000, "num_steps_trained": 1008000, "num_agent_steps_trained": 4032000, "num_steps_trained_this_iter": 0}, "evaluation": {"episode_reward_max": 17.0, "episode_reward_min": 2.0, "episode_reward_mean": 9.9, "episode_len_mean": 500.0, "episode_media": {}, "episodes_this_iter": 10, "policy_reward_min": {"shared_policy": 0.0}, "policy_reward_max": {"shared_policy": 6.0}, "policy_reward_mean": {"shared_policy": 2.475}, "custom_metrics": {}, "hist_stats": {"episode_reward": [13.0, 2.0, 7.0, 9.0, 17.0, 7.0, 15.0, 8.0, 17.0, 4.0], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500], "policy_shared_policy_reward": [3.0, 1.0, 4.0, 5.0, 1.0, 0.0, 1.0, 0.0, 1.0, 3.0, 1.0, 2.0, 3.0, 1.0, 2.0, 3.0, 3.0, 5.0, 5.0, 4.0, 2.0, 2.0, 1.0, 2.0, 4.0, 3.0, 4.0, 4.0, 1.0, 4.0, 1.0, 2.0, 3.0, 2.0, 6.0, 6.0, 0.0, 1.0, 1.0, 2.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.09239667559275566, "mean_inference_ms": 0.4011080415472247, "mean_action_processing_ms": 0.028299505788556882, "mean_env_wait_ms": 0.40348154725390495, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}}, "done": false, "episodes_total": 2016, "training_iteration": 100, "trial_id": "71426_00000", "experiment_id": "84bca2f7b35f43248fca18d21abe2ebf", "date": "2024-06-12_03-03-05", "timestamp": 1718128985, "time_this_iter_s": 14.993839502334595, "time_total_s": 1033.3261008262634, "pid": 363902, "hostname": "DESKTOP-LQ219J4", "node_ip": "192.168.46.185", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 20, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 5000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 500, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Base_Model", "custom_model_config": {"env": "rware", "env_args": {"n_agents": 4, "column_height": 1, "max_inactivity_steps": null, "max_steps": 500, "fast_obs": true, "msg_bits": 0, "sensor_range": 1, "shelf_rows": 1, "shelf_columns": 3, "request_queue_size": 4, "reward_type": "RewardType.INDIVIDUAL", "map_name": "customized_map", "map_size": "tiny", "difficulty": "medium"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": true, "force_coop": false, "local_mode": true, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 4, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 100, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64}, "algorithm": "ia2c", "space_obs": "Dict(obs:Box([-100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100.], [100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.], (112,), float32))", "space_act": "Discrete(5)", "num_agents": 4, "episode_limit": 500, "policy_mapping_info": {"all_scenario": {"description": "rware all scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2", "agent_3"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "rware_customized_map", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 10, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.IA2CTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_il.<locals>.<lambda> at 0x7f3808651ee0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "grad_clip": 40.0, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "microbatch_size": null}, "time_since_restore": 1033.3261008262634, "timesteps_since_restore": 0, "iterations_since_restore": 100, "perf": {"cpu_util_percent": 4.4714285714285715, "ram_util_percent": 60.59523809523809}}
{"episode_reward_max": 18.0, "episode_reward_min": 0.0, "episode_reward_mean": 6.83, "episode_len_mean": 500.0, "episode_media": {}, "episodes_this_iter": 20, "policy_reward_min": {"shared_policy": 0.0}, "policy_reward_max": {"shared_policy": 6.0}, "policy_reward_mean": {"shared_policy": 1.7075}, "custom_metrics": {}, "hist_stats": {"episode_reward": [5.0, 3.0, 9.0, 14.0, 5.0, 1.0, 6.0, 3.0, 5.0, 4.0, 8.0, 7.0, 8.0, 6.0, 6.0, 5.0, 9.0, 4.0, 17.0, 11.0, 8.0, 4.0, 2.0, 3.0, 10.0, 5.0, 3.0, 8.0, 5.0, 7.0, 0.0, 5.0, 6.0, 7.0, 15.0, 3.0, 7.0, 9.0, 9.0, 6.0, 5.0, 4.0, 6.0, 8.0, 7.0, 12.0, 0.0, 4.0, 4.0, 3.0, 17.0, 11.0, 8.0, 6.0, 8.0, 7.0, 8.0, 9.0, 11.0, 11.0, 5.0, 0.0, 15.0, 5.0, 10.0, 11.0, 4.0, 18.0, 4.0, 7.0, 9.0, 5.0, 10.0, 14.0, 6.0, 9.0, 6.0, 4.0, 9.0, 6.0, 6.0, 2.0, 4.0, 2.0, 8.0, 7.0, 5.0, 6.0, 9.0, 3.0, 5.0, 9.0, 3.0, 5.0, 9.0, 11.0, 4.0, 3.0, 10.0, 8.0], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500], "policy_shared_policy_reward": [0.0, 1.0, 2.0, 2.0, 1.0, 1.0, 1.0, 0.0, 2.0, 2.0, 2.0, 3.0, 4.0, 3.0, 3.0, 4.0, 1.0, 1.0, 2.0, 1.0, 0.0, 0.0, 1.0, 0.0, 3.0, 1.0, 1.0, 1.0, 1.0, 0.0, 2.0, 0.0, 1.0, 2.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 2.0, 2.0, 2.0, 2.0, 3.0, 2.0, 2.0, 0.0, 2.0, 1.0, 4.0, 1.0, 2.0, 1.0, 1.0, 2.0, 2.0, 1.0, 2.0, 1.0, 2.0, 1.0, 1.0, 1.0, 3.0, 4.0, 1.0, 1.0, 1.0, 1.0, 2.0, 0.0, 5.0, 6.0, 3.0, 3.0, 2.0, 4.0, 4.0, 1.0, 1.0, 2.0, 3.0, 2.0, 0.0, 2.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 3.0, 2.0, 2.0, 3.0, 1.0, 2.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 2.0, 1.0, 3.0, 2.0, 0.0, 2.0, 1.0, 2.0, 2.0, 1.0, 1.0, 3.0, 0.0, 0.0, 0.0, 0.0, 1.0, 2.0, 1.0, 1.0, 1.0, 1.0, 2.0, 2.0, 3.0, 3.0, 1.0, 0.0, 4.0, 2.0, 5.0, 4.0, 1.0, 1.0, 0.0, 1.0, 2.0, 3.0, 1.0, 1.0, 1.0, 0.0, 4.0, 4.0, 3.0, 2.0, 2.0, 2.0, 1.0, 2.0, 1.0, 2.0, 1.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0, 1.0, 1.0, 2.0, 1.0, 2.0, 1.0, 1.0, 3.0, 3.0, 2.0, 2.0, 1.0, 2.0, 3.0, 3.0, 4.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 2.0, 1.0, 0.0, 2.0, 2.0, 0.0, 1.0, 0.0, 1.0, 1.0, 3.0, 5.0, 4.0, 5.0, 4.0, 3.0, 2.0, 2.0, 2.0, 2.0, 3.0, 1.0, 2.0, 2.0, 1.0, 1.0, 2.0, 2.0, 2.0, 2.0, 2.0, 1.0, 2.0, 2.0, 3.0, 2.0, 2.0, 1.0, 2.0, 2.0, 4.0, 1.0, 2.0, 3.0, 3.0, 3.0, 1.0, 3.0, 4.0, 3.0, 1.0, 1.0, 1.0, 2.0, 0.0, 0.0, 0.0, 0.0, 4.0, 3.0, 5.0, 3.0, 1.0, 1.0, 1.0, 2.0, 2.0, 1.0, 2.0, 5.0, 2.0, 3.0, 3.0, 3.0, 1.0, 1.0, 2.0, 0.0, 2.0, 4.0, 6.0, 6.0, 1.0, 1.0, 1.0, 1.0, 1.0, 2.0, 3.0, 1.0, 2.0, 3.0, 3.0, 1.0, 1.0, 1.0, 1.0, 2.0, 2.0, 4.0, 3.0, 1.0, 2.0, 4.0, 4.0, 4.0, 2.0, 2.0, 0.0, 2.0, 2.0, 3.0, 2.0, 2.0, 1.0, 0.0, 3.0, 2.0, 1.0, 0.0, 1.0, 2.0, 0.0, 4.0, 2.0, 3.0, 2.0, 1.0, 1.0, 2.0, 1.0, 3.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 2.0, 0.0, 0.0, 1.0, 1.0, 1.0, 3.0, 2.0, 2.0, 2.0, 2.0, 2.0, 1.0, 0.0, 1.0, 2.0, 2.0, 1.0, 3.0, 0.0, 2.0, 4.0, 2.0, 1.0, 2.0, 1.0, 1.0, 0.0, 1.0, 2.0, 1.0, 2.0, 0.0, 2.0, 4.0, 0.0, 3.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 2.0, 1.0, 1.0, 4.0, 3.0, 1.0, 3.0, 3.0, 3.0, 2.0, 1.0, 2.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 3.0, 2.0, 2.0, 3.0, 2.0, 1.0, 2.0, 3.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.1337826267228395, "mean_inference_ms": 0.3908559578004598, "mean_action_processing_ms": 0.029202788434053967, "mean_env_wait_ms": 0.40427543845650504, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 1018080, "timesteps_this_iter": 0, "agent_timesteps_total": 4072320, "timers": {"sample_time_ms": 5611.13, "sample_throughput": 898.215, "load_time_ms": 0.162, "load_throughput": 31128393.698, "learn_time_ms": 127.885, "learn_throughput": 39410.501, "update_time_ms": 2.416}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 166.77052307128906, "policy_entropy": 7843.620849609375, "policy_loss": -58.21847343444824, "vf_loss": 49.581862449645996}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 1018080, "num_agent_steps_sampled": 4072320, "num_steps_trained": 1018080, "num_agent_steps_trained": 4072320, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 2036, "training_iteration": 101, "trial_id": "71426_00000", "experiment_id": "84bca2f7b35f43248fca18d21abe2ebf", "date": "2024-06-12_03-03-15", "timestamp": 1718128995, "time_this_iter_s": 9.964386224746704, "time_total_s": 1043.2904870510101, "pid": 363902, "hostname": "DESKTOP-LQ219J4", "node_ip": "192.168.46.185", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 20, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 5000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 500, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Base_Model", "custom_model_config": {"env": "rware", "env_args": {"n_agents": 4, "column_height": 1, "max_inactivity_steps": null, "max_steps": 500, "fast_obs": true, "msg_bits": 0, "sensor_range": 1, "shelf_rows": 1, "shelf_columns": 3, "request_queue_size": 4, "reward_type": "RewardType.INDIVIDUAL", "map_name": "customized_map", "map_size": "tiny", "difficulty": "medium"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": true, "force_coop": false, "local_mode": true, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 4, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 100, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64}, "algorithm": "ia2c", "space_obs": "Dict(obs:Box([-100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100.], [100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.], (112,), float32))", "space_act": "Discrete(5)", "num_agents": 4, "episode_limit": 500, "policy_mapping_info": {"all_scenario": {"description": "rware all scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2", "agent_3"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "rware_customized_map", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 10, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.IA2CTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_il.<locals>.<lambda> at 0x7f38081d5af0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "grad_clip": 40.0, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "microbatch_size": null}, "time_since_restore": 1043.2904870510101, "timesteps_since_restore": 0, "iterations_since_restore": 101, "perf": {"cpu_util_percent": 4.673333333333334, "ram_util_percent": 60.81333333333331}}
{"episode_reward_max": 18.0, "episode_reward_min": 0.0, "episode_reward_mean": 6.73, "episode_len_mean": 500.0, "episode_media": {}, "episodes_this_iter": 20, "policy_reward_min": {"shared_policy": 0.0}, "policy_reward_max": {"shared_policy": 6.0}, "policy_reward_mean": {"shared_policy": 1.6825}, "custom_metrics": {}, "hist_stats": {"episode_reward": [8.0, 4.0, 2.0, 3.0, 10.0, 5.0, 3.0, 8.0, 5.0, 7.0, 0.0, 5.0, 6.0, 7.0, 15.0, 3.0, 7.0, 9.0, 9.0, 6.0, 5.0, 4.0, 6.0, 8.0, 7.0, 12.0, 0.0, 4.0, 4.0, 3.0, 17.0, 11.0, 8.0, 6.0, 8.0, 7.0, 8.0, 9.0, 11.0, 11.0, 5.0, 0.0, 15.0, 5.0, 10.0, 11.0, 4.0, 18.0, 4.0, 7.0, 9.0, 5.0, 10.0, 14.0, 6.0, 9.0, 6.0, 4.0, 9.0, 6.0, 6.0, 2.0, 4.0, 2.0, 8.0, 7.0, 5.0, 6.0, 9.0, 3.0, 5.0, 9.0, 3.0, 5.0, 9.0, 11.0, 4.0, 3.0, 10.0, 8.0, 9.0, 6.0, 3.0, 9.0, 5.0, 6.0, 3.0, 11.0, 4.0, 16.0, 6.0, 2.0, 3.0, 12.0, 4.0, 7.0, 3.0, 2.0, 5.0, 10.0], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500], "policy_shared_policy_reward": [1.0, 2.0, 3.0, 2.0, 0.0, 2.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 3.0, 2.0, 2.0, 3.0, 1.0, 2.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 2.0, 1.0, 3.0, 2.0, 0.0, 2.0, 1.0, 2.0, 2.0, 1.0, 1.0, 3.0, 0.0, 0.0, 0.0, 0.0, 1.0, 2.0, 1.0, 1.0, 1.0, 1.0, 2.0, 2.0, 3.0, 3.0, 1.0, 0.0, 4.0, 2.0, 5.0, 4.0, 1.0, 1.0, 0.0, 1.0, 2.0, 3.0, 1.0, 1.0, 1.0, 0.0, 4.0, 4.0, 3.0, 2.0, 2.0, 2.0, 1.0, 2.0, 1.0, 2.0, 1.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0, 1.0, 1.0, 2.0, 1.0, 2.0, 1.0, 1.0, 3.0, 3.0, 2.0, 2.0, 1.0, 2.0, 3.0, 3.0, 4.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 2.0, 1.0, 0.0, 2.0, 2.0, 0.0, 1.0, 0.0, 1.0, 1.0, 3.0, 5.0, 4.0, 5.0, 4.0, 3.0, 2.0, 2.0, 2.0, 2.0, 3.0, 1.0, 2.0, 2.0, 1.0, 1.0, 2.0, 2.0, 2.0, 2.0, 2.0, 1.0, 2.0, 2.0, 3.0, 2.0, 2.0, 1.0, 2.0, 2.0, 4.0, 1.0, 2.0, 3.0, 3.0, 3.0, 1.0, 3.0, 4.0, 3.0, 1.0, 1.0, 1.0, 2.0, 0.0, 0.0, 0.0, 0.0, 4.0, 3.0, 5.0, 3.0, 1.0, 1.0, 1.0, 2.0, 2.0, 1.0, 2.0, 5.0, 2.0, 3.0, 3.0, 3.0, 1.0, 1.0, 2.0, 0.0, 2.0, 4.0, 6.0, 6.0, 1.0, 1.0, 1.0, 1.0, 1.0, 2.0, 3.0, 1.0, 2.0, 3.0, 3.0, 1.0, 1.0, 1.0, 1.0, 2.0, 2.0, 4.0, 3.0, 1.0, 2.0, 4.0, 4.0, 4.0, 2.0, 2.0, 0.0, 2.0, 2.0, 3.0, 2.0, 2.0, 1.0, 0.0, 3.0, 2.0, 1.0, 0.0, 1.0, 2.0, 0.0, 4.0, 2.0, 3.0, 2.0, 1.0, 1.0, 2.0, 1.0, 3.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 2.0, 0.0, 0.0, 1.0, 1.0, 1.0, 3.0, 2.0, 2.0, 2.0, 2.0, 2.0, 1.0, 0.0, 1.0, 2.0, 2.0, 1.0, 3.0, 0.0, 2.0, 4.0, 2.0, 1.0, 2.0, 1.0, 1.0, 0.0, 1.0, 2.0, 1.0, 2.0, 0.0, 2.0, 4.0, 0.0, 3.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 2.0, 1.0, 1.0, 4.0, 3.0, 1.0, 3.0, 3.0, 3.0, 2.0, 1.0, 2.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 3.0, 2.0, 2.0, 3.0, 2.0, 1.0, 2.0, 3.0, 3.0, 1.0, 4.0, 1.0, 2.0, 1.0, 1.0, 2.0, 1.0, 2.0, 0.0, 0.0, 3.0, 1.0, 2.0, 3.0, 2.0, 0.0, 1.0, 2.0, 2.0, 2.0, 1.0, 1.0, 2.0, 1.0, 0.0, 0.0, 3.0, 3.0, 3.0, 2.0, 1.0, 0.0, 2.0, 1.0, 3.0, 3.0, 4.0, 6.0, 2.0, 2.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 2.0, 4.0, 3.0, 3.0, 1.0, 0.0, 1.0, 2.0, 0.0, 4.0, 1.0, 2.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 3.0, 1.0, 0.0, 1.0, 3.0, 4.0, 2.0, 1.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.13379408576728616, "mean_inference_ms": 0.3908731448003111, "mean_action_processing_ms": 0.02920316507845747, "mean_env_wait_ms": 0.4042597647091651, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 1028160, "timesteps_this_iter": 0, "agent_timesteps_total": 4112640, "timers": {"sample_time_ms": 5621.412, "sample_throughput": 896.572, "load_time_ms": 0.162, "load_throughput": 31027876.354, "learn_time_ms": 126.98, "learn_throughput": 39691.329, "update_time_ms": 2.441}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 330.51116943359375, "policy_entropy": 7838.4603271484375, "policy_loss": -36.597333908081055, "vf_loss": 58.553080558776855}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 1028160, "num_agent_steps_sampled": 4112640, "num_steps_trained": 1028160, "num_agent_steps_trained": 4112640, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 2056, "training_iteration": 102, "trial_id": "71426_00000", "experiment_id": "84bca2f7b35f43248fca18d21abe2ebf", "date": "2024-06-12_03-03-26", "timestamp": 1718129006, "time_this_iter_s": 10.487905740737915, "time_total_s": 1053.778392791748, "pid": 363902, "hostname": "DESKTOP-LQ219J4", "node_ip": "192.168.46.185", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 20, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 5000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 500, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Base_Model", "custom_model_config": {"env": "rware", "env_args": {"n_agents": 4, "column_height": 1, "max_inactivity_steps": null, "max_steps": 500, "fast_obs": true, "msg_bits": 0, "sensor_range": 1, "shelf_rows": 1, "shelf_columns": 3, "request_queue_size": 4, "reward_type": "RewardType.INDIVIDUAL", "map_name": "customized_map", "map_size": "tiny", "difficulty": "medium"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": true, "force_coop": false, "local_mode": true, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 4, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 100, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64}, "algorithm": "ia2c", "space_obs": "Dict(obs:Box([-100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100.], [100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.], (112,), float32))", "space_act": "Discrete(5)", "num_agents": 4, "episode_limit": 500, "policy_mapping_info": {"all_scenario": {"description": "rware all scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2", "agent_3"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "rware_customized_map", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 10, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.IA2CTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_il.<locals>.<lambda> at 0x7f38081d70d0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "grad_clip": 40.0, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "microbatch_size": null}, "time_since_restore": 1053.778392791748, "timesteps_since_restore": 0, "iterations_since_restore": 102, "perf": {"cpu_util_percent": 4.693333333333333, "ram_util_percent": 61.073333333333345}}
{"episode_reward_max": 18.0, "episode_reward_min": 0.0, "episode_reward_mean": 6.7, "episode_len_mean": 500.0, "episode_media": {}, "episodes_this_iter": 20, "policy_reward_min": {"shared_policy": 0.0}, "policy_reward_max": {"shared_policy": 6.0}, "policy_reward_mean": {"shared_policy": 1.675}, "custom_metrics": {}, "hist_stats": {"episode_reward": [5.0, 4.0, 6.0, 8.0, 7.0, 12.0, 0.0, 4.0, 4.0, 3.0, 17.0, 11.0, 8.0, 6.0, 8.0, 7.0, 8.0, 9.0, 11.0, 11.0, 5.0, 0.0, 15.0, 5.0, 10.0, 11.0, 4.0, 18.0, 4.0, 7.0, 9.0, 5.0, 10.0, 14.0, 6.0, 9.0, 6.0, 4.0, 9.0, 6.0, 6.0, 2.0, 4.0, 2.0, 8.0, 7.0, 5.0, 6.0, 9.0, 3.0, 5.0, 9.0, 3.0, 5.0, 9.0, 11.0, 4.0, 3.0, 10.0, 8.0, 9.0, 6.0, 3.0, 9.0, 5.0, 6.0, 3.0, 11.0, 4.0, 16.0, 6.0, 2.0, 3.0, 12.0, 4.0, 7.0, 3.0, 2.0, 5.0, 10.0, 7.0, 5.0, 6.0, 7.0, 6.0, 3.0, 4.0, 10.0, 3.0, 5.0, 11.0, 1.0, 4.0, 6.0, 6.0, 7.0, 2.0, 9.0, 8.0, 9.0], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500], "policy_shared_policy_reward": [1.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0, 1.0, 1.0, 2.0, 1.0, 2.0, 1.0, 1.0, 3.0, 3.0, 2.0, 2.0, 1.0, 2.0, 3.0, 3.0, 4.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 2.0, 1.0, 0.0, 2.0, 2.0, 0.0, 1.0, 0.0, 1.0, 1.0, 3.0, 5.0, 4.0, 5.0, 4.0, 3.0, 2.0, 2.0, 2.0, 2.0, 3.0, 1.0, 2.0, 2.0, 1.0, 1.0, 2.0, 2.0, 2.0, 2.0, 2.0, 1.0, 2.0, 2.0, 3.0, 2.0, 2.0, 1.0, 2.0, 2.0, 4.0, 1.0, 2.0, 3.0, 3.0, 3.0, 1.0, 3.0, 4.0, 3.0, 1.0, 1.0, 1.0, 2.0, 0.0, 0.0, 0.0, 0.0, 4.0, 3.0, 5.0, 3.0, 1.0, 1.0, 1.0, 2.0, 2.0, 1.0, 2.0, 5.0, 2.0, 3.0, 3.0, 3.0, 1.0, 1.0, 2.0, 0.0, 2.0, 4.0, 6.0, 6.0, 1.0, 1.0, 1.0, 1.0, 1.0, 2.0, 3.0, 1.0, 2.0, 3.0, 3.0, 1.0, 1.0, 1.0, 1.0, 2.0, 2.0, 4.0, 3.0, 1.0, 2.0, 4.0, 4.0, 4.0, 2.0, 2.0, 0.0, 2.0, 2.0, 3.0, 2.0, 2.0, 1.0, 0.0, 3.0, 2.0, 1.0, 0.0, 1.0, 2.0, 0.0, 4.0, 2.0, 3.0, 2.0, 1.0, 1.0, 2.0, 1.0, 3.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 2.0, 0.0, 0.0, 1.0, 1.0, 1.0, 3.0, 2.0, 2.0, 2.0, 2.0, 2.0, 1.0, 0.0, 1.0, 2.0, 2.0, 1.0, 3.0, 0.0, 2.0, 4.0, 2.0, 1.0, 2.0, 1.0, 1.0, 0.0, 1.0, 2.0, 1.0, 2.0, 0.0, 2.0, 4.0, 0.0, 3.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 2.0, 1.0, 1.0, 4.0, 3.0, 1.0, 3.0, 3.0, 3.0, 2.0, 1.0, 2.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 3.0, 2.0, 2.0, 3.0, 2.0, 1.0, 2.0, 3.0, 3.0, 1.0, 4.0, 1.0, 2.0, 1.0, 1.0, 2.0, 1.0, 2.0, 0.0, 0.0, 3.0, 1.0, 2.0, 3.0, 2.0, 0.0, 1.0, 2.0, 2.0, 2.0, 1.0, 1.0, 2.0, 1.0, 0.0, 0.0, 3.0, 3.0, 3.0, 2.0, 1.0, 0.0, 2.0, 1.0, 3.0, 3.0, 4.0, 6.0, 2.0, 2.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 2.0, 4.0, 3.0, 3.0, 1.0, 0.0, 1.0, 2.0, 0.0, 4.0, 1.0, 2.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 3.0, 1.0, 0.0, 1.0, 3.0, 4.0, 2.0, 1.0, 2.0, 1.0, 1.0, 3.0, 0.0, 2.0, 1.0, 2.0, 2.0, 1.0, 1.0, 2.0, 2.0, 1.0, 2.0, 2.0, 1.0, 2.0, 1.0, 2.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 4.0, 3.0, 2.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 2.0, 2.0, 3.0, 3.0, 3.0, 0.0, 1.0, 0.0, 0.0, 1.0, 2.0, 0.0, 1.0, 1.0, 1.0, 2.0, 2.0, 2.0, 1.0, 2.0, 1.0, 2.0, 2.0, 2.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 4.0, 3.0, 1.0, 2.0, 2.0, 1.0, 3.0, 1.0, 3.0, 3.0, 2.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.13379843118350532, "mean_inference_ms": 0.39087680641234646, "mean_action_processing_ms": 0.029203129316358725, "mean_env_wait_ms": 0.4042356552216851, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 1038240, "timesteps_this_iter": 0, "agent_timesteps_total": 4152960, "timers": {"sample_time_ms": 5603.555, "sample_throughput": 899.429, "load_time_ms": 0.161, "load_throughput": 31298922.357, "learn_time_ms": 126.094, "learn_throughput": 39970.141, "update_time_ms": 2.392}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 270.0340576171875, "policy_entropy": 7817.6617431640625, "policy_loss": -45.99761962890625, "vf_loss": 49.67374801635742}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 1038240, "num_agent_steps_sampled": 4152960, "num_steps_trained": 1038240, "num_agent_steps_trained": 4152960, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 2076, "training_iteration": 103, "trial_id": "71426_00000", "experiment_id": "84bca2f7b35f43248fca18d21abe2ebf", "date": "2024-06-12_03-03-36", "timestamp": 1718129016, "time_this_iter_s": 10.190453290939331, "time_total_s": 1063.9688460826874, "pid": 363902, "hostname": "DESKTOP-LQ219J4", "node_ip": "192.168.46.185", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 20, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 5000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 500, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Base_Model", "custom_model_config": {"env": "rware", "env_args": {"n_agents": 4, "column_height": 1, "max_inactivity_steps": null, "max_steps": 500, "fast_obs": true, "msg_bits": 0, "sensor_range": 1, "shelf_rows": 1, "shelf_columns": 3, "request_queue_size": 4, "reward_type": "RewardType.INDIVIDUAL", "map_name": "customized_map", "map_size": "tiny", "difficulty": "medium"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": true, "force_coop": false, "local_mode": true, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 4, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 100, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64}, "algorithm": "ia2c", "space_obs": "Dict(obs:Box([-100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100.], [100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.], (112,), float32))", "space_act": "Discrete(5)", "num_agents": 4, "episode_limit": 500, "policy_mapping_info": {"all_scenario": {"description": "rware all scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2", "agent_3"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "rware_customized_map", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 10, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.IA2CTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_il.<locals>.<lambda> at 0x7f382806e940>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "grad_clip": 40.0, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "microbatch_size": null}, "time_since_restore": 1063.9688460826874, "timesteps_since_restore": 0, "iterations_since_restore": 103, "perf": {"cpu_util_percent": 4.428571428571429, "ram_util_percent": 61.39999999999999}}
{"episode_reward_max": 18.0, "episode_reward_min": 0.0, "episode_reward_mean": 6.93, "episode_len_mean": 500.0, "episode_media": {}, "episodes_this_iter": 20, "policy_reward_min": {"shared_policy": 0.0}, "policy_reward_max": {"shared_policy": 7.0}, "policy_reward_mean": {"shared_policy": 1.7325}, "custom_metrics": {}, "hist_stats": {"episode_reward": [5.0, 0.0, 15.0, 5.0, 10.0, 11.0, 4.0, 18.0, 4.0, 7.0, 9.0, 5.0, 10.0, 14.0, 6.0, 9.0, 6.0, 4.0, 9.0, 6.0, 6.0, 2.0, 4.0, 2.0, 8.0, 7.0, 5.0, 6.0, 9.0, 3.0, 5.0, 9.0, 3.0, 5.0, 9.0, 11.0, 4.0, 3.0, 10.0, 8.0, 9.0, 6.0, 3.0, 9.0, 5.0, 6.0, 3.0, 11.0, 4.0, 16.0, 6.0, 2.0, 3.0, 12.0, 4.0, 7.0, 3.0, 2.0, 5.0, 10.0, 7.0, 5.0, 6.0, 7.0, 6.0, 3.0, 4.0, 10.0, 3.0, 5.0, 11.0, 1.0, 4.0, 6.0, 6.0, 7.0, 2.0, 9.0, 8.0, 9.0, 11.0, 6.0, 3.0, 6.0, 4.0, 5.0, 4.0, 8.0, 6.0, 12.0, 2.0, 14.0, 9.0, 7.0, 11.0, 8.0, 9.0, 16.0, 18.0, 13.0], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500], "policy_shared_policy_reward": [1.0, 1.0, 1.0, 2.0, 0.0, 0.0, 0.0, 0.0, 4.0, 3.0, 5.0, 3.0, 1.0, 1.0, 1.0, 2.0, 2.0, 1.0, 2.0, 5.0, 2.0, 3.0, 3.0, 3.0, 1.0, 1.0, 2.0, 0.0, 2.0, 4.0, 6.0, 6.0, 1.0, 1.0, 1.0, 1.0, 1.0, 2.0, 3.0, 1.0, 2.0, 3.0, 3.0, 1.0, 1.0, 1.0, 1.0, 2.0, 2.0, 4.0, 3.0, 1.0, 2.0, 4.0, 4.0, 4.0, 2.0, 2.0, 0.0, 2.0, 2.0, 3.0, 2.0, 2.0, 1.0, 0.0, 3.0, 2.0, 1.0, 0.0, 1.0, 2.0, 0.0, 4.0, 2.0, 3.0, 2.0, 1.0, 1.0, 2.0, 1.0, 3.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 2.0, 0.0, 0.0, 1.0, 1.0, 1.0, 3.0, 2.0, 2.0, 2.0, 2.0, 2.0, 1.0, 0.0, 1.0, 2.0, 2.0, 1.0, 3.0, 0.0, 2.0, 4.0, 2.0, 1.0, 2.0, 1.0, 1.0, 0.0, 1.0, 2.0, 1.0, 2.0, 0.0, 2.0, 4.0, 0.0, 3.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 2.0, 1.0, 1.0, 4.0, 3.0, 1.0, 3.0, 3.0, 3.0, 2.0, 1.0, 2.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 3.0, 2.0, 2.0, 3.0, 2.0, 1.0, 2.0, 3.0, 3.0, 1.0, 4.0, 1.0, 2.0, 1.0, 1.0, 2.0, 1.0, 2.0, 0.0, 0.0, 3.0, 1.0, 2.0, 3.0, 2.0, 0.0, 1.0, 2.0, 2.0, 2.0, 1.0, 1.0, 2.0, 1.0, 0.0, 0.0, 3.0, 3.0, 3.0, 2.0, 1.0, 0.0, 2.0, 1.0, 3.0, 3.0, 4.0, 6.0, 2.0, 2.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 2.0, 4.0, 3.0, 3.0, 1.0, 0.0, 1.0, 2.0, 0.0, 4.0, 1.0, 2.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 3.0, 1.0, 0.0, 1.0, 3.0, 4.0, 2.0, 1.0, 2.0, 1.0, 1.0, 3.0, 0.0, 2.0, 1.0, 2.0, 2.0, 1.0, 1.0, 2.0, 2.0, 1.0, 2.0, 2.0, 1.0, 2.0, 1.0, 2.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 4.0, 3.0, 2.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 2.0, 2.0, 3.0, 3.0, 3.0, 0.0, 1.0, 0.0, 0.0, 1.0, 2.0, 0.0, 1.0, 1.0, 1.0, 2.0, 2.0, 2.0, 1.0, 2.0, 1.0, 2.0, 2.0, 2.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 4.0, 3.0, 1.0, 2.0, 2.0, 1.0, 3.0, 1.0, 3.0, 3.0, 2.0, 2.0, 4.0, 1.0, 4.0, 1.0, 0.0, 3.0, 2.0, 2.0, 0.0, 0.0, 1.0, 2.0, 3.0, 1.0, 0.0, 0.0, 1.0, 2.0, 1.0, 2.0, 2.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 3.0, 3.0, 2.0, 2.0, 1.0, 1.0, 2.0, 3.0, 3.0, 4.0, 0.0, 0.0, 1.0, 1.0, 1.0, 5.0, 6.0, 2.0, 2.0, 3.0, 3.0, 1.0, 2.0, 2.0, 1.0, 2.0, 3.0, 2.0, 4.0, 2.0, 2.0, 4.0, 1.0, 1.0, 2.0, 2.0, 2.0, 3.0, 5.0, 4.0, 4.0, 3.0, 5.0, 7.0, 3.0, 3.0, 3.0, 2.0, 4.0, 4.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.13379627875841224, "mean_inference_ms": 0.390867622647167, "mean_action_processing_ms": 0.02920249106924836, "mean_env_wait_ms": 0.4042075231252963, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 1048320, "timesteps_this_iter": 0, "agent_timesteps_total": 4193280, "timers": {"sample_time_ms": 5585.066, "sample_throughput": 902.406, "load_time_ms": 0.16, "load_throughput": 31452599.554, "learn_time_ms": 124.606, "learn_throughput": 40447.61, "update_time_ms": 2.409}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 177.30270385742188, "policy_entropy": 7694.447021484375, "policy_loss": 52.10911148786545, "vf_loss": 59.766279220581055}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 1048320, "num_agent_steps_sampled": 4193280, "num_steps_trained": 1048320, "num_agent_steps_trained": 4193280, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 2096, "training_iteration": 104, "trial_id": "71426_00000", "experiment_id": "84bca2f7b35f43248fca18d21abe2ebf", "date": "2024-06-12_03-03-46", "timestamp": 1718129026, "time_this_iter_s": 10.107732057571411, "time_total_s": 1074.0765781402588, "pid": 363902, "hostname": "DESKTOP-LQ219J4", "node_ip": "192.168.46.185", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 20, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 5000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 500, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Base_Model", "custom_model_config": {"env": "rware", "env_args": {"n_agents": 4, "column_height": 1, "max_inactivity_steps": null, "max_steps": 500, "fast_obs": true, "msg_bits": 0, "sensor_range": 1, "shelf_rows": 1, "shelf_columns": 3, "request_queue_size": 4, "reward_type": "RewardType.INDIVIDUAL", "map_name": "customized_map", "map_size": "tiny", "difficulty": "medium"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": true, "force_coop": false, "local_mode": true, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 4, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 100, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64}, "algorithm": "ia2c", "space_obs": "Dict(obs:Box([-100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100.], [100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.], (112,), float32))", "space_act": "Discrete(5)", "num_agents": 4, "episode_limit": 500, "policy_mapping_info": {"all_scenario": {"description": "rware all scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2", "agent_3"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "rware_customized_map", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 10, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.IA2CTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_il.<locals>.<lambda> at 0x7f38081d6820>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "grad_clip": 40.0, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "microbatch_size": null}, "time_since_restore": 1074.0765781402588, "timesteps_since_restore": 0, "iterations_since_restore": 104, "perf": {"cpu_util_percent": 4.406666666666666, "ram_util_percent": 61.620000000000005}}
{"episode_reward_max": 18.0, "episode_reward_min": 1.0, "episode_reward_mean": 6.7, "episode_len_mean": 500.0, "episode_media": {}, "episodes_this_iter": 20, "policy_reward_min": {"shared_policy": 0.0}, "policy_reward_max": {"shared_policy": 7.0}, "policy_reward_mean": {"shared_policy": 1.675}, "custom_metrics": {}, "hist_stats": {"episode_reward": [6.0, 2.0, 4.0, 2.0, 8.0, 7.0, 5.0, 6.0, 9.0, 3.0, 5.0, 9.0, 3.0, 5.0, 9.0, 11.0, 4.0, 3.0, 10.0, 8.0, 9.0, 6.0, 3.0, 9.0, 5.0, 6.0, 3.0, 11.0, 4.0, 16.0, 6.0, 2.0, 3.0, 12.0, 4.0, 7.0, 3.0, 2.0, 5.0, 10.0, 7.0, 5.0, 6.0, 7.0, 6.0, 3.0, 4.0, 10.0, 3.0, 5.0, 11.0, 1.0, 4.0, 6.0, 6.0, 7.0, 2.0, 9.0, 8.0, 9.0, 11.0, 6.0, 3.0, 6.0, 4.0, 5.0, 4.0, 8.0, 6.0, 12.0, 2.0, 14.0, 9.0, 7.0, 11.0, 8.0, 9.0, 16.0, 18.0, 13.0, 3.0, 5.0, 8.0, 12.0, 8.0, 10.0, 5.0, 6.0, 10.0, 3.0, 4.0, 11.0, 3.0, 7.0, 9.0, 1.0, 4.0, 7.0, 4.0, 14.0], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500], "policy_shared_policy_reward": [1.0, 3.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 2.0, 0.0, 0.0, 1.0, 1.0, 1.0, 3.0, 2.0, 2.0, 2.0, 2.0, 2.0, 1.0, 0.0, 1.0, 2.0, 2.0, 1.0, 3.0, 0.0, 2.0, 4.0, 2.0, 1.0, 2.0, 1.0, 1.0, 0.0, 1.0, 2.0, 1.0, 2.0, 0.0, 2.0, 4.0, 0.0, 3.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 2.0, 1.0, 1.0, 4.0, 3.0, 1.0, 3.0, 3.0, 3.0, 2.0, 1.0, 2.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 3.0, 2.0, 2.0, 3.0, 2.0, 1.0, 2.0, 3.0, 3.0, 1.0, 4.0, 1.0, 2.0, 1.0, 1.0, 2.0, 1.0, 2.0, 0.0, 0.0, 3.0, 1.0, 2.0, 3.0, 2.0, 0.0, 1.0, 2.0, 2.0, 2.0, 1.0, 1.0, 2.0, 1.0, 0.0, 0.0, 3.0, 3.0, 3.0, 2.0, 1.0, 0.0, 2.0, 1.0, 3.0, 3.0, 4.0, 6.0, 2.0, 2.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 2.0, 4.0, 3.0, 3.0, 1.0, 0.0, 1.0, 2.0, 0.0, 4.0, 1.0, 2.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 3.0, 1.0, 0.0, 1.0, 3.0, 4.0, 2.0, 1.0, 2.0, 1.0, 1.0, 3.0, 0.0, 2.0, 1.0, 2.0, 2.0, 1.0, 1.0, 2.0, 2.0, 1.0, 2.0, 2.0, 1.0, 2.0, 1.0, 2.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 4.0, 3.0, 2.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 2.0, 2.0, 3.0, 3.0, 3.0, 0.0, 1.0, 0.0, 0.0, 1.0, 2.0, 0.0, 1.0, 1.0, 1.0, 2.0, 2.0, 2.0, 1.0, 2.0, 1.0, 2.0, 2.0, 2.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 4.0, 3.0, 1.0, 2.0, 2.0, 1.0, 3.0, 1.0, 3.0, 3.0, 2.0, 2.0, 4.0, 1.0, 4.0, 1.0, 0.0, 3.0, 2.0, 2.0, 0.0, 0.0, 1.0, 2.0, 3.0, 1.0, 0.0, 0.0, 1.0, 2.0, 1.0, 2.0, 2.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 3.0, 3.0, 2.0, 2.0, 1.0, 1.0, 2.0, 3.0, 3.0, 4.0, 0.0, 0.0, 1.0, 1.0, 1.0, 5.0, 6.0, 2.0, 2.0, 3.0, 3.0, 1.0, 2.0, 2.0, 1.0, 2.0, 3.0, 2.0, 4.0, 2.0, 2.0, 4.0, 1.0, 1.0, 2.0, 2.0, 2.0, 3.0, 5.0, 4.0, 4.0, 3.0, 5.0, 7.0, 3.0, 3.0, 3.0, 2.0, 4.0, 4.0, 1.0, 1.0, 1.0, 0.0, 2.0, 1.0, 1.0, 1.0, 3.0, 1.0, 3.0, 1.0, 4.0, 3.0, 4.0, 1.0, 1.0, 2.0, 3.0, 2.0, 2.0, 3.0, 2.0, 3.0, 3.0, 0.0, 1.0, 1.0, 1.0, 2.0, 2.0, 1.0, 1.0, 2.0, 3.0, 4.0, 1.0, 1.0, 1.0, 0.0, 2.0, 1.0, 0.0, 1.0, 1.0, 4.0, 3.0, 3.0, 1.0, 0.0, 0.0, 2.0, 2.0, 2.0, 1.0, 2.0, 2.0, 3.0, 3.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 2.0, 1.0, 2.0, 1.0, 2.0, 2.0, 1.0, 1.0, 0.0, 2.0, 4.0, 3.0, 2.0, 5.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.1338055654285174, "mean_inference_ms": 0.3908834455193631, "mean_action_processing_ms": 0.029205919485816745, "mean_env_wait_ms": 0.40418585684687985, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 1058400, "timesteps_this_iter": 0, "agent_timesteps_total": 4233600, "timers": {"sample_time_ms": 5577.96, "sample_throughput": 903.556, "load_time_ms": 0.162, "load_throughput": 31123810.601, "learn_time_ms": 124.293, "learn_throughput": 40549.318, "update_time_ms": 2.465}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 472.3937683105469, "policy_entropy": 7646.11181640625, "policy_loss": 30.08066201210022, "vf_loss": 61.023170471191406}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 1058400, "num_agent_steps_sampled": 4233600, "num_steps_trained": 1058400, "num_agent_steps_trained": 4233600, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 2116, "training_iteration": 105, "trial_id": "71426_00000", "experiment_id": "84bca2f7b35f43248fca18d21abe2ebf", "date": "2024-06-12_03-03-56", "timestamp": 1718129036, "time_this_iter_s": 10.17101526260376, "time_total_s": 1084.2475934028625, "pid": 363902, "hostname": "DESKTOP-LQ219J4", "node_ip": "192.168.46.185", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 20, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 5000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 500, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Base_Model", "custom_model_config": {"env": "rware", "env_args": {"n_agents": 4, "column_height": 1, "max_inactivity_steps": null, "max_steps": 500, "fast_obs": true, "msg_bits": 0, "sensor_range": 1, "shelf_rows": 1, "shelf_columns": 3, "request_queue_size": 4, "reward_type": "RewardType.INDIVIDUAL", "map_name": "customized_map", "map_size": "tiny", "difficulty": "medium"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": true, "force_coop": false, "local_mode": true, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 4, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 100, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64}, "algorithm": "ia2c", "space_obs": "Dict(obs:Box([-100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100.], [100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.], (112,), float32))", "space_act": "Discrete(5)", "num_agents": 4, "episode_limit": 500, "policy_mapping_info": {"all_scenario": {"description": "rware all scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2", "agent_3"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "rware_customized_map", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 10, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.IA2CTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_il.<locals>.<lambda> at 0x7f3808645b80>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "grad_clip": 40.0, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "microbatch_size": null}, "time_since_restore": 1084.2475934028625, "timesteps_since_restore": 0, "iterations_since_restore": 105, "perf": {"cpu_util_percent": 4.385714285714287, "ram_util_percent": 61.89999999999999}}
{"episode_reward_max": 18.0, "episode_reward_min": 1.0, "episode_reward_mean": 7.11, "episode_len_mean": 500.0, "episode_media": {}, "episodes_this_iter": 20, "policy_reward_min": {"shared_policy": 0.0}, "policy_reward_max": {"shared_policy": 7.0}, "policy_reward_mean": {"shared_policy": 1.7775}, "custom_metrics": {}, "hist_stats": {"episode_reward": [9.0, 6.0, 3.0, 9.0, 5.0, 6.0, 3.0, 11.0, 4.0, 16.0, 6.0, 2.0, 3.0, 12.0, 4.0, 7.0, 3.0, 2.0, 5.0, 10.0, 7.0, 5.0, 6.0, 7.0, 6.0, 3.0, 4.0, 10.0, 3.0, 5.0, 11.0, 1.0, 4.0, 6.0, 6.0, 7.0, 2.0, 9.0, 8.0, 9.0, 11.0, 6.0, 3.0, 6.0, 4.0, 5.0, 4.0, 8.0, 6.0, 12.0, 2.0, 14.0, 9.0, 7.0, 11.0, 8.0, 9.0, 16.0, 18.0, 13.0, 3.0, 5.0, 8.0, 12.0, 8.0, 10.0, 5.0, 6.0, 10.0, 3.0, 4.0, 11.0, 3.0, 7.0, 9.0, 1.0, 4.0, 7.0, 4.0, 14.0, 3.0, 11.0, 8.0, 5.0, 5.0, 5.0, 17.0, 7.0, 8.0, 15.0, 7.0, 8.0, 5.0, 6.0, 12.0, 9.0, 7.0, 10.0, 2.0, 10.0], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500], "policy_shared_policy_reward": [3.0, 1.0, 4.0, 1.0, 2.0, 1.0, 1.0, 2.0, 1.0, 2.0, 0.0, 0.0, 3.0, 1.0, 2.0, 3.0, 2.0, 0.0, 1.0, 2.0, 2.0, 2.0, 1.0, 1.0, 2.0, 1.0, 0.0, 0.0, 3.0, 3.0, 3.0, 2.0, 1.0, 0.0, 2.0, 1.0, 3.0, 3.0, 4.0, 6.0, 2.0, 2.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 2.0, 4.0, 3.0, 3.0, 1.0, 0.0, 1.0, 2.0, 0.0, 4.0, 1.0, 2.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 3.0, 1.0, 0.0, 1.0, 3.0, 4.0, 2.0, 1.0, 2.0, 1.0, 1.0, 3.0, 0.0, 2.0, 1.0, 2.0, 2.0, 1.0, 1.0, 2.0, 2.0, 1.0, 2.0, 2.0, 1.0, 2.0, 1.0, 2.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 4.0, 3.0, 2.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 2.0, 2.0, 3.0, 3.0, 3.0, 0.0, 1.0, 0.0, 0.0, 1.0, 2.0, 0.0, 1.0, 1.0, 1.0, 2.0, 2.0, 2.0, 1.0, 2.0, 1.0, 2.0, 2.0, 2.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 4.0, 3.0, 1.0, 2.0, 2.0, 1.0, 3.0, 1.0, 3.0, 3.0, 2.0, 2.0, 4.0, 1.0, 4.0, 1.0, 0.0, 3.0, 2.0, 2.0, 0.0, 0.0, 1.0, 2.0, 3.0, 1.0, 0.0, 0.0, 1.0, 2.0, 1.0, 2.0, 2.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 3.0, 3.0, 2.0, 2.0, 1.0, 1.0, 2.0, 3.0, 3.0, 4.0, 0.0, 0.0, 1.0, 1.0, 1.0, 5.0, 6.0, 2.0, 2.0, 3.0, 3.0, 1.0, 2.0, 2.0, 1.0, 2.0, 3.0, 2.0, 4.0, 2.0, 2.0, 4.0, 1.0, 1.0, 2.0, 2.0, 2.0, 3.0, 5.0, 4.0, 4.0, 3.0, 5.0, 7.0, 3.0, 3.0, 3.0, 2.0, 4.0, 4.0, 1.0, 1.0, 1.0, 0.0, 2.0, 1.0, 1.0, 1.0, 3.0, 1.0, 3.0, 1.0, 4.0, 3.0, 4.0, 1.0, 1.0, 2.0, 3.0, 2.0, 2.0, 3.0, 2.0, 3.0, 3.0, 0.0, 1.0, 1.0, 1.0, 2.0, 2.0, 1.0, 1.0, 2.0, 3.0, 4.0, 1.0, 1.0, 1.0, 0.0, 2.0, 1.0, 0.0, 1.0, 1.0, 4.0, 3.0, 3.0, 1.0, 0.0, 0.0, 2.0, 2.0, 2.0, 1.0, 2.0, 2.0, 3.0, 3.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 2.0, 1.0, 2.0, 1.0, 2.0, 2.0, 1.0, 1.0, 0.0, 2.0, 4.0, 3.0, 2.0, 5.0, 0.0, 2.0, 1.0, 0.0, 3.0, 4.0, 2.0, 2.0, 2.0, 1.0, 2.0, 3.0, 2.0, 1.0, 2.0, 0.0, 2.0, 1.0, 1.0, 1.0, 2.0, 1.0, 2.0, 0.0, 5.0, 7.0, 3.0, 2.0, 2.0, 2.0, 1.0, 2.0, 2.0, 2.0, 3.0, 1.0, 2.0, 7.0, 2.0, 4.0, 2.0, 1.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 1.0, 2.0, 0.0, 2.0, 2.0, 1.0, 1.0, 3.0, 2.0, 2.0, 5.0, 2.0, 2.0, 2.0, 3.0, 3.0, 1.0, 1.0, 2.0, 3.0, 2.0, 2.0, 3.0, 0.0, 1.0, 1.0, 0.0, 2.0, 2.0, 3.0, 3.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.13380418680114092, "mean_inference_ms": 0.39088461836157, "mean_action_processing_ms": 0.029205917051020366, "mean_env_wait_ms": 0.4041739064974599, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 1068480, "timesteps_this_iter": 0, "agent_timesteps_total": 4273920, "timers": {"sample_time_ms": 5123.894, "sample_throughput": 983.627, "load_time_ms": 0.166, "load_throughput": 30324619.366, "learn_time_ms": 124.832, "learn_throughput": 40374.144, "update_time_ms": 2.447}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 307.5096435546875, "policy_entropy": 7706.2913818359375, "policy_loss": -10.509321212768555, "vf_loss": 51.70987319946289}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 1068480, "num_agent_steps_sampled": 4273920, "num_steps_trained": 1068480, "num_agent_steps_trained": 4273920, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 2136, "training_iteration": 106, "trial_id": "71426_00000", "experiment_id": "84bca2f7b35f43248fca18d21abe2ebf", "date": "2024-06-12_03-04-07", "timestamp": 1718129047, "time_this_iter_s": 10.188978910446167, "time_total_s": 1094.4365723133087, "pid": 363902, "hostname": "DESKTOP-LQ219J4", "node_ip": "192.168.46.185", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 20, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 5000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 500, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Base_Model", "custom_model_config": {"env": "rware", "env_args": {"n_agents": 4, "column_height": 1, "max_inactivity_steps": null, "max_steps": 500, "fast_obs": true, "msg_bits": 0, "sensor_range": 1, "shelf_rows": 1, "shelf_columns": 3, "request_queue_size": 4, "reward_type": "RewardType.INDIVIDUAL", "map_name": "customized_map", "map_size": "tiny", "difficulty": "medium"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": true, "force_coop": false, "local_mode": true, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 4, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 100, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64}, "algorithm": "ia2c", "space_obs": "Dict(obs:Box([-100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100.], [100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.], (112,), float32))", "space_act": "Discrete(5)", "num_agents": 4, "episode_limit": 500, "policy_mapping_info": {"all_scenario": {"description": "rware all scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2", "agent_3"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "rware_customized_map", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 10, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.IA2CTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_il.<locals>.<lambda> at 0x7f38280b2160>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "grad_clip": 40.0, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "microbatch_size": null}, "time_since_restore": 1094.4365723133087, "timesteps_since_restore": 0, "iterations_since_restore": 106, "perf": {"cpu_util_percent": 4.519999999999999, "ram_util_percent": 62.20000000000002}}
{"episode_reward_max": 18.0, "episode_reward_min": 0.0, "episode_reward_mean": 7.49, "episode_len_mean": 500.0, "episode_media": {}, "episodes_this_iter": 20, "policy_reward_min": {"shared_policy": 0.0}, "policy_reward_max": {"shared_policy": 7.0}, "policy_reward_mean": {"shared_policy": 1.8725}, "custom_metrics": {}, "hist_stats": {"episode_reward": [7.0, 5.0, 6.0, 7.0, 6.0, 3.0, 4.0, 10.0, 3.0, 5.0, 11.0, 1.0, 4.0, 6.0, 6.0, 7.0, 2.0, 9.0, 8.0, 9.0, 11.0, 6.0, 3.0, 6.0, 4.0, 5.0, 4.0, 8.0, 6.0, 12.0, 2.0, 14.0, 9.0, 7.0, 11.0, 8.0, 9.0, 16.0, 18.0, 13.0, 3.0, 5.0, 8.0, 12.0, 8.0, 10.0, 5.0, 6.0, 10.0, 3.0, 4.0, 11.0, 3.0, 7.0, 9.0, 1.0, 4.0, 7.0, 4.0, 14.0, 3.0, 11.0, 8.0, 5.0, 5.0, 5.0, 17.0, 7.0, 8.0, 15.0, 7.0, 8.0, 5.0, 6.0, 12.0, 9.0, 7.0, 10.0, 2.0, 10.0, 11.0, 7.0, 5.0, 8.0, 14.0, 9.0, 4.0, 5.0, 11.0, 9.0, 0.0, 10.0, 7.0, 12.0, 11.0, 13.0, 8.0, 3.0, 11.0, 6.0], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500], "policy_shared_policy_reward": [2.0, 1.0, 1.0, 3.0, 0.0, 2.0, 1.0, 2.0, 2.0, 1.0, 1.0, 2.0, 2.0, 1.0, 2.0, 2.0, 1.0, 2.0, 1.0, 2.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 4.0, 3.0, 2.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 2.0, 2.0, 3.0, 3.0, 3.0, 0.0, 1.0, 0.0, 0.0, 1.0, 2.0, 0.0, 1.0, 1.0, 1.0, 2.0, 2.0, 2.0, 1.0, 2.0, 1.0, 2.0, 2.0, 2.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 4.0, 3.0, 1.0, 2.0, 2.0, 1.0, 3.0, 1.0, 3.0, 3.0, 2.0, 2.0, 4.0, 1.0, 4.0, 1.0, 0.0, 3.0, 2.0, 2.0, 0.0, 0.0, 1.0, 2.0, 3.0, 1.0, 0.0, 0.0, 1.0, 2.0, 1.0, 2.0, 2.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 3.0, 3.0, 2.0, 2.0, 1.0, 1.0, 2.0, 3.0, 3.0, 4.0, 0.0, 0.0, 1.0, 1.0, 1.0, 5.0, 6.0, 2.0, 2.0, 3.0, 3.0, 1.0, 2.0, 2.0, 1.0, 2.0, 3.0, 2.0, 4.0, 2.0, 2.0, 4.0, 1.0, 1.0, 2.0, 2.0, 2.0, 3.0, 5.0, 4.0, 4.0, 3.0, 5.0, 7.0, 3.0, 3.0, 3.0, 2.0, 4.0, 4.0, 1.0, 1.0, 1.0, 0.0, 2.0, 1.0, 1.0, 1.0, 3.0, 1.0, 3.0, 1.0, 4.0, 3.0, 4.0, 1.0, 1.0, 2.0, 3.0, 2.0, 2.0, 3.0, 2.0, 3.0, 3.0, 0.0, 1.0, 1.0, 1.0, 2.0, 2.0, 1.0, 1.0, 2.0, 3.0, 4.0, 1.0, 1.0, 1.0, 0.0, 2.0, 1.0, 0.0, 1.0, 1.0, 4.0, 3.0, 3.0, 1.0, 0.0, 0.0, 2.0, 2.0, 2.0, 1.0, 2.0, 2.0, 3.0, 3.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 2.0, 1.0, 2.0, 1.0, 2.0, 2.0, 1.0, 1.0, 0.0, 2.0, 4.0, 3.0, 2.0, 5.0, 0.0, 2.0, 1.0, 0.0, 3.0, 4.0, 2.0, 2.0, 2.0, 1.0, 2.0, 3.0, 2.0, 1.0, 2.0, 0.0, 2.0, 1.0, 1.0, 1.0, 2.0, 1.0, 2.0, 0.0, 5.0, 7.0, 3.0, 2.0, 2.0, 2.0, 1.0, 2.0, 2.0, 2.0, 3.0, 1.0, 2.0, 7.0, 2.0, 4.0, 2.0, 1.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 1.0, 2.0, 0.0, 2.0, 2.0, 1.0, 1.0, 3.0, 2.0, 2.0, 5.0, 2.0, 2.0, 2.0, 3.0, 3.0, 1.0, 1.0, 2.0, 3.0, 2.0, 2.0, 3.0, 0.0, 1.0, 1.0, 0.0, 2.0, 2.0, 3.0, 3.0, 3.0, 1.0, 3.0, 4.0, 2.0, 2.0, 1.0, 2.0, 1.0, 0.0, 2.0, 2.0, 1.0, 2.0, 2.0, 3.0, 2.0, 3.0, 4.0, 5.0, 4.0, 2.0, 2.0, 1.0, 1.0, 1.0, 0.0, 2.0, 1.0, 2.0, 2.0, 0.0, 4.0, 2.0, 4.0, 1.0, 1.0, 3.0, 2.0, 3.0, 0.0, 0.0, 0.0, 0.0, 3.0, 2.0, 3.0, 2.0, 2.0, 1.0, 2.0, 2.0, 6.0, 1.0, 3.0, 2.0, 3.0, 2.0, 3.0, 3.0, 3.0, 4.0, 2.0, 4.0, 2.0, 2.0, 2.0, 2.0, 1.0, 1.0, 1.0, 0.0, 3.0, 2.0, 4.0, 2.0, 2.0, 2.0, 1.0, 1.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.13379992052037773, "mean_inference_ms": 0.3908787166760767, "mean_action_processing_ms": 0.029204881309196865, "mean_env_wait_ms": 0.4041595609740197, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 1078560, "timesteps_this_iter": 0, "agent_timesteps_total": 4314240, "timers": {"sample_time_ms": 5119.447, "sample_throughput": 984.481, "load_time_ms": 0.168, "load_throughput": 29980559.013, "learn_time_ms": 128.915, "learn_throughput": 39095.543, "update_time_ms": 2.467}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 388.36749267578125, "policy_entropy": 7785.847900390625, "policy_loss": 107.14676094055176, "vf_loss": 83.06498146057129}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 1078560, "num_agent_steps_sampled": 4314240, "num_steps_trained": 1078560, "num_agent_steps_trained": 4314240, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 2156, "training_iteration": 107, "trial_id": "71426_00000", "experiment_id": "84bca2f7b35f43248fca18d21abe2ebf", "date": "2024-06-12_03-04-17", "timestamp": 1718129057, "time_this_iter_s": 10.475813865661621, "time_total_s": 1104.9123861789703, "pid": 363902, "hostname": "DESKTOP-LQ219J4", "node_ip": "192.168.46.185", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 20, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 5000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 500, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Base_Model", "custom_model_config": {"env": "rware", "env_args": {"n_agents": 4, "column_height": 1, "max_inactivity_steps": null, "max_steps": 500, "fast_obs": true, "msg_bits": 0, "sensor_range": 1, "shelf_rows": 1, "shelf_columns": 3, "request_queue_size": 4, "reward_type": "RewardType.INDIVIDUAL", "map_name": "customized_map", "map_size": "tiny", "difficulty": "medium"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": true, "force_coop": false, "local_mode": true, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 4, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 100, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64}, "algorithm": "ia2c", "space_obs": "Dict(obs:Box([-100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100.], [100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.], (112,), float32))", "space_act": "Discrete(5)", "num_agents": 4, "episode_limit": 500, "policy_mapping_info": {"all_scenario": {"description": "rware all scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2", "agent_3"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "rware_customized_map", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 10, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.IA2CTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_il.<locals>.<lambda> at 0x7f38081d6670>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "grad_clip": 40.0, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "microbatch_size": null}, "time_since_restore": 1104.9123861789703, "timesteps_since_restore": 0, "iterations_since_restore": 107, "perf": {"cpu_util_percent": 4.335714285714285, "ram_util_percent": 62.5}}
{"episode_reward_max": 18.0, "episode_reward_min": 0.0, "episode_reward_mean": 7.76, "episode_len_mean": 500.0, "episode_media": {}, "episodes_this_iter": 20, "policy_reward_min": {"shared_policy": 0.0}, "policy_reward_max": {"shared_policy": 7.0}, "policy_reward_mean": {"shared_policy": 1.94}, "custom_metrics": {}, "hist_stats": {"episode_reward": [11.0, 6.0, 3.0, 6.0, 4.0, 5.0, 4.0, 8.0, 6.0, 12.0, 2.0, 14.0, 9.0, 7.0, 11.0, 8.0, 9.0, 16.0, 18.0, 13.0, 3.0, 5.0, 8.0, 12.0, 8.0, 10.0, 5.0, 6.0, 10.0, 3.0, 4.0, 11.0, 3.0, 7.0, 9.0, 1.0, 4.0, 7.0, 4.0, 14.0, 3.0, 11.0, 8.0, 5.0, 5.0, 5.0, 17.0, 7.0, 8.0, 15.0, 7.0, 8.0, 5.0, 6.0, 12.0, 9.0, 7.0, 10.0, 2.0, 10.0, 11.0, 7.0, 5.0, 8.0, 14.0, 9.0, 4.0, 5.0, 11.0, 9.0, 0.0, 10.0, 7.0, 12.0, 11.0, 13.0, 8.0, 3.0, 11.0, 6.0, 11.0, 8.0, 6.0, 6.0, 9.0, 4.0, 9.0, 12.0, 5.0, 6.0, 5.0, 14.0, 8.0, 2.0, 3.0, 10.0, 4.0, 5.0, 9.0, 10.0], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500], "policy_shared_policy_reward": [2.0, 4.0, 1.0, 4.0, 1.0, 0.0, 3.0, 2.0, 2.0, 0.0, 0.0, 1.0, 2.0, 3.0, 1.0, 0.0, 0.0, 1.0, 2.0, 1.0, 2.0, 2.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 3.0, 3.0, 2.0, 2.0, 1.0, 1.0, 2.0, 3.0, 3.0, 4.0, 0.0, 0.0, 1.0, 1.0, 1.0, 5.0, 6.0, 2.0, 2.0, 3.0, 3.0, 1.0, 2.0, 2.0, 1.0, 2.0, 3.0, 2.0, 4.0, 2.0, 2.0, 4.0, 1.0, 1.0, 2.0, 2.0, 2.0, 3.0, 5.0, 4.0, 4.0, 3.0, 5.0, 7.0, 3.0, 3.0, 3.0, 2.0, 4.0, 4.0, 1.0, 1.0, 1.0, 0.0, 2.0, 1.0, 1.0, 1.0, 3.0, 1.0, 3.0, 1.0, 4.0, 3.0, 4.0, 1.0, 1.0, 2.0, 3.0, 2.0, 2.0, 3.0, 2.0, 3.0, 3.0, 0.0, 1.0, 1.0, 1.0, 2.0, 2.0, 1.0, 1.0, 2.0, 3.0, 4.0, 1.0, 1.0, 1.0, 0.0, 2.0, 1.0, 0.0, 1.0, 1.0, 4.0, 3.0, 3.0, 1.0, 0.0, 0.0, 2.0, 2.0, 2.0, 1.0, 2.0, 2.0, 3.0, 3.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 2.0, 1.0, 2.0, 1.0, 2.0, 2.0, 1.0, 1.0, 0.0, 2.0, 4.0, 3.0, 2.0, 5.0, 0.0, 2.0, 1.0, 0.0, 3.0, 4.0, 2.0, 2.0, 2.0, 1.0, 2.0, 3.0, 2.0, 1.0, 2.0, 0.0, 2.0, 1.0, 1.0, 1.0, 2.0, 1.0, 2.0, 0.0, 5.0, 7.0, 3.0, 2.0, 2.0, 2.0, 1.0, 2.0, 2.0, 2.0, 3.0, 1.0, 2.0, 7.0, 2.0, 4.0, 2.0, 1.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 1.0, 2.0, 0.0, 2.0, 2.0, 1.0, 1.0, 3.0, 2.0, 2.0, 5.0, 2.0, 2.0, 2.0, 3.0, 3.0, 1.0, 1.0, 2.0, 3.0, 2.0, 2.0, 3.0, 0.0, 1.0, 1.0, 0.0, 2.0, 2.0, 3.0, 3.0, 3.0, 1.0, 3.0, 4.0, 2.0, 2.0, 1.0, 2.0, 1.0, 0.0, 2.0, 2.0, 1.0, 2.0, 2.0, 3.0, 2.0, 3.0, 4.0, 5.0, 4.0, 2.0, 2.0, 1.0, 1.0, 1.0, 0.0, 2.0, 1.0, 2.0, 2.0, 0.0, 4.0, 2.0, 4.0, 1.0, 1.0, 3.0, 2.0, 3.0, 0.0, 0.0, 0.0, 0.0, 3.0, 2.0, 3.0, 2.0, 2.0, 1.0, 2.0, 2.0, 6.0, 1.0, 3.0, 2.0, 3.0, 2.0, 3.0, 3.0, 3.0, 4.0, 2.0, 4.0, 2.0, 2.0, 2.0, 2.0, 1.0, 1.0, 1.0, 0.0, 3.0, 2.0, 4.0, 2.0, 2.0, 2.0, 1.0, 1.0, 3.0, 2.0, 3.0, 3.0, 2.0, 3.0, 2.0, 1.0, 2.0, 2.0, 1.0, 1.0, 2.0, 1.0, 1.0, 2.0, 2.0, 2.0, 2.0, 3.0, 0.0, 1.0, 1.0, 2.0, 2.0, 2.0, 2.0, 3.0, 2.0, 2.0, 4.0, 4.0, 2.0, 1.0, 0.0, 2.0, 3.0, 0.0, 2.0, 1.0, 2.0, 2.0, 1.0, 0.0, 3.0, 5.0, 3.0, 3.0, 2.0, 1.0, 3.0, 2.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 2.0, 3.0, 3.0, 2.0, 2.0, 1.0, 0.0, 1.0, 1.0, 1.0, 2.0, 1.0, 2.0, 1.0, 3.0, 3.0, 1.0, 3.0, 3.0, 3.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.1337940906022292, "mean_inference_ms": 0.390864299220714, "mean_action_processing_ms": 0.029202979080860808, "mean_env_wait_ms": 0.4041389979998142, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 1088640, "timesteps_this_iter": 0, "agent_timesteps_total": 4354560, "timers": {"sample_time_ms": 5114.019, "sample_throughput": 985.526, "load_time_ms": 0.173, "load_throughput": 29061440.968, "learn_time_ms": 132.64, "learn_throughput": 37997.62, "update_time_ms": 2.483}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 490.2873840332031, "policy_entropy": 7831.2987060546875, "policy_loss": -80.9395523071289, "vf_loss": 41.38101863861084}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 1088640, "num_agent_steps_sampled": 4354560, "num_steps_trained": 1088640, "num_agent_steps_trained": 4354560, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 2176, "training_iteration": 108, "trial_id": "71426_00000", "experiment_id": "84bca2f7b35f43248fca18d21abe2ebf", "date": "2024-06-12_03-04-27", "timestamp": 1718129067, "time_this_iter_s": 10.141931295394897, "time_total_s": 1115.0543174743652, "pid": 363902, "hostname": "DESKTOP-LQ219J4", "node_ip": "192.168.46.185", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 20, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 5000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 500, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Base_Model", "custom_model_config": {"env": "rware", "env_args": {"n_agents": 4, "column_height": 1, "max_inactivity_steps": null, "max_steps": 500, "fast_obs": true, "msg_bits": 0, "sensor_range": 1, "shelf_rows": 1, "shelf_columns": 3, "request_queue_size": 4, "reward_type": "RewardType.INDIVIDUAL", "map_name": "customized_map", "map_size": "tiny", "difficulty": "medium"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": true, "force_coop": false, "local_mode": true, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 4, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 100, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64}, "algorithm": "ia2c", "space_obs": "Dict(obs:Box([-100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100.], [100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.], (112,), float32))", "space_act": "Discrete(5)", "num_agents": 4, "episode_limit": 500, "policy_mapping_info": {"all_scenario": {"description": "rware all scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2", "agent_3"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "rware_customized_map", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 10, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.IA2CTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_il.<locals>.<lambda> at 0x7f38081d6ee0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "grad_clip": 40.0, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "microbatch_size": null}, "time_since_restore": 1115.0543174743652, "timesteps_since_restore": 0, "iterations_since_restore": 108, "perf": {"cpu_util_percent": 4.266666666666667, "ram_util_percent": 62.753333333333316}}
{"episode_reward_max": 17.0, "episode_reward_min": 0.0, "episode_reward_mean": 7.57, "episode_len_mean": 500.0, "episode_media": {}, "episodes_this_iter": 20, "policy_reward_min": {"shared_policy": 0.0}, "policy_reward_max": {"shared_policy": 7.0}, "policy_reward_mean": {"shared_policy": 1.8925}, "custom_metrics": {}, "hist_stats": {"episode_reward": [3.0, 5.0, 8.0, 12.0, 8.0, 10.0, 5.0, 6.0, 10.0, 3.0, 4.0, 11.0, 3.0, 7.0, 9.0, 1.0, 4.0, 7.0, 4.0, 14.0, 3.0, 11.0, 8.0, 5.0, 5.0, 5.0, 17.0, 7.0, 8.0, 15.0, 7.0, 8.0, 5.0, 6.0, 12.0, 9.0, 7.0, 10.0, 2.0, 10.0, 11.0, 7.0, 5.0, 8.0, 14.0, 9.0, 4.0, 5.0, 11.0, 9.0, 0.0, 10.0, 7.0, 12.0, 11.0, 13.0, 8.0, 3.0, 11.0, 6.0, 11.0, 8.0, 6.0, 6.0, 9.0, 4.0, 9.0, 12.0, 5.0, 6.0, 5.0, 14.0, 8.0, 2.0, 3.0, 10.0, 4.0, 5.0, 9.0, 10.0, 6.0, 10.0, 5.0, 6.0, 15.0, 8.0, 2.0, 7.0, 9.0, 6.0, 9.0, 4.0, 12.0, 7.0, 6.0, 5.0, 11.0, 11.0, 8.0, 6.0], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500], "policy_shared_policy_reward": [1.0, 1.0, 1.0, 0.0, 2.0, 1.0, 1.0, 1.0, 3.0, 1.0, 3.0, 1.0, 4.0, 3.0, 4.0, 1.0, 1.0, 2.0, 3.0, 2.0, 2.0, 3.0, 2.0, 3.0, 3.0, 0.0, 1.0, 1.0, 1.0, 2.0, 2.0, 1.0, 1.0, 2.0, 3.0, 4.0, 1.0, 1.0, 1.0, 0.0, 2.0, 1.0, 0.0, 1.0, 1.0, 4.0, 3.0, 3.0, 1.0, 0.0, 0.0, 2.0, 2.0, 2.0, 1.0, 2.0, 2.0, 3.0, 3.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 2.0, 1.0, 2.0, 1.0, 2.0, 2.0, 1.0, 1.0, 0.0, 2.0, 4.0, 3.0, 2.0, 5.0, 0.0, 2.0, 1.0, 0.0, 3.0, 4.0, 2.0, 2.0, 2.0, 1.0, 2.0, 3.0, 2.0, 1.0, 2.0, 0.0, 2.0, 1.0, 1.0, 1.0, 2.0, 1.0, 2.0, 0.0, 5.0, 7.0, 3.0, 2.0, 2.0, 2.0, 1.0, 2.0, 2.0, 2.0, 3.0, 1.0, 2.0, 7.0, 2.0, 4.0, 2.0, 1.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 1.0, 2.0, 0.0, 2.0, 2.0, 1.0, 1.0, 3.0, 2.0, 2.0, 5.0, 2.0, 2.0, 2.0, 3.0, 3.0, 1.0, 1.0, 2.0, 3.0, 2.0, 2.0, 3.0, 0.0, 1.0, 1.0, 0.0, 2.0, 2.0, 3.0, 3.0, 3.0, 1.0, 3.0, 4.0, 2.0, 2.0, 1.0, 2.0, 1.0, 0.0, 2.0, 2.0, 1.0, 2.0, 2.0, 3.0, 2.0, 3.0, 4.0, 5.0, 4.0, 2.0, 2.0, 1.0, 1.0, 1.0, 0.0, 2.0, 1.0, 2.0, 2.0, 0.0, 4.0, 2.0, 4.0, 1.0, 1.0, 3.0, 2.0, 3.0, 0.0, 0.0, 0.0, 0.0, 3.0, 2.0, 3.0, 2.0, 2.0, 1.0, 2.0, 2.0, 6.0, 1.0, 3.0, 2.0, 3.0, 2.0, 3.0, 3.0, 3.0, 4.0, 2.0, 4.0, 2.0, 2.0, 2.0, 2.0, 1.0, 1.0, 1.0, 0.0, 3.0, 2.0, 4.0, 2.0, 2.0, 2.0, 1.0, 1.0, 3.0, 2.0, 3.0, 3.0, 2.0, 3.0, 2.0, 1.0, 2.0, 2.0, 1.0, 1.0, 2.0, 1.0, 1.0, 2.0, 2.0, 2.0, 2.0, 3.0, 0.0, 1.0, 1.0, 2.0, 2.0, 2.0, 2.0, 3.0, 2.0, 2.0, 4.0, 4.0, 2.0, 1.0, 0.0, 2.0, 3.0, 0.0, 2.0, 1.0, 2.0, 2.0, 1.0, 0.0, 3.0, 5.0, 3.0, 3.0, 2.0, 1.0, 3.0, 2.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 2.0, 3.0, 3.0, 2.0, 2.0, 1.0, 0.0, 1.0, 1.0, 1.0, 2.0, 1.0, 2.0, 1.0, 3.0, 3.0, 1.0, 3.0, 3.0, 3.0, 2.0, 2.0, 1.0, 1.0, 3.0, 3.0, 2.0, 2.0, 1.0, 1.0, 1.0, 2.0, 1.0, 2.0, 2.0, 1.0, 4.0, 3.0, 6.0, 2.0, 3.0, 1.0, 2.0, 2.0, 0.0, 1.0, 0.0, 1.0, 2.0, 2.0, 1.0, 2.0, 2.0, 2.0, 2.0, 3.0, 2.0, 1.0, 1.0, 2.0, 2.0, 2.0, 1.0, 4.0, 0.0, 2.0, 0.0, 2.0, 3.0, 2.0, 4.0, 3.0, 2.0, 2.0, 1.0, 2.0, 1.0, 0.0, 2.0, 3.0, 2.0, 1.0, 0.0, 2.0, 2.0, 3.0, 3.0, 3.0, 3.0, 2.0, 2.0, 4.0, 2.0, 1.0, 3.0, 2.0, 2.0, 1.0, 2.0, 1.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.13379092598189926, "mean_inference_ms": 0.3908553477508947, "mean_action_processing_ms": 0.02920154862523532, "mean_env_wait_ms": 0.40412207469538686, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 1098720, "timesteps_this_iter": 0, "agent_timesteps_total": 4394880, "timers": {"sample_time_ms": 5123.963, "sample_throughput": 983.614, "load_time_ms": 0.174, "load_throughput": 29025528.161, "learn_time_ms": 133.673, "learn_throughput": 37703.848, "update_time_ms": 2.491}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 224.4805908203125, "policy_entropy": 7811.4683837890625, "policy_loss": -12.17483675479889, "vf_loss": 55.525108337402344}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 1098720, "num_agent_steps_sampled": 4394880, "num_steps_trained": 1098720, "num_agent_steps_trained": 4394880, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 2196, "training_iteration": 109, "trial_id": "71426_00000", "experiment_id": "84bca2f7b35f43248fca18d21abe2ebf", "date": "2024-06-12_03-04-38", "timestamp": 1718129078, "time_this_iter_s": 10.18159031867981, "time_total_s": 1125.235907793045, "pid": 363902, "hostname": "DESKTOP-LQ219J4", "node_ip": "192.168.46.185", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 20, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 5000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 500, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Base_Model", "custom_model_config": {"env": "rware", "env_args": {"n_agents": 4, "column_height": 1, "max_inactivity_steps": null, "max_steps": 500, "fast_obs": true, "msg_bits": 0, "sensor_range": 1, "shelf_rows": 1, "shelf_columns": 3, "request_queue_size": 4, "reward_type": "RewardType.INDIVIDUAL", "map_name": "customized_map", "map_size": "tiny", "difficulty": "medium"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": true, "force_coop": false, "local_mode": true, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 4, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 100, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64}, "algorithm": "ia2c", "space_obs": "Dict(obs:Box([-100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100.], [100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.], (112,), float32))", "space_act": "Discrete(5)", "num_agents": 4, "episode_limit": 500, "policy_mapping_info": {"all_scenario": {"description": "rware all scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2", "agent_3"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "rware_customized_map", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 10, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.IA2CTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_il.<locals>.<lambda> at 0x7f380824d700>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "grad_clip": 40.0, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "microbatch_size": null}, "time_since_restore": 1125.235907793045, "timesteps_since_restore": 0, "iterations_since_restore": 109, "perf": {"cpu_util_percent": 4.292857142857143, "ram_util_percent": 63.0}}
{"episode_reward_max": 17.0, "episode_reward_min": 0.0, "episode_reward_mean": 7.74, "episode_len_mean": 500.0, "episode_media": {}, "episodes_this_iter": 20, "policy_reward_min": {"shared_policy": 0.0}, "policy_reward_max": {"shared_policy": 7.0}, "policy_reward_mean": {"shared_policy": 1.935}, "custom_metrics": {}, "hist_stats": {"episode_reward": [3.0, 11.0, 8.0, 5.0, 5.0, 5.0, 17.0, 7.0, 8.0, 15.0, 7.0, 8.0, 5.0, 6.0, 12.0, 9.0, 7.0, 10.0, 2.0, 10.0, 11.0, 7.0, 5.0, 8.0, 14.0, 9.0, 4.0, 5.0, 11.0, 9.0, 0.0, 10.0, 7.0, 12.0, 11.0, 13.0, 8.0, 3.0, 11.0, 6.0, 11.0, 8.0, 6.0, 6.0, 9.0, 4.0, 9.0, 12.0, 5.0, 6.0, 5.0, 14.0, 8.0, 2.0, 3.0, 10.0, 4.0, 5.0, 9.0, 10.0, 6.0, 10.0, 5.0, 6.0, 15.0, 8.0, 2.0, 7.0, 9.0, 6.0, 9.0, 4.0, 12.0, 7.0, 6.0, 5.0, 11.0, 11.0, 8.0, 6.0, 2.0, 4.0, 13.0, 9.0, 11.0, 5.0, 2.0, 9.0, 10.0, 3.0, 9.0, 12.0, 5.0, 12.0, 12.0, 1.0, 7.0, 10.0, 6.0, 9.0], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500], "policy_shared_policy_reward": [0.0, 2.0, 1.0, 0.0, 3.0, 4.0, 2.0, 2.0, 2.0, 1.0, 2.0, 3.0, 2.0, 1.0, 2.0, 0.0, 2.0, 1.0, 1.0, 1.0, 2.0, 1.0, 2.0, 0.0, 5.0, 7.0, 3.0, 2.0, 2.0, 2.0, 1.0, 2.0, 2.0, 2.0, 3.0, 1.0, 2.0, 7.0, 2.0, 4.0, 2.0, 1.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 1.0, 2.0, 0.0, 2.0, 2.0, 1.0, 1.0, 3.0, 2.0, 2.0, 5.0, 2.0, 2.0, 2.0, 3.0, 3.0, 1.0, 1.0, 2.0, 3.0, 2.0, 2.0, 3.0, 0.0, 1.0, 1.0, 0.0, 2.0, 2.0, 3.0, 3.0, 3.0, 1.0, 3.0, 4.0, 2.0, 2.0, 1.0, 2.0, 1.0, 0.0, 2.0, 2.0, 1.0, 2.0, 2.0, 3.0, 2.0, 3.0, 4.0, 5.0, 4.0, 2.0, 2.0, 1.0, 1.0, 1.0, 0.0, 2.0, 1.0, 2.0, 2.0, 0.0, 4.0, 2.0, 4.0, 1.0, 1.0, 3.0, 2.0, 3.0, 0.0, 0.0, 0.0, 0.0, 3.0, 2.0, 3.0, 2.0, 2.0, 1.0, 2.0, 2.0, 6.0, 1.0, 3.0, 2.0, 3.0, 2.0, 3.0, 3.0, 3.0, 4.0, 2.0, 4.0, 2.0, 2.0, 2.0, 2.0, 1.0, 1.0, 1.0, 0.0, 3.0, 2.0, 4.0, 2.0, 2.0, 2.0, 1.0, 1.0, 3.0, 2.0, 3.0, 3.0, 2.0, 3.0, 2.0, 1.0, 2.0, 2.0, 1.0, 1.0, 2.0, 1.0, 1.0, 2.0, 2.0, 2.0, 2.0, 3.0, 0.0, 1.0, 1.0, 2.0, 2.0, 2.0, 2.0, 3.0, 2.0, 2.0, 4.0, 4.0, 2.0, 1.0, 0.0, 2.0, 3.0, 0.0, 2.0, 1.0, 2.0, 2.0, 1.0, 0.0, 3.0, 5.0, 3.0, 3.0, 2.0, 1.0, 3.0, 2.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 2.0, 3.0, 3.0, 2.0, 2.0, 1.0, 0.0, 1.0, 1.0, 1.0, 2.0, 1.0, 2.0, 1.0, 3.0, 3.0, 1.0, 3.0, 3.0, 3.0, 2.0, 2.0, 1.0, 1.0, 3.0, 3.0, 2.0, 2.0, 1.0, 1.0, 1.0, 2.0, 1.0, 2.0, 2.0, 1.0, 4.0, 3.0, 6.0, 2.0, 3.0, 1.0, 2.0, 2.0, 0.0, 1.0, 0.0, 1.0, 2.0, 2.0, 1.0, 2.0, 2.0, 2.0, 2.0, 3.0, 2.0, 1.0, 1.0, 2.0, 2.0, 2.0, 1.0, 4.0, 0.0, 2.0, 0.0, 2.0, 3.0, 2.0, 4.0, 3.0, 2.0, 2.0, 1.0, 2.0, 1.0, 0.0, 2.0, 3.0, 2.0, 1.0, 0.0, 2.0, 2.0, 3.0, 3.0, 3.0, 3.0, 2.0, 2.0, 4.0, 2.0, 1.0, 3.0, 2.0, 2.0, 1.0, 2.0, 1.0, 1.0, 0.0, 0.0, 1.0, 2.0, 0.0, 1.0, 1.0, 4.0, 4.0, 3.0, 2.0, 1.0, 2.0, 3.0, 3.0, 3.0, 3.0, 3.0, 2.0, 1.0, 1.0, 2.0, 1.0, 1.0, 0.0, 0.0, 1.0, 4.0, 4.0, 1.0, 0.0, 3.0, 4.0, 2.0, 1.0, 1.0, 1.0, 1.0, 0.0, 2.0, 3.0, 2.0, 2.0, 4.0, 2.0, 3.0, 3.0, 1.0, 1.0, 2.0, 1.0, 3.0, 3.0, 3.0, 3.0, 2.0, 4.0, 3.0, 3.0, 1.0, 0.0, 0.0, 0.0, 2.0, 1.0, 3.0, 1.0, 2.0, 4.0, 2.0, 2.0, 2.0, 1.0, 2.0, 1.0, 3.0, 2.0, 2.0, 2.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.13378973296490163, "mean_inference_ms": 0.39085157157570033, "mean_action_processing_ms": 0.029200613626418032, "mean_env_wait_ms": 0.40410838749679784, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 1108800, "timesteps_this_iter": 0, "agent_timesteps_total": 4435200, "timers": {"sample_time_ms": 5129.84, "sample_throughput": 982.487, "load_time_ms": 0.174, "load_throughput": 28926234.483, "learn_time_ms": 132.86, "learn_throughput": 37934.704, "update_time_ms": 2.43}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 278.57635498046875, "policy_entropy": 7670.8375244140625, "policy_loss": 19.614728927612305, "vf_loss": 63.8414249420166}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 1108800, "num_agent_steps_sampled": 4435200, "num_steps_trained": 1108800, "num_agent_steps_trained": 4435200, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 2216, "training_iteration": 110, "trial_id": "71426_00000", "experiment_id": "84bca2f7b35f43248fca18d21abe2ebf", "date": "2024-06-12_03-04-48", "timestamp": 1718129088, "time_this_iter_s": 10.218091011047363, "time_total_s": 1135.4539988040924, "pid": 363902, "hostname": "DESKTOP-LQ219J4", "node_ip": "192.168.46.185", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 20, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 5000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 500, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Base_Model", "custom_model_config": {"env": "rware", "env_args": {"n_agents": 4, "column_height": 1, "max_inactivity_steps": null, "max_steps": 500, "fast_obs": true, "msg_bits": 0, "sensor_range": 1, "shelf_rows": 1, "shelf_columns": 3, "request_queue_size": 4, "reward_type": "RewardType.INDIVIDUAL", "map_name": "customized_map", "map_size": "tiny", "difficulty": "medium"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": true, "force_coop": false, "local_mode": true, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 4, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 100, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64}, "algorithm": "ia2c", "space_obs": "Dict(obs:Box([-100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100.], [100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.], (112,), float32))", "space_act": "Discrete(5)", "num_agents": 4, "episode_limit": 500, "policy_mapping_info": {"all_scenario": {"description": "rware all scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2", "agent_3"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "rware_customized_map", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 10, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.IA2CTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_il.<locals>.<lambda> at 0x7f38081d6d30>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "grad_clip": 40.0, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "microbatch_size": null}, "time_since_restore": 1135.4539988040924, "timesteps_since_restore": 0, "iterations_since_restore": 110, "perf": {"cpu_util_percent": 4.233333333333333, "ram_util_percent": 63.299999999999976}}
{"episode_reward_max": 15.0, "episode_reward_min": 0.0, "episode_reward_mean": 7.34, "episode_len_mean": 500.0, "episode_media": {}, "episodes_this_iter": 20, "policy_reward_min": {"shared_policy": 0.0}, "policy_reward_max": {"shared_policy": 6.0}, "policy_reward_mean": {"shared_policy": 1.835}, "custom_metrics": {}, "hist_stats": {"episode_reward": [11.0, 7.0, 5.0, 8.0, 14.0, 9.0, 4.0, 5.0, 11.0, 9.0, 0.0, 10.0, 7.0, 12.0, 11.0, 13.0, 8.0, 3.0, 11.0, 6.0, 11.0, 8.0, 6.0, 6.0, 9.0, 4.0, 9.0, 12.0, 5.0, 6.0, 5.0, 14.0, 8.0, 2.0, 3.0, 10.0, 4.0, 5.0, 9.0, 10.0, 6.0, 10.0, 5.0, 6.0, 15.0, 8.0, 2.0, 7.0, 9.0, 6.0, 9.0, 4.0, 12.0, 7.0, 6.0, 5.0, 11.0, 11.0, 8.0, 6.0, 2.0, 4.0, 13.0, 9.0, 11.0, 5.0, 2.0, 9.0, 10.0, 3.0, 9.0, 12.0, 5.0, 12.0, 12.0, 1.0, 7.0, 10.0, 6.0, 9.0, 8.0, 9.0, 11.0, 5.0, 6.0, 2.0, 12.0, 5.0, 6.0, 5.0, 2.0, 3.0, 4.0, 8.0, 2.0, 12.0, 5.0, 8.0, 3.0, 4.0], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500], "policy_shared_policy_reward": [3.0, 1.0, 3.0, 4.0, 2.0, 2.0, 1.0, 2.0, 1.0, 0.0, 2.0, 2.0, 1.0, 2.0, 2.0, 3.0, 2.0, 3.0, 4.0, 5.0, 4.0, 2.0, 2.0, 1.0, 1.0, 1.0, 0.0, 2.0, 1.0, 2.0, 2.0, 0.0, 4.0, 2.0, 4.0, 1.0, 1.0, 3.0, 2.0, 3.0, 0.0, 0.0, 0.0, 0.0, 3.0, 2.0, 3.0, 2.0, 2.0, 1.0, 2.0, 2.0, 6.0, 1.0, 3.0, 2.0, 3.0, 2.0, 3.0, 3.0, 3.0, 4.0, 2.0, 4.0, 2.0, 2.0, 2.0, 2.0, 1.0, 1.0, 1.0, 0.0, 3.0, 2.0, 4.0, 2.0, 2.0, 2.0, 1.0, 1.0, 3.0, 2.0, 3.0, 3.0, 2.0, 3.0, 2.0, 1.0, 2.0, 2.0, 1.0, 1.0, 2.0, 1.0, 1.0, 2.0, 2.0, 2.0, 2.0, 3.0, 0.0, 1.0, 1.0, 2.0, 2.0, 2.0, 2.0, 3.0, 2.0, 2.0, 4.0, 4.0, 2.0, 1.0, 0.0, 2.0, 3.0, 0.0, 2.0, 1.0, 2.0, 2.0, 1.0, 0.0, 3.0, 5.0, 3.0, 3.0, 2.0, 1.0, 3.0, 2.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 2.0, 3.0, 3.0, 2.0, 2.0, 1.0, 0.0, 1.0, 1.0, 1.0, 2.0, 1.0, 2.0, 1.0, 3.0, 3.0, 1.0, 3.0, 3.0, 3.0, 2.0, 2.0, 1.0, 1.0, 3.0, 3.0, 2.0, 2.0, 1.0, 1.0, 1.0, 2.0, 1.0, 2.0, 2.0, 1.0, 4.0, 3.0, 6.0, 2.0, 3.0, 1.0, 2.0, 2.0, 0.0, 1.0, 0.0, 1.0, 2.0, 2.0, 1.0, 2.0, 2.0, 2.0, 2.0, 3.0, 2.0, 1.0, 1.0, 2.0, 2.0, 2.0, 1.0, 4.0, 0.0, 2.0, 0.0, 2.0, 3.0, 2.0, 4.0, 3.0, 2.0, 2.0, 1.0, 2.0, 1.0, 0.0, 2.0, 3.0, 2.0, 1.0, 0.0, 2.0, 2.0, 3.0, 3.0, 3.0, 3.0, 2.0, 2.0, 4.0, 2.0, 1.0, 3.0, 2.0, 2.0, 1.0, 2.0, 1.0, 1.0, 0.0, 0.0, 1.0, 2.0, 0.0, 1.0, 1.0, 4.0, 4.0, 3.0, 2.0, 1.0, 2.0, 3.0, 3.0, 3.0, 3.0, 3.0, 2.0, 1.0, 1.0, 2.0, 1.0, 1.0, 0.0, 0.0, 1.0, 4.0, 4.0, 1.0, 0.0, 3.0, 4.0, 2.0, 1.0, 1.0, 1.0, 1.0, 0.0, 2.0, 3.0, 2.0, 2.0, 4.0, 2.0, 3.0, 3.0, 1.0, 1.0, 2.0, 1.0, 3.0, 3.0, 3.0, 3.0, 2.0, 4.0, 3.0, 3.0, 1.0, 0.0, 0.0, 0.0, 2.0, 1.0, 3.0, 1.0, 2.0, 4.0, 2.0, 2.0, 2.0, 1.0, 2.0, 1.0, 3.0, 2.0, 2.0, 2.0, 2.0, 3.0, 2.0, 1.0, 2.0, 2.0, 3.0, 2.0, 3.0, 3.0, 1.0, 4.0, 1.0, 1.0, 1.0, 2.0, 1.0, 2.0, 1.0, 2.0, 1.0, 1.0, 0.0, 0.0, 2.0, 3.0, 4.0, 3.0, 3.0, 0.0, 1.0, 1.0, 3.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 2.0, 0.0, 1.0, 0.0, 1.0, 0.0, 2.0, 1.0, 0.0, 2.0, 1.0, 1.0, 0.0, 1.0, 2.0, 3.0, 2.0, 2.0, 0.0, 0.0, 0.0, 2.0, 1.0, 5.0, 4.0, 0.0, 2.0, 1.0, 2.0, 2.0, 2.0, 1.0, 3.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 2.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.13378548514744287, "mean_inference_ms": 0.39083574998216847, "mean_action_processing_ms": 0.029198925900265973, "mean_env_wait_ms": 0.40407011143875904, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 1118880, "timesteps_this_iter": 0, "agent_timesteps_total": 4475520, "timers": {"sample_time_ms": 5109.778, "sample_throughput": 986.344, "load_time_ms": 0.172, "load_throughput": 29339753.171, "learn_time_ms": 134.37, "learn_throughput": 37508.507, "update_time_ms": 2.444}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 224.87945556640625, "policy_entropy": 7734.673583984375, "policy_loss": -47.299909710884094, "vf_loss": 44.48837327957153}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 1118880, "num_agent_steps_sampled": 4475520, "num_steps_trained": 1118880, "num_agent_steps_trained": 4475520, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 2236, "training_iteration": 111, "trial_id": "71426_00000", "experiment_id": "84bca2f7b35f43248fca18d21abe2ebf", "date": "2024-06-12_03-04-58", "timestamp": 1718129098, "time_this_iter_s": 10.015104055404663, "time_total_s": 1145.469102859497, "pid": 363902, "hostname": "DESKTOP-LQ219J4", "node_ip": "192.168.46.185", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 20, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 5000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 500, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Base_Model", "custom_model_config": {"env": "rware", "env_args": {"n_agents": 4, "column_height": 1, "max_inactivity_steps": null, "max_steps": 500, "fast_obs": true, "msg_bits": 0, "sensor_range": 1, "shelf_rows": 1, "shelf_columns": 3, "request_queue_size": 4, "reward_type": "RewardType.INDIVIDUAL", "map_name": "customized_map", "map_size": "tiny", "difficulty": "medium"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": true, "force_coop": false, "local_mode": true, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 4, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 100, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64}, "algorithm": "ia2c", "space_obs": "Dict(obs:Box([-100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100.], [100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.], (112,), float32))", "space_act": "Discrete(5)", "num_agents": 4, "episode_limit": 500, "policy_mapping_info": {"all_scenario": {"description": "rware all scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2", "agent_3"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "rware_customized_map", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 10, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.IA2CTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_il.<locals>.<lambda> at 0x7f38082f8ca0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "grad_clip": 40.0, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "microbatch_size": null}, "time_since_restore": 1145.469102859497, "timesteps_since_restore": 0, "iterations_since_restore": 111, "perf": {"cpu_util_percent": 4.264285714285714, "ram_util_percent": 63.60000000000001}}
{"episode_reward_max": 15.0, "episode_reward_min": 1.0, "episode_reward_mean": 7.19, "episode_len_mean": 500.0, "episode_media": {}, "episodes_this_iter": 20, "policy_reward_min": {"shared_policy": 0.0}, "policy_reward_max": {"shared_policy": 6.0}, "policy_reward_mean": {"shared_policy": 1.7975}, "custom_metrics": {}, "hist_stats": {"episode_reward": [11.0, 8.0, 6.0, 6.0, 9.0, 4.0, 9.0, 12.0, 5.0, 6.0, 5.0, 14.0, 8.0, 2.0, 3.0, 10.0, 4.0, 5.0, 9.0, 10.0, 6.0, 10.0, 5.0, 6.0, 15.0, 8.0, 2.0, 7.0, 9.0, 6.0, 9.0, 4.0, 12.0, 7.0, 6.0, 5.0, 11.0, 11.0, 8.0, 6.0, 2.0, 4.0, 13.0, 9.0, 11.0, 5.0, 2.0, 9.0, 10.0, 3.0, 9.0, 12.0, 5.0, 12.0, 12.0, 1.0, 7.0, 10.0, 6.0, 9.0, 8.0, 9.0, 11.0, 5.0, 6.0, 2.0, 12.0, 5.0, 6.0, 5.0, 2.0, 3.0, 4.0, 8.0, 2.0, 12.0, 5.0, 8.0, 3.0, 4.0, 6.0, 8.0, 13.0, 7.0, 5.0, 15.0, 1.0, 4.0, 6.0, 10.0, 9.0, 7.0, 8.0, 8.0, 6.0, 3.0, 9.0, 5.0, 7.0, 12.0], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500], "policy_shared_policy_reward": [3.0, 2.0, 3.0, 3.0, 2.0, 3.0, 2.0, 1.0, 2.0, 2.0, 1.0, 1.0, 2.0, 1.0, 1.0, 2.0, 2.0, 2.0, 2.0, 3.0, 0.0, 1.0, 1.0, 2.0, 2.0, 2.0, 2.0, 3.0, 2.0, 2.0, 4.0, 4.0, 2.0, 1.0, 0.0, 2.0, 3.0, 0.0, 2.0, 1.0, 2.0, 2.0, 1.0, 0.0, 3.0, 5.0, 3.0, 3.0, 2.0, 1.0, 3.0, 2.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 2.0, 3.0, 3.0, 2.0, 2.0, 1.0, 0.0, 1.0, 1.0, 1.0, 2.0, 1.0, 2.0, 1.0, 3.0, 3.0, 1.0, 3.0, 3.0, 3.0, 2.0, 2.0, 1.0, 1.0, 3.0, 3.0, 2.0, 2.0, 1.0, 1.0, 1.0, 2.0, 1.0, 2.0, 2.0, 1.0, 4.0, 3.0, 6.0, 2.0, 3.0, 1.0, 2.0, 2.0, 0.0, 1.0, 0.0, 1.0, 2.0, 2.0, 1.0, 2.0, 2.0, 2.0, 2.0, 3.0, 2.0, 1.0, 1.0, 2.0, 2.0, 2.0, 1.0, 4.0, 0.0, 2.0, 0.0, 2.0, 3.0, 2.0, 4.0, 3.0, 2.0, 2.0, 1.0, 2.0, 1.0, 0.0, 2.0, 3.0, 2.0, 1.0, 0.0, 2.0, 2.0, 3.0, 3.0, 3.0, 3.0, 2.0, 2.0, 4.0, 2.0, 1.0, 3.0, 2.0, 2.0, 1.0, 2.0, 1.0, 1.0, 0.0, 0.0, 1.0, 2.0, 0.0, 1.0, 1.0, 4.0, 4.0, 3.0, 2.0, 1.0, 2.0, 3.0, 3.0, 3.0, 3.0, 3.0, 2.0, 1.0, 1.0, 2.0, 1.0, 1.0, 0.0, 0.0, 1.0, 4.0, 4.0, 1.0, 0.0, 3.0, 4.0, 2.0, 1.0, 1.0, 1.0, 1.0, 0.0, 2.0, 3.0, 2.0, 2.0, 4.0, 2.0, 3.0, 3.0, 1.0, 1.0, 2.0, 1.0, 3.0, 3.0, 3.0, 3.0, 2.0, 4.0, 3.0, 3.0, 1.0, 0.0, 0.0, 0.0, 2.0, 1.0, 3.0, 1.0, 2.0, 4.0, 2.0, 2.0, 2.0, 1.0, 2.0, 1.0, 3.0, 2.0, 2.0, 2.0, 2.0, 3.0, 2.0, 1.0, 2.0, 2.0, 3.0, 2.0, 3.0, 3.0, 1.0, 4.0, 1.0, 1.0, 1.0, 2.0, 1.0, 2.0, 1.0, 2.0, 1.0, 1.0, 0.0, 0.0, 2.0, 3.0, 4.0, 3.0, 3.0, 0.0, 1.0, 1.0, 3.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 2.0, 0.0, 1.0, 0.0, 1.0, 0.0, 2.0, 1.0, 0.0, 2.0, 1.0, 1.0, 0.0, 1.0, 2.0, 3.0, 2.0, 2.0, 0.0, 0.0, 0.0, 2.0, 1.0, 5.0, 4.0, 0.0, 2.0, 1.0, 2.0, 2.0, 2.0, 1.0, 3.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 2.0, 1.0, 3.0, 2.0, 0.0, 0.0, 3.0, 2.0, 3.0, 4.0, 4.0, 1.0, 4.0, 0.0, 2.0, 3.0, 2.0, 1.0, 1.0, 0.0, 3.0, 5.0, 5.0, 4.0, 1.0, 0.0, 0.0, 0.0, 1.0, 2.0, 2.0, 0.0, 0.0, 2.0, 2.0, 1.0, 1.0, 1.0, 3.0, 3.0, 3.0, 3.0, 2.0, 1.0, 3.0, 1.0, 1.0, 3.0, 2.0, 2.0, 2.0, 1.0, 3.0, 2.0, 3.0, 1.0, 2.0, 2.0, 1.0, 1.0, 2.0, 1.0, 2.0, 0.0, 0.0, 2.0, 2.0, 3.0, 2.0, 0.0, 1.0, 2.0, 2.0, 1.0, 2.0, 1.0, 3.0, 2.0, 3.0, 4.0, 3.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.133772443330907, "mean_inference_ms": 0.39079886449739226, "mean_action_processing_ms": 0.02919638435603021, "mean_env_wait_ms": 0.4040137290108966, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 1128960, "timesteps_this_iter": 0, "agent_timesteps_total": 4515840, "timers": {"sample_time_ms": 5082.671, "sample_throughput": 991.605, "load_time_ms": 0.17, "load_throughput": 29615147.324, "learn_time_ms": 131.584, "learn_throughput": 38302.564, "update_time_ms": 2.501}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 330.05352783203125, "policy_entropy": 7761.5438232421875, "policy_loss": -15.38517951965332, "vf_loss": 57.83421993255615}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 1128960, "num_agent_steps_sampled": 4515840, "num_steps_trained": 1128960, "num_agent_steps_trained": 4515840, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 2256, "training_iteration": 112, "trial_id": "71426_00000", "experiment_id": "84bca2f7b35f43248fca18d21abe2ebf", "date": "2024-06-12_03-05-08", "timestamp": 1718129108, "time_this_iter_s": 10.154666900634766, "time_total_s": 1155.6237697601318, "pid": 363902, "hostname": "DESKTOP-LQ219J4", "node_ip": "192.168.46.185", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 20, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 5000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 500, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Base_Model", "custom_model_config": {"env": "rware", "env_args": {"n_agents": 4, "column_height": 1, "max_inactivity_steps": null, "max_steps": 500, "fast_obs": true, "msg_bits": 0, "sensor_range": 1, "shelf_rows": 1, "shelf_columns": 3, "request_queue_size": 4, "reward_type": "RewardType.INDIVIDUAL", "map_name": "customized_map", "map_size": "tiny", "difficulty": "medium"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": true, "force_coop": false, "local_mode": true, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 4, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 100, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64}, "algorithm": "ia2c", "space_obs": "Dict(obs:Box([-100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100.], [100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.], (112,), float32))", "space_act": "Discrete(5)", "num_agents": 4, "episode_limit": 500, "policy_mapping_info": {"all_scenario": {"description": "rware all scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2", "agent_3"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "rware_customized_map", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 10, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.IA2CTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_il.<locals>.<lambda> at 0x7f38086c1c10>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "grad_clip": 40.0, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "microbatch_size": null}, "time_since_restore": 1155.6237697601318, "timesteps_since_restore": 0, "iterations_since_restore": 112, "perf": {"cpu_util_percent": 4.239999999999999, "ram_util_percent": 63.89999999999999}}
{"episode_reward_max": 15.0, "episode_reward_min": 1.0, "episode_reward_mean": 7.25, "episode_len_mean": 500.0, "episode_media": {}, "episodes_this_iter": 20, "policy_reward_min": {"shared_policy": 0.0}, "policy_reward_max": {"shared_policy": 6.0}, "policy_reward_mean": {"shared_policy": 1.8125}, "custom_metrics": {}, "hist_stats": {"episode_reward": [6.0, 10.0, 5.0, 6.0, 15.0, 8.0, 2.0, 7.0, 9.0, 6.0, 9.0, 4.0, 12.0, 7.0, 6.0, 5.0, 11.0, 11.0, 8.0, 6.0, 2.0, 4.0, 13.0, 9.0, 11.0, 5.0, 2.0, 9.0, 10.0, 3.0, 9.0, 12.0, 5.0, 12.0, 12.0, 1.0, 7.0, 10.0, 6.0, 9.0, 8.0, 9.0, 11.0, 5.0, 6.0, 2.0, 12.0, 5.0, 6.0, 5.0, 2.0, 3.0, 4.0, 8.0, 2.0, 12.0, 5.0, 8.0, 3.0, 4.0, 6.0, 8.0, 13.0, 7.0, 5.0, 15.0, 1.0, 4.0, 6.0, 10.0, 9.0, 7.0, 8.0, 8.0, 6.0, 3.0, 9.0, 5.0, 7.0, 12.0, 5.0, 7.0, 4.0, 6.0, 11.0, 9.0, 10.0, 13.0, 7.0, 10.0, 9.0, 2.0, 9.0, 8.0, 7.0, 9.0, 4.0, 8.0, 7.0, 7.0], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500], "policy_shared_policy_reward": [2.0, 2.0, 1.0, 1.0, 3.0, 3.0, 2.0, 2.0, 1.0, 1.0, 1.0, 2.0, 1.0, 2.0, 2.0, 1.0, 4.0, 3.0, 6.0, 2.0, 3.0, 1.0, 2.0, 2.0, 0.0, 1.0, 0.0, 1.0, 2.0, 2.0, 1.0, 2.0, 2.0, 2.0, 2.0, 3.0, 2.0, 1.0, 1.0, 2.0, 2.0, 2.0, 1.0, 4.0, 0.0, 2.0, 0.0, 2.0, 3.0, 2.0, 4.0, 3.0, 2.0, 2.0, 1.0, 2.0, 1.0, 0.0, 2.0, 3.0, 2.0, 1.0, 0.0, 2.0, 2.0, 3.0, 3.0, 3.0, 3.0, 2.0, 2.0, 4.0, 2.0, 1.0, 3.0, 2.0, 2.0, 1.0, 2.0, 1.0, 1.0, 0.0, 0.0, 1.0, 2.0, 0.0, 1.0, 1.0, 4.0, 4.0, 3.0, 2.0, 1.0, 2.0, 3.0, 3.0, 3.0, 3.0, 3.0, 2.0, 1.0, 1.0, 2.0, 1.0, 1.0, 0.0, 0.0, 1.0, 4.0, 4.0, 1.0, 0.0, 3.0, 4.0, 2.0, 1.0, 1.0, 1.0, 1.0, 0.0, 2.0, 3.0, 2.0, 2.0, 4.0, 2.0, 3.0, 3.0, 1.0, 1.0, 2.0, 1.0, 3.0, 3.0, 3.0, 3.0, 2.0, 4.0, 3.0, 3.0, 1.0, 0.0, 0.0, 0.0, 2.0, 1.0, 3.0, 1.0, 2.0, 4.0, 2.0, 2.0, 2.0, 1.0, 2.0, 1.0, 3.0, 2.0, 2.0, 2.0, 2.0, 3.0, 2.0, 1.0, 2.0, 2.0, 3.0, 2.0, 3.0, 3.0, 1.0, 4.0, 1.0, 1.0, 1.0, 2.0, 1.0, 2.0, 1.0, 2.0, 1.0, 1.0, 0.0, 0.0, 2.0, 3.0, 4.0, 3.0, 3.0, 0.0, 1.0, 1.0, 3.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 2.0, 0.0, 1.0, 0.0, 1.0, 0.0, 2.0, 1.0, 0.0, 2.0, 1.0, 1.0, 0.0, 1.0, 2.0, 3.0, 2.0, 2.0, 0.0, 0.0, 0.0, 2.0, 1.0, 5.0, 4.0, 0.0, 2.0, 1.0, 2.0, 2.0, 2.0, 1.0, 3.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 2.0, 1.0, 3.0, 2.0, 0.0, 0.0, 3.0, 2.0, 3.0, 4.0, 4.0, 1.0, 4.0, 0.0, 2.0, 3.0, 2.0, 1.0, 1.0, 0.0, 3.0, 5.0, 5.0, 4.0, 1.0, 0.0, 0.0, 0.0, 1.0, 2.0, 2.0, 0.0, 0.0, 2.0, 2.0, 1.0, 1.0, 1.0, 3.0, 3.0, 3.0, 3.0, 2.0, 1.0, 3.0, 1.0, 1.0, 3.0, 2.0, 2.0, 2.0, 1.0, 3.0, 2.0, 3.0, 1.0, 2.0, 2.0, 1.0, 1.0, 2.0, 1.0, 2.0, 0.0, 0.0, 2.0, 2.0, 3.0, 2.0, 0.0, 1.0, 2.0, 2.0, 1.0, 2.0, 1.0, 3.0, 2.0, 3.0, 4.0, 3.0, 0.0, 2.0, 2.0, 1.0, 1.0, 2.0, 3.0, 1.0, 1.0, 2.0, 0.0, 1.0, 1.0, 2.0, 1.0, 2.0, 1.0, 3.0, 4.0, 3.0, 3.0, 3.0, 1.0, 2.0, 2.0, 1.0, 4.0, 3.0, 4.0, 2.0, 3.0, 4.0, 2.0, 2.0, 2.0, 1.0, 2.0, 4.0, 2.0, 2.0, 3.0, 3.0, 3.0, 0.0, 0.0, 1.0, 1.0, 0.0, 2.0, 3.0, 2.0, 2.0, 2.0, 1.0, 2.0, 3.0, 2.0, 2.0, 2.0, 1.0, 2.0, 1.0, 3.0, 3.0, 0.0, 2.0, 0.0, 2.0, 1.0, 2.0, 3.0, 2.0, 2.0, 2.0, 1.0, 2.0, 3.0, 2.0, 1.0, 1.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.13376324135542464, "mean_inference_ms": 0.39077221521721467, "mean_action_processing_ms": 0.02919472506562971, "mean_env_wait_ms": 0.40397251725980415, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 1139040, "timesteps_this_iter": 0, "agent_timesteps_total": 4556160, "timers": {"sample_time_ms": 5094.255, "sample_throughput": 989.35, "load_time_ms": 0.171, "load_throughput": 29409143.239, "learn_time_ms": 130.498, "learn_throughput": 38621.393, "update_time_ms": 2.537}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 296.04034423828125, "policy_entropy": 7741.30419921875, "policy_loss": -17.49718999862671, "vf_loss": 58.747267723083496}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 1139040, "num_agent_steps_sampled": 4556160, "num_steps_trained": 1139040, "num_agent_steps_trained": 4556160, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 2276, "training_iteration": 113, "trial_id": "71426_00000", "experiment_id": "84bca2f7b35f43248fca18d21abe2ebf", "date": "2024-06-12_03-05-18", "timestamp": 1718129118, "time_this_iter_s": 10.273338317871094, "time_total_s": 1165.897108078003, "pid": 363902, "hostname": "DESKTOP-LQ219J4", "node_ip": "192.168.46.185", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 20, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 5000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 500, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Base_Model", "custom_model_config": {"env": "rware", "env_args": {"n_agents": 4, "column_height": 1, "max_inactivity_steps": null, "max_steps": 500, "fast_obs": true, "msg_bits": 0, "sensor_range": 1, "shelf_rows": 1, "shelf_columns": 3, "request_queue_size": 4, "reward_type": "RewardType.INDIVIDUAL", "map_name": "customized_map", "map_size": "tiny", "difficulty": "medium"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": true, "force_coop": false, "local_mode": true, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 4, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 100, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64}, "algorithm": "ia2c", "space_obs": "Dict(obs:Box([-100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100.], [100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.], (112,), float32))", "space_act": "Discrete(5)", "num_agents": 4, "episode_limit": 500, "policy_mapping_info": {"all_scenario": {"description": "rware all scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2", "agent_3"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "rware_customized_map", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 10, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.IA2CTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_il.<locals>.<lambda> at 0x7f3808651b80>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "grad_clip": 40.0, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "microbatch_size": null}, "time_since_restore": 1165.897108078003, "timesteps_since_restore": 0, "iterations_since_restore": 113, "perf": {"cpu_util_percent": 4.2333333333333325, "ram_util_percent": 64.14000000000001}}
{"episode_reward_max": 15.0, "episode_reward_min": 1.0, "episode_reward_mean": 7.08, "episode_len_mean": 500.0, "episode_media": {}, "episodes_this_iter": 20, "policy_reward_min": {"shared_policy": 0.0}, "policy_reward_max": {"shared_policy": 5.0}, "policy_reward_mean": {"shared_policy": 1.77}, "custom_metrics": {}, "hist_stats": {"episode_reward": [2.0, 4.0, 13.0, 9.0, 11.0, 5.0, 2.0, 9.0, 10.0, 3.0, 9.0, 12.0, 5.0, 12.0, 12.0, 1.0, 7.0, 10.0, 6.0, 9.0, 8.0, 9.0, 11.0, 5.0, 6.0, 2.0, 12.0, 5.0, 6.0, 5.0, 2.0, 3.0, 4.0, 8.0, 2.0, 12.0, 5.0, 8.0, 3.0, 4.0, 6.0, 8.0, 13.0, 7.0, 5.0, 15.0, 1.0, 4.0, 6.0, 10.0, 9.0, 7.0, 8.0, 8.0, 6.0, 3.0, 9.0, 5.0, 7.0, 12.0, 5.0, 7.0, 4.0, 6.0, 11.0, 9.0, 10.0, 13.0, 7.0, 10.0, 9.0, 2.0, 9.0, 8.0, 7.0, 9.0, 4.0, 8.0, 7.0, 7.0, 2.0, 7.0, 14.0, 4.0, 7.0, 6.0, 8.0, 7.0, 8.0, 8.0, 5.0, 5.0, 7.0, 3.0, 5.0, 9.0, 8.0, 10.0, 8.0, 5.0], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500], "policy_shared_policy_reward": [1.0, 0.0, 0.0, 1.0, 2.0, 0.0, 1.0, 1.0, 4.0, 4.0, 3.0, 2.0, 1.0, 2.0, 3.0, 3.0, 3.0, 3.0, 3.0, 2.0, 1.0, 1.0, 2.0, 1.0, 1.0, 0.0, 0.0, 1.0, 4.0, 4.0, 1.0, 0.0, 3.0, 4.0, 2.0, 1.0, 1.0, 1.0, 1.0, 0.0, 2.0, 3.0, 2.0, 2.0, 4.0, 2.0, 3.0, 3.0, 1.0, 1.0, 2.0, 1.0, 3.0, 3.0, 3.0, 3.0, 2.0, 4.0, 3.0, 3.0, 1.0, 0.0, 0.0, 0.0, 2.0, 1.0, 3.0, 1.0, 2.0, 4.0, 2.0, 2.0, 2.0, 1.0, 2.0, 1.0, 3.0, 2.0, 2.0, 2.0, 2.0, 3.0, 2.0, 1.0, 2.0, 2.0, 3.0, 2.0, 3.0, 3.0, 1.0, 4.0, 1.0, 1.0, 1.0, 2.0, 1.0, 2.0, 1.0, 2.0, 1.0, 1.0, 0.0, 0.0, 2.0, 3.0, 4.0, 3.0, 3.0, 0.0, 1.0, 1.0, 3.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 2.0, 0.0, 1.0, 0.0, 1.0, 0.0, 2.0, 1.0, 0.0, 2.0, 1.0, 1.0, 0.0, 1.0, 2.0, 3.0, 2.0, 2.0, 0.0, 0.0, 0.0, 2.0, 1.0, 5.0, 4.0, 0.0, 2.0, 1.0, 2.0, 2.0, 2.0, 1.0, 3.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 2.0, 1.0, 3.0, 2.0, 0.0, 0.0, 3.0, 2.0, 3.0, 4.0, 4.0, 1.0, 4.0, 0.0, 2.0, 3.0, 2.0, 1.0, 1.0, 0.0, 3.0, 5.0, 5.0, 4.0, 1.0, 0.0, 0.0, 0.0, 1.0, 2.0, 2.0, 0.0, 0.0, 2.0, 2.0, 1.0, 1.0, 1.0, 3.0, 3.0, 3.0, 3.0, 2.0, 1.0, 3.0, 1.0, 1.0, 3.0, 2.0, 2.0, 2.0, 1.0, 3.0, 2.0, 3.0, 1.0, 2.0, 2.0, 1.0, 1.0, 2.0, 1.0, 2.0, 0.0, 0.0, 2.0, 2.0, 3.0, 2.0, 0.0, 1.0, 2.0, 2.0, 1.0, 2.0, 1.0, 3.0, 2.0, 3.0, 4.0, 3.0, 0.0, 2.0, 2.0, 1.0, 1.0, 2.0, 3.0, 1.0, 1.0, 2.0, 0.0, 1.0, 1.0, 2.0, 1.0, 2.0, 1.0, 3.0, 4.0, 3.0, 3.0, 3.0, 1.0, 2.0, 2.0, 1.0, 4.0, 3.0, 4.0, 2.0, 3.0, 4.0, 2.0, 2.0, 2.0, 1.0, 2.0, 4.0, 2.0, 2.0, 3.0, 3.0, 3.0, 0.0, 0.0, 1.0, 1.0, 0.0, 2.0, 3.0, 2.0, 2.0, 2.0, 1.0, 2.0, 3.0, 2.0, 2.0, 2.0, 1.0, 2.0, 1.0, 3.0, 3.0, 0.0, 2.0, 0.0, 2.0, 1.0, 2.0, 3.0, 2.0, 2.0, 2.0, 1.0, 2.0, 3.0, 2.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 2.0, 1.0, 2.0, 2.0, 4.0, 4.0, 3.0, 3.0, 2.0, 0.0, 1.0, 1.0, 2.0, 1.0, 2.0, 2.0, 2.0, 0.0, 3.0, 1.0, 3.0, 1.0, 2.0, 2.0, 2.0, 3.0, 1.0, 1.0, 3.0, 3.0, 0.0, 2.0, 2.0, 3.0, 1.0, 2.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0, 1.0, 2.0, 1.0, 2.0, 2.0, 2.0, 1.0, 1.0, 1.0, 0.0, 2.0, 0.0, 2.0, 1.0, 3.0, 2.0, 3.0, 1.0, 2.0, 1.0, 2.0, 3.0, 2.0, 2.0, 2.0, 4.0, 3.0, 1.0, 2.0, 2.0, 1.0, 1.0, 1.0, 2.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.13375852690284717, "mean_inference_ms": 0.3907569365966843, "mean_action_processing_ms": 0.029193576900417736, "mean_env_wait_ms": 0.4039460824195146, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 1149120, "timesteps_this_iter": 0, "agent_timesteps_total": 4596480, "timers": {"sample_time_ms": 5109.207, "sample_throughput": 986.454, "load_time_ms": 0.167, "load_throughput": 30181742.09, "learn_time_ms": 129.158, "learn_throughput": 39021.823, "update_time_ms": 2.512}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 192.23162841796875, "policy_entropy": 7831.8759765625, "policy_loss": -69.19879102706909, "vf_loss": 42.848326683044434}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 1149120, "num_agent_steps_sampled": 4596480, "num_steps_trained": 1149120, "num_agent_steps_trained": 4596480, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 2296, "training_iteration": 114, "trial_id": "71426_00000", "experiment_id": "84bca2f7b35f43248fca18d21abe2ebf", "date": "2024-06-12_03-05-29", "timestamp": 1718129129, "time_this_iter_s": 10.342466115951538, "time_total_s": 1176.2395741939545, "pid": 363902, "hostname": "DESKTOP-LQ219J4", "node_ip": "192.168.46.185", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 20, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 5000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 500, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Base_Model", "custom_model_config": {"env": "rware", "env_args": {"n_agents": 4, "column_height": 1, "max_inactivity_steps": null, "max_steps": 500, "fast_obs": true, "msg_bits": 0, "sensor_range": 1, "shelf_rows": 1, "shelf_columns": 3, "request_queue_size": 4, "reward_type": "RewardType.INDIVIDUAL", "map_name": "customized_map", "map_size": "tiny", "difficulty": "medium"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": true, "force_coop": false, "local_mode": true, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 4, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 100, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64}, "algorithm": "ia2c", "space_obs": "Dict(obs:Box([-100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100.], [100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.], (112,), float32))", "space_act": "Discrete(5)", "num_agents": 4, "episode_limit": 500, "policy_mapping_info": {"all_scenario": {"description": "rware all scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2", "agent_3"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "rware_customized_map", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 10, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.IA2CTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_il.<locals>.<lambda> at 0x7f382806e940>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "grad_clip": 40.0, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "microbatch_size": null}, "time_since_restore": 1176.2395741939545, "timesteps_since_restore": 0, "iterations_since_restore": 114, "perf": {"cpu_util_percent": 4.278571428571428, "ram_util_percent": 64.45}}
{"episode_reward_max": 15.0, "episode_reward_min": 1.0, "episode_reward_mean": 7.05, "episode_len_mean": 500.0, "episode_media": {}, "episodes_this_iter": 20, "policy_reward_min": {"shared_policy": 0.0}, "policy_reward_max": {"shared_policy": 5.0}, "policy_reward_mean": {"shared_policy": 1.7625}, "custom_metrics": {}, "hist_stats": {"episode_reward": [8.0, 9.0, 11.0, 5.0, 6.0, 2.0, 12.0, 5.0, 6.0, 5.0, 2.0, 3.0, 4.0, 8.0, 2.0, 12.0, 5.0, 8.0, 3.0, 4.0, 6.0, 8.0, 13.0, 7.0, 5.0, 15.0, 1.0, 4.0, 6.0, 10.0, 9.0, 7.0, 8.0, 8.0, 6.0, 3.0, 9.0, 5.0, 7.0, 12.0, 5.0, 7.0, 4.0, 6.0, 11.0, 9.0, 10.0, 13.0, 7.0, 10.0, 9.0, 2.0, 9.0, 8.0, 7.0, 9.0, 4.0, 8.0, 7.0, 7.0, 2.0, 7.0, 14.0, 4.0, 7.0, 6.0, 8.0, 7.0, 8.0, 8.0, 5.0, 5.0, 7.0, 3.0, 5.0, 9.0, 8.0, 10.0, 8.0, 5.0, 6.0, 3.0, 8.0, 7.0, 9.0, 5.0, 10.0, 3.0, 4.0, 7.0, 5.0, 10.0, 7.0, 5.0, 14.0, 10.0, 11.0, 7.0, 12.0, 5.0], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500], "policy_shared_policy_reward": [2.0, 3.0, 2.0, 1.0, 2.0, 2.0, 3.0, 2.0, 3.0, 3.0, 1.0, 4.0, 1.0, 1.0, 1.0, 2.0, 1.0, 2.0, 1.0, 2.0, 1.0, 1.0, 0.0, 0.0, 2.0, 3.0, 4.0, 3.0, 3.0, 0.0, 1.0, 1.0, 3.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 2.0, 0.0, 1.0, 0.0, 1.0, 0.0, 2.0, 1.0, 0.0, 2.0, 1.0, 1.0, 0.0, 1.0, 2.0, 3.0, 2.0, 2.0, 0.0, 0.0, 0.0, 2.0, 1.0, 5.0, 4.0, 0.0, 2.0, 1.0, 2.0, 2.0, 2.0, 1.0, 3.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 2.0, 1.0, 3.0, 2.0, 0.0, 0.0, 3.0, 2.0, 3.0, 4.0, 4.0, 1.0, 4.0, 0.0, 2.0, 3.0, 2.0, 1.0, 1.0, 0.0, 3.0, 5.0, 5.0, 4.0, 1.0, 0.0, 0.0, 0.0, 1.0, 2.0, 2.0, 0.0, 0.0, 2.0, 2.0, 1.0, 1.0, 1.0, 3.0, 3.0, 3.0, 3.0, 2.0, 1.0, 3.0, 1.0, 1.0, 3.0, 2.0, 2.0, 2.0, 1.0, 3.0, 2.0, 3.0, 1.0, 2.0, 2.0, 1.0, 1.0, 2.0, 1.0, 2.0, 0.0, 0.0, 2.0, 2.0, 3.0, 2.0, 0.0, 1.0, 2.0, 2.0, 1.0, 2.0, 1.0, 3.0, 2.0, 3.0, 4.0, 3.0, 0.0, 2.0, 2.0, 1.0, 1.0, 2.0, 3.0, 1.0, 1.0, 2.0, 0.0, 1.0, 1.0, 2.0, 1.0, 2.0, 1.0, 3.0, 4.0, 3.0, 3.0, 3.0, 1.0, 2.0, 2.0, 1.0, 4.0, 3.0, 4.0, 2.0, 3.0, 4.0, 2.0, 2.0, 2.0, 1.0, 2.0, 4.0, 2.0, 2.0, 3.0, 3.0, 3.0, 0.0, 0.0, 1.0, 1.0, 0.0, 2.0, 3.0, 2.0, 2.0, 2.0, 1.0, 2.0, 3.0, 2.0, 2.0, 2.0, 1.0, 2.0, 1.0, 3.0, 3.0, 0.0, 2.0, 0.0, 2.0, 1.0, 2.0, 3.0, 2.0, 2.0, 2.0, 1.0, 2.0, 3.0, 2.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 2.0, 1.0, 2.0, 2.0, 4.0, 4.0, 3.0, 3.0, 2.0, 0.0, 1.0, 1.0, 2.0, 1.0, 2.0, 2.0, 2.0, 0.0, 3.0, 1.0, 3.0, 1.0, 2.0, 2.0, 2.0, 3.0, 1.0, 1.0, 3.0, 3.0, 0.0, 2.0, 2.0, 3.0, 1.0, 2.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0, 1.0, 2.0, 1.0, 2.0, 2.0, 2.0, 1.0, 1.0, 1.0, 0.0, 2.0, 0.0, 2.0, 1.0, 3.0, 2.0, 3.0, 1.0, 2.0, 1.0, 2.0, 3.0, 2.0, 2.0, 2.0, 4.0, 3.0, 1.0, 2.0, 2.0, 1.0, 1.0, 1.0, 2.0, 3.0, 1.0, 2.0, 0.0, 1.0, 1.0, 0.0, 1.0, 2.0, 3.0, 1.0, 2.0, 1.0, 1.0, 4.0, 1.0, 2.0, 3.0, 3.0, 1.0, 1.0, 2.0, 0.0, 2.0, 2.0, 3.0, 4.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 2.0, 0.0, 2.0, 2.0, 2.0, 1.0, 2.0, 1.0, 1.0, 1.0, 2.0, 4.0, 2.0, 2.0, 1.0, 2.0, 1.0, 3.0, 2.0, 0.0, 1.0, 2.0, 3.0, 5.0, 3.0, 3.0, 3.0, 2.0, 2.0, 3.0, 5.0, 1.0, 2.0, 3.0, 1.0, 3.0, 2.0, 1.0, 3.0, 2.0, 3.0, 4.0, 2.0, 1.0, 1.0, 1.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.13375043379599405, "mean_inference_ms": 0.3907411613184568, "mean_action_processing_ms": 0.029192214737330417, "mean_env_wait_ms": 0.40391342976996675, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 1159200, "timesteps_this_iter": 0, "agent_timesteps_total": 4636800, "timers": {"sample_time_ms": 5102.626, "sample_throughput": 987.727, "load_time_ms": 0.169, "load_throughput": 29748511.343, "learn_time_ms": 130.537, "learn_throughput": 38609.663, "update_time_ms": 2.504}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 525.8473510742188, "policy_entropy": 7779.8367919921875, "policy_loss": 151.77245807647705, "vf_loss": 70.17966365814209}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 1159200, "num_agent_steps_sampled": 4636800, "num_steps_trained": 1159200, "num_agent_steps_trained": 4636800, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 2316, "training_iteration": 115, "trial_id": "71426_00000", "experiment_id": "84bca2f7b35f43248fca18d21abe2ebf", "date": "2024-06-12_03-05-39", "timestamp": 1718129139, "time_this_iter_s": 10.169012784957886, "time_total_s": 1186.4085869789124, "pid": 363902, "hostname": "DESKTOP-LQ219J4", "node_ip": "192.168.46.185", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 20, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 5000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 500, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Base_Model", "custom_model_config": {"env": "rware", "env_args": {"n_agents": 4, "column_height": 1, "max_inactivity_steps": null, "max_steps": 500, "fast_obs": true, "msg_bits": 0, "sensor_range": 1, "shelf_rows": 1, "shelf_columns": 3, "request_queue_size": 4, "reward_type": "RewardType.INDIVIDUAL", "map_name": "customized_map", "map_size": "tiny", "difficulty": "medium"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": true, "force_coop": false, "local_mode": true, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 4, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 100, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64}, "algorithm": "ia2c", "space_obs": "Dict(obs:Box([-100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100.], [100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.], (112,), float32))", "space_act": "Discrete(5)", "num_agents": 4, "episode_limit": 500, "policy_mapping_info": {"all_scenario": {"description": "rware all scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2", "agent_3"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "rware_customized_map", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 10, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.IA2CTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_il.<locals>.<lambda> at 0x7f38086c1c10>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "grad_clip": 40.0, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "microbatch_size": null}, "time_since_restore": 1186.4085869789124, "timesteps_since_restore": 0, "iterations_since_restore": 115, "perf": {"cpu_util_percent": 4.293333333333334, "ram_util_percent": 64.70000000000002}}
{"episode_reward_max": 17.0, "episode_reward_min": 1.0, "episode_reward_mean": 7.44, "episode_len_mean": 500.0, "episode_media": {}, "episodes_this_iter": 20, "policy_reward_min": {"shared_policy": 0.0}, "policy_reward_max": {"shared_policy": 5.0}, "policy_reward_mean": {"shared_policy": 1.86}, "custom_metrics": {}, "hist_stats": {"episode_reward": [6.0, 8.0, 13.0, 7.0, 5.0, 15.0, 1.0, 4.0, 6.0, 10.0, 9.0, 7.0, 8.0, 8.0, 6.0, 3.0, 9.0, 5.0, 7.0, 12.0, 5.0, 7.0, 4.0, 6.0, 11.0, 9.0, 10.0, 13.0, 7.0, 10.0, 9.0, 2.0, 9.0, 8.0, 7.0, 9.0, 4.0, 8.0, 7.0, 7.0, 2.0, 7.0, 14.0, 4.0, 7.0, 6.0, 8.0, 7.0, 8.0, 8.0, 5.0, 5.0, 7.0, 3.0, 5.0, 9.0, 8.0, 10.0, 8.0, 5.0, 6.0, 3.0, 8.0, 7.0, 9.0, 5.0, 10.0, 3.0, 4.0, 7.0, 5.0, 10.0, 7.0, 5.0, 14.0, 10.0, 11.0, 7.0, 12.0, 5.0, 13.0, 11.0, 3.0, 3.0, 6.0, 9.0, 8.0, 12.0, 7.0, 3.0, 15.0, 8.0, 10.0, 3.0, 7.0, 17.0, 12.0, 7.0, 4.0, 1.0], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500], "policy_shared_policy_reward": [1.0, 3.0, 2.0, 0.0, 0.0, 3.0, 2.0, 3.0, 4.0, 4.0, 1.0, 4.0, 0.0, 2.0, 3.0, 2.0, 1.0, 1.0, 0.0, 3.0, 5.0, 5.0, 4.0, 1.0, 0.0, 0.0, 0.0, 1.0, 2.0, 2.0, 0.0, 0.0, 2.0, 2.0, 1.0, 1.0, 1.0, 3.0, 3.0, 3.0, 3.0, 2.0, 1.0, 3.0, 1.0, 1.0, 3.0, 2.0, 2.0, 2.0, 1.0, 3.0, 2.0, 3.0, 1.0, 2.0, 2.0, 1.0, 1.0, 2.0, 1.0, 2.0, 0.0, 0.0, 2.0, 2.0, 3.0, 2.0, 0.0, 1.0, 2.0, 2.0, 1.0, 2.0, 1.0, 3.0, 2.0, 3.0, 4.0, 3.0, 0.0, 2.0, 2.0, 1.0, 1.0, 2.0, 3.0, 1.0, 1.0, 2.0, 0.0, 1.0, 1.0, 2.0, 1.0, 2.0, 1.0, 3.0, 4.0, 3.0, 3.0, 3.0, 1.0, 2.0, 2.0, 1.0, 4.0, 3.0, 4.0, 2.0, 3.0, 4.0, 2.0, 2.0, 2.0, 1.0, 2.0, 4.0, 2.0, 2.0, 3.0, 3.0, 3.0, 0.0, 0.0, 1.0, 1.0, 0.0, 2.0, 3.0, 2.0, 2.0, 2.0, 1.0, 2.0, 3.0, 2.0, 2.0, 2.0, 1.0, 2.0, 1.0, 3.0, 3.0, 0.0, 2.0, 0.0, 2.0, 1.0, 2.0, 3.0, 2.0, 2.0, 2.0, 1.0, 2.0, 3.0, 2.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 2.0, 1.0, 2.0, 2.0, 4.0, 4.0, 3.0, 3.0, 2.0, 0.0, 1.0, 1.0, 2.0, 1.0, 2.0, 2.0, 2.0, 0.0, 3.0, 1.0, 3.0, 1.0, 2.0, 2.0, 2.0, 3.0, 1.0, 1.0, 3.0, 3.0, 0.0, 2.0, 2.0, 3.0, 1.0, 2.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0, 1.0, 2.0, 1.0, 2.0, 2.0, 2.0, 1.0, 1.0, 1.0, 0.0, 2.0, 0.0, 2.0, 1.0, 3.0, 2.0, 3.0, 1.0, 2.0, 1.0, 2.0, 3.0, 2.0, 2.0, 2.0, 4.0, 3.0, 1.0, 2.0, 2.0, 1.0, 1.0, 1.0, 2.0, 3.0, 1.0, 2.0, 0.0, 1.0, 1.0, 0.0, 1.0, 2.0, 3.0, 1.0, 2.0, 1.0, 1.0, 4.0, 1.0, 2.0, 3.0, 3.0, 1.0, 1.0, 2.0, 0.0, 2.0, 2.0, 3.0, 4.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 2.0, 0.0, 2.0, 2.0, 2.0, 1.0, 2.0, 1.0, 1.0, 1.0, 2.0, 4.0, 2.0, 2.0, 1.0, 2.0, 1.0, 3.0, 2.0, 0.0, 1.0, 2.0, 3.0, 5.0, 3.0, 3.0, 3.0, 2.0, 2.0, 3.0, 5.0, 1.0, 2.0, 3.0, 1.0, 3.0, 2.0, 1.0, 3.0, 2.0, 3.0, 4.0, 2.0, 1.0, 1.0, 1.0, 4.0, 3.0, 3.0, 3.0, 3.0, 3.0, 4.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 3.0, 1.0, 2.0, 0.0, 3.0, 2.0, 3.0, 1.0, 1.0, 2.0, 3.0, 2.0, 2.0, 4.0, 3.0, 3.0, 2.0, 1.0, 1.0, 3.0, 0.0, 1.0, 0.0, 2.0, 3.0, 4.0, 3.0, 5.0, 2.0, 2.0, 2.0, 2.0, 3.0, 3.0, 1.0, 3.0, 1.0, 1.0, 0.0, 1.0, 2.0, 2.0, 1.0, 2.0, 5.0, 2.0, 5.0, 5.0, 2.0, 3.0, 3.0, 4.0, 3.0, 2.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.13374846060346196, "mean_inference_ms": 0.3907400947899417, "mean_action_processing_ms": 0.029191179892418807, "mean_env_wait_ms": 0.40390240858787324, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 1169280, "timesteps_this_iter": 0, "agent_timesteps_total": 4677120, "timers": {"sample_time_ms": 5124.109, "sample_throughput": 983.586, "load_time_ms": 0.165, "load_throughput": 30570198.351, "learn_time_ms": 129.581, "learn_throughput": 38894.577, "update_time_ms": 2.493}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 351.6029052734375, "policy_entropy": 7754.7869873046875, "policy_loss": -79.21841049194336, "vf_loss": 32.12019157409668}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 1169280, "num_agent_steps_sampled": 4677120, "num_steps_trained": 1169280, "num_agent_steps_trained": 4677120, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 2336, "training_iteration": 116, "trial_id": "71426_00000", "experiment_id": "84bca2f7b35f43248fca18d21abe2ebf", "date": "2024-06-12_03-05-49", "timestamp": 1718129149, "time_this_iter_s": 10.203043460845947, "time_total_s": 1196.6116304397583, "pid": 363902, "hostname": "DESKTOP-LQ219J4", "node_ip": "192.168.46.185", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 20, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 5000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 500, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Base_Model", "custom_model_config": {"env": "rware", "env_args": {"n_agents": 4, "column_height": 1, "max_inactivity_steps": null, "max_steps": 500, "fast_obs": true, "msg_bits": 0, "sensor_range": 1, "shelf_rows": 1, "shelf_columns": 3, "request_queue_size": 4, "reward_type": "RewardType.INDIVIDUAL", "map_name": "customized_map", "map_size": "tiny", "difficulty": "medium"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": true, "force_coop": false, "local_mode": true, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 4, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 100, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64}, "algorithm": "ia2c", "space_obs": "Dict(obs:Box([-100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100.], [100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.], (112,), float32))", "space_act": "Discrete(5)", "num_agents": 4, "episode_limit": 500, "policy_mapping_info": {"all_scenario": {"description": "rware all scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2", "agent_3"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "rware_customized_map", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 10, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.IA2CTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_il.<locals>.<lambda> at 0x7f383066ab80>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "grad_clip": 40.0, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "microbatch_size": null}, "time_since_restore": 1196.6116304397583, "timesteps_since_restore": 0, "iterations_since_restore": 116, "perf": {"cpu_util_percent": 4.442857142857143, "ram_util_percent": 65.05000000000001}}
{"episode_reward_max": 17.0, "episode_reward_min": 1.0, "episode_reward_mean": 7.19, "episode_len_mean": 500.0, "episode_media": {}, "episodes_this_iter": 20, "policy_reward_min": {"shared_policy": 0.0}, "policy_reward_max": {"shared_policy": 5.0}, "policy_reward_mean": {"shared_policy": 1.7975}, "custom_metrics": {}, "hist_stats": {"episode_reward": [5.0, 7.0, 4.0, 6.0, 11.0, 9.0, 10.0, 13.0, 7.0, 10.0, 9.0, 2.0, 9.0, 8.0, 7.0, 9.0, 4.0, 8.0, 7.0, 7.0, 2.0, 7.0, 14.0, 4.0, 7.0, 6.0, 8.0, 7.0, 8.0, 8.0, 5.0, 5.0, 7.0, 3.0, 5.0, 9.0, 8.0, 10.0, 8.0, 5.0, 6.0, 3.0, 8.0, 7.0, 9.0, 5.0, 10.0, 3.0, 4.0, 7.0, 5.0, 10.0, 7.0, 5.0, 14.0, 10.0, 11.0, 7.0, 12.0, 5.0, 13.0, 11.0, 3.0, 3.0, 6.0, 9.0, 8.0, 12.0, 7.0, 3.0, 15.0, 8.0, 10.0, 3.0, 7.0, 17.0, 12.0, 7.0, 4.0, 1.0, 9.0, 8.0, 3.0, 5.0, 8.0, 4.0, 6.0, 5.0, 2.0, 7.0, 6.0, 7.0, 3.0, 3.0, 4.0, 11.0, 11.0, 6.0, 6.0, 10.0], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500], "policy_shared_policy_reward": [0.0, 2.0, 2.0, 1.0, 1.0, 2.0, 3.0, 1.0, 1.0, 2.0, 0.0, 1.0, 1.0, 2.0, 1.0, 2.0, 1.0, 3.0, 4.0, 3.0, 3.0, 3.0, 1.0, 2.0, 2.0, 1.0, 4.0, 3.0, 4.0, 2.0, 3.0, 4.0, 2.0, 2.0, 2.0, 1.0, 2.0, 4.0, 2.0, 2.0, 3.0, 3.0, 3.0, 0.0, 0.0, 1.0, 1.0, 0.0, 2.0, 3.0, 2.0, 2.0, 2.0, 1.0, 2.0, 3.0, 2.0, 2.0, 2.0, 1.0, 2.0, 1.0, 3.0, 3.0, 0.0, 2.0, 0.0, 2.0, 1.0, 2.0, 3.0, 2.0, 2.0, 2.0, 1.0, 2.0, 3.0, 2.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 2.0, 1.0, 2.0, 2.0, 4.0, 4.0, 3.0, 3.0, 2.0, 0.0, 1.0, 1.0, 2.0, 1.0, 2.0, 2.0, 2.0, 0.0, 3.0, 1.0, 3.0, 1.0, 2.0, 2.0, 2.0, 3.0, 1.0, 1.0, 3.0, 3.0, 0.0, 2.0, 2.0, 3.0, 1.0, 2.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0, 1.0, 2.0, 1.0, 2.0, 2.0, 2.0, 1.0, 1.0, 1.0, 0.0, 2.0, 0.0, 2.0, 1.0, 3.0, 2.0, 3.0, 1.0, 2.0, 1.0, 2.0, 3.0, 2.0, 2.0, 2.0, 4.0, 3.0, 1.0, 2.0, 2.0, 1.0, 1.0, 1.0, 2.0, 3.0, 1.0, 2.0, 0.0, 1.0, 1.0, 0.0, 1.0, 2.0, 3.0, 1.0, 2.0, 1.0, 1.0, 4.0, 1.0, 2.0, 3.0, 3.0, 1.0, 1.0, 2.0, 0.0, 2.0, 2.0, 3.0, 4.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 2.0, 0.0, 2.0, 2.0, 2.0, 1.0, 2.0, 1.0, 1.0, 1.0, 2.0, 4.0, 2.0, 2.0, 1.0, 2.0, 1.0, 3.0, 2.0, 0.0, 1.0, 2.0, 3.0, 5.0, 3.0, 3.0, 3.0, 2.0, 2.0, 3.0, 5.0, 1.0, 2.0, 3.0, 1.0, 3.0, 2.0, 1.0, 3.0, 2.0, 3.0, 4.0, 2.0, 1.0, 1.0, 1.0, 4.0, 3.0, 3.0, 3.0, 3.0, 3.0, 4.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 3.0, 1.0, 2.0, 0.0, 3.0, 2.0, 3.0, 1.0, 1.0, 2.0, 3.0, 2.0, 2.0, 4.0, 3.0, 3.0, 2.0, 1.0, 1.0, 3.0, 0.0, 1.0, 0.0, 2.0, 3.0, 4.0, 3.0, 5.0, 2.0, 2.0, 2.0, 2.0, 3.0, 3.0, 1.0, 3.0, 1.0, 1.0, 0.0, 1.0, 2.0, 2.0, 1.0, 2.0, 5.0, 2.0, 5.0, 5.0, 2.0, 3.0, 3.0, 4.0, 3.0, 2.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 3.0, 1.0, 4.0, 1.0, 1.0, 0.0, 3.0, 4.0, 0.0, 2.0, 1.0, 0.0, 1.0, 1.0, 2.0, 1.0, 1.0, 2.0, 2.0, 3.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 3.0, 1.0, 2.0, 2.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 2.0, 1.0, 2.0, 2.0, 2.0, 1.0, 2.0, 1.0, 2.0, 2.0, 0.0, 3.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 4.0, 3.0, 2.0, 2.0, 2.0, 4.0, 2.0, 3.0, 1.0, 1.0, 3.0, 1.0, 2.0, 1.0, 1.0, 2.0, 2.0, 1.0, 4.0, 3.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.13374968683698416, "mean_inference_ms": 0.3907483787058603, "mean_action_processing_ms": 0.029190287462836997, "mean_env_wait_ms": 0.40390793870649416, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 1179360, "timesteps_this_iter": 0, "agent_timesteps_total": 4717440, "timers": {"sample_time_ms": 5140.1, "sample_throughput": 980.526, "load_time_ms": 0.166, "load_throughput": 30302884.404, "learn_time_ms": 129.129, "learn_throughput": 39030.858, "update_time_ms": 2.444}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 171.3890380859375, "policy_entropy": 7668.005615234375, "policy_loss": -14.497223854064941, "vf_loss": 42.36922836303711}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 1179360, "num_agent_steps_sampled": 4717440, "num_steps_trained": 1179360, "num_agent_steps_trained": 4717440, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 2356, "training_iteration": 117, "trial_id": "71426_00000", "experiment_id": "84bca2f7b35f43248fca18d21abe2ebf", "date": "2024-06-12_03-05-59", "timestamp": 1718129159, "time_this_iter_s": 10.331076860427856, "time_total_s": 1206.9427073001862, "pid": 363902, "hostname": "DESKTOP-LQ219J4", "node_ip": "192.168.46.185", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 20, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 5000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 500, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Base_Model", "custom_model_config": {"env": "rware", "env_args": {"n_agents": 4, "column_height": 1, "max_inactivity_steps": null, "max_steps": 500, "fast_obs": true, "msg_bits": 0, "sensor_range": 1, "shelf_rows": 1, "shelf_columns": 3, "request_queue_size": 4, "reward_type": "RewardType.INDIVIDUAL", "map_name": "customized_map", "map_size": "tiny", "difficulty": "medium"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": true, "force_coop": false, "local_mode": true, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 4, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 100, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64}, "algorithm": "ia2c", "space_obs": "Dict(obs:Box([-100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100.], [100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.], (112,), float32))", "space_act": "Discrete(5)", "num_agents": 4, "episode_limit": 500, "policy_mapping_info": {"all_scenario": {"description": "rware all scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2", "agent_3"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "rware_customized_map", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 10, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.IA2CTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_il.<locals>.<lambda> at 0x7f38280b2160>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "grad_clip": 40.0, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "microbatch_size": null}, "time_since_restore": 1206.9427073001862, "timesteps_since_restore": 0, "iterations_since_restore": 117, "perf": {"cpu_util_percent": 4.733333333333333, "ram_util_percent": 65.29999999999998}}
{"episode_reward_max": 17.0, "episode_reward_min": 1.0, "episode_reward_mean": 7.06, "episode_len_mean": 500.0, "episode_media": {}, "episodes_this_iter": 20, "policy_reward_min": {"shared_policy": 0.0}, "policy_reward_max": {"shared_policy": 5.0}, "policy_reward_mean": {"shared_policy": 1.765}, "custom_metrics": {}, "hist_stats": {"episode_reward": [2.0, 7.0, 14.0, 4.0, 7.0, 6.0, 8.0, 7.0, 8.0, 8.0, 5.0, 5.0, 7.0, 3.0, 5.0, 9.0, 8.0, 10.0, 8.0, 5.0, 6.0, 3.0, 8.0, 7.0, 9.0, 5.0, 10.0, 3.0, 4.0, 7.0, 5.0, 10.0, 7.0, 5.0, 14.0, 10.0, 11.0, 7.0, 12.0, 5.0, 13.0, 11.0, 3.0, 3.0, 6.0, 9.0, 8.0, 12.0, 7.0, 3.0, 15.0, 8.0, 10.0, 3.0, 7.0, 17.0, 12.0, 7.0, 4.0, 1.0, 9.0, 8.0, 3.0, 5.0, 8.0, 4.0, 6.0, 5.0, 2.0, 7.0, 6.0, 7.0, 3.0, 3.0, 4.0, 11.0, 11.0, 6.0, 6.0, 10.0, 4.0, 11.0, 8.0, 7.0, 2.0, 9.0, 4.0, 8.0, 7.0, 8.0, 7.0, 10.0, 5.0, 3.0, 7.0, 6.0, 12.0, 6.0, 7.0, 8.0], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500], "policy_shared_policy_reward": [1.0, 0.0, 0.0, 1.0, 2.0, 1.0, 2.0, 2.0, 4.0, 4.0, 3.0, 3.0, 2.0, 0.0, 1.0, 1.0, 2.0, 1.0, 2.0, 2.0, 2.0, 0.0, 3.0, 1.0, 3.0, 1.0, 2.0, 2.0, 2.0, 3.0, 1.0, 1.0, 3.0, 3.0, 0.0, 2.0, 2.0, 3.0, 1.0, 2.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0, 1.0, 2.0, 1.0, 2.0, 2.0, 2.0, 1.0, 1.0, 1.0, 0.0, 2.0, 0.0, 2.0, 1.0, 3.0, 2.0, 3.0, 1.0, 2.0, 1.0, 2.0, 3.0, 2.0, 2.0, 2.0, 4.0, 3.0, 1.0, 2.0, 2.0, 1.0, 1.0, 1.0, 2.0, 3.0, 1.0, 2.0, 0.0, 1.0, 1.0, 0.0, 1.0, 2.0, 3.0, 1.0, 2.0, 1.0, 1.0, 4.0, 1.0, 2.0, 3.0, 3.0, 1.0, 1.0, 2.0, 0.0, 2.0, 2.0, 3.0, 4.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 2.0, 0.0, 2.0, 2.0, 2.0, 1.0, 2.0, 1.0, 1.0, 1.0, 2.0, 4.0, 2.0, 2.0, 1.0, 2.0, 1.0, 3.0, 2.0, 0.0, 1.0, 2.0, 3.0, 5.0, 3.0, 3.0, 3.0, 2.0, 2.0, 3.0, 5.0, 1.0, 2.0, 3.0, 1.0, 3.0, 2.0, 1.0, 3.0, 2.0, 3.0, 4.0, 2.0, 1.0, 1.0, 1.0, 4.0, 3.0, 3.0, 3.0, 3.0, 3.0, 4.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 3.0, 1.0, 2.0, 0.0, 3.0, 2.0, 3.0, 1.0, 1.0, 2.0, 3.0, 2.0, 2.0, 4.0, 3.0, 3.0, 2.0, 1.0, 1.0, 3.0, 0.0, 1.0, 0.0, 2.0, 3.0, 4.0, 3.0, 5.0, 2.0, 2.0, 2.0, 2.0, 3.0, 3.0, 1.0, 3.0, 1.0, 1.0, 0.0, 1.0, 2.0, 2.0, 1.0, 2.0, 5.0, 2.0, 5.0, 5.0, 2.0, 3.0, 3.0, 4.0, 3.0, 2.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 3.0, 1.0, 4.0, 1.0, 1.0, 0.0, 3.0, 4.0, 0.0, 2.0, 1.0, 0.0, 1.0, 1.0, 2.0, 1.0, 1.0, 2.0, 2.0, 3.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 3.0, 1.0, 2.0, 2.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 2.0, 1.0, 2.0, 2.0, 2.0, 1.0, 2.0, 1.0, 2.0, 2.0, 0.0, 3.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 4.0, 3.0, 2.0, 2.0, 2.0, 4.0, 2.0, 3.0, 1.0, 1.0, 3.0, 1.0, 2.0, 1.0, 1.0, 2.0, 2.0, 1.0, 4.0, 3.0, 1.0, 2.0, 1.0, 0.0, 3.0, 4.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 3.0, 2.0, 2.0, 0.0, 1.0, 0.0, 1.0, 0.0, 4.0, 1.0, 1.0, 3.0, 1.0, 0.0, 2.0, 1.0, 1.0, 2.0, 2.0, 3.0, 1.0, 2.0, 2.0, 2.0, 2.0, 3.0, 2.0, 1.0, 1.0, 1.0, 3.0, 2.0, 3.0, 4.0, 2.0, 1.0, 1.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0, 0.0, 2.0, 2.0, 2.0, 1.0, 2.0, 1.0, 2.0, 1.0, 3.0, 3.0, 2.0, 4.0, 1.0, 1.0, 3.0, 1.0, 3.0, 1.0, 2.0, 1.0, 1.0, 2.0, 4.0, 1.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.13376010976209524, "mean_inference_ms": 0.39077863301624605, "mean_action_processing_ms": 0.029190462954320245, "mean_env_wait_ms": 0.4039337995032527, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 1189440, "timesteps_this_iter": 0, "agent_timesteps_total": 4757760, "timers": {"sample_time_ms": 5175.851, "sample_throughput": 973.753, "load_time_ms": 0.181, "load_throughput": 27862517.675, "learn_time_ms": 129.404, "learn_throughput": 38947.663, "update_time_ms": 2.582}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 175.6522674560547, "policy_entropy": 7775.6007080078125, "policy_loss": -41.68827301263809, "vf_loss": 28.442425966262817}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 1189440, "num_agent_steps_sampled": 4757760, "num_steps_trained": 1189440, "num_agent_steps_trained": 4757760, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 2376, "training_iteration": 118, "trial_id": "71426_00000", "experiment_id": "84bca2f7b35f43248fca18d21abe2ebf", "date": "2024-06-12_03-06-10", "timestamp": 1718129170, "time_this_iter_s": 10.632241010665894, "time_total_s": 1217.574948310852, "pid": 363902, "hostname": "DESKTOP-LQ219J4", "node_ip": "192.168.46.185", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 20, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 5000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 500, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Base_Model", "custom_model_config": {"env": "rware", "env_args": {"n_agents": 4, "column_height": 1, "max_inactivity_steps": null, "max_steps": 500, "fast_obs": true, "msg_bits": 0, "sensor_range": 1, "shelf_rows": 1, "shelf_columns": 3, "request_queue_size": 4, "reward_type": "RewardType.INDIVIDUAL", "map_name": "customized_map", "map_size": "tiny", "difficulty": "medium"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": true, "force_coop": false, "local_mode": true, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 4, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 100, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64}, "algorithm": "ia2c", "space_obs": "Dict(obs:Box([-100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100.], [100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.], (112,), float32))", "space_act": "Discrete(5)", "num_agents": 4, "episode_limit": 500, "policy_mapping_info": {"all_scenario": {"description": "rware all scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2", "agent_3"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "rware_customized_map", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 10, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.IA2CTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_il.<locals>.<lambda> at 0x7f383066adc0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "grad_clip": 40.0, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "microbatch_size": null}, "time_since_restore": 1217.574948310852, "timesteps_since_restore": 0, "iterations_since_restore": 118, "perf": {"cpu_util_percent": 4.3066666666666675, "ram_util_percent": 65.54666666666668}}
{"episode_reward_max": 18.0, "episode_reward_min": 1.0, "episode_reward_mean": 7.31, "episode_len_mean": 500.0, "episode_media": {}, "episodes_this_iter": 20, "policy_reward_min": {"shared_policy": 0.0}, "policy_reward_max": {"shared_policy": 6.0}, "policy_reward_mean": {"shared_policy": 1.8275}, "custom_metrics": {}, "hist_stats": {"episode_reward": [6.0, 3.0, 8.0, 7.0, 9.0, 5.0, 10.0, 3.0, 4.0, 7.0, 5.0, 10.0, 7.0, 5.0, 14.0, 10.0, 11.0, 7.0, 12.0, 5.0, 13.0, 11.0, 3.0, 3.0, 6.0, 9.0, 8.0, 12.0, 7.0, 3.0, 15.0, 8.0, 10.0, 3.0, 7.0, 17.0, 12.0, 7.0, 4.0, 1.0, 9.0, 8.0, 3.0, 5.0, 8.0, 4.0, 6.0, 5.0, 2.0, 7.0, 6.0, 7.0, 3.0, 3.0, 4.0, 11.0, 11.0, 6.0, 6.0, 10.0, 4.0, 11.0, 8.0, 7.0, 2.0, 9.0, 4.0, 8.0, 7.0, 8.0, 7.0, 10.0, 5.0, 3.0, 7.0, 6.0, 12.0, 6.0, 7.0, 8.0, 3.0, 10.0, 13.0, 5.0, 8.0, 1.0, 3.0, 6.0, 12.0, 9.0, 7.0, 10.0, 11.0, 6.0, 10.0, 4.0, 8.0, 7.0, 18.0, 10.0], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500], "policy_shared_policy_reward": [3.0, 1.0, 2.0, 0.0, 1.0, 1.0, 0.0, 1.0, 2.0, 3.0, 1.0, 2.0, 1.0, 1.0, 4.0, 1.0, 2.0, 3.0, 3.0, 1.0, 1.0, 2.0, 0.0, 2.0, 2.0, 3.0, 4.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 2.0, 0.0, 2.0, 2.0, 2.0, 1.0, 2.0, 1.0, 1.0, 1.0, 2.0, 4.0, 2.0, 2.0, 1.0, 2.0, 1.0, 3.0, 2.0, 0.0, 1.0, 2.0, 3.0, 5.0, 3.0, 3.0, 3.0, 2.0, 2.0, 3.0, 5.0, 1.0, 2.0, 3.0, 1.0, 3.0, 2.0, 1.0, 3.0, 2.0, 3.0, 4.0, 2.0, 1.0, 1.0, 1.0, 4.0, 3.0, 3.0, 3.0, 3.0, 3.0, 4.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 3.0, 1.0, 2.0, 0.0, 3.0, 2.0, 3.0, 1.0, 1.0, 2.0, 3.0, 2.0, 2.0, 4.0, 3.0, 3.0, 2.0, 1.0, 1.0, 3.0, 0.0, 1.0, 0.0, 2.0, 3.0, 4.0, 3.0, 5.0, 2.0, 2.0, 2.0, 2.0, 3.0, 3.0, 1.0, 3.0, 1.0, 1.0, 0.0, 1.0, 2.0, 2.0, 1.0, 2.0, 5.0, 2.0, 5.0, 5.0, 2.0, 3.0, 3.0, 4.0, 3.0, 2.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 3.0, 1.0, 4.0, 1.0, 1.0, 0.0, 3.0, 4.0, 0.0, 2.0, 1.0, 0.0, 1.0, 1.0, 2.0, 1.0, 1.0, 2.0, 2.0, 3.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 3.0, 1.0, 2.0, 2.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 2.0, 1.0, 2.0, 2.0, 2.0, 1.0, 2.0, 1.0, 2.0, 2.0, 0.0, 3.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 4.0, 3.0, 2.0, 2.0, 2.0, 4.0, 2.0, 3.0, 1.0, 1.0, 3.0, 1.0, 2.0, 1.0, 1.0, 2.0, 2.0, 1.0, 4.0, 3.0, 1.0, 2.0, 1.0, 0.0, 3.0, 4.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 3.0, 2.0, 2.0, 0.0, 1.0, 0.0, 1.0, 0.0, 4.0, 1.0, 1.0, 3.0, 1.0, 0.0, 2.0, 1.0, 1.0, 2.0, 2.0, 3.0, 1.0, 2.0, 2.0, 2.0, 2.0, 3.0, 2.0, 1.0, 1.0, 1.0, 3.0, 2.0, 3.0, 4.0, 2.0, 1.0, 1.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0, 0.0, 2.0, 2.0, 2.0, 1.0, 2.0, 1.0, 2.0, 1.0, 3.0, 3.0, 2.0, 4.0, 1.0, 1.0, 3.0, 1.0, 3.0, 1.0, 2.0, 1.0, 1.0, 2.0, 4.0, 1.0, 1.0, 1.0, 1.0, 0.0, 3.0, 1.0, 4.0, 2.0, 2.0, 4.0, 3.0, 4.0, 1.0, 1.0, 2.0, 1.0, 2.0, 1.0, 3.0, 2.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 2.0, 1.0, 1.0, 2.0, 3.0, 3.0, 3.0, 3.0, 1.0, 4.0, 2.0, 2.0, 2.0, 1.0, 1.0, 3.0, 4.0, 3.0, 2.0, 1.0, 3.0, 3.0, 3.0, 2.0, 1.0, 1.0, 2.0, 2.0, 4.0, 1.0, 3.0, 2.0, 1.0, 1.0, 2.0, 0.0, 2.0, 3.0, 1.0, 2.0, 3.0, 1.0, 2.0, 1.0, 4.0, 6.0, 5.0, 3.0, 3.0, 2.0, 2.0, 3.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.13378007438923156, "mean_inference_ms": 0.3908372543651579, "mean_action_processing_ms": 0.029192855483216505, "mean_env_wait_ms": 0.4039846953051061, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 1199520, "timesteps_this_iter": 0, "agent_timesteps_total": 4798080, "timers": {"sample_time_ms": 5217.784, "sample_throughput": 965.927, "load_time_ms": 0.185, "load_throughput": 27262435.079, "learn_time_ms": 130.277, "learn_throughput": 38686.766, "update_time_ms": 2.639}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 469.093017578125, "policy_entropy": 7711.8514404296875, "policy_loss": 160.58772659301758, "vf_loss": 82.39535903930664}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 1199520, "num_agent_steps_sampled": 4798080, "num_steps_trained": 1199520, "num_agent_steps_trained": 4798080, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 2396, "training_iteration": 119, "trial_id": "71426_00000", "experiment_id": "84bca2f7b35f43248fca18d21abe2ebf", "date": "2024-06-12_03-06-21", "timestamp": 1718129181, "time_this_iter_s": 10.767941951751709, "time_total_s": 1228.3428902626038, "pid": 363902, "hostname": "DESKTOP-LQ219J4", "node_ip": "192.168.46.185", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 20, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 5000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 500, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Base_Model", "custom_model_config": {"env": "rware", "env_args": {"n_agents": 4, "column_height": 1, "max_inactivity_steps": null, "max_steps": 500, "fast_obs": true, "msg_bits": 0, "sensor_range": 1, "shelf_rows": 1, "shelf_columns": 3, "request_queue_size": 4, "reward_type": "RewardType.INDIVIDUAL", "map_name": "customized_map", "map_size": "tiny", "difficulty": "medium"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": true, "force_coop": false, "local_mode": true, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 4, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 100, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64}, "algorithm": "ia2c", "space_obs": "Dict(obs:Box([-100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100.], [100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.], (112,), float32))", "space_act": "Discrete(5)", "num_agents": 4, "episode_limit": 500, "policy_mapping_info": {"all_scenario": {"description": "rware all scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2", "agent_3"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "rware_customized_map", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 10, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.IA2CTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_il.<locals>.<lambda> at 0x7f38082f8790>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "grad_clip": 40.0, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "microbatch_size": null}, "time_since_restore": 1228.3428902626038, "timesteps_since_restore": 0, "iterations_since_restore": 119, "perf": {"cpu_util_percent": 4.33125, "ram_util_percent": 65.85624999999999}}
{"episode_reward_max": 18.0, "episode_reward_min": 1.0, "episode_reward_mean": 7.74, "episode_len_mean": 500.0, "episode_media": {}, "episodes_this_iter": 20, "policy_reward_min": {"shared_policy": 0.0}, "policy_reward_max": {"shared_policy": 6.0}, "policy_reward_mean": {"shared_policy": 1.935}, "custom_metrics": {}, "hist_stats": {"episode_reward": [13.0, 11.0, 3.0, 3.0, 6.0, 9.0, 8.0, 12.0, 7.0, 3.0, 15.0, 8.0, 10.0, 3.0, 7.0, 17.0, 12.0, 7.0, 4.0, 1.0, 9.0, 8.0, 3.0, 5.0, 8.0, 4.0, 6.0, 5.0, 2.0, 7.0, 6.0, 7.0, 3.0, 3.0, 4.0, 11.0, 11.0, 6.0, 6.0, 10.0, 4.0, 11.0, 8.0, 7.0, 2.0, 9.0, 4.0, 8.0, 7.0, 8.0, 7.0, 10.0, 5.0, 3.0, 7.0, 6.0, 12.0, 6.0, 7.0, 8.0, 3.0, 10.0, 13.0, 5.0, 8.0, 1.0, 3.0, 6.0, 12.0, 9.0, 7.0, 10.0, 11.0, 6.0, 10.0, 4.0, 8.0, 7.0, 18.0, 10.0, 15.0, 7.0, 17.0, 12.0, 12.0, 5.0, 2.0, 6.0, 9.0, 14.0, 12.0, 8.0, 4.0, 8.0, 10.0, 10.0, 8.0, 12.0, 7.0, 13.0], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500], "policy_shared_policy_reward": [4.0, 3.0, 3.0, 3.0, 3.0, 3.0, 4.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 3.0, 1.0, 2.0, 0.0, 3.0, 2.0, 3.0, 1.0, 1.0, 2.0, 3.0, 2.0, 2.0, 4.0, 3.0, 3.0, 2.0, 1.0, 1.0, 3.0, 0.0, 1.0, 0.0, 2.0, 3.0, 4.0, 3.0, 5.0, 2.0, 2.0, 2.0, 2.0, 3.0, 3.0, 1.0, 3.0, 1.0, 1.0, 0.0, 1.0, 2.0, 2.0, 1.0, 2.0, 5.0, 2.0, 5.0, 5.0, 2.0, 3.0, 3.0, 4.0, 3.0, 2.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 3.0, 1.0, 4.0, 1.0, 1.0, 0.0, 3.0, 4.0, 0.0, 2.0, 1.0, 0.0, 1.0, 1.0, 2.0, 1.0, 1.0, 2.0, 2.0, 3.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 3.0, 1.0, 2.0, 2.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 2.0, 1.0, 2.0, 2.0, 2.0, 1.0, 2.0, 1.0, 2.0, 2.0, 0.0, 3.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 4.0, 3.0, 2.0, 2.0, 2.0, 4.0, 2.0, 3.0, 1.0, 1.0, 3.0, 1.0, 2.0, 1.0, 1.0, 2.0, 2.0, 1.0, 4.0, 3.0, 1.0, 2.0, 1.0, 0.0, 3.0, 4.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 3.0, 2.0, 2.0, 0.0, 1.0, 0.0, 1.0, 0.0, 4.0, 1.0, 1.0, 3.0, 1.0, 0.0, 2.0, 1.0, 1.0, 2.0, 2.0, 3.0, 1.0, 2.0, 2.0, 2.0, 2.0, 3.0, 2.0, 1.0, 1.0, 1.0, 3.0, 2.0, 3.0, 4.0, 2.0, 1.0, 1.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0, 0.0, 2.0, 2.0, 2.0, 1.0, 2.0, 1.0, 2.0, 1.0, 3.0, 3.0, 2.0, 4.0, 1.0, 1.0, 3.0, 1.0, 3.0, 1.0, 2.0, 1.0, 1.0, 2.0, 4.0, 1.0, 1.0, 1.0, 1.0, 0.0, 3.0, 1.0, 4.0, 2.0, 2.0, 4.0, 3.0, 4.0, 1.0, 1.0, 2.0, 1.0, 2.0, 1.0, 3.0, 2.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 2.0, 1.0, 1.0, 2.0, 3.0, 3.0, 3.0, 3.0, 1.0, 4.0, 2.0, 2.0, 2.0, 1.0, 1.0, 3.0, 4.0, 3.0, 2.0, 1.0, 3.0, 3.0, 3.0, 2.0, 1.0, 1.0, 2.0, 2.0, 4.0, 1.0, 3.0, 2.0, 1.0, 1.0, 2.0, 0.0, 2.0, 3.0, 1.0, 2.0, 3.0, 1.0, 2.0, 1.0, 4.0, 6.0, 5.0, 3.0, 3.0, 2.0, 2.0, 3.0, 4.0, 5.0, 3.0, 3.0, 1.0, 2.0, 1.0, 3.0, 5.0, 3.0, 4.0, 5.0, 2.0, 3.0, 2.0, 5.0, 3.0, 2.0, 5.0, 2.0, 1.0, 2.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 3.0, 2.0, 0.0, 1.0, 2.0, 3.0, 2.0, 2.0, 3.0, 4.0, 5.0, 2.0, 2.0, 4.0, 2.0, 4.0, 2.0, 2.0, 2.0, 2.0, 1.0, 1.0, 1.0, 1.0, 1.0, 2.0, 3.0, 2.0, 3.0, 1.0, 2.0, 4.0, 3.0, 0.0, 3.0, 4.0, 3.0, 3.0, 2.0, 0.0, 3.0, 4.0, 3.0, 2.0, 1.0, 2.0, 2.0, 2.0, 3.0, 4.0, 4.0, 2.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.133802881665142, "mean_inference_ms": 0.39089805057221455, "mean_action_processing_ms": 0.029195596744033638, "mean_env_wait_ms": 0.4040426748209146, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 1209600, "timesteps_this_iter": 0, "agent_timesteps_total": 4838400, "timers": {"sample_time_ms": 5228.975, "sample_throughput": 963.86, "load_time_ms": 0.184, "load_throughput": 27400249.073, "learn_time_ms": 130.752, "learn_throughput": 38546.371, "update_time_ms": 2.657}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 145.32290649414062, "policy_entropy": 7716.151123046875, "policy_loss": 20.17764499783516, "vf_loss": 59.928486824035645}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 1209600, "num_agent_steps_sampled": 4838400, "num_steps_trained": 1209600, "num_agent_steps_trained": 4838400, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 2416, "training_iteration": 120, "trial_id": "71426_00000", "experiment_id": "84bca2f7b35f43248fca18d21abe2ebf", "date": "2024-06-12_03-06-31", "timestamp": 1718129191, "time_this_iter_s": 10.262292861938477, "time_total_s": 1238.6051831245422, "pid": 363902, "hostname": "DESKTOP-LQ219J4", "node_ip": "192.168.46.185", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 20, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 5000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 500, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Base_Model", "custom_model_config": {"env": "rware", "env_args": {"n_agents": 4, "column_height": 1, "max_inactivity_steps": null, "max_steps": 500, "fast_obs": true, "msg_bits": 0, "sensor_range": 1, "shelf_rows": 1, "shelf_columns": 3, "request_queue_size": 4, "reward_type": "RewardType.INDIVIDUAL", "map_name": "customized_map", "map_size": "tiny", "difficulty": "medium"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": true, "force_coop": false, "local_mode": true, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 4, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 100, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64}, "algorithm": "ia2c", "space_obs": "Dict(obs:Box([-100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100.], [100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.], (112,), float32))", "space_act": "Discrete(5)", "num_agents": 4, "episode_limit": 500, "policy_mapping_info": {"all_scenario": {"description": "rware all scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2", "agent_3"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "rware_customized_map", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 10, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.IA2CTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_il.<locals>.<lambda> at 0x7f380824d4c0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "grad_clip": 40.0, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "microbatch_size": null}, "time_since_restore": 1238.6051831245422, "timesteps_since_restore": 0, "iterations_since_restore": 120, "perf": {"cpu_util_percent": 4.214285714285714, "ram_util_percent": 66.10000000000001}}
{"episode_reward_max": 18.0, "episode_reward_min": 1.0, "episode_reward_mean": 7.85, "episode_len_mean": 500.0, "episode_media": {}, "episodes_this_iter": 20, "policy_reward_min": {"shared_policy": 0.0}, "policy_reward_max": {"shared_policy": 6.0}, "policy_reward_mean": {"shared_policy": 1.9625}, "custom_metrics": {}, "hist_stats": {"episode_reward": [9.0, 8.0, 3.0, 5.0, 8.0, 4.0, 6.0, 5.0, 2.0, 7.0, 6.0, 7.0, 3.0, 3.0, 4.0, 11.0, 11.0, 6.0, 6.0, 10.0, 4.0, 11.0, 8.0, 7.0, 2.0, 9.0, 4.0, 8.0, 7.0, 8.0, 7.0, 10.0, 5.0, 3.0, 7.0, 6.0, 12.0, 6.0, 7.0, 8.0, 3.0, 10.0, 13.0, 5.0, 8.0, 1.0, 3.0, 6.0, 12.0, 9.0, 7.0, 10.0, 11.0, 6.0, 10.0, 4.0, 8.0, 7.0, 18.0, 10.0, 15.0, 7.0, 17.0, 12.0, 12.0, 5.0, 2.0, 6.0, 9.0, 14.0, 12.0, 8.0, 4.0, 8.0, 10.0, 10.0, 8.0, 12.0, 7.0, 13.0, 8.0, 13.0, 13.0, 3.0, 7.0, 10.0, 12.0, 6.0, 3.0, 9.0, 8.0, 9.0, 8.0, 12.0, 8.0, 6.0, 8.0, 4.0, 14.0, 9.0], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500], "policy_shared_policy_reward": [3.0, 1.0, 4.0, 1.0, 1.0, 0.0, 3.0, 4.0, 0.0, 2.0, 1.0, 0.0, 1.0, 1.0, 2.0, 1.0, 1.0, 2.0, 2.0, 3.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 3.0, 1.0, 2.0, 2.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 2.0, 1.0, 2.0, 2.0, 2.0, 1.0, 2.0, 1.0, 2.0, 2.0, 0.0, 3.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 4.0, 3.0, 2.0, 2.0, 2.0, 4.0, 2.0, 3.0, 1.0, 1.0, 3.0, 1.0, 2.0, 1.0, 1.0, 2.0, 2.0, 1.0, 4.0, 3.0, 1.0, 2.0, 1.0, 0.0, 3.0, 4.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 3.0, 2.0, 2.0, 0.0, 1.0, 0.0, 1.0, 0.0, 4.0, 1.0, 1.0, 3.0, 1.0, 0.0, 2.0, 1.0, 1.0, 2.0, 2.0, 3.0, 1.0, 2.0, 2.0, 2.0, 2.0, 3.0, 2.0, 1.0, 1.0, 1.0, 3.0, 2.0, 3.0, 4.0, 2.0, 1.0, 1.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0, 0.0, 2.0, 2.0, 2.0, 1.0, 2.0, 1.0, 2.0, 1.0, 3.0, 3.0, 2.0, 4.0, 1.0, 1.0, 3.0, 1.0, 3.0, 1.0, 2.0, 1.0, 1.0, 2.0, 4.0, 1.0, 1.0, 1.0, 1.0, 0.0, 3.0, 1.0, 4.0, 2.0, 2.0, 4.0, 3.0, 4.0, 1.0, 1.0, 2.0, 1.0, 2.0, 1.0, 3.0, 2.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 2.0, 1.0, 1.0, 2.0, 3.0, 3.0, 3.0, 3.0, 1.0, 4.0, 2.0, 2.0, 2.0, 1.0, 1.0, 3.0, 4.0, 3.0, 2.0, 1.0, 3.0, 3.0, 3.0, 2.0, 1.0, 1.0, 2.0, 2.0, 4.0, 1.0, 3.0, 2.0, 1.0, 1.0, 2.0, 0.0, 2.0, 3.0, 1.0, 2.0, 3.0, 1.0, 2.0, 1.0, 4.0, 6.0, 5.0, 3.0, 3.0, 2.0, 2.0, 3.0, 4.0, 5.0, 3.0, 3.0, 1.0, 2.0, 1.0, 3.0, 5.0, 3.0, 4.0, 5.0, 2.0, 3.0, 2.0, 5.0, 3.0, 2.0, 5.0, 2.0, 1.0, 2.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 3.0, 2.0, 0.0, 1.0, 2.0, 3.0, 2.0, 2.0, 3.0, 4.0, 5.0, 2.0, 2.0, 4.0, 2.0, 4.0, 2.0, 2.0, 2.0, 2.0, 1.0, 1.0, 1.0, 1.0, 1.0, 2.0, 3.0, 2.0, 3.0, 1.0, 2.0, 4.0, 3.0, 0.0, 3.0, 4.0, 3.0, 3.0, 2.0, 0.0, 3.0, 4.0, 3.0, 2.0, 1.0, 2.0, 2.0, 2.0, 3.0, 4.0, 4.0, 2.0, 2.0, 2.0, 3.0, 1.0, 4.0, 2.0, 2.0, 5.0, 3.0, 4.0, 4.0, 2.0, 1.0, 1.0, 0.0, 1.0, 2.0, 2.0, 2.0, 1.0, 2.0, 1.0, 3.0, 4.0, 3.0, 3.0, 3.0, 3.0, 2.0, 0.0, 2.0, 2.0, 2.0, 1.0, 0.0, 0.0, 4.0, 1.0, 2.0, 2.0, 2.0, 3.0, 2.0, 1.0, 4.0, 0.0, 3.0, 2.0, 2.0, 2.0, 3.0, 1.0, 3.0, 4.0, 4.0, 1.0, 2.0, 2.0, 3.0, 1.0, 2.0, 1.0, 2.0, 1.0, 2.0, 1.0, 3.0, 2.0, 1.0, 1.0, 1.0, 1.0, 5.0, 2.0, 3.0, 4.0, 3.0, 1.0, 2.0, 3.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.133822852308007, "mean_inference_ms": 0.3909553310981551, "mean_action_processing_ms": 0.029198512290490322, "mean_env_wait_ms": 0.40410119063824795, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 1219680, "timesteps_this_iter": 0, "agent_timesteps_total": 4878720, "timers": {"sample_time_ms": 5222.974, "sample_throughput": 964.967, "load_time_ms": 0.182, "load_throughput": 27643902.393, "learn_time_ms": 130.27, "learn_throughput": 38688.812, "update_time_ms": 2.689}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 464.531982421875, "policy_entropy": 7773.9185791015625, "policy_loss": 19.965610444545746, "vf_loss": 68.55066871643066}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 1219680, "num_agent_steps_sampled": 4878720, "num_steps_trained": 1219680, "num_agent_steps_trained": 4878720, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 2436, "training_iteration": 121, "trial_id": "71426_00000", "experiment_id": "84bca2f7b35f43248fca18d21abe2ebf", "date": "2024-06-12_03-06-41", "timestamp": 1718129201, "time_this_iter_s": 10.158312320709229, "time_total_s": 1248.7634954452515, "pid": 363902, "hostname": "DESKTOP-LQ219J4", "node_ip": "192.168.46.185", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 20, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 5000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 500, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Base_Model", "custom_model_config": {"env": "rware", "env_args": {"n_agents": 4, "column_height": 1, "max_inactivity_steps": null, "max_steps": 500, "fast_obs": true, "msg_bits": 0, "sensor_range": 1, "shelf_rows": 1, "shelf_columns": 3, "request_queue_size": 4, "reward_type": "RewardType.INDIVIDUAL", "map_name": "customized_map", "map_size": "tiny", "difficulty": "medium"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": true, "force_coop": false, "local_mode": true, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 4, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 100, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64}, "algorithm": "ia2c", "space_obs": "Dict(obs:Box([-100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100.], [100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.], (112,), float32))", "space_act": "Discrete(5)", "num_agents": 4, "episode_limit": 500, "policy_mapping_info": {"all_scenario": {"description": "rware all scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2", "agent_3"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "rware_customized_map", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 10, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.IA2CTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_il.<locals>.<lambda> at 0x7f3808651940>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "grad_clip": 40.0, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "microbatch_size": null}, "time_since_restore": 1248.7634954452515, "timesteps_since_restore": 0, "iterations_since_restore": 121, "perf": {"cpu_util_percent": 4.16, "ram_util_percent": 66.37999999999998}}
{"episode_reward_max": 19.0, "episode_reward_min": 1.0, "episode_reward_mean": 8.41, "episode_len_mean": 500.0, "episode_media": {}, "episodes_this_iter": 20, "policy_reward_min": {"shared_policy": 0.0}, "policy_reward_max": {"shared_policy": 7.0}, "policy_reward_mean": {"shared_policy": 2.1025}, "custom_metrics": {}, "hist_stats": {"episode_reward": [4.0, 11.0, 8.0, 7.0, 2.0, 9.0, 4.0, 8.0, 7.0, 8.0, 7.0, 10.0, 5.0, 3.0, 7.0, 6.0, 12.0, 6.0, 7.0, 8.0, 3.0, 10.0, 13.0, 5.0, 8.0, 1.0, 3.0, 6.0, 12.0, 9.0, 7.0, 10.0, 11.0, 6.0, 10.0, 4.0, 8.0, 7.0, 18.0, 10.0, 15.0, 7.0, 17.0, 12.0, 12.0, 5.0, 2.0, 6.0, 9.0, 14.0, 12.0, 8.0, 4.0, 8.0, 10.0, 10.0, 8.0, 12.0, 7.0, 13.0, 8.0, 13.0, 13.0, 3.0, 7.0, 10.0, 12.0, 6.0, 3.0, 9.0, 8.0, 9.0, 8.0, 12.0, 8.0, 6.0, 8.0, 4.0, 14.0, 9.0, 7.0, 13.0, 14.0, 9.0, 10.0, 12.0, 5.0, 4.0, 15.0, 9.0, 8.0, 4.0, 9.0, 5.0, 8.0, 19.0, 11.0, 8.0, 7.0, 3.0], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500], "policy_shared_policy_reward": [1.0, 2.0, 1.0, 0.0, 3.0, 4.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 3.0, 2.0, 2.0, 0.0, 1.0, 0.0, 1.0, 0.0, 4.0, 1.0, 1.0, 3.0, 1.0, 0.0, 2.0, 1.0, 1.0, 2.0, 2.0, 3.0, 1.0, 2.0, 2.0, 2.0, 2.0, 3.0, 2.0, 1.0, 1.0, 1.0, 3.0, 2.0, 3.0, 4.0, 2.0, 1.0, 1.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0, 0.0, 2.0, 2.0, 2.0, 1.0, 2.0, 1.0, 2.0, 1.0, 3.0, 3.0, 2.0, 4.0, 1.0, 1.0, 3.0, 1.0, 3.0, 1.0, 2.0, 1.0, 1.0, 2.0, 4.0, 1.0, 1.0, 1.0, 1.0, 0.0, 3.0, 1.0, 4.0, 2.0, 2.0, 4.0, 3.0, 4.0, 1.0, 1.0, 2.0, 1.0, 2.0, 1.0, 3.0, 2.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 2.0, 1.0, 1.0, 2.0, 3.0, 3.0, 3.0, 3.0, 1.0, 4.0, 2.0, 2.0, 2.0, 1.0, 1.0, 3.0, 4.0, 3.0, 2.0, 1.0, 3.0, 3.0, 3.0, 2.0, 1.0, 1.0, 2.0, 2.0, 4.0, 1.0, 3.0, 2.0, 1.0, 1.0, 2.0, 0.0, 2.0, 3.0, 1.0, 2.0, 3.0, 1.0, 2.0, 1.0, 4.0, 6.0, 5.0, 3.0, 3.0, 2.0, 2.0, 3.0, 4.0, 5.0, 3.0, 3.0, 1.0, 2.0, 1.0, 3.0, 5.0, 3.0, 4.0, 5.0, 2.0, 3.0, 2.0, 5.0, 3.0, 2.0, 5.0, 2.0, 1.0, 2.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 3.0, 2.0, 0.0, 1.0, 2.0, 3.0, 2.0, 2.0, 3.0, 4.0, 5.0, 2.0, 2.0, 4.0, 2.0, 4.0, 2.0, 2.0, 2.0, 2.0, 1.0, 1.0, 1.0, 1.0, 1.0, 2.0, 3.0, 2.0, 3.0, 1.0, 2.0, 4.0, 3.0, 0.0, 3.0, 4.0, 3.0, 3.0, 2.0, 0.0, 3.0, 4.0, 3.0, 2.0, 1.0, 2.0, 2.0, 2.0, 3.0, 4.0, 4.0, 2.0, 2.0, 2.0, 3.0, 1.0, 4.0, 2.0, 2.0, 5.0, 3.0, 4.0, 4.0, 2.0, 1.0, 1.0, 0.0, 1.0, 2.0, 2.0, 2.0, 1.0, 2.0, 1.0, 3.0, 4.0, 3.0, 3.0, 3.0, 3.0, 2.0, 0.0, 2.0, 2.0, 2.0, 1.0, 0.0, 0.0, 4.0, 1.0, 2.0, 2.0, 2.0, 3.0, 2.0, 1.0, 4.0, 0.0, 3.0, 2.0, 2.0, 2.0, 3.0, 1.0, 3.0, 4.0, 4.0, 1.0, 2.0, 2.0, 3.0, 1.0, 2.0, 1.0, 2.0, 1.0, 2.0, 1.0, 3.0, 2.0, 1.0, 1.0, 1.0, 1.0, 5.0, 2.0, 3.0, 4.0, 3.0, 1.0, 2.0, 3.0, 2.0, 3.0, 2.0, 0.0, 2.0, 3.0, 4.0, 4.0, 5.0, 2.0, 4.0, 3.0, 3.0, 1.0, 3.0, 2.0, 6.0, 1.0, 1.0, 2.0, 4.0, 2.0, 4.0, 2.0, 2.0, 1.0, 0.0, 2.0, 0.0, 1.0, 1.0, 2.0, 3.0, 5.0, 3.0, 4.0, 2.0, 2.0, 3.0, 2.0, 2.0, 1.0, 2.0, 3.0, 2.0, 1.0, 0.0, 1.0, 2.0, 2.0, 4.0, 1.0, 2.0, 1.0, 1.0, 1.0, 2.0, 3.0, 1.0, 2.0, 5.0, 4.0, 3.0, 7.0, 4.0, 5.0, 1.0, 1.0, 3.0, 2.0, 2.0, 1.0, 3.0, 3.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.13383851853903572, "mean_inference_ms": 0.3909985923571263, "mean_action_processing_ms": 0.029200956327180894, "mean_env_wait_ms": 0.4041405712040498, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 1229760, "timesteps_this_iter": 0, "agent_timesteps_total": 4919040, "timers": {"sample_time_ms": 5200.251, "sample_throughput": 969.184, "load_time_ms": 0.179, "load_throughput": 28118239.106, "learn_time_ms": 130.485, "learn_throughput": 38625.19, "update_time_ms": 2.71}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 308.18304443359375, "policy_entropy": 7773.8209228515625, "policy_loss": -6.423791885375977, "vf_loss": 59.52633190155029}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 1229760, "num_agent_steps_sampled": 4919040, "num_steps_trained": 1229760, "num_agent_steps_trained": 4919040, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 2456, "training_iteration": 122, "trial_id": "71426_00000", "experiment_id": "84bca2f7b35f43248fca18d21abe2ebf", "date": "2024-06-12_03-06-51", "timestamp": 1718129211, "time_this_iter_s": 10.100950241088867, "time_total_s": 1258.8644456863403, "pid": 363902, "hostname": "DESKTOP-LQ219J4", "node_ip": "192.168.46.185", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 20, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 5000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 500, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Base_Model", "custom_model_config": {"env": "rware", "env_args": {"n_agents": 4, "column_height": 1, "max_inactivity_steps": null, "max_steps": 500, "fast_obs": true, "msg_bits": 0, "sensor_range": 1, "shelf_rows": 1, "shelf_columns": 3, "request_queue_size": 4, "reward_type": "RewardType.INDIVIDUAL", "map_name": "customized_map", "map_size": "tiny", "difficulty": "medium"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": true, "force_coop": false, "local_mode": true, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 4, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 100, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64}, "algorithm": "ia2c", "space_obs": "Dict(obs:Box([-100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100.], [100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.], (112,), float32))", "space_act": "Discrete(5)", "num_agents": 4, "episode_limit": 500, "policy_mapping_info": {"all_scenario": {"description": "rware all scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2", "agent_3"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "rware_customized_map", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 10, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.IA2CTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_il.<locals>.<lambda> at 0x7f382806e940>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "grad_clip": 40.0, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "microbatch_size": null}, "time_since_restore": 1258.8644456863403, "timesteps_since_restore": 0, "iterations_since_restore": 122, "perf": {"cpu_util_percent": 4.314285714285714, "ram_util_percent": 66.65000000000002}}
{"episode_reward_max": 20.0, "episode_reward_min": 1.0, "episode_reward_mean": 8.87, "episode_len_mean": 500.0, "episode_media": {}, "episodes_this_iter": 20, "policy_reward_min": {"shared_policy": 0.0}, "policy_reward_max": {"shared_policy": 7.0}, "policy_reward_mean": {"shared_policy": 2.2175}, "custom_metrics": {}, "hist_stats": {"episode_reward": [3.0, 10.0, 13.0, 5.0, 8.0, 1.0, 3.0, 6.0, 12.0, 9.0, 7.0, 10.0, 11.0, 6.0, 10.0, 4.0, 8.0, 7.0, 18.0, 10.0, 15.0, 7.0, 17.0, 12.0, 12.0, 5.0, 2.0, 6.0, 9.0, 14.0, 12.0, 8.0, 4.0, 8.0, 10.0, 10.0, 8.0, 12.0, 7.0, 13.0, 8.0, 13.0, 13.0, 3.0, 7.0, 10.0, 12.0, 6.0, 3.0, 9.0, 8.0, 9.0, 8.0, 12.0, 8.0, 6.0, 8.0, 4.0, 14.0, 9.0, 7.0, 13.0, 14.0, 9.0, 10.0, 12.0, 5.0, 4.0, 15.0, 9.0, 8.0, 4.0, 9.0, 5.0, 8.0, 19.0, 11.0, 8.0, 7.0, 3.0, 2.0, 3.0, 17.0, 7.0, 11.0, 13.0, 14.0, 7.0, 8.0, 12.0, 12.0, 6.0, 20.0, 8.0, 4.0, 13.0, 4.0, 7.0, 14.0, 3.0], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500], "policy_shared_policy_reward": [1.0, 1.0, 1.0, 0.0, 3.0, 1.0, 4.0, 2.0, 2.0, 4.0, 3.0, 4.0, 1.0, 1.0, 2.0, 1.0, 2.0, 1.0, 3.0, 2.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 2.0, 1.0, 1.0, 2.0, 3.0, 3.0, 3.0, 3.0, 1.0, 4.0, 2.0, 2.0, 2.0, 1.0, 1.0, 3.0, 4.0, 3.0, 2.0, 1.0, 3.0, 3.0, 3.0, 2.0, 1.0, 1.0, 2.0, 2.0, 4.0, 1.0, 3.0, 2.0, 1.0, 1.0, 2.0, 0.0, 2.0, 3.0, 1.0, 2.0, 3.0, 1.0, 2.0, 1.0, 4.0, 6.0, 5.0, 3.0, 3.0, 2.0, 2.0, 3.0, 4.0, 5.0, 3.0, 3.0, 1.0, 2.0, 1.0, 3.0, 5.0, 3.0, 4.0, 5.0, 2.0, 3.0, 2.0, 5.0, 3.0, 2.0, 5.0, 2.0, 1.0, 2.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 3.0, 2.0, 0.0, 1.0, 2.0, 3.0, 2.0, 2.0, 3.0, 4.0, 5.0, 2.0, 2.0, 4.0, 2.0, 4.0, 2.0, 2.0, 2.0, 2.0, 1.0, 1.0, 1.0, 1.0, 1.0, 2.0, 3.0, 2.0, 3.0, 1.0, 2.0, 4.0, 3.0, 0.0, 3.0, 4.0, 3.0, 3.0, 2.0, 0.0, 3.0, 4.0, 3.0, 2.0, 1.0, 2.0, 2.0, 2.0, 3.0, 4.0, 4.0, 2.0, 2.0, 2.0, 3.0, 1.0, 4.0, 2.0, 2.0, 5.0, 3.0, 4.0, 4.0, 2.0, 1.0, 1.0, 0.0, 1.0, 2.0, 2.0, 2.0, 1.0, 2.0, 1.0, 3.0, 4.0, 3.0, 3.0, 3.0, 3.0, 2.0, 0.0, 2.0, 2.0, 2.0, 1.0, 0.0, 0.0, 4.0, 1.0, 2.0, 2.0, 2.0, 3.0, 2.0, 1.0, 4.0, 0.0, 3.0, 2.0, 2.0, 2.0, 3.0, 1.0, 3.0, 4.0, 4.0, 1.0, 2.0, 2.0, 3.0, 1.0, 2.0, 1.0, 2.0, 1.0, 2.0, 1.0, 3.0, 2.0, 1.0, 1.0, 1.0, 1.0, 5.0, 2.0, 3.0, 4.0, 3.0, 1.0, 2.0, 3.0, 2.0, 3.0, 2.0, 0.0, 2.0, 3.0, 4.0, 4.0, 5.0, 2.0, 4.0, 3.0, 3.0, 1.0, 3.0, 2.0, 6.0, 1.0, 1.0, 2.0, 4.0, 2.0, 4.0, 2.0, 2.0, 1.0, 0.0, 2.0, 0.0, 1.0, 1.0, 2.0, 3.0, 5.0, 3.0, 4.0, 2.0, 2.0, 3.0, 2.0, 2.0, 1.0, 2.0, 3.0, 2.0, 1.0, 0.0, 1.0, 2.0, 2.0, 4.0, 1.0, 2.0, 1.0, 1.0, 1.0, 2.0, 3.0, 1.0, 2.0, 5.0, 4.0, 3.0, 7.0, 4.0, 5.0, 1.0, 1.0, 3.0, 2.0, 2.0, 1.0, 3.0, 3.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 7.0, 3.0, 3.0, 4.0, 1.0, 2.0, 1.0, 3.0, 2.0, 4.0, 1.0, 4.0, 5.0, 3.0, 3.0, 2.0, 5.0, 2.0, 4.0, 3.0, 1.0, 2.0, 2.0, 2.0, 4.0, 1.0, 1.0, 2.0, 2.0, 3.0, 3.0, 4.0, 1.0, 4.0, 4.0, 3.0, 1.0, 2.0, 2.0, 1.0, 6.0, 7.0, 2.0, 5.0, 2.0, 3.0, 2.0, 1.0, 1.0, 1.0, 1.0, 1.0, 3.0, 3.0, 3.0, 4.0, 0.0, 1.0, 1.0, 2.0, 0.0, 3.0, 2.0, 2.0, 3.0, 4.0, 4.0, 3.0, 0.0, 2.0, 0.0, 1.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.13384226096857968, "mean_inference_ms": 0.3910136509753802, "mean_action_processing_ms": 0.02920172994090009, "mean_env_wait_ms": 0.4041479005890993, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 1239840, "timesteps_this_iter": 0, "agent_timesteps_total": 4959360, "timers": {"sample_time_ms": 5151.875, "sample_throughput": 978.285, "load_time_ms": 0.158, "load_throughput": 31937289.863, "learn_time_ms": 127.844, "learn_throughput": 39422.981, "update_time_ms": 2.548}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 317.56719970703125, "policy_entropy": 7742.19140625, "policy_loss": 20.735263347625732, "vf_loss": 74.34799671173096}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 1239840, "num_agent_steps_sampled": 4959360, "num_steps_trained": 1239840, "num_agent_steps_trained": 4959360, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 2476, "training_iteration": 123, "trial_id": "71426_00000", "experiment_id": "84bca2f7b35f43248fca18d21abe2ebf", "date": "2024-06-12_03-07-02", "timestamp": 1718129222, "time_this_iter_s": 10.134921312332153, "time_total_s": 1268.9993669986725, "pid": 363902, "hostname": "DESKTOP-LQ219J4", "node_ip": "192.168.46.185", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 20, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 5000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 500, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Base_Model", "custom_model_config": {"env": "rware", "env_args": {"n_agents": 4, "column_height": 1, "max_inactivity_steps": null, "max_steps": 500, "fast_obs": true, "msg_bits": 0, "sensor_range": 1, "shelf_rows": 1, "shelf_columns": 3, "request_queue_size": 4, "reward_type": "RewardType.INDIVIDUAL", "map_name": "customized_map", "map_size": "tiny", "difficulty": "medium"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": true, "force_coop": false, "local_mode": true, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 4, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 100, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64}, "algorithm": "ia2c", "space_obs": "Dict(obs:Box([-100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100.], [100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.], (112,), float32))", "space_act": "Discrete(5)", "num_agents": 4, "episode_limit": 500, "policy_mapping_info": {"all_scenario": {"description": "rware all scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2", "agent_3"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "rware_customized_map", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 10, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.IA2CTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_il.<locals>.<lambda> at 0x7f3808102ee0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "grad_clip": 40.0, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "microbatch_size": null}, "time_since_restore": 1268.9993669986725, "timesteps_since_restore": 0, "iterations_since_restore": 123, "perf": {"cpu_util_percent": 4.1466666666666665, "ram_util_percent": 66.89999999999999}}
{"episode_reward_max": 20.0, "episode_reward_min": 1.0, "episode_reward_mean": 9.32, "episode_len_mean": 500.0, "episode_media": {}, "episodes_this_iter": 20, "policy_reward_min": {"shared_policy": 0.0}, "policy_reward_max": {"shared_policy": 7.0}, "policy_reward_mean": {"shared_policy": 2.33}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 7.0, 17.0, 12.0, 12.0, 5.0, 2.0, 6.0, 9.0, 14.0, 12.0, 8.0, 4.0, 8.0, 10.0, 10.0, 8.0, 12.0, 7.0, 13.0, 8.0, 13.0, 13.0, 3.0, 7.0, 10.0, 12.0, 6.0, 3.0, 9.0, 8.0, 9.0, 8.0, 12.0, 8.0, 6.0, 8.0, 4.0, 14.0, 9.0, 7.0, 13.0, 14.0, 9.0, 10.0, 12.0, 5.0, 4.0, 15.0, 9.0, 8.0, 4.0, 9.0, 5.0, 8.0, 19.0, 11.0, 8.0, 7.0, 3.0, 2.0, 3.0, 17.0, 7.0, 11.0, 13.0, 14.0, 7.0, 8.0, 12.0, 12.0, 6.0, 20.0, 8.0, 4.0, 13.0, 4.0, 7.0, 14.0, 3.0, 14.0, 15.0, 16.0, 16.0, 12.0, 7.0, 5.0, 10.0, 13.0, 13.0, 11.0, 7.0, 7.0, 5.0, 11.0, 8.0, 13.0, 1.0, 13.0, 9.0], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500], "policy_shared_policy_reward": [4.0, 5.0, 3.0, 3.0, 1.0, 2.0, 1.0, 3.0, 5.0, 3.0, 4.0, 5.0, 2.0, 3.0, 2.0, 5.0, 3.0, 2.0, 5.0, 2.0, 1.0, 2.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 3.0, 2.0, 0.0, 1.0, 2.0, 3.0, 2.0, 2.0, 3.0, 4.0, 5.0, 2.0, 2.0, 4.0, 2.0, 4.0, 2.0, 2.0, 2.0, 2.0, 1.0, 1.0, 1.0, 1.0, 1.0, 2.0, 3.0, 2.0, 3.0, 1.0, 2.0, 4.0, 3.0, 0.0, 3.0, 4.0, 3.0, 3.0, 2.0, 0.0, 3.0, 4.0, 3.0, 2.0, 1.0, 2.0, 2.0, 2.0, 3.0, 4.0, 4.0, 2.0, 2.0, 2.0, 3.0, 1.0, 4.0, 2.0, 2.0, 5.0, 3.0, 4.0, 4.0, 2.0, 1.0, 1.0, 0.0, 1.0, 2.0, 2.0, 2.0, 1.0, 2.0, 1.0, 3.0, 4.0, 3.0, 3.0, 3.0, 3.0, 2.0, 0.0, 2.0, 2.0, 2.0, 1.0, 0.0, 0.0, 4.0, 1.0, 2.0, 2.0, 2.0, 3.0, 2.0, 1.0, 4.0, 0.0, 3.0, 2.0, 2.0, 2.0, 3.0, 1.0, 3.0, 4.0, 4.0, 1.0, 2.0, 2.0, 3.0, 1.0, 2.0, 1.0, 2.0, 1.0, 2.0, 1.0, 3.0, 2.0, 1.0, 1.0, 1.0, 1.0, 5.0, 2.0, 3.0, 4.0, 3.0, 1.0, 2.0, 3.0, 2.0, 3.0, 2.0, 0.0, 2.0, 3.0, 4.0, 4.0, 5.0, 2.0, 4.0, 3.0, 3.0, 1.0, 3.0, 2.0, 6.0, 1.0, 1.0, 2.0, 4.0, 2.0, 4.0, 2.0, 2.0, 1.0, 0.0, 2.0, 0.0, 1.0, 1.0, 2.0, 3.0, 5.0, 3.0, 4.0, 2.0, 2.0, 3.0, 2.0, 2.0, 1.0, 2.0, 3.0, 2.0, 1.0, 0.0, 1.0, 2.0, 2.0, 4.0, 1.0, 2.0, 1.0, 1.0, 1.0, 2.0, 3.0, 1.0, 2.0, 5.0, 4.0, 3.0, 7.0, 4.0, 5.0, 1.0, 1.0, 3.0, 2.0, 2.0, 1.0, 3.0, 3.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 7.0, 3.0, 3.0, 4.0, 1.0, 2.0, 1.0, 3.0, 2.0, 4.0, 1.0, 4.0, 5.0, 3.0, 3.0, 2.0, 5.0, 2.0, 4.0, 3.0, 1.0, 2.0, 2.0, 2.0, 4.0, 1.0, 1.0, 2.0, 2.0, 3.0, 3.0, 4.0, 1.0, 4.0, 4.0, 3.0, 1.0, 2.0, 2.0, 1.0, 6.0, 7.0, 2.0, 5.0, 2.0, 3.0, 2.0, 1.0, 1.0, 1.0, 1.0, 1.0, 3.0, 3.0, 3.0, 4.0, 0.0, 1.0, 1.0, 2.0, 0.0, 3.0, 2.0, 2.0, 3.0, 4.0, 4.0, 3.0, 0.0, 2.0, 0.0, 1.0, 3.0, 3.0, 5.0, 3.0, 6.0, 2.0, 4.0, 3.0, 5.0, 4.0, 2.0, 5.0, 5.0, 3.0, 2.0, 6.0, 3.0, 4.0, 1.0, 4.0, 1.0, 3.0, 1.0, 2.0, 2.0, 1.0, 2.0, 0.0, 2.0, 2.0, 3.0, 3.0, 2.0, 4.0, 3.0, 4.0, 3.0, 4.0, 1.0, 5.0, 4.0, 3.0, 2.0, 2.0, 1.0, 4.0, 1.0, 1.0, 1.0, 3.0, 0.0, 3.0, 1.0, 1.0, 2.0, 1.0, 1.0, 4.0, 3.0, 3.0, 3.0, 0.0, 2.0, 3.0, 5.0, 3.0, 1.0, 4.0, 0.0, 0.0, 1.0, 0.0, 2.0, 5.0, 4.0, 2.0, 2.0, 4.0, 2.0, 1.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.1338305940411473, "mean_inference_ms": 0.39098341242247436, "mean_action_processing_ms": 0.029199841026747872, "mean_env_wait_ms": 0.40411242673223297, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 1249920, "timesteps_this_iter": 0, "agent_timesteps_total": 4999680, "timers": {"sample_time_ms": 5084.103, "sample_throughput": 991.325, "load_time_ms": 0.153, "load_throughput": 32978614.914, "learn_time_ms": 127.38, "learn_throughput": 39566.632, "update_time_ms": 2.54}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 452.7718505859375, "policy_entropy": 7704.9326171875, "policy_loss": 66.53878021240234, "vf_loss": 79.58462715148926}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 1249920, "num_agent_steps_sampled": 4999680, "num_steps_trained": 1249920, "num_agent_steps_trained": 4999680, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 2496, "training_iteration": 124, "trial_id": "71426_00000", "experiment_id": "84bca2f7b35f43248fca18d21abe2ebf", "date": "2024-06-12_03-07-12", "timestamp": 1718129232, "time_this_iter_s": 10.101196765899658, "time_total_s": 1279.1005637645721, "pid": 363902, "hostname": "DESKTOP-LQ219J4", "node_ip": "192.168.46.185", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 20, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 5000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 500, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Base_Model", "custom_model_config": {"env": "rware", "env_args": {"n_agents": 4, "column_height": 1, "max_inactivity_steps": null, "max_steps": 500, "fast_obs": true, "msg_bits": 0, "sensor_range": 1, "shelf_rows": 1, "shelf_columns": 3, "request_queue_size": 4, "reward_type": "RewardType.INDIVIDUAL", "map_name": "customized_map", "map_size": "tiny", "difficulty": "medium"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": true, "force_coop": false, "local_mode": true, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 4, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 100, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64}, "algorithm": "ia2c", "space_obs": "Dict(obs:Box([-100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100.], [100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.], (112,), float32))", "space_act": "Discrete(5)", "num_agents": 4, "episode_limit": 500, "policy_mapping_info": {"all_scenario": {"description": "rware all scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2", "agent_3"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "rware_customized_map", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 10, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.IA2CTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_il.<locals>.<lambda> at 0x7f383066aee0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "grad_clip": 40.0, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "microbatch_size": null}, "time_since_restore": 1279.1005637645721, "timesteps_since_restore": 0, "iterations_since_restore": 124, "perf": {"cpu_util_percent": 4.314285714285714, "ram_util_percent": 67.20000000000002}}
{"episode_reward_max": 20.0, "episode_reward_min": 1.0, "episode_reward_mean": 9.32, "episode_len_mean": 500.0, "episode_media": {}, "episodes_this_iter": 24, "policy_reward_min": {"shared_policy": 0.0}, "policy_reward_max": {"shared_policy": 7.0}, "policy_reward_mean": {"shared_policy": 2.33}, "custom_metrics": {}, "hist_stats": {"episode_reward": [7.0, 10.0, 12.0, 6.0, 3.0, 9.0, 8.0, 9.0, 8.0, 12.0, 8.0, 6.0, 8.0, 4.0, 14.0, 9.0, 7.0, 13.0, 14.0, 9.0, 10.0, 12.0, 5.0, 4.0, 15.0, 9.0, 8.0, 4.0, 9.0, 5.0, 8.0, 19.0, 11.0, 8.0, 7.0, 3.0, 2.0, 3.0, 17.0, 7.0, 11.0, 13.0, 14.0, 7.0, 8.0, 12.0, 12.0, 6.0, 20.0, 8.0, 4.0, 13.0, 4.0, 7.0, 14.0, 3.0, 14.0, 15.0, 16.0, 16.0, 12.0, 7.0, 5.0, 10.0, 13.0, 13.0, 11.0, 7.0, 7.0, 5.0, 11.0, 8.0, 13.0, 1.0, 13.0, 9.0, 15.0, 10.0, 9.0, 12.0, 12.0, 9.0, 5.0, 14.0, 10.0, 7.0, 7.0, 11.0, 4.0, 16.0, 2.0, 8.0, 4.0, 17.0, 4.0, 18.0, 7.0, 16.0, 5.0, 6.0], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500], "policy_shared_policy_reward": [2.0, 2.0, 2.0, 1.0, 2.0, 1.0, 3.0, 4.0, 3.0, 3.0, 3.0, 3.0, 2.0, 0.0, 2.0, 2.0, 2.0, 1.0, 0.0, 0.0, 4.0, 1.0, 2.0, 2.0, 2.0, 3.0, 2.0, 1.0, 4.0, 0.0, 3.0, 2.0, 2.0, 2.0, 3.0, 1.0, 3.0, 4.0, 4.0, 1.0, 2.0, 2.0, 3.0, 1.0, 2.0, 1.0, 2.0, 1.0, 2.0, 1.0, 3.0, 2.0, 1.0, 1.0, 1.0, 1.0, 5.0, 2.0, 3.0, 4.0, 3.0, 1.0, 2.0, 3.0, 2.0, 3.0, 2.0, 0.0, 2.0, 3.0, 4.0, 4.0, 5.0, 2.0, 4.0, 3.0, 3.0, 1.0, 3.0, 2.0, 6.0, 1.0, 1.0, 2.0, 4.0, 2.0, 4.0, 2.0, 2.0, 1.0, 0.0, 2.0, 0.0, 1.0, 1.0, 2.0, 3.0, 5.0, 3.0, 4.0, 2.0, 2.0, 3.0, 2.0, 2.0, 1.0, 2.0, 3.0, 2.0, 1.0, 0.0, 1.0, 2.0, 2.0, 4.0, 1.0, 2.0, 1.0, 1.0, 1.0, 2.0, 3.0, 1.0, 2.0, 5.0, 4.0, 3.0, 7.0, 4.0, 5.0, 1.0, 1.0, 3.0, 2.0, 2.0, 1.0, 3.0, 3.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 7.0, 3.0, 3.0, 4.0, 1.0, 2.0, 1.0, 3.0, 2.0, 4.0, 1.0, 4.0, 5.0, 3.0, 3.0, 2.0, 5.0, 2.0, 4.0, 3.0, 1.0, 2.0, 2.0, 2.0, 4.0, 1.0, 1.0, 2.0, 2.0, 3.0, 3.0, 4.0, 1.0, 4.0, 4.0, 3.0, 1.0, 2.0, 2.0, 1.0, 6.0, 7.0, 2.0, 5.0, 2.0, 3.0, 2.0, 1.0, 1.0, 1.0, 1.0, 1.0, 3.0, 3.0, 3.0, 4.0, 0.0, 1.0, 1.0, 2.0, 0.0, 3.0, 2.0, 2.0, 3.0, 4.0, 4.0, 3.0, 0.0, 2.0, 0.0, 1.0, 3.0, 3.0, 5.0, 3.0, 6.0, 2.0, 4.0, 3.0, 5.0, 4.0, 2.0, 5.0, 5.0, 3.0, 2.0, 6.0, 3.0, 4.0, 1.0, 4.0, 1.0, 3.0, 1.0, 2.0, 2.0, 1.0, 2.0, 0.0, 2.0, 2.0, 3.0, 3.0, 2.0, 4.0, 3.0, 4.0, 3.0, 4.0, 1.0, 5.0, 4.0, 3.0, 2.0, 2.0, 1.0, 4.0, 1.0, 1.0, 1.0, 3.0, 0.0, 3.0, 1.0, 1.0, 2.0, 1.0, 1.0, 4.0, 3.0, 3.0, 3.0, 0.0, 2.0, 3.0, 5.0, 3.0, 1.0, 4.0, 0.0, 0.0, 1.0, 0.0, 2.0, 5.0, 4.0, 2.0, 2.0, 4.0, 2.0, 1.0, 3.0, 4.0, 3.0, 5.0, 1.0, 2.0, 4.0, 3.0, 4.0, 1.0, 3.0, 1.0, 3.0, 1.0, 5.0, 3.0, 3.0, 2.0, 2.0, 5.0, 2.0, 3.0, 2.0, 2.0, 1.0, 0.0, 2.0, 2.0, 3.0, 2.0, 4.0, 5.0, 2.0, 3.0, 3.0, 2.0, 1.0, 2.0, 2.0, 2.0, 2.0, 2.0, 3.0, 0.0, 3.0, 3.0, 2.0, 3.0, 1.0, 2.0, 1.0, 0.0, 3.0, 5.0, 4.0, 4.0, 1.0, 1.0, 0.0, 0.0, 2.0, 3.0, 1.0, 2.0, 1.0, 1.0, 2.0, 0.0, 5.0, 4.0, 2.0, 6.0, 1.0, 0.0, 0.0, 3.0, 4.0, 6.0, 4.0, 4.0, 2.0, 0.0, 3.0, 2.0, 3.0, 6.0, 4.0, 3.0, 1.0, 1.0, 3.0, 0.0, 2.0, 0.0, 2.0, 2.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.13379881692121484, "mean_inference_ms": 0.39090662643881247, "mean_action_processing_ms": 0.029192715341086032, "mean_env_wait_ms": 0.40401962420598736, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 1260000, "timesteps_this_iter": 0, "agent_timesteps_total": 5040000, "timers": {"sample_time_ms": 5062.013, "sample_throughput": 995.651, "load_time_ms": 0.151, "load_throughput": 33485335.276, "learn_time_ms": 126.369, "learn_throughput": 39883.267, "update_time_ms": 2.576}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 342.6181335449219, "policy_entropy": 7721.8570556640625, "policy_loss": -68.44814443588257, "vf_loss": 62.036452293395996}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 1260000, "num_agent_steps_sampled": 5040000, "num_steps_trained": 1260000, "num_agent_steps_trained": 5040000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 2520, "training_iteration": 125, "trial_id": "71426_00000", "experiment_id": "84bca2f7b35f43248fca18d21abe2ebf", "date": "2024-06-12_03-07-22", "timestamp": 1718129242, "time_this_iter_s": 10.049718379974365, "time_total_s": 1289.1502821445465, "pid": 363902, "hostname": "DESKTOP-LQ219J4", "node_ip": "192.168.46.185", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 20, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 5000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 500, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Base_Model", "custom_model_config": {"env": "rware", "env_args": {"n_agents": 4, "column_height": 1, "max_inactivity_steps": null, "max_steps": 500, "fast_obs": true, "msg_bits": 0, "sensor_range": 1, "shelf_rows": 1, "shelf_columns": 3, "request_queue_size": 4, "reward_type": "RewardType.INDIVIDUAL", "map_name": "customized_map", "map_size": "tiny", "difficulty": "medium"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": true, "force_coop": false, "local_mode": true, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 4, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 100, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64}, "algorithm": "ia2c", "space_obs": "Dict(obs:Box([-100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100.], [100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.], (112,), float32))", "space_act": "Discrete(5)", "num_agents": 4, "episode_limit": 500, "policy_mapping_info": {"all_scenario": {"description": "rware all scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2", "agent_3"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "rware_customized_map", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 10, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.IA2CTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_il.<locals>.<lambda> at 0x7f38081d5f70>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "grad_clip": 40.0, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "microbatch_size": null}, "time_since_restore": 1289.1502821445465, "timesteps_since_restore": 0, "iterations_since_restore": 125, "perf": {"cpu_util_percent": 4.333333333333333, "ram_util_percent": 67.5}}
{"episode_reward_max": 20.0, "episode_reward_min": 1.0, "episode_reward_mean": 9.23, "episode_len_mean": 500.0, "episode_media": {}, "episodes_this_iter": 20, "policy_reward_min": {"shared_policy": 0.0}, "policy_reward_max": {"shared_policy": 7.0}, "policy_reward_mean": {"shared_policy": 2.3075}, "custom_metrics": {}, "hist_stats": {"episode_reward": [10.0, 12.0, 5.0, 4.0, 15.0, 9.0, 8.0, 4.0, 9.0, 5.0, 8.0, 19.0, 11.0, 8.0, 7.0, 3.0, 2.0, 3.0, 17.0, 7.0, 11.0, 13.0, 14.0, 7.0, 8.0, 12.0, 12.0, 6.0, 20.0, 8.0, 4.0, 13.0, 4.0, 7.0, 14.0, 3.0, 14.0, 15.0, 16.0, 16.0, 12.0, 7.0, 5.0, 10.0, 13.0, 13.0, 11.0, 7.0, 7.0, 5.0, 11.0, 8.0, 13.0, 1.0, 13.0, 9.0, 15.0, 10.0, 9.0, 12.0, 12.0, 9.0, 5.0, 14.0, 10.0, 7.0, 7.0, 11.0, 4.0, 16.0, 2.0, 8.0, 4.0, 17.0, 4.0, 18.0, 7.0, 16.0, 5.0, 6.0, 5.0, 12.0, 15.0, 3.0, 8.0, 13.0, 8.0, 4.0, 12.0, 3.0, 8.0, 8.0, 14.0, 8.0, 7.0, 8.0, 6.0, 4.0, 13.0, 8.0], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500], "policy_shared_policy_reward": [6.0, 1.0, 1.0, 2.0, 4.0, 2.0, 4.0, 2.0, 2.0, 1.0, 0.0, 2.0, 0.0, 1.0, 1.0, 2.0, 3.0, 5.0, 3.0, 4.0, 2.0, 2.0, 3.0, 2.0, 2.0, 1.0, 2.0, 3.0, 2.0, 1.0, 0.0, 1.0, 2.0, 2.0, 4.0, 1.0, 2.0, 1.0, 1.0, 1.0, 2.0, 3.0, 1.0, 2.0, 5.0, 4.0, 3.0, 7.0, 4.0, 5.0, 1.0, 1.0, 3.0, 2.0, 2.0, 1.0, 3.0, 3.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 7.0, 3.0, 3.0, 4.0, 1.0, 2.0, 1.0, 3.0, 2.0, 4.0, 1.0, 4.0, 5.0, 3.0, 3.0, 2.0, 5.0, 2.0, 4.0, 3.0, 1.0, 2.0, 2.0, 2.0, 4.0, 1.0, 1.0, 2.0, 2.0, 3.0, 3.0, 4.0, 1.0, 4.0, 4.0, 3.0, 1.0, 2.0, 2.0, 1.0, 6.0, 7.0, 2.0, 5.0, 2.0, 3.0, 2.0, 1.0, 1.0, 1.0, 1.0, 1.0, 3.0, 3.0, 3.0, 4.0, 0.0, 1.0, 1.0, 2.0, 0.0, 3.0, 2.0, 2.0, 3.0, 4.0, 4.0, 3.0, 0.0, 2.0, 0.0, 1.0, 3.0, 3.0, 5.0, 3.0, 6.0, 2.0, 4.0, 3.0, 5.0, 4.0, 2.0, 5.0, 5.0, 3.0, 2.0, 6.0, 3.0, 4.0, 1.0, 4.0, 1.0, 3.0, 1.0, 2.0, 2.0, 1.0, 2.0, 0.0, 2.0, 2.0, 3.0, 3.0, 2.0, 4.0, 3.0, 4.0, 3.0, 4.0, 1.0, 5.0, 4.0, 3.0, 2.0, 2.0, 1.0, 4.0, 1.0, 1.0, 1.0, 3.0, 0.0, 3.0, 1.0, 1.0, 2.0, 1.0, 1.0, 4.0, 3.0, 3.0, 3.0, 0.0, 2.0, 3.0, 5.0, 3.0, 1.0, 4.0, 0.0, 0.0, 1.0, 0.0, 2.0, 5.0, 4.0, 2.0, 2.0, 4.0, 2.0, 1.0, 3.0, 4.0, 3.0, 5.0, 1.0, 2.0, 4.0, 3.0, 4.0, 1.0, 3.0, 1.0, 3.0, 1.0, 5.0, 3.0, 3.0, 2.0, 2.0, 5.0, 2.0, 3.0, 2.0, 2.0, 1.0, 0.0, 2.0, 2.0, 3.0, 2.0, 4.0, 5.0, 2.0, 3.0, 3.0, 2.0, 1.0, 2.0, 2.0, 2.0, 2.0, 2.0, 3.0, 0.0, 3.0, 3.0, 2.0, 3.0, 1.0, 2.0, 1.0, 0.0, 3.0, 5.0, 4.0, 4.0, 1.0, 1.0, 0.0, 0.0, 2.0, 3.0, 1.0, 2.0, 1.0, 1.0, 2.0, 0.0, 5.0, 4.0, 2.0, 6.0, 1.0, 0.0, 0.0, 3.0, 4.0, 6.0, 4.0, 4.0, 2.0, 0.0, 3.0, 2.0, 3.0, 6.0, 4.0, 3.0, 1.0, 1.0, 3.0, 0.0, 2.0, 0.0, 2.0, 2.0, 0.0, 2.0, 1.0, 2.0, 1.0, 3.0, 3.0, 5.0, 2.0, 4.0, 5.0, 4.0, 1.0, 1.0, 0.0, 1.0, 1.0, 3.0, 1.0, 3.0, 1.0, 3.0, 6.0, 3.0, 2.0, 0.0, 3.0, 3.0, 1.0, 2.0, 0.0, 1.0, 4.0, 3.0, 3.0, 2.0, 1.0, 0.0, 1.0, 1.0, 2.0, 1.0, 3.0, 2.0, 2.0, 2.0, 3.0, 1.0, 6.0, 3.0, 3.0, 2.0, 1.0, 3.0, 1.0, 3.0, 3.0, 2.0, 1.0, 1.0, 2.0, 1.0, 3.0, 2.0, 2.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0, 1.0, 3.0, 3.0, 3.0, 4.0, 3.0, 3.0, 1.0, 1.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.13378172254818754, "mean_inference_ms": 0.39086194141955305, "mean_action_processing_ms": 0.029189450500424333, "mean_env_wait_ms": 0.40396538245277114, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 1270080, "timesteps_this_iter": 0, "agent_timesteps_total": 5080320, "timers": {"sample_time_ms": 5053.055, "sample_throughput": 997.416, "load_time_ms": 0.151, "load_throughput": 33284982.145, "learn_time_ms": 126.641, "learn_throughput": 39797.459, "update_time_ms": 2.59}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 250.56903076171875, "policy_entropy": 7770.1881103515625, "policy_loss": -60.36989164352417, "vf_loss": 57.73278999328613}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 1270080, "num_agent_steps_sampled": 5080320, "num_steps_trained": 1270080, "num_agent_steps_trained": 5080320, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 2540, "training_iteration": 126, "trial_id": "71426_00000", "experiment_id": "84bca2f7b35f43248fca18d21abe2ebf", "date": "2024-06-12_03-07-32", "timestamp": 1718129252, "time_this_iter_s": 10.060397863388062, "time_total_s": 1299.2106800079346, "pid": 363902, "hostname": "DESKTOP-LQ219J4", "node_ip": "192.168.46.185", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 20, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 5000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 500, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Base_Model", "custom_model_config": {"env": "rware", "env_args": {"n_agents": 4, "column_height": 1, "max_inactivity_steps": null, "max_steps": 500, "fast_obs": true, "msg_bits": 0, "sensor_range": 1, "shelf_rows": 1, "shelf_columns": 3, "request_queue_size": 4, "reward_type": "RewardType.INDIVIDUAL", "map_name": "customized_map", "map_size": "tiny", "difficulty": "medium"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": true, "force_coop": false, "local_mode": true, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 4, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 100, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64}, "algorithm": "ia2c", "space_obs": "Dict(obs:Box([-100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100.], [100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.], (112,), float32))", "space_act": "Discrete(5)", "num_agents": 4, "episode_limit": 500, "policy_mapping_info": {"all_scenario": {"description": "rware all scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2", "agent_3"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "rware_customized_map", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 10, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.IA2CTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_il.<locals>.<lambda> at 0x7f38281ee430>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "grad_clip": 40.0, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "microbatch_size": null}, "time_since_restore": 1299.2106800079346, "timesteps_since_restore": 0, "iterations_since_restore": 126, "perf": {"cpu_util_percent": 4.15, "ram_util_percent": 67.79999999999998}}
{"episode_reward_max": 20.0, "episode_reward_min": 1.0, "episode_reward_mean": 9.75, "episode_len_mean": 500.0, "episode_media": {}, "episodes_this_iter": 20, "policy_reward_min": {"shared_policy": 0.0}, "policy_reward_max": {"shared_policy": 7.0}, "policy_reward_mean": {"shared_policy": 2.4375}, "custom_metrics": {}, "hist_stats": {"episode_reward": [11.0, 13.0, 14.0, 7.0, 8.0, 12.0, 12.0, 6.0, 20.0, 8.0, 4.0, 13.0, 4.0, 7.0, 14.0, 3.0, 14.0, 15.0, 16.0, 16.0, 12.0, 7.0, 5.0, 10.0, 13.0, 13.0, 11.0, 7.0, 7.0, 5.0, 11.0, 8.0, 13.0, 1.0, 13.0, 9.0, 15.0, 10.0, 9.0, 12.0, 12.0, 9.0, 5.0, 14.0, 10.0, 7.0, 7.0, 11.0, 4.0, 16.0, 2.0, 8.0, 4.0, 17.0, 4.0, 18.0, 7.0, 16.0, 5.0, 6.0, 5.0, 12.0, 15.0, 3.0, 8.0, 13.0, 8.0, 4.0, 12.0, 3.0, 8.0, 8.0, 14.0, 8.0, 7.0, 8.0, 6.0, 4.0, 13.0, 8.0, 11.0, 14.0, 7.0, 13.0, 13.0, 8.0, 6.0, 13.0, 11.0, 11.0, 16.0, 12.0, 13.0, 7.0, 9.0, 10.0, 5.0, 11.0, 8.0, 20.0], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500], "policy_shared_policy_reward": [2.0, 4.0, 1.0, 4.0, 5.0, 3.0, 3.0, 2.0, 5.0, 2.0, 4.0, 3.0, 1.0, 2.0, 2.0, 2.0, 4.0, 1.0, 1.0, 2.0, 2.0, 3.0, 3.0, 4.0, 1.0, 4.0, 4.0, 3.0, 1.0, 2.0, 2.0, 1.0, 6.0, 7.0, 2.0, 5.0, 2.0, 3.0, 2.0, 1.0, 1.0, 1.0, 1.0, 1.0, 3.0, 3.0, 3.0, 4.0, 0.0, 1.0, 1.0, 2.0, 0.0, 3.0, 2.0, 2.0, 3.0, 4.0, 4.0, 3.0, 0.0, 2.0, 0.0, 1.0, 3.0, 3.0, 5.0, 3.0, 6.0, 2.0, 4.0, 3.0, 5.0, 4.0, 2.0, 5.0, 5.0, 3.0, 2.0, 6.0, 3.0, 4.0, 1.0, 4.0, 1.0, 3.0, 1.0, 2.0, 2.0, 1.0, 2.0, 0.0, 2.0, 2.0, 3.0, 3.0, 2.0, 4.0, 3.0, 4.0, 3.0, 4.0, 1.0, 5.0, 4.0, 3.0, 2.0, 2.0, 1.0, 4.0, 1.0, 1.0, 1.0, 3.0, 0.0, 3.0, 1.0, 1.0, 2.0, 1.0, 1.0, 4.0, 3.0, 3.0, 3.0, 0.0, 2.0, 3.0, 5.0, 3.0, 1.0, 4.0, 0.0, 0.0, 1.0, 0.0, 2.0, 5.0, 4.0, 2.0, 2.0, 4.0, 2.0, 1.0, 3.0, 4.0, 3.0, 5.0, 1.0, 2.0, 4.0, 3.0, 4.0, 1.0, 3.0, 1.0, 3.0, 1.0, 5.0, 3.0, 3.0, 2.0, 2.0, 5.0, 2.0, 3.0, 2.0, 2.0, 1.0, 0.0, 2.0, 2.0, 3.0, 2.0, 4.0, 5.0, 2.0, 3.0, 3.0, 2.0, 1.0, 2.0, 2.0, 2.0, 2.0, 2.0, 3.0, 0.0, 3.0, 3.0, 2.0, 3.0, 1.0, 2.0, 1.0, 0.0, 3.0, 5.0, 4.0, 4.0, 1.0, 1.0, 0.0, 0.0, 2.0, 3.0, 1.0, 2.0, 1.0, 1.0, 2.0, 0.0, 5.0, 4.0, 2.0, 6.0, 1.0, 0.0, 0.0, 3.0, 4.0, 6.0, 4.0, 4.0, 2.0, 0.0, 3.0, 2.0, 3.0, 6.0, 4.0, 3.0, 1.0, 1.0, 3.0, 0.0, 2.0, 0.0, 2.0, 2.0, 0.0, 2.0, 1.0, 2.0, 1.0, 3.0, 3.0, 5.0, 2.0, 4.0, 5.0, 4.0, 1.0, 1.0, 0.0, 1.0, 1.0, 3.0, 1.0, 3.0, 1.0, 3.0, 6.0, 3.0, 2.0, 0.0, 3.0, 3.0, 1.0, 2.0, 0.0, 1.0, 4.0, 3.0, 3.0, 2.0, 1.0, 0.0, 1.0, 1.0, 2.0, 1.0, 3.0, 2.0, 2.0, 2.0, 3.0, 1.0, 6.0, 3.0, 3.0, 2.0, 1.0, 3.0, 1.0, 3.0, 3.0, 2.0, 1.0, 1.0, 2.0, 1.0, 3.0, 2.0, 2.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0, 1.0, 3.0, 3.0, 3.0, 4.0, 3.0, 3.0, 1.0, 1.0, 4.0, 3.0, 3.0, 1.0, 3.0, 2.0, 7.0, 2.0, 2.0, 2.0, 2.0, 1.0, 1.0, 3.0, 5.0, 4.0, 5.0, 2.0, 2.0, 4.0, 1.0, 1.0, 2.0, 4.0, 2.0, 1.0, 1.0, 2.0, 4.0, 2.0, 4.0, 3.0, 2.0, 3.0, 2.0, 4.0, 1.0, 4.0, 3.0, 3.0, 5.0, 4.0, 4.0, 3.0, 3.0, 4.0, 2.0, 3.0, 3.0, 1.0, 5.0, 4.0, 3.0, 2.0, 1.0, 1.0, 1.0, 4.0, 2.0, 2.0, 3.0, 3.0, 2.0, 2.0, 2.0, 1.0, 1.0, 1.0, 2.0, 2.0, 2.0, 5.0, 1.0, 3.0, 1.0, 3.0, 2.0, 6.0, 7.0, 5.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.13376805019667565, "mean_inference_ms": 0.3908253242819162, "mean_action_processing_ms": 0.029186576651917075, "mean_env_wait_ms": 0.40390841740171296, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 1280160, "timesteps_this_iter": 0, "agent_timesteps_total": 5120640, "timers": {"sample_time_ms": 5057.786, "sample_throughput": 996.483, "load_time_ms": 0.159, "load_throughput": 31674096.734, "learn_time_ms": 126.885, "learn_throughput": 39721.049, "update_time_ms": 2.545}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 572.5301513671875, "policy_entropy": 7646.4796142578125, "policy_loss": 64.30605697631836, "vf_loss": 95.99317359924316}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 1280160, "num_agent_steps_sampled": 5120640, "num_steps_trained": 1280160, "num_agent_steps_trained": 5120640, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 2560, "training_iteration": 127, "trial_id": "71426_00000", "experiment_id": "84bca2f7b35f43248fca18d21abe2ebf", "date": "2024-06-12_03-07-42", "timestamp": 1718129262, "time_this_iter_s": 10.153497695922852, "time_total_s": 1309.3641777038574, "pid": 363902, "hostname": "DESKTOP-LQ219J4", "node_ip": "192.168.46.185", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 20, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 5000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 500, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Base_Model", "custom_model_config": {"env": "rware", "env_args": {"n_agents": 4, "column_height": 1, "max_inactivity_steps": null, "max_steps": 500, "fast_obs": true, "msg_bits": 0, "sensor_range": 1, "shelf_rows": 1, "shelf_columns": 3, "request_queue_size": 4, "reward_type": "RewardType.INDIVIDUAL", "map_name": "customized_map", "map_size": "tiny", "difficulty": "medium"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": true, "force_coop": false, "local_mode": true, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 4, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 100, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64}, "algorithm": "ia2c", "space_obs": "Dict(obs:Box([-100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100.], [100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.], (112,), float32))", "space_act": "Discrete(5)", "num_agents": 4, "episode_limit": 500, "policy_mapping_info": {"all_scenario": {"description": "rware all scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2", "agent_3"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "rware_customized_map", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 10, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.IA2CTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_il.<locals>.<lambda> at 0x7f38082f8160>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "grad_clip": 40.0, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "microbatch_size": null}, "time_since_restore": 1309.3641777038574, "timesteps_since_restore": 0, "iterations_since_restore": 127, "perf": {"cpu_util_percent": 4.228571428571429, "ram_util_percent": 68.09285714285714}}
{"episode_reward_max": 22.0, "episode_reward_min": 1.0, "episode_reward_mean": 9.9, "episode_len_mean": 500.0, "episode_media": {}, "episodes_this_iter": 20, "policy_reward_min": {"shared_policy": 0.0}, "policy_reward_max": {"shared_policy": 8.0}, "policy_reward_mean": {"shared_policy": 2.475}, "custom_metrics": {}, "hist_stats": {"episode_reward": [12.0, 7.0, 5.0, 10.0, 13.0, 13.0, 11.0, 7.0, 7.0, 5.0, 11.0, 8.0, 13.0, 1.0, 13.0, 9.0, 15.0, 10.0, 9.0, 12.0, 12.0, 9.0, 5.0, 14.0, 10.0, 7.0, 7.0, 11.0, 4.0, 16.0, 2.0, 8.0, 4.0, 17.0, 4.0, 18.0, 7.0, 16.0, 5.0, 6.0, 5.0, 12.0, 15.0, 3.0, 8.0, 13.0, 8.0, 4.0, 12.0, 3.0, 8.0, 8.0, 14.0, 8.0, 7.0, 8.0, 6.0, 4.0, 13.0, 8.0, 11.0, 14.0, 7.0, 13.0, 13.0, 8.0, 6.0, 13.0, 11.0, 11.0, 16.0, 12.0, 13.0, 7.0, 9.0, 10.0, 5.0, 11.0, 8.0, 20.0, 10.0, 12.0, 20.0, 14.0, 12.0, 11.0, 10.0, 5.0, 12.0, 9.0, 14.0, 5.0, 11.0, 22.0, 14.0, 11.0, 10.0, 6.0, 8.0, 16.0], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500], "policy_shared_policy_reward": [3.0, 4.0, 1.0, 4.0, 1.0, 3.0, 1.0, 2.0, 2.0, 1.0, 2.0, 0.0, 2.0, 2.0, 3.0, 3.0, 2.0, 4.0, 3.0, 4.0, 3.0, 4.0, 1.0, 5.0, 4.0, 3.0, 2.0, 2.0, 1.0, 4.0, 1.0, 1.0, 1.0, 3.0, 0.0, 3.0, 1.0, 1.0, 2.0, 1.0, 1.0, 4.0, 3.0, 3.0, 3.0, 0.0, 2.0, 3.0, 5.0, 3.0, 1.0, 4.0, 0.0, 0.0, 1.0, 0.0, 2.0, 5.0, 4.0, 2.0, 2.0, 4.0, 2.0, 1.0, 3.0, 4.0, 3.0, 5.0, 1.0, 2.0, 4.0, 3.0, 4.0, 1.0, 3.0, 1.0, 3.0, 1.0, 5.0, 3.0, 3.0, 2.0, 2.0, 5.0, 2.0, 3.0, 2.0, 2.0, 1.0, 0.0, 2.0, 2.0, 3.0, 2.0, 4.0, 5.0, 2.0, 3.0, 3.0, 2.0, 1.0, 2.0, 2.0, 2.0, 2.0, 2.0, 3.0, 0.0, 3.0, 3.0, 2.0, 3.0, 1.0, 2.0, 1.0, 0.0, 3.0, 5.0, 4.0, 4.0, 1.0, 1.0, 0.0, 0.0, 2.0, 3.0, 1.0, 2.0, 1.0, 1.0, 2.0, 0.0, 5.0, 4.0, 2.0, 6.0, 1.0, 0.0, 0.0, 3.0, 4.0, 6.0, 4.0, 4.0, 2.0, 0.0, 3.0, 2.0, 3.0, 6.0, 4.0, 3.0, 1.0, 1.0, 3.0, 0.0, 2.0, 0.0, 2.0, 2.0, 0.0, 2.0, 1.0, 2.0, 1.0, 3.0, 3.0, 5.0, 2.0, 4.0, 5.0, 4.0, 1.0, 1.0, 0.0, 1.0, 1.0, 3.0, 1.0, 3.0, 1.0, 3.0, 6.0, 3.0, 2.0, 0.0, 3.0, 3.0, 1.0, 2.0, 0.0, 1.0, 4.0, 3.0, 3.0, 2.0, 1.0, 0.0, 1.0, 1.0, 2.0, 1.0, 3.0, 2.0, 2.0, 2.0, 3.0, 1.0, 6.0, 3.0, 3.0, 2.0, 1.0, 3.0, 1.0, 3.0, 3.0, 2.0, 1.0, 1.0, 2.0, 1.0, 3.0, 2.0, 2.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0, 1.0, 3.0, 3.0, 3.0, 4.0, 3.0, 3.0, 1.0, 1.0, 4.0, 3.0, 3.0, 1.0, 3.0, 2.0, 7.0, 2.0, 2.0, 2.0, 2.0, 1.0, 1.0, 3.0, 5.0, 4.0, 5.0, 2.0, 2.0, 4.0, 1.0, 1.0, 2.0, 4.0, 2.0, 1.0, 1.0, 2.0, 4.0, 2.0, 4.0, 3.0, 2.0, 3.0, 2.0, 4.0, 1.0, 4.0, 3.0, 3.0, 5.0, 4.0, 4.0, 3.0, 3.0, 4.0, 2.0, 3.0, 3.0, 1.0, 5.0, 4.0, 3.0, 2.0, 1.0, 1.0, 1.0, 4.0, 2.0, 2.0, 3.0, 3.0, 2.0, 2.0, 2.0, 1.0, 1.0, 1.0, 2.0, 2.0, 2.0, 5.0, 1.0, 3.0, 1.0, 3.0, 2.0, 6.0, 7.0, 5.0, 3.0, 2.0, 2.0, 3.0, 2.0, 3.0, 3.0, 4.0, 8.0, 4.0, 3.0, 5.0, 4.0, 5.0, 2.0, 3.0, 4.0, 3.0, 3.0, 2.0, 4.0, 3.0, 1.0, 3.0, 3.0, 4.0, 1.0, 2.0, 0.0, 1.0, 1.0, 3.0, 3.0, 3.0, 4.0, 2.0, 4.0, 1.0, 2.0, 2.0, 4.0, 2.0, 5.0, 3.0, 1.0, 3.0, 1.0, 0.0, 1.0, 3.0, 3.0, 4.0, 5.0, 7.0, 6.0, 4.0, 4.0, 4.0, 2.0, 4.0, 3.0, 2.0, 2.0, 4.0, 3.0, 2.0, 4.0, 1.0, 2.0, 1.0, 2.0, 1.0, 2.0, 2.0, 2.0, 2.0, 4.0, 5.0, 3.0, 4.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.13375633107038012, "mean_inference_ms": 0.3907945994240478, "mean_action_processing_ms": 0.029184435842526897, "mean_env_wait_ms": 0.40384651394204296, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 1290240, "timesteps_this_iter": 0, "agent_timesteps_total": 5160960, "timers": {"sample_time_ms": 5065.397, "sample_throughput": 994.986, "load_time_ms": 0.157, "load_throughput": 32063237.009, "learn_time_ms": 127.425, "learn_throughput": 39552.633, "update_time_ms": 2.515}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 461.94805908203125, "policy_entropy": 7669.6370849609375, "policy_loss": 42.761674880981445, "vf_loss": 93.4283275604248}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 1290240, "num_agent_steps_sampled": 5160960, "num_steps_trained": 1290240, "num_agent_steps_trained": 5160960, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 2580, "training_iteration": 128, "trial_id": "71426_00000", "experiment_id": "84bca2f7b35f43248fca18d21abe2ebf", "date": "2024-06-12_03-07-52", "timestamp": 1718129272, "time_this_iter_s": 10.219899415969849, "time_total_s": 1319.5840771198273, "pid": 363902, "hostname": "DESKTOP-LQ219J4", "node_ip": "192.168.46.185", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 20, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 5000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 500, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Base_Model", "custom_model_config": {"env": "rware", "env_args": {"n_agents": 4, "column_height": 1, "max_inactivity_steps": null, "max_steps": 500, "fast_obs": true, "msg_bits": 0, "sensor_range": 1, "shelf_rows": 1, "shelf_columns": 3, "request_queue_size": 4, "reward_type": "RewardType.INDIVIDUAL", "map_name": "customized_map", "map_size": "tiny", "difficulty": "medium"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": true, "force_coop": false, "local_mode": true, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 4, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 100, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64}, "algorithm": "ia2c", "space_obs": "Dict(obs:Box([-100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100.], [100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.], (112,), float32))", "space_act": "Discrete(5)", "num_agents": 4, "episode_limit": 500, "policy_mapping_info": {"all_scenario": {"description": "rware all scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2", "agent_3"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "rware_customized_map", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 10, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.IA2CTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_il.<locals>.<lambda> at 0x7f3808645160>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "grad_clip": 40.0, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "microbatch_size": null}, "time_since_restore": 1319.5840771198273, "timesteps_since_restore": 0, "iterations_since_restore": 128, "perf": {"cpu_util_percent": 4.246666666666667, "ram_util_percent": 68.34666666666665}}
{"episode_reward_max": 22.0, "episode_reward_min": 1.0, "episode_reward_mean": 9.42, "episode_len_mean": 500.0, "episode_media": {}, "episodes_this_iter": 20, "policy_reward_min": {"shared_policy": 0.0}, "policy_reward_max": {"shared_policy": 8.0}, "policy_reward_mean": {"shared_policy": 2.355}, "custom_metrics": {}, "hist_stats": {"episode_reward": [12.0, 9.0, 5.0, 14.0, 10.0, 7.0, 7.0, 11.0, 4.0, 16.0, 2.0, 8.0, 4.0, 17.0, 4.0, 18.0, 7.0, 16.0, 5.0, 6.0, 5.0, 12.0, 15.0, 3.0, 8.0, 13.0, 8.0, 4.0, 12.0, 3.0, 8.0, 8.0, 14.0, 8.0, 7.0, 8.0, 6.0, 4.0, 13.0, 8.0, 11.0, 14.0, 7.0, 13.0, 13.0, 8.0, 6.0, 13.0, 11.0, 11.0, 16.0, 12.0, 13.0, 7.0, 9.0, 10.0, 5.0, 11.0, 8.0, 20.0, 10.0, 12.0, 20.0, 14.0, 12.0, 11.0, 10.0, 5.0, 12.0, 9.0, 14.0, 5.0, 11.0, 22.0, 14.0, 11.0, 10.0, 6.0, 8.0, 16.0, 6.0, 9.0, 8.0, 11.0, 3.0, 13.0, 8.0, 6.0, 12.0, 3.0, 8.0, 6.0, 7.0, 7.0, 7.0, 3.0, 6.0, 3.0, 16.0, 1.0], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500], "policy_shared_policy_reward": [3.0, 2.0, 2.0, 5.0, 2.0, 3.0, 2.0, 2.0, 1.0, 0.0, 2.0, 2.0, 3.0, 2.0, 4.0, 5.0, 2.0, 3.0, 3.0, 2.0, 1.0, 2.0, 2.0, 2.0, 2.0, 2.0, 3.0, 0.0, 3.0, 3.0, 2.0, 3.0, 1.0, 2.0, 1.0, 0.0, 3.0, 5.0, 4.0, 4.0, 1.0, 1.0, 0.0, 0.0, 2.0, 3.0, 1.0, 2.0, 1.0, 1.0, 2.0, 0.0, 5.0, 4.0, 2.0, 6.0, 1.0, 0.0, 0.0, 3.0, 4.0, 6.0, 4.0, 4.0, 2.0, 0.0, 3.0, 2.0, 3.0, 6.0, 4.0, 3.0, 1.0, 1.0, 3.0, 0.0, 2.0, 0.0, 2.0, 2.0, 0.0, 2.0, 1.0, 2.0, 1.0, 3.0, 3.0, 5.0, 2.0, 4.0, 5.0, 4.0, 1.0, 1.0, 0.0, 1.0, 1.0, 3.0, 1.0, 3.0, 1.0, 3.0, 6.0, 3.0, 2.0, 0.0, 3.0, 3.0, 1.0, 2.0, 0.0, 1.0, 4.0, 3.0, 3.0, 2.0, 1.0, 0.0, 1.0, 1.0, 2.0, 1.0, 3.0, 2.0, 2.0, 2.0, 3.0, 1.0, 6.0, 3.0, 3.0, 2.0, 1.0, 3.0, 1.0, 3.0, 3.0, 2.0, 1.0, 1.0, 2.0, 1.0, 3.0, 2.0, 2.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0, 1.0, 3.0, 3.0, 3.0, 4.0, 3.0, 3.0, 1.0, 1.0, 4.0, 3.0, 3.0, 1.0, 3.0, 2.0, 7.0, 2.0, 2.0, 2.0, 2.0, 1.0, 1.0, 3.0, 5.0, 4.0, 5.0, 2.0, 2.0, 4.0, 1.0, 1.0, 2.0, 4.0, 2.0, 1.0, 1.0, 2.0, 4.0, 2.0, 4.0, 3.0, 2.0, 3.0, 2.0, 4.0, 1.0, 4.0, 3.0, 3.0, 5.0, 4.0, 4.0, 3.0, 3.0, 4.0, 2.0, 3.0, 3.0, 1.0, 5.0, 4.0, 3.0, 2.0, 1.0, 1.0, 1.0, 4.0, 2.0, 2.0, 3.0, 3.0, 2.0, 2.0, 2.0, 1.0, 1.0, 1.0, 2.0, 2.0, 2.0, 5.0, 1.0, 3.0, 1.0, 3.0, 2.0, 6.0, 7.0, 5.0, 3.0, 2.0, 2.0, 3.0, 2.0, 3.0, 3.0, 4.0, 8.0, 4.0, 3.0, 5.0, 4.0, 5.0, 2.0, 3.0, 4.0, 3.0, 3.0, 2.0, 4.0, 3.0, 1.0, 3.0, 3.0, 4.0, 1.0, 2.0, 0.0, 1.0, 1.0, 3.0, 3.0, 3.0, 4.0, 2.0, 4.0, 1.0, 2.0, 2.0, 4.0, 2.0, 5.0, 3.0, 1.0, 3.0, 1.0, 0.0, 1.0, 3.0, 3.0, 4.0, 5.0, 7.0, 6.0, 4.0, 4.0, 4.0, 2.0, 4.0, 3.0, 2.0, 2.0, 4.0, 3.0, 2.0, 4.0, 1.0, 2.0, 1.0, 2.0, 1.0, 2.0, 2.0, 2.0, 2.0, 4.0, 5.0, 3.0, 4.0, 2.0, 1.0, 1.0, 2.0, 4.0, 1.0, 1.0, 3.0, 2.0, 2.0, 2.0, 2.0, 4.0, 3.0, 4.0, 0.0, 0.0, 1.0, 1.0, 1.0, 2.0, 3.0, 6.0, 2.0, 3.0, 3.0, 2.0, 0.0, 3.0, 2.0, 1.0, 0.0, 3.0, 4.0, 3.0, 2.0, 1.0, 0.0, 1.0, 1.0, 4.0, 2.0, 2.0, 0.0, 0.0, 1.0, 2.0, 3.0, 2.0, 2.0, 1.0, 2.0, 2.0, 0.0, 3.0, 2.0, 1.0, 3.0, 1.0, 2.0, 1.0, 0.0, 1.0, 1.0, 2.0, 1.0, 2.0, 1.0, 2.0, 0.0, 0.0, 1.0, 2.0, 5.0, 3.0, 6.0, 1.0, 0.0, 0.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.13374508895635173, "mean_inference_ms": 0.39076522978708594, "mean_action_processing_ms": 0.029181888887586657, "mean_env_wait_ms": 0.4037939112259774, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 1300320, "timesteps_this_iter": 0, "agent_timesteps_total": 5201280, "timers": {"sample_time_ms": 5064.569, "sample_throughput": 995.149, "load_time_ms": 0.161, "load_throughput": 31257270.679, "learn_time_ms": 127.948, "learn_throughput": 39390.864, "update_time_ms": 2.477}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 513.659912109375, "policy_entropy": 7783.3697509765625, "policy_loss": -122.33544540405273, "vf_loss": 54.77421569824219}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 1300320, "num_agent_steps_sampled": 5201280, "num_steps_trained": 1300320, "num_agent_steps_trained": 5201280, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 2600, "training_iteration": 129, "trial_id": "71426_00000", "experiment_id": "84bca2f7b35f43248fca18d21abe2ebf", "date": "2024-06-12_03-08-02", "timestamp": 1718129282, "time_this_iter_s": 10.088645219802856, "time_total_s": 1329.6727223396301, "pid": 363902, "hostname": "DESKTOP-LQ219J4", "node_ip": "192.168.46.185", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 20, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 5000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 500, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Base_Model", "custom_model_config": {"env": "rware", "env_args": {"n_agents": 4, "column_height": 1, "max_inactivity_steps": null, "max_steps": 500, "fast_obs": true, "msg_bits": 0, "sensor_range": 1, "shelf_rows": 1, "shelf_columns": 3, "request_queue_size": 4, "reward_type": "RewardType.INDIVIDUAL", "map_name": "customized_map", "map_size": "tiny", "difficulty": "medium"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": true, "force_coop": false, "local_mode": true, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 4, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 100, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64}, "algorithm": "ia2c", "space_obs": "Dict(obs:Box([-100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100.], [100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.], (112,), float32))", "space_act": "Discrete(5)", "num_agents": 4, "episode_limit": 500, "policy_mapping_info": {"all_scenario": {"description": "rware all scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2", "agent_3"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "rware_customized_map", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 10, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.IA2CTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_il.<locals>.<lambda> at 0x7f38081d5f70>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "grad_clip": 40.0, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "microbatch_size": null}, "time_since_restore": 1329.6727223396301, "timesteps_since_restore": 0, "iterations_since_restore": 129, "perf": {"cpu_util_percent": 4.314285714285715, "ram_util_percent": 68.65000000000002}}
{"episode_reward_max": 24.0, "episode_reward_min": 1.0, "episode_reward_mean": 9.22, "episode_len_mean": 500.0, "episode_media": {}, "episodes_this_iter": 20, "policy_reward_min": {"shared_policy": 0.0}, "policy_reward_max": {"shared_policy": 8.0}, "policy_reward_mean": {"shared_policy": 2.305}, "custom_metrics": {}, "hist_stats": {"episode_reward": [5.0, 12.0, 15.0, 3.0, 8.0, 13.0, 8.0, 4.0, 12.0, 3.0, 8.0, 8.0, 14.0, 8.0, 7.0, 8.0, 6.0, 4.0, 13.0, 8.0, 11.0, 14.0, 7.0, 13.0, 13.0, 8.0, 6.0, 13.0, 11.0, 11.0, 16.0, 12.0, 13.0, 7.0, 9.0, 10.0, 5.0, 11.0, 8.0, 20.0, 10.0, 12.0, 20.0, 14.0, 12.0, 11.0, 10.0, 5.0, 12.0, 9.0, 14.0, 5.0, 11.0, 22.0, 14.0, 11.0, 10.0, 6.0, 8.0, 16.0, 6.0, 9.0, 8.0, 11.0, 3.0, 13.0, 8.0, 6.0, 12.0, 3.0, 8.0, 6.0, 7.0, 7.0, 7.0, 3.0, 6.0, 3.0, 16.0, 1.0, 6.0, 5.0, 3.0, 4.0, 24.0, 4.0, 5.0, 9.0, 2.0, 7.0, 11.0, 14.0, 5.0, 8.0, 12.0, 6.0, 6.0, 13.0, 5.0, 13.0], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500], "policy_shared_policy_reward": [0.0, 2.0, 1.0, 2.0, 1.0, 3.0, 3.0, 5.0, 2.0, 4.0, 5.0, 4.0, 1.0, 1.0, 0.0, 1.0, 1.0, 3.0, 1.0, 3.0, 1.0, 3.0, 6.0, 3.0, 2.0, 0.0, 3.0, 3.0, 1.0, 2.0, 0.0, 1.0, 4.0, 3.0, 3.0, 2.0, 1.0, 0.0, 1.0, 1.0, 2.0, 1.0, 3.0, 2.0, 2.0, 2.0, 3.0, 1.0, 6.0, 3.0, 3.0, 2.0, 1.0, 3.0, 1.0, 3.0, 3.0, 2.0, 1.0, 1.0, 2.0, 1.0, 3.0, 2.0, 2.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0, 1.0, 3.0, 3.0, 3.0, 4.0, 3.0, 3.0, 1.0, 1.0, 4.0, 3.0, 3.0, 1.0, 3.0, 2.0, 7.0, 2.0, 2.0, 2.0, 2.0, 1.0, 1.0, 3.0, 5.0, 4.0, 5.0, 2.0, 2.0, 4.0, 1.0, 1.0, 2.0, 4.0, 2.0, 1.0, 1.0, 2.0, 4.0, 2.0, 4.0, 3.0, 2.0, 3.0, 2.0, 4.0, 1.0, 4.0, 3.0, 3.0, 5.0, 4.0, 4.0, 3.0, 3.0, 4.0, 2.0, 3.0, 3.0, 1.0, 5.0, 4.0, 3.0, 2.0, 1.0, 1.0, 1.0, 4.0, 2.0, 2.0, 3.0, 3.0, 2.0, 2.0, 2.0, 1.0, 1.0, 1.0, 2.0, 2.0, 2.0, 5.0, 1.0, 3.0, 1.0, 3.0, 2.0, 6.0, 7.0, 5.0, 3.0, 2.0, 2.0, 3.0, 2.0, 3.0, 3.0, 4.0, 8.0, 4.0, 3.0, 5.0, 4.0, 5.0, 2.0, 3.0, 4.0, 3.0, 3.0, 2.0, 4.0, 3.0, 1.0, 3.0, 3.0, 4.0, 1.0, 2.0, 0.0, 1.0, 1.0, 3.0, 3.0, 3.0, 4.0, 2.0, 4.0, 1.0, 2.0, 2.0, 4.0, 2.0, 5.0, 3.0, 1.0, 3.0, 1.0, 0.0, 1.0, 3.0, 3.0, 4.0, 5.0, 7.0, 6.0, 4.0, 4.0, 4.0, 2.0, 4.0, 3.0, 2.0, 2.0, 4.0, 3.0, 2.0, 4.0, 1.0, 2.0, 1.0, 2.0, 1.0, 2.0, 2.0, 2.0, 2.0, 4.0, 5.0, 3.0, 4.0, 2.0, 1.0, 1.0, 2.0, 4.0, 1.0, 1.0, 3.0, 2.0, 2.0, 2.0, 2.0, 4.0, 3.0, 4.0, 0.0, 0.0, 1.0, 1.0, 1.0, 2.0, 3.0, 6.0, 2.0, 3.0, 3.0, 2.0, 0.0, 3.0, 2.0, 1.0, 0.0, 3.0, 4.0, 3.0, 2.0, 1.0, 0.0, 1.0, 1.0, 4.0, 2.0, 2.0, 0.0, 0.0, 1.0, 2.0, 3.0, 2.0, 2.0, 1.0, 2.0, 2.0, 0.0, 3.0, 2.0, 1.0, 3.0, 1.0, 2.0, 1.0, 0.0, 1.0, 1.0, 2.0, 1.0, 2.0, 1.0, 2.0, 0.0, 0.0, 1.0, 2.0, 5.0, 3.0, 6.0, 1.0, 0.0, 0.0, 0.0, 1.0, 2.0, 2.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 6.0, 5.0, 7.0, 6.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 2.0, 2.0, 3.0, 1.0, 3.0, 1.0, 1.0, 0.0, 0.0, 1.0, 3.0, 1.0, 2.0, 3.0, 2.0, 4.0, 2.0, 1.0, 6.0, 3.0, 4.0, 2.0, 1.0, 1.0, 1.0, 1.0, 4.0, 2.0, 1.0, 3.0, 4.0, 1.0, 4.0, 2.0, 2.0, 2.0, 0.0, 2.0, 1.0, 1.0, 2.0, 6.0, 2.0, 3.0, 2.0, 0.0, 1.0, 2.0, 2.0, 5.0, 3.0, 2.0, 3.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.13374844972430824, "mean_inference_ms": 0.3907665550054159, "mean_action_processing_ms": 0.02918332888542488, "mean_env_wait_ms": 0.4037787025177178, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 1310400, "timesteps_this_iter": 0, "agent_timesteps_total": 5241600, "timers": {"sample_time_ms": 5071.899, "sample_throughput": 993.711, "load_time_ms": 0.161, "load_throughput": 31336039.371, "learn_time_ms": 129.016, "learn_throughput": 39064.859, "update_time_ms": 2.426}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 334.5594482421875, "policy_entropy": 7740.6158447265625, "policy_loss": -48.92335867881775, "vf_loss": 58.30768013000488}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 1310400, "num_agent_steps_sampled": 5241600, "num_steps_trained": 1310400, "num_agent_steps_trained": 5241600, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 2620, "training_iteration": 130, "trial_id": "71426_00000", "experiment_id": "84bca2f7b35f43248fca18d21abe2ebf", "date": "2024-06-12_03-08-12", "timestamp": 1718129292, "time_this_iter_s": 10.13200855255127, "time_total_s": 1339.8047308921814, "pid": 363902, "hostname": "DESKTOP-LQ219J4", "node_ip": "192.168.46.185", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 20, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 5000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 500, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Base_Model", "custom_model_config": {"env": "rware", "env_args": {"n_agents": 4, "column_height": 1, "max_inactivity_steps": null, "max_steps": 500, "fast_obs": true, "msg_bits": 0, "sensor_range": 1, "shelf_rows": 1, "shelf_columns": 3, "request_queue_size": 4, "reward_type": "RewardType.INDIVIDUAL", "map_name": "customized_map", "map_size": "tiny", "difficulty": "medium"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": true, "force_coop": false, "local_mode": true, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 4, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 100, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64}, "algorithm": "ia2c", "space_obs": "Dict(obs:Box([-100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100.], [100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.], (112,), float32))", "space_act": "Discrete(5)", "num_agents": 4, "episode_limit": 500, "policy_mapping_info": {"all_scenario": {"description": "rware all scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2", "agent_3"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "rware_customized_map", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 10, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.IA2CTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_il.<locals>.<lambda> at 0x7f38082f8160>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "grad_clip": 40.0, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "microbatch_size": null}, "time_since_restore": 1339.8047308921814, "timesteps_since_restore": 0, "iterations_since_restore": 130, "perf": {"cpu_util_percent": 4.206666666666666, "ram_util_percent": 68.9}}
{"episode_reward_max": 24.0, "episode_reward_min": 1.0, "episode_reward_mean": 9.38, "episode_len_mean": 500.0, "episode_media": {}, "episodes_this_iter": 20, "policy_reward_min": {"shared_policy": 0.0}, "policy_reward_max": {"shared_policy": 8.0}, "policy_reward_mean": {"shared_policy": 2.345}, "custom_metrics": {}, "hist_stats": {"episode_reward": [11.0, 14.0, 7.0, 13.0, 13.0, 8.0, 6.0, 13.0, 11.0, 11.0, 16.0, 12.0, 13.0, 7.0, 9.0, 10.0, 5.0, 11.0, 8.0, 20.0, 10.0, 12.0, 20.0, 14.0, 12.0, 11.0, 10.0, 5.0, 12.0, 9.0, 14.0, 5.0, 11.0, 22.0, 14.0, 11.0, 10.0, 6.0, 8.0, 16.0, 6.0, 9.0, 8.0, 11.0, 3.0, 13.0, 8.0, 6.0, 12.0, 3.0, 8.0, 6.0, 7.0, 7.0, 7.0, 3.0, 6.0, 3.0, 16.0, 1.0, 6.0, 5.0, 3.0, 4.0, 24.0, 4.0, 5.0, 9.0, 2.0, 7.0, 11.0, 14.0, 5.0, 8.0, 12.0, 6.0, 6.0, 13.0, 5.0, 13.0, 14.0, 7.0, 13.0, 2.0, 4.0, 3.0, 4.0, 23.0, 8.0, 7.0, 8.0, 6.0, 16.0, 14.0, 4.0, 7.0, 15.0, 5.0, 9.0, 14.0], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500], "policy_shared_policy_reward": [4.0, 3.0, 3.0, 1.0, 3.0, 2.0, 7.0, 2.0, 2.0, 2.0, 2.0, 1.0, 1.0, 3.0, 5.0, 4.0, 5.0, 2.0, 2.0, 4.0, 1.0, 1.0, 2.0, 4.0, 2.0, 1.0, 1.0, 2.0, 4.0, 2.0, 4.0, 3.0, 2.0, 3.0, 2.0, 4.0, 1.0, 4.0, 3.0, 3.0, 5.0, 4.0, 4.0, 3.0, 3.0, 4.0, 2.0, 3.0, 3.0, 1.0, 5.0, 4.0, 3.0, 2.0, 1.0, 1.0, 1.0, 4.0, 2.0, 2.0, 3.0, 3.0, 2.0, 2.0, 2.0, 1.0, 1.0, 1.0, 2.0, 2.0, 2.0, 5.0, 1.0, 3.0, 1.0, 3.0, 2.0, 6.0, 7.0, 5.0, 3.0, 2.0, 2.0, 3.0, 2.0, 3.0, 3.0, 4.0, 8.0, 4.0, 3.0, 5.0, 4.0, 5.0, 2.0, 3.0, 4.0, 3.0, 3.0, 2.0, 4.0, 3.0, 1.0, 3.0, 3.0, 4.0, 1.0, 2.0, 0.0, 1.0, 1.0, 3.0, 3.0, 3.0, 4.0, 2.0, 4.0, 1.0, 2.0, 2.0, 4.0, 2.0, 5.0, 3.0, 1.0, 3.0, 1.0, 0.0, 1.0, 3.0, 3.0, 4.0, 5.0, 7.0, 6.0, 4.0, 4.0, 4.0, 2.0, 4.0, 3.0, 2.0, 2.0, 4.0, 3.0, 2.0, 4.0, 1.0, 2.0, 1.0, 2.0, 1.0, 2.0, 2.0, 2.0, 2.0, 4.0, 5.0, 3.0, 4.0, 2.0, 1.0, 1.0, 2.0, 4.0, 1.0, 1.0, 3.0, 2.0, 2.0, 2.0, 2.0, 4.0, 3.0, 4.0, 0.0, 0.0, 1.0, 1.0, 1.0, 2.0, 3.0, 6.0, 2.0, 3.0, 3.0, 2.0, 0.0, 3.0, 2.0, 1.0, 0.0, 3.0, 4.0, 3.0, 2.0, 1.0, 0.0, 1.0, 1.0, 4.0, 2.0, 2.0, 0.0, 0.0, 1.0, 2.0, 3.0, 2.0, 2.0, 1.0, 2.0, 2.0, 0.0, 3.0, 2.0, 1.0, 3.0, 1.0, 2.0, 1.0, 0.0, 1.0, 1.0, 2.0, 1.0, 2.0, 1.0, 2.0, 0.0, 0.0, 1.0, 2.0, 5.0, 3.0, 6.0, 1.0, 0.0, 0.0, 0.0, 1.0, 2.0, 2.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 6.0, 5.0, 7.0, 6.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 2.0, 2.0, 3.0, 1.0, 3.0, 1.0, 1.0, 0.0, 0.0, 1.0, 3.0, 1.0, 2.0, 3.0, 2.0, 4.0, 2.0, 1.0, 6.0, 3.0, 4.0, 2.0, 1.0, 1.0, 1.0, 1.0, 4.0, 2.0, 1.0, 3.0, 4.0, 1.0, 4.0, 2.0, 2.0, 2.0, 0.0, 2.0, 1.0, 1.0, 2.0, 6.0, 2.0, 3.0, 2.0, 0.0, 1.0, 2.0, 2.0, 5.0, 3.0, 2.0, 3.0, 1.0, 5.0, 4.0, 4.0, 2.0, 2.0, 2.0, 1.0, 2.0, 2.0, 4.0, 5.0, 1.0, 0.0, 0.0, 1.0, 0.0, 2.0, 1.0, 1.0, 2.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 7.0, 4.0, 7.0, 5.0, 1.0, 2.0, 2.0, 3.0, 1.0, 1.0, 4.0, 1.0, 2.0, 2.0, 2.0, 2.0, 2.0, 1.0, 2.0, 1.0, 4.0, 7.0, 2.0, 3.0, 6.0, 3.0, 4.0, 1.0, 2.0, 0.0, 1.0, 1.0, 0.0, 3.0, 2.0, 2.0, 3.0, 6.0, 2.0, 4.0, 1.0, 1.0, 1.0, 2.0, 3.0, 2.0, 3.0, 1.0, 3.0, 2.0, 4.0, 5.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.13374208296627965, "mean_inference_ms": 0.3907438591489064, "mean_action_processing_ms": 0.029181233719620572, "mean_env_wait_ms": 0.4037310707598038, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 1320480, "timesteps_this_iter": 0, "agent_timesteps_total": 5281920, "timers": {"sample_time_ms": 5079.249, "sample_throughput": 992.273, "load_time_ms": 0.174, "load_throughput": 29029514.09, "learn_time_ms": 128.375, "learn_throughput": 39259.928, "update_time_ms": 2.37}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 224.5853271484375, "policy_entropy": 7753.208740234375, "policy_loss": 4.991792440414429, "vf_loss": 78.05078887939453}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 1320480, "num_agent_steps_sampled": 5281920, "num_steps_trained": 1320480, "num_agent_steps_trained": 5281920, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 2640, "training_iteration": 131, "trial_id": "71426_00000", "experiment_id": "84bca2f7b35f43248fca18d21abe2ebf", "date": "2024-06-12_03-08-23", "timestamp": 1718129303, "time_this_iter_s": 10.11821722984314, "time_total_s": 1349.9229481220245, "pid": 363902, "hostname": "DESKTOP-LQ219J4", "node_ip": "192.168.46.185", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 20, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 5000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 500, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Base_Model", "custom_model_config": {"env": "rware", "env_args": {"n_agents": 4, "column_height": 1, "max_inactivity_steps": null, "max_steps": 500, "fast_obs": true, "msg_bits": 0, "sensor_range": 1, "shelf_rows": 1, "shelf_columns": 3, "request_queue_size": 4, "reward_type": "RewardType.INDIVIDUAL", "map_name": "customized_map", "map_size": "tiny", "difficulty": "medium"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": true, "force_coop": false, "local_mode": true, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 4, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 100, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64}, "algorithm": "ia2c", "space_obs": "Dict(obs:Box([-100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100.], [100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.], (112,), float32))", "space_act": "Discrete(5)", "num_agents": 4, "episode_limit": 500, "policy_mapping_info": {"all_scenario": {"description": "rware all scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2", "agent_3"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "rware_customized_map", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 10, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.IA2CTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_il.<locals>.<lambda> at 0x7f38280b24c0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "grad_clip": 40.0, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "microbatch_size": null}, "time_since_restore": 1349.9229481220245, "timesteps_since_restore": 0, "iterations_since_restore": 131, "perf": {"cpu_util_percent": 4.221428571428572, "ram_util_percent": 69.20000000000002}}
{"episode_reward_max": 24.0, "episode_reward_min": 1.0, "episode_reward_mean": 9.37, "episode_len_mean": 500.0, "episode_media": {}, "episodes_this_iter": 20, "policy_reward_min": {"shared_policy": 0.0}, "policy_reward_max": {"shared_policy": 8.0}, "policy_reward_mean": {"shared_policy": 2.3425}, "custom_metrics": {}, "hist_stats": {"episode_reward": [10.0, 12.0, 20.0, 14.0, 12.0, 11.0, 10.0, 5.0, 12.0, 9.0, 14.0, 5.0, 11.0, 22.0, 14.0, 11.0, 10.0, 6.0, 8.0, 16.0, 6.0, 9.0, 8.0, 11.0, 3.0, 13.0, 8.0, 6.0, 12.0, 3.0, 8.0, 6.0, 7.0, 7.0, 7.0, 3.0, 6.0, 3.0, 16.0, 1.0, 6.0, 5.0, 3.0, 4.0, 24.0, 4.0, 5.0, 9.0, 2.0, 7.0, 11.0, 14.0, 5.0, 8.0, 12.0, 6.0, 6.0, 13.0, 5.0, 13.0, 14.0, 7.0, 13.0, 2.0, 4.0, 3.0, 4.0, 23.0, 8.0, 7.0, 8.0, 6.0, 16.0, 14.0, 4.0, 7.0, 15.0, 5.0, 9.0, 14.0, 10.0, 10.0, 9.0, 14.0, 8.0, 20.0, 20.0, 12.0, 8.0, 11.0, 7.0, 13.0, 6.0, 11.0, 14.0, 10.0, 11.0, 13.0, 8.0, 2.0], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500], "policy_shared_policy_reward": [3.0, 2.0, 2.0, 3.0, 2.0, 3.0, 3.0, 4.0, 8.0, 4.0, 3.0, 5.0, 4.0, 5.0, 2.0, 3.0, 4.0, 3.0, 3.0, 2.0, 4.0, 3.0, 1.0, 3.0, 3.0, 4.0, 1.0, 2.0, 0.0, 1.0, 1.0, 3.0, 3.0, 3.0, 4.0, 2.0, 4.0, 1.0, 2.0, 2.0, 4.0, 2.0, 5.0, 3.0, 1.0, 3.0, 1.0, 0.0, 1.0, 3.0, 3.0, 4.0, 5.0, 7.0, 6.0, 4.0, 4.0, 4.0, 2.0, 4.0, 3.0, 2.0, 2.0, 4.0, 3.0, 2.0, 4.0, 1.0, 2.0, 1.0, 2.0, 1.0, 2.0, 2.0, 2.0, 2.0, 4.0, 5.0, 3.0, 4.0, 2.0, 1.0, 1.0, 2.0, 4.0, 1.0, 1.0, 3.0, 2.0, 2.0, 2.0, 2.0, 4.0, 3.0, 4.0, 0.0, 0.0, 1.0, 1.0, 1.0, 2.0, 3.0, 6.0, 2.0, 3.0, 3.0, 2.0, 0.0, 3.0, 2.0, 1.0, 0.0, 3.0, 4.0, 3.0, 2.0, 1.0, 0.0, 1.0, 1.0, 4.0, 2.0, 2.0, 0.0, 0.0, 1.0, 2.0, 3.0, 2.0, 2.0, 1.0, 2.0, 2.0, 0.0, 3.0, 2.0, 1.0, 3.0, 1.0, 2.0, 1.0, 0.0, 1.0, 1.0, 2.0, 1.0, 2.0, 1.0, 2.0, 0.0, 0.0, 1.0, 2.0, 5.0, 3.0, 6.0, 1.0, 0.0, 0.0, 0.0, 1.0, 2.0, 2.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 6.0, 5.0, 7.0, 6.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 2.0, 2.0, 3.0, 1.0, 3.0, 1.0, 1.0, 0.0, 0.0, 1.0, 3.0, 1.0, 2.0, 3.0, 2.0, 4.0, 2.0, 1.0, 6.0, 3.0, 4.0, 2.0, 1.0, 1.0, 1.0, 1.0, 4.0, 2.0, 1.0, 3.0, 4.0, 1.0, 4.0, 2.0, 2.0, 2.0, 0.0, 2.0, 1.0, 1.0, 2.0, 6.0, 2.0, 3.0, 2.0, 0.0, 1.0, 2.0, 2.0, 5.0, 3.0, 2.0, 3.0, 1.0, 5.0, 4.0, 4.0, 2.0, 2.0, 2.0, 1.0, 2.0, 2.0, 4.0, 5.0, 1.0, 0.0, 0.0, 1.0, 0.0, 2.0, 1.0, 1.0, 2.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 7.0, 4.0, 7.0, 5.0, 1.0, 2.0, 2.0, 3.0, 1.0, 1.0, 4.0, 1.0, 2.0, 2.0, 2.0, 2.0, 2.0, 1.0, 2.0, 1.0, 4.0, 7.0, 2.0, 3.0, 6.0, 3.0, 4.0, 1.0, 2.0, 0.0, 1.0, 1.0, 0.0, 3.0, 2.0, 2.0, 3.0, 6.0, 2.0, 4.0, 1.0, 1.0, 1.0, 2.0, 3.0, 2.0, 3.0, 1.0, 3.0, 2.0, 4.0, 5.0, 2.0, 2.0, 3.0, 3.0, 1.0, 2.0, 3.0, 4.0, 2.0, 3.0, 2.0, 2.0, 4.0, 2.0, 6.0, 2.0, 1.0, 2.0, 2.0, 3.0, 7.0, 3.0, 6.0, 4.0, 6.0, 4.0, 6.0, 4.0, 2.0, 4.0, 4.0, 2.0, 2.0, 3.0, 2.0, 1.0, 1.0, 4.0, 2.0, 4.0, 2.0, 1.0, 2.0, 2.0, 2.0, 3.0, 4.0, 4.0, 2.0, 1.0, 1.0, 2.0, 4.0, 3.0, 2.0, 2.0, 4.0, 4.0, 3.0, 3.0, 2.0, 3.0, 3.0, 2.0, 4.0, 3.0, 2.0, 2.0, 2.0, 4.0, 2.0, 5.0, 3.0, 2.0, 1.0, 2.0, 0.0, 1.0, 0.0, 1.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.1337342089544275, "mean_inference_ms": 0.39071837359059286, "mean_action_processing_ms": 0.02917899853529008, "mean_env_wait_ms": 0.40369285986356696, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 1330560, "timesteps_this_iter": 0, "agent_timesteps_total": 5322240, "timers": {"sample_time_ms": 5080.277, "sample_throughput": 992.072, "load_time_ms": 0.169, "load_throughput": 29883081.934, "learn_time_ms": 126.821, "learn_throughput": 39740.92, "update_time_ms": 2.35}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 345.02349853515625, "policy_entropy": 7720.7735595703125, "policy_loss": -42.52774357795715, "vf_loss": 88.34594535827637}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 1330560, "num_agent_steps_sampled": 5322240, "num_steps_trained": 1330560, "num_agent_steps_trained": 5322240, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 2660, "training_iteration": 132, "trial_id": "71426_00000", "experiment_id": "84bca2f7b35f43248fca18d21abe2ebf", "date": "2024-06-12_03-08-33", "timestamp": 1718129313, "time_this_iter_s": 10.157179594039917, "time_total_s": 1360.0801277160645, "pid": 363902, "hostname": "DESKTOP-LQ219J4", "node_ip": "192.168.46.185", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 20, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 5000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 500, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Base_Model", "custom_model_config": {"env": "rware", "env_args": {"n_agents": 4, "column_height": 1, "max_inactivity_steps": null, "max_steps": 500, "fast_obs": true, "msg_bits": 0, "sensor_range": 1, "shelf_rows": 1, "shelf_columns": 3, "request_queue_size": 4, "reward_type": "RewardType.INDIVIDUAL", "map_name": "customized_map", "map_size": "tiny", "difficulty": "medium"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": true, "force_coop": false, "local_mode": true, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 4, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 100, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64}, "algorithm": "ia2c", "space_obs": "Dict(obs:Box([-100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100.], [100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.], (112,), float32))", "space_act": "Discrete(5)", "num_agents": 4, "episode_limit": 500, "policy_mapping_info": {"all_scenario": {"description": "rware all scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2", "agent_3"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "rware_customized_map", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 10, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.IA2CTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_il.<locals>.<lambda> at 0x7f382806e9d0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "grad_clip": 40.0, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "microbatch_size": null}, "time_since_restore": 1360.0801277160645, "timesteps_since_restore": 0, "iterations_since_restore": 132, "perf": {"cpu_util_percent": 4.2, "ram_util_percent": 69.4}}
{"episode_reward_max": 24.0, "episode_reward_min": 1.0, "episode_reward_mean": 9.1, "episode_len_mean": 500.0, "episode_media": {}, "episodes_this_iter": 20, "policy_reward_min": {"shared_policy": 0.0}, "policy_reward_max": {"shared_policy": 7.0}, "policy_reward_mean": {"shared_policy": 2.275}, "custom_metrics": {}, "hist_stats": {"episode_reward": [6.0, 9.0, 8.0, 11.0, 3.0, 13.0, 8.0, 6.0, 12.0, 3.0, 8.0, 6.0, 7.0, 7.0, 7.0, 3.0, 6.0, 3.0, 16.0, 1.0, 6.0, 5.0, 3.0, 4.0, 24.0, 4.0, 5.0, 9.0, 2.0, 7.0, 11.0, 14.0, 5.0, 8.0, 12.0, 6.0, 6.0, 13.0, 5.0, 13.0, 14.0, 7.0, 13.0, 2.0, 4.0, 3.0, 4.0, 23.0, 8.0, 7.0, 8.0, 6.0, 16.0, 14.0, 4.0, 7.0, 15.0, 5.0, 9.0, 14.0, 10.0, 10.0, 9.0, 14.0, 8.0, 20.0, 20.0, 12.0, 8.0, 11.0, 7.0, 13.0, 6.0, 11.0, 14.0, 10.0, 11.0, 13.0, 8.0, 2.0, 13.0, 10.0, 8.0, 11.0, 17.0, 9.0, 13.0, 21.0, 7.0, 7.0, 7.0, 12.0, 19.0, 6.0, 10.0, 5.0, 19.0, 2.0, 3.0, 6.0], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500], "policy_shared_policy_reward": [2.0, 1.0, 1.0, 2.0, 4.0, 1.0, 1.0, 3.0, 2.0, 2.0, 2.0, 2.0, 4.0, 3.0, 4.0, 0.0, 0.0, 1.0, 1.0, 1.0, 2.0, 3.0, 6.0, 2.0, 3.0, 3.0, 2.0, 0.0, 3.0, 2.0, 1.0, 0.0, 3.0, 4.0, 3.0, 2.0, 1.0, 0.0, 1.0, 1.0, 4.0, 2.0, 2.0, 0.0, 0.0, 1.0, 2.0, 3.0, 2.0, 2.0, 1.0, 2.0, 2.0, 0.0, 3.0, 2.0, 1.0, 3.0, 1.0, 2.0, 1.0, 0.0, 1.0, 1.0, 2.0, 1.0, 2.0, 1.0, 2.0, 0.0, 0.0, 1.0, 2.0, 5.0, 3.0, 6.0, 1.0, 0.0, 0.0, 0.0, 1.0, 2.0, 2.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 6.0, 5.0, 7.0, 6.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 2.0, 2.0, 3.0, 1.0, 3.0, 1.0, 1.0, 0.0, 0.0, 1.0, 3.0, 1.0, 2.0, 3.0, 2.0, 4.0, 2.0, 1.0, 6.0, 3.0, 4.0, 2.0, 1.0, 1.0, 1.0, 1.0, 4.0, 2.0, 1.0, 3.0, 4.0, 1.0, 4.0, 2.0, 2.0, 2.0, 0.0, 2.0, 1.0, 1.0, 2.0, 6.0, 2.0, 3.0, 2.0, 0.0, 1.0, 2.0, 2.0, 5.0, 3.0, 2.0, 3.0, 1.0, 5.0, 4.0, 4.0, 2.0, 2.0, 2.0, 1.0, 2.0, 2.0, 4.0, 5.0, 1.0, 0.0, 0.0, 1.0, 0.0, 2.0, 1.0, 1.0, 2.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 7.0, 4.0, 7.0, 5.0, 1.0, 2.0, 2.0, 3.0, 1.0, 1.0, 4.0, 1.0, 2.0, 2.0, 2.0, 2.0, 2.0, 1.0, 2.0, 1.0, 4.0, 7.0, 2.0, 3.0, 6.0, 3.0, 4.0, 1.0, 2.0, 0.0, 1.0, 1.0, 0.0, 3.0, 2.0, 2.0, 3.0, 6.0, 2.0, 4.0, 1.0, 1.0, 1.0, 2.0, 3.0, 2.0, 3.0, 1.0, 3.0, 2.0, 4.0, 5.0, 2.0, 2.0, 3.0, 3.0, 1.0, 2.0, 3.0, 4.0, 2.0, 3.0, 2.0, 2.0, 4.0, 2.0, 6.0, 2.0, 1.0, 2.0, 2.0, 3.0, 7.0, 3.0, 6.0, 4.0, 6.0, 4.0, 6.0, 4.0, 2.0, 4.0, 4.0, 2.0, 2.0, 3.0, 2.0, 1.0, 1.0, 4.0, 2.0, 4.0, 2.0, 1.0, 2.0, 2.0, 2.0, 3.0, 4.0, 4.0, 2.0, 1.0, 1.0, 2.0, 4.0, 3.0, 2.0, 2.0, 4.0, 4.0, 3.0, 3.0, 2.0, 3.0, 3.0, 2.0, 4.0, 3.0, 2.0, 2.0, 2.0, 4.0, 2.0, 5.0, 3.0, 2.0, 1.0, 2.0, 0.0, 1.0, 0.0, 1.0, 4.0, 3.0, 1.0, 5.0, 3.0, 2.0, 3.0, 2.0, 1.0, 2.0, 3.0, 2.0, 2.0, 4.0, 3.0, 2.0, 4.0, 5.0, 5.0, 3.0, 3.0, 1.0, 3.0, 2.0, 3.0, 4.0, 3.0, 3.0, 6.0, 5.0, 6.0, 4.0, 2.0, 1.0, 2.0, 2.0, 1.0, 1.0, 1.0, 4.0, 3.0, 1.0, 2.0, 1.0, 3.0, 2.0, 2.0, 5.0, 3.0, 4.0, 5.0, 7.0, 1.0, 3.0, 2.0, 0.0, 3.0, 2.0, 2.0, 3.0, 0.0, 2.0, 1.0, 2.0, 5.0, 3.0, 6.0, 5.0, 0.0, 0.0, 1.0, 1.0, 2.0, 0.0, 1.0, 0.0, 2.0, 1.0, 1.0, 2.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.1337272358684433, "mean_inference_ms": 0.3906951017711334, "mean_action_processing_ms": 0.029176649419564566, "mean_env_wait_ms": 0.4036596548625929, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 1340640, "timesteps_this_iter": 0, "agent_timesteps_total": 5362560, "timers": {"sample_time_ms": 5084.18, "sample_throughput": 991.31, "load_time_ms": 0.176, "load_throughput": 28640146.538, "learn_time_ms": 126.532, "learn_throughput": 39831.707, "update_time_ms": 2.367}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 355.5945129394531, "policy_entropy": 7645.350341796875, "policy_loss": -123.73666477203369, "vf_loss": 61.38117980957031}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 1340640, "num_agent_steps_sampled": 5362560, "num_steps_trained": 1340640, "num_agent_steps_trained": 5362560, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 2680, "training_iteration": 133, "trial_id": "71426_00000", "experiment_id": "84bca2f7b35f43248fca18d21abe2ebf", "date": "2024-06-12_03-08-43", "timestamp": 1718129323, "time_this_iter_s": 10.263447523117065, "time_total_s": 1370.3435752391815, "pid": 363902, "hostname": "DESKTOP-LQ219J4", "node_ip": "192.168.46.185", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 20, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 5000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 500, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Base_Model", "custom_model_config": {"env": "rware", "env_args": {"n_agents": 4, "column_height": 1, "max_inactivity_steps": null, "max_steps": 500, "fast_obs": true, "msg_bits": 0, "sensor_range": 1, "shelf_rows": 1, "shelf_columns": 3, "request_queue_size": 4, "reward_type": "RewardType.INDIVIDUAL", "map_name": "customized_map", "map_size": "tiny", "difficulty": "medium"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": true, "force_coop": false, "local_mode": true, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 4, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 100, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64}, "algorithm": "ia2c", "space_obs": "Dict(obs:Box([-100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100.], [100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.], (112,), float32))", "space_act": "Discrete(5)", "num_agents": 4, "episode_limit": 500, "policy_mapping_info": {"all_scenario": {"description": "rware all scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2", "agent_3"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "rware_customized_map", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 10, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.IA2CTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_il.<locals>.<lambda> at 0x7f38082f8160>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "grad_clip": 40.0, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "microbatch_size": null}, "time_since_restore": 1370.3435752391815, "timesteps_since_restore": 0, "iterations_since_restore": 133, "perf": {"cpu_util_percent": 4.164285714285715, "ram_util_percent": 69.70000000000002}}
{"episode_reward_max": 24.0, "episode_reward_min": 2.0, "episode_reward_mean": 9.79, "episode_len_mean": 500.0, "episode_media": {}, "episodes_this_iter": 20, "policy_reward_min": {"shared_policy": 0.0}, "policy_reward_max": {"shared_policy": 7.0}, "policy_reward_mean": {"shared_policy": 2.4475}, "custom_metrics": {}, "hist_stats": {"episode_reward": [6.0, 5.0, 3.0, 4.0, 24.0, 4.0, 5.0, 9.0, 2.0, 7.0, 11.0, 14.0, 5.0, 8.0, 12.0, 6.0, 6.0, 13.0, 5.0, 13.0, 14.0, 7.0, 13.0, 2.0, 4.0, 3.0, 4.0, 23.0, 8.0, 7.0, 8.0, 6.0, 16.0, 14.0, 4.0, 7.0, 15.0, 5.0, 9.0, 14.0, 10.0, 10.0, 9.0, 14.0, 8.0, 20.0, 20.0, 12.0, 8.0, 11.0, 7.0, 13.0, 6.0, 11.0, 14.0, 10.0, 11.0, 13.0, 8.0, 2.0, 13.0, 10.0, 8.0, 11.0, 17.0, 9.0, 13.0, 21.0, 7.0, 7.0, 7.0, 12.0, 19.0, 6.0, 10.0, 5.0, 19.0, 2.0, 3.0, 6.0, 13.0, 5.0, 4.0, 14.0, 16.0, 11.0, 9.0, 15.0, 10.0, 9.0, 10.0, 2.0, 9.0, 20.0, 11.0, 7.0, 12.0, 15.0, 8.0, 12.0], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500], "policy_shared_policy_reward": [1.0, 2.0, 2.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 6.0, 5.0, 7.0, 6.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 2.0, 2.0, 3.0, 1.0, 3.0, 1.0, 1.0, 0.0, 0.0, 1.0, 3.0, 1.0, 2.0, 3.0, 2.0, 4.0, 2.0, 1.0, 6.0, 3.0, 4.0, 2.0, 1.0, 1.0, 1.0, 1.0, 4.0, 2.0, 1.0, 3.0, 4.0, 1.0, 4.0, 2.0, 2.0, 2.0, 0.0, 2.0, 1.0, 1.0, 2.0, 6.0, 2.0, 3.0, 2.0, 0.0, 1.0, 2.0, 2.0, 5.0, 3.0, 2.0, 3.0, 1.0, 5.0, 4.0, 4.0, 2.0, 2.0, 2.0, 1.0, 2.0, 2.0, 4.0, 5.0, 1.0, 0.0, 0.0, 1.0, 0.0, 2.0, 1.0, 1.0, 2.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 7.0, 4.0, 7.0, 5.0, 1.0, 2.0, 2.0, 3.0, 1.0, 1.0, 4.0, 1.0, 2.0, 2.0, 2.0, 2.0, 2.0, 1.0, 2.0, 1.0, 4.0, 7.0, 2.0, 3.0, 6.0, 3.0, 4.0, 1.0, 2.0, 0.0, 1.0, 1.0, 0.0, 3.0, 2.0, 2.0, 3.0, 6.0, 2.0, 4.0, 1.0, 1.0, 1.0, 2.0, 3.0, 2.0, 3.0, 1.0, 3.0, 2.0, 4.0, 5.0, 2.0, 2.0, 3.0, 3.0, 1.0, 2.0, 3.0, 4.0, 2.0, 3.0, 2.0, 2.0, 4.0, 2.0, 6.0, 2.0, 1.0, 2.0, 2.0, 3.0, 7.0, 3.0, 6.0, 4.0, 6.0, 4.0, 6.0, 4.0, 2.0, 4.0, 4.0, 2.0, 2.0, 3.0, 2.0, 1.0, 1.0, 4.0, 2.0, 4.0, 2.0, 1.0, 2.0, 2.0, 2.0, 3.0, 4.0, 4.0, 2.0, 1.0, 1.0, 2.0, 4.0, 3.0, 2.0, 2.0, 4.0, 4.0, 3.0, 3.0, 2.0, 3.0, 3.0, 2.0, 4.0, 3.0, 2.0, 2.0, 2.0, 4.0, 2.0, 5.0, 3.0, 2.0, 1.0, 2.0, 0.0, 1.0, 0.0, 1.0, 4.0, 3.0, 1.0, 5.0, 3.0, 2.0, 3.0, 2.0, 1.0, 2.0, 3.0, 2.0, 2.0, 4.0, 3.0, 2.0, 4.0, 5.0, 5.0, 3.0, 3.0, 1.0, 3.0, 2.0, 3.0, 4.0, 3.0, 3.0, 6.0, 5.0, 6.0, 4.0, 2.0, 1.0, 2.0, 2.0, 1.0, 1.0, 1.0, 4.0, 3.0, 1.0, 2.0, 1.0, 3.0, 2.0, 2.0, 5.0, 3.0, 4.0, 5.0, 7.0, 1.0, 3.0, 2.0, 0.0, 3.0, 2.0, 2.0, 3.0, 0.0, 2.0, 1.0, 2.0, 5.0, 3.0, 6.0, 5.0, 0.0, 0.0, 1.0, 1.0, 2.0, 0.0, 1.0, 0.0, 2.0, 1.0, 1.0, 2.0, 4.0, 5.0, 1.0, 3.0, 2.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 2.0, 4.0, 3.0, 3.0, 4.0, 2.0, 5.0, 3.0, 6.0, 3.0, 2.0, 4.0, 2.0, 4.0, 1.0, 2.0, 2.0, 4.0, 3.0, 5.0, 3.0, 2.0, 3.0, 3.0, 2.0, 3.0, 3.0, 1.0, 2.0, 3.0, 5.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 3.0, 2.0, 2.0, 2.0, 4.0, 4.0, 6.0, 6.0, 3.0, 3.0, 2.0, 3.0, 2.0, 1.0, 3.0, 1.0, 4.0, 3.0, 3.0, 2.0, 5.0, 6.0, 1.0, 3.0, 2.0, 2.0, 1.0, 3.0, 3.0, 3.0, 4.0, 2.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.1337202398346477, "mean_inference_ms": 0.3906695029629452, "mean_action_processing_ms": 0.02917420132935475, "mean_env_wait_ms": 0.4036297948722942, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 1350720, "timesteps_this_iter": 0, "agent_timesteps_total": 5402880, "timers": {"sample_time_ms": 5081.739, "sample_throughput": 991.786, "load_time_ms": 0.174, "load_throughput": 28934152.97, "learn_time_ms": 125.858, "learn_throughput": 40045.199, "update_time_ms": 2.372}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 280.8773498535156, "policy_entropy": 7593.9832763671875, "policy_loss": 47.79732322692871, "vf_loss": 93.6639633178711}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 1350720, "num_agent_steps_sampled": 5402880, "num_steps_trained": 1350720, "num_agent_steps_trained": 5402880, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 2700, "training_iteration": 134, "trial_id": "71426_00000", "experiment_id": "84bca2f7b35f43248fca18d21abe2ebf", "date": "2024-06-12_03-08-53", "timestamp": 1718129333, "time_this_iter_s": 10.065123796463013, "time_total_s": 1380.4086990356445, "pid": 363902, "hostname": "DESKTOP-LQ219J4", "node_ip": "192.168.46.185", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 20, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 5000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 500, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Base_Model", "custom_model_config": {"env": "rware", "env_args": {"n_agents": 4, "column_height": 1, "max_inactivity_steps": null, "max_steps": 500, "fast_obs": true, "msg_bits": 0, "sensor_range": 1, "shelf_rows": 1, "shelf_columns": 3, "request_queue_size": 4, "reward_type": "RewardType.INDIVIDUAL", "map_name": "customized_map", "map_size": "tiny", "difficulty": "medium"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": true, "force_coop": false, "local_mode": true, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 4, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 100, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64}, "algorithm": "ia2c", "space_obs": "Dict(obs:Box([-100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100.], [100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.], (112,), float32))", "space_act": "Discrete(5)", "num_agents": 4, "episode_limit": 500, "policy_mapping_info": {"all_scenario": {"description": "rware all scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2", "agent_3"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "rware_customized_map", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 10, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.IA2CTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_il.<locals>.<lambda> at 0x7f38081a9a60>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "grad_clip": 40.0, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "microbatch_size": null}, "time_since_restore": 1380.4086990356445, "timesteps_since_restore": 0, "iterations_since_restore": 134, "perf": {"cpu_util_percent": 4.24, "ram_util_percent": 70.0}}
{"episode_reward_max": 23.0, "episode_reward_min": 2.0, "episode_reward_mean": 10.13, "episode_len_mean": 500.0, "episode_media": {}, "episodes_this_iter": 20, "policy_reward_min": {"shared_policy": 0.0}, "policy_reward_max": {"shared_policy": 7.0}, "policy_reward_mean": {"shared_policy": 2.5325}, "custom_metrics": {}, "hist_stats": {"episode_reward": [14.0, 7.0, 13.0, 2.0, 4.0, 3.0, 4.0, 23.0, 8.0, 7.0, 8.0, 6.0, 16.0, 14.0, 4.0, 7.0, 15.0, 5.0, 9.0, 14.0, 10.0, 10.0, 9.0, 14.0, 8.0, 20.0, 20.0, 12.0, 8.0, 11.0, 7.0, 13.0, 6.0, 11.0, 14.0, 10.0, 11.0, 13.0, 8.0, 2.0, 13.0, 10.0, 8.0, 11.0, 17.0, 9.0, 13.0, 21.0, 7.0, 7.0, 7.0, 12.0, 19.0, 6.0, 10.0, 5.0, 19.0, 2.0, 3.0, 6.0, 13.0, 5.0, 4.0, 14.0, 16.0, 11.0, 9.0, 15.0, 10.0, 9.0, 10.0, 2.0, 9.0, 20.0, 11.0, 7.0, 12.0, 15.0, 8.0, 12.0, 18.0, 6.0, 17.0, 4.0, 13.0, 12.0, 12.0, 8.0, 4.0, 15.0, 8.0, 5.0, 15.0, 4.0, 8.0, 11.0, 5.0, 13.0, 10.0, 8.0], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500], "policy_shared_policy_reward": [1.0, 5.0, 4.0, 4.0, 2.0, 2.0, 2.0, 1.0, 2.0, 2.0, 4.0, 5.0, 1.0, 0.0, 0.0, 1.0, 0.0, 2.0, 1.0, 1.0, 2.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 7.0, 4.0, 7.0, 5.0, 1.0, 2.0, 2.0, 3.0, 1.0, 1.0, 4.0, 1.0, 2.0, 2.0, 2.0, 2.0, 2.0, 1.0, 2.0, 1.0, 4.0, 7.0, 2.0, 3.0, 6.0, 3.0, 4.0, 1.0, 2.0, 0.0, 1.0, 1.0, 0.0, 3.0, 2.0, 2.0, 3.0, 6.0, 2.0, 4.0, 1.0, 1.0, 1.0, 2.0, 3.0, 2.0, 3.0, 1.0, 3.0, 2.0, 4.0, 5.0, 2.0, 2.0, 3.0, 3.0, 1.0, 2.0, 3.0, 4.0, 2.0, 3.0, 2.0, 2.0, 4.0, 2.0, 6.0, 2.0, 1.0, 2.0, 2.0, 3.0, 7.0, 3.0, 6.0, 4.0, 6.0, 4.0, 6.0, 4.0, 2.0, 4.0, 4.0, 2.0, 2.0, 3.0, 2.0, 1.0, 1.0, 4.0, 2.0, 4.0, 2.0, 1.0, 2.0, 2.0, 2.0, 3.0, 4.0, 4.0, 2.0, 1.0, 1.0, 2.0, 4.0, 3.0, 2.0, 2.0, 4.0, 4.0, 3.0, 3.0, 2.0, 3.0, 3.0, 2.0, 4.0, 3.0, 2.0, 2.0, 2.0, 4.0, 2.0, 5.0, 3.0, 2.0, 1.0, 2.0, 0.0, 1.0, 0.0, 1.0, 4.0, 3.0, 1.0, 5.0, 3.0, 2.0, 3.0, 2.0, 1.0, 2.0, 3.0, 2.0, 2.0, 4.0, 3.0, 2.0, 4.0, 5.0, 5.0, 3.0, 3.0, 1.0, 3.0, 2.0, 3.0, 4.0, 3.0, 3.0, 6.0, 5.0, 6.0, 4.0, 2.0, 1.0, 2.0, 2.0, 1.0, 1.0, 1.0, 4.0, 3.0, 1.0, 2.0, 1.0, 3.0, 2.0, 2.0, 5.0, 3.0, 4.0, 5.0, 7.0, 1.0, 3.0, 2.0, 0.0, 3.0, 2.0, 2.0, 3.0, 0.0, 2.0, 1.0, 2.0, 5.0, 3.0, 6.0, 5.0, 0.0, 0.0, 1.0, 1.0, 2.0, 0.0, 1.0, 0.0, 2.0, 1.0, 1.0, 2.0, 4.0, 5.0, 1.0, 3.0, 2.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 2.0, 4.0, 3.0, 3.0, 4.0, 2.0, 5.0, 3.0, 6.0, 3.0, 2.0, 4.0, 2.0, 4.0, 1.0, 2.0, 2.0, 4.0, 3.0, 5.0, 3.0, 2.0, 3.0, 3.0, 2.0, 3.0, 3.0, 1.0, 2.0, 3.0, 5.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 3.0, 2.0, 2.0, 2.0, 4.0, 4.0, 6.0, 6.0, 3.0, 3.0, 2.0, 3.0, 2.0, 1.0, 3.0, 1.0, 4.0, 3.0, 3.0, 2.0, 5.0, 6.0, 1.0, 3.0, 2.0, 2.0, 1.0, 3.0, 3.0, 3.0, 4.0, 2.0, 5.0, 5.0, 4.0, 4.0, 2.0, 1.0, 1.0, 2.0, 4.0, 4.0, 3.0, 6.0, 1.0, 1.0, 1.0, 1.0, 3.0, 2.0, 4.0, 4.0, 3.0, 2.0, 3.0, 4.0, 3.0, 4.0, 3.0, 2.0, 1.0, 1.0, 3.0, 3.0, 0.0, 2.0, 1.0, 1.0, 4.0, 6.0, 2.0, 3.0, 2.0, 1.0, 3.0, 2.0, 1.0, 1.0, 2.0, 1.0, 3.0, 6.0, 4.0, 2.0, 1.0, 1.0, 1.0, 1.0, 2.0, 4.0, 1.0, 1.0, 3.0, 3.0, 3.0, 2.0, 1.0, 1.0, 2.0, 1.0, 2.0, 5.0, 4.0, 2.0, 3.0, 2.0, 2.0, 3.0, 1.0, 2.0, 3.0, 2.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.13371826544453216, "mean_inference_ms": 0.39065713467574414, "mean_action_processing_ms": 0.029172626656693547, "mean_env_wait_ms": 0.4036115450091855, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 1360800, "timesteps_this_iter": 0, "agent_timesteps_total": 5443200, "timers": {"sample_time_ms": 5104.116, "sample_throughput": 987.438, "load_time_ms": 0.194, "load_throughput": 26007987.402, "learn_time_ms": 125.975, "learn_throughput": 40007.995, "update_time_ms": 2.424}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 561.1312255859375, "policy_entropy": 7654.458251953125, "policy_loss": -163.11377811431885, "vf_loss": 64.07302665710449}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 1360800, "num_agent_steps_sampled": 5443200, "num_steps_trained": 1360800, "num_agent_steps_trained": 5443200, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 2720, "training_iteration": 135, "trial_id": "71426_00000", "experiment_id": "84bca2f7b35f43248fca18d21abe2ebf", "date": "2024-06-12_03-09-03", "timestamp": 1718129343, "time_this_iter_s": 10.338432788848877, "time_total_s": 1390.7471318244934, "pid": 363902, "hostname": "DESKTOP-LQ219J4", "node_ip": "192.168.46.185", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 20, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 5000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 500, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Base_Model", "custom_model_config": {"env": "rware", "env_args": {"n_agents": 4, "column_height": 1, "max_inactivity_steps": null, "max_steps": 500, "fast_obs": true, "msg_bits": 0, "sensor_range": 1, "shelf_rows": 1, "shelf_columns": 3, "request_queue_size": 4, "reward_type": "RewardType.INDIVIDUAL", "map_name": "customized_map", "map_size": "tiny", "difficulty": "medium"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": true, "force_coop": false, "local_mode": true, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 4, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 100, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64}, "algorithm": "ia2c", "space_obs": "Dict(obs:Box([-100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100.], [100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.], (112,), float32))", "space_act": "Discrete(5)", "num_agents": 4, "episode_limit": 500, "policy_mapping_info": {"all_scenario": {"description": "rware all scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2", "agent_3"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "rware_customized_map", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 10, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.IA2CTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_il.<locals>.<lambda> at 0x7f38081d5f70>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "grad_clip": 40.0, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "microbatch_size": null}, "time_since_restore": 1390.7471318244934, "timesteps_since_restore": 0, "iterations_since_restore": 135, "perf": {"cpu_util_percent": 4.328571428571428, "ram_util_percent": 70.24999999999999}}
{"episode_reward_max": 21.0, "episode_reward_min": 2.0, "episode_reward_mean": 10.19, "episode_len_mean": 500.0, "episode_media": {}, "episodes_this_iter": 20, "policy_reward_min": {"shared_policy": 0.0}, "policy_reward_max": {"shared_policy": 7.0}, "policy_reward_mean": {"shared_policy": 2.5475}, "custom_metrics": {}, "hist_stats": {"episode_reward": [10.0, 10.0, 9.0, 14.0, 8.0, 20.0, 20.0, 12.0, 8.0, 11.0, 7.0, 13.0, 6.0, 11.0, 14.0, 10.0, 11.0, 13.0, 8.0, 2.0, 13.0, 10.0, 8.0, 11.0, 17.0, 9.0, 13.0, 21.0, 7.0, 7.0, 7.0, 12.0, 19.0, 6.0, 10.0, 5.0, 19.0, 2.0, 3.0, 6.0, 13.0, 5.0, 4.0, 14.0, 16.0, 11.0, 9.0, 15.0, 10.0, 9.0, 10.0, 2.0, 9.0, 20.0, 11.0, 7.0, 12.0, 15.0, 8.0, 12.0, 18.0, 6.0, 17.0, 4.0, 13.0, 12.0, 12.0, 8.0, 4.0, 15.0, 8.0, 5.0, 15.0, 4.0, 8.0, 11.0, 5.0, 13.0, 10.0, 8.0, 6.0, 15.0, 9.0, 17.0, 10.0, 9.0, 6.0, 17.0, 13.0, 9.0, 4.0, 4.0, 7.0, 9.0, 8.0, 2.0, 10.0, 14.0, 7.0, 13.0], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500], "policy_shared_policy_reward": [2.0, 2.0, 3.0, 3.0, 1.0, 2.0, 3.0, 4.0, 2.0, 3.0, 2.0, 2.0, 4.0, 2.0, 6.0, 2.0, 1.0, 2.0, 2.0, 3.0, 7.0, 3.0, 6.0, 4.0, 6.0, 4.0, 6.0, 4.0, 2.0, 4.0, 4.0, 2.0, 2.0, 3.0, 2.0, 1.0, 1.0, 4.0, 2.0, 4.0, 2.0, 1.0, 2.0, 2.0, 2.0, 3.0, 4.0, 4.0, 2.0, 1.0, 1.0, 2.0, 4.0, 3.0, 2.0, 2.0, 4.0, 4.0, 3.0, 3.0, 2.0, 3.0, 3.0, 2.0, 4.0, 3.0, 2.0, 2.0, 2.0, 4.0, 2.0, 5.0, 3.0, 2.0, 1.0, 2.0, 0.0, 1.0, 0.0, 1.0, 4.0, 3.0, 1.0, 5.0, 3.0, 2.0, 3.0, 2.0, 1.0, 2.0, 3.0, 2.0, 2.0, 4.0, 3.0, 2.0, 4.0, 5.0, 5.0, 3.0, 3.0, 1.0, 3.0, 2.0, 3.0, 4.0, 3.0, 3.0, 6.0, 5.0, 6.0, 4.0, 2.0, 1.0, 2.0, 2.0, 1.0, 1.0, 1.0, 4.0, 3.0, 1.0, 2.0, 1.0, 3.0, 2.0, 2.0, 5.0, 3.0, 4.0, 5.0, 7.0, 1.0, 3.0, 2.0, 0.0, 3.0, 2.0, 2.0, 3.0, 0.0, 2.0, 1.0, 2.0, 5.0, 3.0, 6.0, 5.0, 0.0, 0.0, 1.0, 1.0, 2.0, 0.0, 1.0, 0.0, 2.0, 1.0, 1.0, 2.0, 4.0, 5.0, 1.0, 3.0, 2.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 2.0, 4.0, 3.0, 3.0, 4.0, 2.0, 5.0, 3.0, 6.0, 3.0, 2.0, 4.0, 2.0, 4.0, 1.0, 2.0, 2.0, 4.0, 3.0, 5.0, 3.0, 2.0, 3.0, 3.0, 2.0, 3.0, 3.0, 1.0, 2.0, 3.0, 5.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 3.0, 2.0, 2.0, 2.0, 4.0, 4.0, 6.0, 6.0, 3.0, 3.0, 2.0, 3.0, 2.0, 1.0, 3.0, 1.0, 4.0, 3.0, 3.0, 2.0, 5.0, 6.0, 1.0, 3.0, 2.0, 2.0, 1.0, 3.0, 3.0, 3.0, 4.0, 2.0, 5.0, 5.0, 4.0, 4.0, 2.0, 1.0, 1.0, 2.0, 4.0, 4.0, 3.0, 6.0, 1.0, 1.0, 1.0, 1.0, 3.0, 2.0, 4.0, 4.0, 3.0, 2.0, 3.0, 4.0, 3.0, 4.0, 3.0, 2.0, 1.0, 1.0, 3.0, 3.0, 0.0, 2.0, 1.0, 1.0, 4.0, 6.0, 2.0, 3.0, 2.0, 1.0, 3.0, 2.0, 1.0, 1.0, 2.0, 1.0, 3.0, 6.0, 4.0, 2.0, 1.0, 1.0, 1.0, 1.0, 2.0, 4.0, 1.0, 1.0, 3.0, 3.0, 3.0, 2.0, 1.0, 1.0, 2.0, 1.0, 2.0, 5.0, 4.0, 2.0, 3.0, 2.0, 2.0, 3.0, 1.0, 2.0, 3.0, 2.0, 2.0, 1.0, 1.0, 2.0, 3.0, 3.0, 6.0, 3.0, 1.0, 2.0, 3.0, 3.0, 3.0, 3.0, 6.0, 5.0, 2.0, 3.0, 3.0, 2.0, 2.0, 2.0, 3.0, 2.0, 2.0, 2.0, 0.0, 2.0, 5.0, 3.0, 3.0, 6.0, 3.0, 2.0, 4.0, 4.0, 1.0, 1.0, 3.0, 4.0, 1.0, 2.0, 0.0, 1.0, 2.0, 1.0, 1.0, 0.0, 2.0, 1.0, 3.0, 1.0, 3.0, 2.0, 1.0, 3.0, 2.0, 2.0, 3.0, 1.0, 1.0, 0.0, 0.0, 1.0, 3.0, 3.0, 2.0, 2.0, 5.0, 4.0, 3.0, 2.0, 1.0, 3.0, 1.0, 2.0, 3.0, 2.0, 3.0, 5.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.13371663062185474, "mean_inference_ms": 0.39064819871565426, "mean_action_processing_ms": 0.029171284513245244, "mean_env_wait_ms": 0.4035947143264535, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 1370880, "timesteps_this_iter": 0, "agent_timesteps_total": 5483520, "timers": {"sample_time_ms": 5106.037, "sample_throughput": 987.067, "load_time_ms": 0.184, "load_throughput": 27386050.214, "learn_time_ms": 126.647, "learn_throughput": 39795.564, "update_time_ms": 2.447}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 215.90342712402344, "policy_entropy": 7653.2044677734375, "policy_loss": 29.722249746322632, "vf_loss": 92.77775001525879}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 1370880, "num_agent_steps_sampled": 5483520, "num_steps_trained": 1370880, "num_agent_steps_trained": 5483520, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 2740, "training_iteration": 136, "trial_id": "71426_00000", "experiment_id": "84bca2f7b35f43248fca18d21abe2ebf", "date": "2024-06-12_03-09-14", "timestamp": 1718129354, "time_this_iter_s": 10.161053657531738, "time_total_s": 1400.9081854820251, "pid": 363902, "hostname": "DESKTOP-LQ219J4", "node_ip": "192.168.46.185", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 20, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 5000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 500, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Base_Model", "custom_model_config": {"env": "rware", "env_args": {"n_agents": 4, "column_height": 1, "max_inactivity_steps": null, "max_steps": 500, "fast_obs": true, "msg_bits": 0, "sensor_range": 1, "shelf_rows": 1, "shelf_columns": 3, "request_queue_size": 4, "reward_type": "RewardType.INDIVIDUAL", "map_name": "customized_map", "map_size": "tiny", "difficulty": "medium"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": true, "force_coop": false, "local_mode": true, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 4, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 100, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64}, "algorithm": "ia2c", "space_obs": "Dict(obs:Box([-100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100.], [100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.], (112,), float32))", "space_act": "Discrete(5)", "num_agents": 4, "episode_limit": 500, "policy_mapping_info": {"all_scenario": {"description": "rware all scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2", "agent_3"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "rware_customized_map", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 10, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.IA2CTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_il.<locals>.<lambda> at 0x7f38081a93a0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "grad_clip": 40.0, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "microbatch_size": null}, "time_since_restore": 1400.9081854820251, "timesteps_since_restore": 0, "iterations_since_restore": 136, "perf": {"cpu_util_percent": 4.2, "ram_util_percent": 70.56}}
{"episode_reward_max": 21.0, "episode_reward_min": 1.0, "episode_reward_mean": 9.79, "episode_len_mean": 500.0, "episode_media": {}, "episodes_this_iter": 20, "policy_reward_min": {"shared_policy": 0.0}, "policy_reward_max": {"shared_policy": 7.0}, "policy_reward_mean": {"shared_policy": 2.4475}, "custom_metrics": {}, "hist_stats": {"episode_reward": [13.0, 10.0, 8.0, 11.0, 17.0, 9.0, 13.0, 21.0, 7.0, 7.0, 7.0, 12.0, 19.0, 6.0, 10.0, 5.0, 19.0, 2.0, 3.0, 6.0, 13.0, 5.0, 4.0, 14.0, 16.0, 11.0, 9.0, 15.0, 10.0, 9.0, 10.0, 2.0, 9.0, 20.0, 11.0, 7.0, 12.0, 15.0, 8.0, 12.0, 18.0, 6.0, 17.0, 4.0, 13.0, 12.0, 12.0, 8.0, 4.0, 15.0, 8.0, 5.0, 15.0, 4.0, 8.0, 11.0, 5.0, 13.0, 10.0, 8.0, 6.0, 15.0, 9.0, 17.0, 10.0, 9.0, 6.0, 17.0, 13.0, 9.0, 4.0, 4.0, 7.0, 9.0, 8.0, 2.0, 10.0, 14.0, 7.0, 13.0, 11.0, 5.0, 10.0, 11.0, 5.0, 10.0, 10.0, 7.0, 10.0, 5.0, 5.0, 12.0, 19.0, 1.0, 13.0, 10.0, 3.0, 14.0, 12.0, 4.0], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500], "policy_shared_policy_reward": [4.0, 3.0, 1.0, 5.0, 3.0, 2.0, 3.0, 2.0, 1.0, 2.0, 3.0, 2.0, 2.0, 4.0, 3.0, 2.0, 4.0, 5.0, 5.0, 3.0, 3.0, 1.0, 3.0, 2.0, 3.0, 4.0, 3.0, 3.0, 6.0, 5.0, 6.0, 4.0, 2.0, 1.0, 2.0, 2.0, 1.0, 1.0, 1.0, 4.0, 3.0, 1.0, 2.0, 1.0, 3.0, 2.0, 2.0, 5.0, 3.0, 4.0, 5.0, 7.0, 1.0, 3.0, 2.0, 0.0, 3.0, 2.0, 2.0, 3.0, 0.0, 2.0, 1.0, 2.0, 5.0, 3.0, 6.0, 5.0, 0.0, 0.0, 1.0, 1.0, 2.0, 0.0, 1.0, 0.0, 2.0, 1.0, 1.0, 2.0, 4.0, 5.0, 1.0, 3.0, 2.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 2.0, 4.0, 3.0, 3.0, 4.0, 2.0, 5.0, 3.0, 6.0, 3.0, 2.0, 4.0, 2.0, 4.0, 1.0, 2.0, 2.0, 4.0, 3.0, 5.0, 3.0, 2.0, 3.0, 3.0, 2.0, 3.0, 3.0, 1.0, 2.0, 3.0, 5.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 3.0, 2.0, 2.0, 2.0, 4.0, 4.0, 6.0, 6.0, 3.0, 3.0, 2.0, 3.0, 2.0, 1.0, 3.0, 1.0, 4.0, 3.0, 3.0, 2.0, 5.0, 6.0, 1.0, 3.0, 2.0, 2.0, 1.0, 3.0, 3.0, 3.0, 4.0, 2.0, 5.0, 5.0, 4.0, 4.0, 2.0, 1.0, 1.0, 2.0, 4.0, 4.0, 3.0, 6.0, 1.0, 1.0, 1.0, 1.0, 3.0, 2.0, 4.0, 4.0, 3.0, 2.0, 3.0, 4.0, 3.0, 4.0, 3.0, 2.0, 1.0, 1.0, 3.0, 3.0, 0.0, 2.0, 1.0, 1.0, 4.0, 6.0, 2.0, 3.0, 2.0, 1.0, 3.0, 2.0, 1.0, 1.0, 2.0, 1.0, 3.0, 6.0, 4.0, 2.0, 1.0, 1.0, 1.0, 1.0, 2.0, 4.0, 1.0, 1.0, 3.0, 3.0, 3.0, 2.0, 1.0, 1.0, 2.0, 1.0, 2.0, 5.0, 4.0, 2.0, 3.0, 2.0, 2.0, 3.0, 1.0, 2.0, 3.0, 2.0, 2.0, 1.0, 1.0, 2.0, 3.0, 3.0, 6.0, 3.0, 1.0, 2.0, 3.0, 3.0, 3.0, 3.0, 6.0, 5.0, 2.0, 3.0, 3.0, 2.0, 2.0, 2.0, 3.0, 2.0, 2.0, 2.0, 0.0, 2.0, 5.0, 3.0, 3.0, 6.0, 3.0, 2.0, 4.0, 4.0, 1.0, 1.0, 3.0, 4.0, 1.0, 2.0, 0.0, 1.0, 2.0, 1.0, 1.0, 0.0, 2.0, 1.0, 3.0, 1.0, 3.0, 2.0, 1.0, 3.0, 2.0, 2.0, 3.0, 1.0, 1.0, 0.0, 0.0, 1.0, 3.0, 3.0, 2.0, 2.0, 5.0, 4.0, 3.0, 2.0, 1.0, 3.0, 1.0, 2.0, 3.0, 2.0, 3.0, 5.0, 2.0, 4.0, 3.0, 2.0, 1.0, 2.0, 1.0, 1.0, 3.0, 3.0, 2.0, 2.0, 4.0, 2.0, 3.0, 2.0, 1.0, 1.0, 2.0, 1.0, 2.0, 2.0, 3.0, 3.0, 3.0, 2.0, 2.0, 3.0, 2.0, 3.0, 1.0, 1.0, 3.0, 3.0, 1.0, 3.0, 1.0, 0.0, 1.0, 3.0, 1.0, 1.0, 1.0, 2.0, 3.0, 3.0, 3.0, 3.0, 7.0, 4.0, 5.0, 3.0, 1.0, 0.0, 0.0, 0.0, 4.0, 4.0, 2.0, 3.0, 4.0, 1.0, 1.0, 4.0, 1.0, 0.0, 1.0, 1.0, 4.0, 4.0, 5.0, 1.0, 3.0, 3.0, 3.0, 3.0, 1.0, 1.0, 2.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.1337139068999055, "mean_inference_ms": 0.39063542776518995, "mean_action_processing_ms": 0.02916973380390612, "mean_env_wait_ms": 0.40357203626622007, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 1380960, "timesteps_this_iter": 0, "agent_timesteps_total": 5523840, "timers": {"sample_time_ms": 5098.673, "sample_throughput": 988.492, "load_time_ms": 0.184, "load_throughput": 27432250.402, "learn_time_ms": 127.261, "learn_throughput": 39603.755, "update_time_ms": 2.431}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 300.7337646484375, "policy_entropy": 7709.63916015625, "policy_loss": -19.528789520263672, "vf_loss": 66.4610538482666}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 1380960, "num_agent_steps_sampled": 5523840, "num_steps_trained": 1380960, "num_agent_steps_trained": 5523840, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 2760, "training_iteration": 137, "trial_id": "71426_00000", "experiment_id": "84bca2f7b35f43248fca18d21abe2ebf", "date": "2024-06-12_03-09-24", "timestamp": 1718129364, "time_this_iter_s": 10.084209203720093, "time_total_s": 1410.9923946857452, "pid": 363902, "hostname": "DESKTOP-LQ219J4", "node_ip": "192.168.46.185", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 20, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 5000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 500, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Base_Model", "custom_model_config": {"env": "rware", "env_args": {"n_agents": 4, "column_height": 1, "max_inactivity_steps": null, "max_steps": 500, "fast_obs": true, "msg_bits": 0, "sensor_range": 1, "shelf_rows": 1, "shelf_columns": 3, "request_queue_size": 4, "reward_type": "RewardType.INDIVIDUAL", "map_name": "customized_map", "map_size": "tiny", "difficulty": "medium"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": true, "force_coop": false, "local_mode": true, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 4, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 100, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64}, "algorithm": "ia2c", "space_obs": "Dict(obs:Box([-100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100.], [100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.], (112,), float32))", "space_act": "Discrete(5)", "num_agents": 4, "episode_limit": 500, "policy_mapping_info": {"all_scenario": {"description": "rware all scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2", "agent_3"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "rware_customized_map", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 10, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.IA2CTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_il.<locals>.<lambda> at 0x7f38086c1d30>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "grad_clip": 40.0, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "microbatch_size": null}, "time_since_restore": 1410.9923946857452, "timesteps_since_restore": 0, "iterations_since_restore": 137, "perf": {"cpu_util_percent": 4.121428571428571, "ram_util_percent": 70.79999999999998}}
{"episode_reward_max": 20.0, "episode_reward_min": 1.0, "episode_reward_mean": 9.91, "episode_len_mean": 500.0, "episode_media": {}, "episodes_this_iter": 20, "policy_reward_min": {"shared_policy": 0.0}, "policy_reward_max": {"shared_policy": 7.0}, "policy_reward_mean": {"shared_policy": 2.4775}, "custom_metrics": {}, "hist_stats": {"episode_reward": [13.0, 5.0, 4.0, 14.0, 16.0, 11.0, 9.0, 15.0, 10.0, 9.0, 10.0, 2.0, 9.0, 20.0, 11.0, 7.0, 12.0, 15.0, 8.0, 12.0, 18.0, 6.0, 17.0, 4.0, 13.0, 12.0, 12.0, 8.0, 4.0, 15.0, 8.0, 5.0, 15.0, 4.0, 8.0, 11.0, 5.0, 13.0, 10.0, 8.0, 6.0, 15.0, 9.0, 17.0, 10.0, 9.0, 6.0, 17.0, 13.0, 9.0, 4.0, 4.0, 7.0, 9.0, 8.0, 2.0, 10.0, 14.0, 7.0, 13.0, 11.0, 5.0, 10.0, 11.0, 5.0, 10.0, 10.0, 7.0, 10.0, 5.0, 5.0, 12.0, 19.0, 1.0, 13.0, 10.0, 3.0, 14.0, 12.0, 4.0, 6.0, 14.0, 12.0, 9.0, 10.0, 10.0, 11.0, 9.0, 8.0, 18.0, 9.0, 9.0, 19.0, 7.0, 11.0, 11.0, 16.0, 6.0, 14.0, 8.0], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500], "policy_shared_policy_reward": [4.0, 5.0, 1.0, 3.0, 2.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 2.0, 4.0, 3.0, 3.0, 4.0, 2.0, 5.0, 3.0, 6.0, 3.0, 2.0, 4.0, 2.0, 4.0, 1.0, 2.0, 2.0, 4.0, 3.0, 5.0, 3.0, 2.0, 3.0, 3.0, 2.0, 3.0, 3.0, 1.0, 2.0, 3.0, 5.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 3.0, 2.0, 2.0, 2.0, 4.0, 4.0, 6.0, 6.0, 3.0, 3.0, 2.0, 3.0, 2.0, 1.0, 3.0, 1.0, 4.0, 3.0, 3.0, 2.0, 5.0, 6.0, 1.0, 3.0, 2.0, 2.0, 1.0, 3.0, 3.0, 3.0, 4.0, 2.0, 5.0, 5.0, 4.0, 4.0, 2.0, 1.0, 1.0, 2.0, 4.0, 4.0, 3.0, 6.0, 1.0, 1.0, 1.0, 1.0, 3.0, 2.0, 4.0, 4.0, 3.0, 2.0, 3.0, 4.0, 3.0, 4.0, 3.0, 2.0, 1.0, 1.0, 3.0, 3.0, 0.0, 2.0, 1.0, 1.0, 4.0, 6.0, 2.0, 3.0, 2.0, 1.0, 3.0, 2.0, 1.0, 1.0, 2.0, 1.0, 3.0, 6.0, 4.0, 2.0, 1.0, 1.0, 1.0, 1.0, 2.0, 4.0, 1.0, 1.0, 3.0, 3.0, 3.0, 2.0, 1.0, 1.0, 2.0, 1.0, 2.0, 5.0, 4.0, 2.0, 3.0, 2.0, 2.0, 3.0, 1.0, 2.0, 3.0, 2.0, 2.0, 1.0, 1.0, 2.0, 3.0, 3.0, 6.0, 3.0, 1.0, 2.0, 3.0, 3.0, 3.0, 3.0, 6.0, 5.0, 2.0, 3.0, 3.0, 2.0, 2.0, 2.0, 3.0, 2.0, 2.0, 2.0, 0.0, 2.0, 5.0, 3.0, 3.0, 6.0, 3.0, 2.0, 4.0, 4.0, 1.0, 1.0, 3.0, 4.0, 1.0, 2.0, 0.0, 1.0, 2.0, 1.0, 1.0, 0.0, 2.0, 1.0, 3.0, 1.0, 3.0, 2.0, 1.0, 3.0, 2.0, 2.0, 3.0, 1.0, 1.0, 0.0, 0.0, 1.0, 3.0, 3.0, 2.0, 2.0, 5.0, 4.0, 3.0, 2.0, 1.0, 3.0, 1.0, 2.0, 3.0, 2.0, 3.0, 5.0, 2.0, 4.0, 3.0, 2.0, 1.0, 2.0, 1.0, 1.0, 3.0, 3.0, 2.0, 2.0, 4.0, 2.0, 3.0, 2.0, 1.0, 1.0, 2.0, 1.0, 2.0, 2.0, 3.0, 3.0, 3.0, 2.0, 2.0, 3.0, 2.0, 3.0, 1.0, 1.0, 3.0, 3.0, 1.0, 3.0, 1.0, 0.0, 1.0, 3.0, 1.0, 1.0, 1.0, 2.0, 3.0, 3.0, 3.0, 3.0, 7.0, 4.0, 5.0, 3.0, 1.0, 0.0, 0.0, 0.0, 4.0, 4.0, 2.0, 3.0, 4.0, 1.0, 1.0, 4.0, 1.0, 0.0, 1.0, 1.0, 4.0, 4.0, 5.0, 1.0, 3.0, 3.0, 3.0, 3.0, 1.0, 1.0, 2.0, 0.0, 2.0, 1.0, 2.0, 1.0, 2.0, 4.0, 4.0, 4.0, 4.0, 4.0, 3.0, 1.0, 1.0, 3.0, 3.0, 2.0, 3.0, 2.0, 4.0, 1.0, 1.0, 2.0, 3.0, 4.0, 2.0, 3.0, 3.0, 3.0, 3.0, 1.0, 3.0, 2.0, 2.0, 2.0, 1.0, 3.0, 3.0, 5.0, 5.0, 5.0, 3.0, 2.0, 2.0, 2.0, 2.0, 2.0, 3.0, 2.0, 6.0, 3.0, 3.0, 7.0, 2.0, 1.0, 2.0, 2.0, 3.0, 3.0, 3.0, 2.0, 2.0, 3.0, 3.0, 3.0, 4.0, 3.0, 5.0, 4.0, 2.0, 1.0, 2.0, 1.0, 3.0, 3.0, 4.0, 4.0, 3.0, 3.0, 1.0, 1.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.1337085251728111, "mean_inference_ms": 0.3906194536537441, "mean_action_processing_ms": 0.029167767546633937, "mean_env_wait_ms": 0.4035311846647282, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 1391040, "timesteps_this_iter": 0, "agent_timesteps_total": 5564160, "timers": {"sample_time_ms": 5081.092, "sample_throughput": 991.913, "load_time_ms": 0.179, "load_throughput": 28099550.924, "learn_time_ms": 127.059, "learn_throughput": 39666.602, "update_time_ms": 2.437}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 258.3744812011719, "policy_entropy": 7719.5479736328125, "policy_loss": 55.46802854537964, "vf_loss": 73.16841220855713}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 1391040, "num_agent_steps_sampled": 5564160, "num_steps_trained": 1391040, "num_agent_steps_trained": 5564160, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 2780, "training_iteration": 138, "trial_id": "71426_00000", "experiment_id": "84bca2f7b35f43248fca18d21abe2ebf", "date": "2024-06-12_03-09-34", "timestamp": 1718129374, "time_this_iter_s": 10.083525657653809, "time_total_s": 1421.075920343399, "pid": 363902, "hostname": "DESKTOP-LQ219J4", "node_ip": "192.168.46.185", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 20, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 5000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 500, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Base_Model", "custom_model_config": {"env": "rware", "env_args": {"n_agents": 4, "column_height": 1, "max_inactivity_steps": null, "max_steps": 500, "fast_obs": true, "msg_bits": 0, "sensor_range": 1, "shelf_rows": 1, "shelf_columns": 3, "request_queue_size": 4, "reward_type": "RewardType.INDIVIDUAL", "map_name": "customized_map", "map_size": "tiny", "difficulty": "medium"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": true, "force_coop": false, "local_mode": true, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 4, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 100, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64}, "algorithm": "ia2c", "space_obs": "Dict(obs:Box([-100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100.], [100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.], (112,), float32))", "space_act": "Discrete(5)", "num_agents": 4, "episode_limit": 500, "policy_mapping_info": {"all_scenario": {"description": "rware all scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2", "agent_3"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "rware_customized_map", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 10, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.IA2CTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_il.<locals>.<lambda> at 0x7f3808651dc0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "grad_clip": 40.0, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "microbatch_size": null}, "time_since_restore": 1421.075920343399, "timesteps_since_restore": 0, "iterations_since_restore": 138, "perf": {"cpu_util_percent": 4.053333333333334, "ram_util_percent": 71.1}}
{"episode_reward_max": 19.0, "episode_reward_min": 1.0, "episode_reward_mean": 9.74, "episode_len_mean": 500.0, "episode_media": {}, "episodes_this_iter": 20, "policy_reward_min": {"shared_policy": 0.0}, "policy_reward_max": {"shared_policy": 7.0}, "policy_reward_mean": {"shared_policy": 2.435}, "custom_metrics": {}, "hist_stats": {"episode_reward": [18.0, 6.0, 17.0, 4.0, 13.0, 12.0, 12.0, 8.0, 4.0, 15.0, 8.0, 5.0, 15.0, 4.0, 8.0, 11.0, 5.0, 13.0, 10.0, 8.0, 6.0, 15.0, 9.0, 17.0, 10.0, 9.0, 6.0, 17.0, 13.0, 9.0, 4.0, 4.0, 7.0, 9.0, 8.0, 2.0, 10.0, 14.0, 7.0, 13.0, 11.0, 5.0, 10.0, 11.0, 5.0, 10.0, 10.0, 7.0, 10.0, 5.0, 5.0, 12.0, 19.0, 1.0, 13.0, 10.0, 3.0, 14.0, 12.0, 4.0, 6.0, 14.0, 12.0, 9.0, 10.0, 10.0, 11.0, 9.0, 8.0, 18.0, 9.0, 9.0, 19.0, 7.0, 11.0, 11.0, 16.0, 6.0, 14.0, 8.0, 13.0, 7.0, 8.0, 11.0, 15.0, 11.0, 5.0, 9.0, 15.0, 12.0, 14.0, 3.0, 6.0, 7.0, 6.0, 16.0, 10.0, 9.0, 6.0, 12.0], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500], "policy_shared_policy_reward": [5.0, 5.0, 4.0, 4.0, 2.0, 1.0, 1.0, 2.0, 4.0, 4.0, 3.0, 6.0, 1.0, 1.0, 1.0, 1.0, 3.0, 2.0, 4.0, 4.0, 3.0, 2.0, 3.0, 4.0, 3.0, 4.0, 3.0, 2.0, 1.0, 1.0, 3.0, 3.0, 0.0, 2.0, 1.0, 1.0, 4.0, 6.0, 2.0, 3.0, 2.0, 1.0, 3.0, 2.0, 1.0, 1.0, 2.0, 1.0, 3.0, 6.0, 4.0, 2.0, 1.0, 1.0, 1.0, 1.0, 2.0, 4.0, 1.0, 1.0, 3.0, 3.0, 3.0, 2.0, 1.0, 1.0, 2.0, 1.0, 2.0, 5.0, 4.0, 2.0, 3.0, 2.0, 2.0, 3.0, 1.0, 2.0, 3.0, 2.0, 2.0, 1.0, 1.0, 2.0, 3.0, 3.0, 6.0, 3.0, 1.0, 2.0, 3.0, 3.0, 3.0, 3.0, 6.0, 5.0, 2.0, 3.0, 3.0, 2.0, 2.0, 2.0, 3.0, 2.0, 2.0, 2.0, 0.0, 2.0, 5.0, 3.0, 3.0, 6.0, 3.0, 2.0, 4.0, 4.0, 1.0, 1.0, 3.0, 4.0, 1.0, 2.0, 0.0, 1.0, 2.0, 1.0, 1.0, 0.0, 2.0, 1.0, 3.0, 1.0, 3.0, 2.0, 1.0, 3.0, 2.0, 2.0, 3.0, 1.0, 1.0, 0.0, 0.0, 1.0, 3.0, 3.0, 2.0, 2.0, 5.0, 4.0, 3.0, 2.0, 1.0, 3.0, 1.0, 2.0, 3.0, 2.0, 3.0, 5.0, 2.0, 4.0, 3.0, 2.0, 1.0, 2.0, 1.0, 1.0, 3.0, 3.0, 2.0, 2.0, 4.0, 2.0, 3.0, 2.0, 1.0, 1.0, 2.0, 1.0, 2.0, 2.0, 3.0, 3.0, 3.0, 2.0, 2.0, 3.0, 2.0, 3.0, 1.0, 1.0, 3.0, 3.0, 1.0, 3.0, 1.0, 0.0, 1.0, 3.0, 1.0, 1.0, 1.0, 2.0, 3.0, 3.0, 3.0, 3.0, 7.0, 4.0, 5.0, 3.0, 1.0, 0.0, 0.0, 0.0, 4.0, 4.0, 2.0, 3.0, 4.0, 1.0, 1.0, 4.0, 1.0, 0.0, 1.0, 1.0, 4.0, 4.0, 5.0, 1.0, 3.0, 3.0, 3.0, 3.0, 1.0, 1.0, 2.0, 0.0, 2.0, 1.0, 2.0, 1.0, 2.0, 4.0, 4.0, 4.0, 4.0, 4.0, 3.0, 1.0, 1.0, 3.0, 3.0, 2.0, 3.0, 2.0, 4.0, 1.0, 1.0, 2.0, 3.0, 4.0, 2.0, 3.0, 3.0, 3.0, 3.0, 1.0, 3.0, 2.0, 2.0, 2.0, 1.0, 3.0, 3.0, 5.0, 5.0, 5.0, 3.0, 2.0, 2.0, 2.0, 2.0, 2.0, 3.0, 2.0, 6.0, 3.0, 3.0, 7.0, 2.0, 1.0, 2.0, 2.0, 3.0, 3.0, 3.0, 2.0, 2.0, 3.0, 3.0, 3.0, 4.0, 3.0, 5.0, 4.0, 2.0, 1.0, 2.0, 1.0, 3.0, 3.0, 4.0, 4.0, 3.0, 3.0, 1.0, 1.0, 2.0, 4.0, 4.0, 3.0, 2.0, 3.0, 1.0, 1.0, 3.0, 2.0, 1.0, 2.0, 2.0, 2.0, 3.0, 4.0, 2.0, 4.0, 4.0, 5.0, 3.0, 4.0, 2.0, 2.0, 1.0, 2.0, 1.0, 1.0, 2.0, 3.0, 1.0, 3.0, 5.0, 3.0, 4.0, 3.0, 4.0, 2.0, 4.0, 2.0, 2.0, 6.0, 2.0, 4.0, 0.0, 2.0, 0.0, 1.0, 2.0, 1.0, 1.0, 2.0, 1.0, 3.0, 2.0, 1.0, 1.0, 1.0, 2.0, 2.0, 5.0, 3.0, 5.0, 3.0, 2.0, 2.0, 3.0, 3.0, 2.0, 2.0, 1.0, 4.0, 1.0, 1.0, 1.0, 3.0, 2.0, 3.0, 3.0, 4.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.13370732558807755, "mean_inference_ms": 0.39061598667608716, "mean_action_processing_ms": 0.02916675780793992, "mean_env_wait_ms": 0.40350098809006063, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 1401120, "timesteps_this_iter": 0, "agent_timesteps_total": 5604480, "timers": {"sample_time_ms": 5101.355, "sample_throughput": 987.973, "load_time_ms": 0.179, "load_throughput": 28092082.605, "learn_time_ms": 128.403, "learn_throughput": 39251.464, "update_time_ms": 2.436}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 641.49658203125, "policy_entropy": 7662.11181640625, "policy_loss": 17.25946044921875, "vf_loss": 73.55936813354492}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 1401120, "num_agent_steps_sampled": 5604480, "num_steps_trained": 1401120, "num_agent_steps_trained": 5604480, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 2800, "training_iteration": 139, "trial_id": "71426_00000", "experiment_id": "84bca2f7b35f43248fca18d21abe2ebf", "date": "2024-06-12_03-09-44", "timestamp": 1718129384, "time_this_iter_s": 10.277013778686523, "time_total_s": 1431.3529341220856, "pid": 363902, "hostname": "DESKTOP-LQ219J4", "node_ip": "192.168.46.185", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 20, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 5000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 500, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Base_Model", "custom_model_config": {"env": "rware", "env_args": {"n_agents": 4, "column_height": 1, "max_inactivity_steps": null, "max_steps": 500, "fast_obs": true, "msg_bits": 0, "sensor_range": 1, "shelf_rows": 1, "shelf_columns": 3, "request_queue_size": 4, "reward_type": "RewardType.INDIVIDUAL", "map_name": "customized_map", "map_size": "tiny", "difficulty": "medium"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": true, "force_coop": false, "local_mode": true, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 4, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 100, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64}, "algorithm": "ia2c", "space_obs": "Dict(obs:Box([-100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100.], [100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.], (112,), float32))", "space_act": "Discrete(5)", "num_agents": 4, "episode_limit": 500, "policy_mapping_info": {"all_scenario": {"description": "rware all scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2", "agent_3"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "rware_customized_map", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 10, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.IA2CTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_il.<locals>.<lambda> at 0x7f38280b24c0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "grad_clip": 40.0, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "microbatch_size": null}, "time_since_restore": 1431.3529341220856, "timesteps_since_restore": 0, "iterations_since_restore": 139, "perf": {"cpu_util_percent": 4.207142857142857, "ram_util_percent": 71.39999999999999}}
{"episode_reward_max": 19.0, "episode_reward_min": 1.0, "episode_reward_mean": 9.91, "episode_len_mean": 500.0, "episode_media": {}, "episodes_this_iter": 20, "policy_reward_min": {"shared_policy": 0.0}, "policy_reward_max": {"shared_policy": 7.0}, "policy_reward_mean": {"shared_policy": 2.4775}, "custom_metrics": {}, "hist_stats": {"episode_reward": [6.0, 15.0, 9.0, 17.0, 10.0, 9.0, 6.0, 17.0, 13.0, 9.0, 4.0, 4.0, 7.0, 9.0, 8.0, 2.0, 10.0, 14.0, 7.0, 13.0, 11.0, 5.0, 10.0, 11.0, 5.0, 10.0, 10.0, 7.0, 10.0, 5.0, 5.0, 12.0, 19.0, 1.0, 13.0, 10.0, 3.0, 14.0, 12.0, 4.0, 6.0, 14.0, 12.0, 9.0, 10.0, 10.0, 11.0, 9.0, 8.0, 18.0, 9.0, 9.0, 19.0, 7.0, 11.0, 11.0, 16.0, 6.0, 14.0, 8.0, 13.0, 7.0, 8.0, 11.0, 15.0, 11.0, 5.0, 9.0, 15.0, 12.0, 14.0, 3.0, 6.0, 7.0, 6.0, 16.0, 10.0, 9.0, 6.0, 12.0, 7.0, 3.0, 15.0, 11.0, 10.0, 16.0, 10.0, 18.0, 14.0, 12.0, 14.0, 16.0, 11.0, 17.0, 1.0, 8.0, 6.0, 10.0, 9.0, 5.0], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500], "policy_shared_policy_reward": [2.0, 1.0, 1.0, 2.0, 3.0, 3.0, 6.0, 3.0, 1.0, 2.0, 3.0, 3.0, 3.0, 3.0, 6.0, 5.0, 2.0, 3.0, 3.0, 2.0, 2.0, 2.0, 3.0, 2.0, 2.0, 2.0, 0.0, 2.0, 5.0, 3.0, 3.0, 6.0, 3.0, 2.0, 4.0, 4.0, 1.0, 1.0, 3.0, 4.0, 1.0, 2.0, 0.0, 1.0, 2.0, 1.0, 1.0, 0.0, 2.0, 1.0, 3.0, 1.0, 3.0, 2.0, 1.0, 3.0, 2.0, 2.0, 3.0, 1.0, 1.0, 0.0, 0.0, 1.0, 3.0, 3.0, 2.0, 2.0, 5.0, 4.0, 3.0, 2.0, 1.0, 3.0, 1.0, 2.0, 3.0, 2.0, 3.0, 5.0, 2.0, 4.0, 3.0, 2.0, 1.0, 2.0, 1.0, 1.0, 3.0, 3.0, 2.0, 2.0, 4.0, 2.0, 3.0, 2.0, 1.0, 1.0, 2.0, 1.0, 2.0, 2.0, 3.0, 3.0, 3.0, 2.0, 2.0, 3.0, 2.0, 3.0, 1.0, 1.0, 3.0, 3.0, 1.0, 3.0, 1.0, 0.0, 1.0, 3.0, 1.0, 1.0, 1.0, 2.0, 3.0, 3.0, 3.0, 3.0, 7.0, 4.0, 5.0, 3.0, 1.0, 0.0, 0.0, 0.0, 4.0, 4.0, 2.0, 3.0, 4.0, 1.0, 1.0, 4.0, 1.0, 0.0, 1.0, 1.0, 4.0, 4.0, 5.0, 1.0, 3.0, 3.0, 3.0, 3.0, 1.0, 1.0, 2.0, 0.0, 2.0, 1.0, 2.0, 1.0, 2.0, 4.0, 4.0, 4.0, 4.0, 4.0, 3.0, 1.0, 1.0, 3.0, 3.0, 2.0, 3.0, 2.0, 4.0, 1.0, 1.0, 2.0, 3.0, 4.0, 2.0, 3.0, 3.0, 3.0, 3.0, 1.0, 3.0, 2.0, 2.0, 2.0, 1.0, 3.0, 3.0, 5.0, 5.0, 5.0, 3.0, 2.0, 2.0, 2.0, 2.0, 2.0, 3.0, 2.0, 6.0, 3.0, 3.0, 7.0, 2.0, 1.0, 2.0, 2.0, 3.0, 3.0, 3.0, 2.0, 2.0, 3.0, 3.0, 3.0, 4.0, 3.0, 5.0, 4.0, 2.0, 1.0, 2.0, 1.0, 3.0, 3.0, 4.0, 4.0, 3.0, 3.0, 1.0, 1.0, 2.0, 4.0, 4.0, 3.0, 2.0, 3.0, 1.0, 1.0, 3.0, 2.0, 1.0, 2.0, 2.0, 2.0, 3.0, 4.0, 2.0, 4.0, 4.0, 5.0, 3.0, 4.0, 2.0, 2.0, 1.0, 2.0, 1.0, 1.0, 2.0, 3.0, 1.0, 3.0, 5.0, 3.0, 4.0, 3.0, 4.0, 2.0, 4.0, 2.0, 2.0, 6.0, 2.0, 4.0, 0.0, 2.0, 0.0, 1.0, 2.0, 1.0, 1.0, 2.0, 1.0, 3.0, 2.0, 1.0, 1.0, 1.0, 2.0, 2.0, 5.0, 3.0, 5.0, 3.0, 2.0, 2.0, 3.0, 3.0, 2.0, 2.0, 1.0, 4.0, 1.0, 1.0, 1.0, 3.0, 2.0, 3.0, 3.0, 4.0, 1.0, 2.0, 1.0, 3.0, 0.0, 2.0, 0.0, 1.0, 4.0, 5.0, 2.0, 4.0, 2.0, 2.0, 3.0, 4.0, 2.0, 3.0, 2.0, 3.0, 5.0, 3.0, 4.0, 4.0, 3.0, 2.0, 2.0, 3.0, 4.0, 3.0, 4.0, 7.0, 3.0, 2.0, 5.0, 4.0, 1.0, 1.0, 5.0, 5.0, 4.0, 3.0, 4.0, 3.0, 5.0, 5.0, 6.0, 0.0, 3.0, 2.0, 4.0, 2.0, 2.0, 4.0, 4.0, 7.0, 0.0, 0.0, 1.0, 0.0, 2.0, 2.0, 0.0, 4.0, 1.0, 2.0, 2.0, 1.0, 4.0, 2.0, 3.0, 1.0, 2.0, 2.0, 3.0, 2.0, 2.0, 1.0, 1.0, 1.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.13370161469071778, "mean_inference_ms": 0.390601282653143, "mean_action_processing_ms": 0.029165377685995687, "mean_env_wait_ms": 0.40346271503989867, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 1411200, "timesteps_this_iter": 0, "agent_timesteps_total": 5644800, "timers": {"sample_time_ms": 5081.611, "sample_throughput": 991.812, "load_time_ms": 0.161, "load_throughput": 31294288.912, "learn_time_ms": 126.9, "learn_throughput": 39716.303, "update_time_ms": 2.399}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 525.2700805664062, "policy_entropy": 7665.556884765625, "policy_loss": -8.42116641998291, "vf_loss": 74.57301902770996}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 1411200, "num_agent_steps_sampled": 5644800, "num_steps_trained": 1411200, "num_agent_steps_trained": 5644800, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 2820, "training_iteration": 140, "trial_id": "71426_00000", "experiment_id": "84bca2f7b35f43248fca18d21abe2ebf", "date": "2024-06-12_03-09-54", "timestamp": 1718129394, "time_this_iter_s": 10.137508869171143, "time_total_s": 1441.4904429912567, "pid": 363902, "hostname": "DESKTOP-LQ219J4", "node_ip": "192.168.46.185", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 20, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 5000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 500, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Base_Model", "custom_model_config": {"env": "rware", "env_args": {"n_agents": 4, "column_height": 1, "max_inactivity_steps": null, "max_steps": 500, "fast_obs": true, "msg_bits": 0, "sensor_range": 1, "shelf_rows": 1, "shelf_columns": 3, "request_queue_size": 4, "reward_type": "RewardType.INDIVIDUAL", "map_name": "customized_map", "map_size": "tiny", "difficulty": "medium"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": true, "force_coop": false, "local_mode": true, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 4, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 100, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64}, "algorithm": "ia2c", "space_obs": "Dict(obs:Box([-100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100.], [100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.], (112,), float32))", "space_act": "Discrete(5)", "num_agents": 4, "episode_limit": 500, "policy_mapping_info": {"all_scenario": {"description": "rware all scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2", "agent_3"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "rware_customized_map", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 10, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.IA2CTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_il.<locals>.<lambda> at 0x7f38082f8dc0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "grad_clip": 40.0, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "microbatch_size": null}, "time_since_restore": 1441.4904429912567, "timesteps_since_restore": 0, "iterations_since_restore": 140, "perf": {"cpu_util_percent": 4.053333333333334, "ram_util_percent": 71.70000000000002}}
{"episode_reward_max": 26.0, "episode_reward_min": 1.0, "episode_reward_mean": 10.18, "episode_len_mean": 500.0, "episode_media": {}, "episodes_this_iter": 20, "policy_reward_min": {"shared_policy": 0.0}, "policy_reward_max": {"shared_policy": 8.0}, "policy_reward_mean": {"shared_policy": 2.545}, "custom_metrics": {}, "hist_stats": {"episode_reward": [11.0, 5.0, 10.0, 11.0, 5.0, 10.0, 10.0, 7.0, 10.0, 5.0, 5.0, 12.0, 19.0, 1.0, 13.0, 10.0, 3.0, 14.0, 12.0, 4.0, 6.0, 14.0, 12.0, 9.0, 10.0, 10.0, 11.0, 9.0, 8.0, 18.0, 9.0, 9.0, 19.0, 7.0, 11.0, 11.0, 16.0, 6.0, 14.0, 8.0, 13.0, 7.0, 8.0, 11.0, 15.0, 11.0, 5.0, 9.0, 15.0, 12.0, 14.0, 3.0, 6.0, 7.0, 6.0, 16.0, 10.0, 9.0, 6.0, 12.0, 7.0, 3.0, 15.0, 11.0, 10.0, 16.0, 10.0, 18.0, 14.0, 12.0, 14.0, 16.0, 11.0, 17.0, 1.0, 8.0, 6.0, 10.0, 9.0, 5.0, 9.0, 5.0, 8.0, 8.0, 10.0, 7.0, 13.0, 10.0, 7.0, 26.0, 11.0, 12.0, 10.0, 14.0, 15.0, 19.0, 4.0, 9.0, 11.0, 8.0], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500], "policy_shared_policy_reward": [2.0, 4.0, 3.0, 2.0, 1.0, 2.0, 1.0, 1.0, 3.0, 3.0, 2.0, 2.0, 4.0, 2.0, 3.0, 2.0, 1.0, 1.0, 2.0, 1.0, 2.0, 2.0, 3.0, 3.0, 3.0, 2.0, 2.0, 3.0, 2.0, 3.0, 1.0, 1.0, 3.0, 3.0, 1.0, 3.0, 1.0, 0.0, 1.0, 3.0, 1.0, 1.0, 1.0, 2.0, 3.0, 3.0, 3.0, 3.0, 7.0, 4.0, 5.0, 3.0, 1.0, 0.0, 0.0, 0.0, 4.0, 4.0, 2.0, 3.0, 4.0, 1.0, 1.0, 4.0, 1.0, 0.0, 1.0, 1.0, 4.0, 4.0, 5.0, 1.0, 3.0, 3.0, 3.0, 3.0, 1.0, 1.0, 2.0, 0.0, 2.0, 1.0, 2.0, 1.0, 2.0, 4.0, 4.0, 4.0, 4.0, 4.0, 3.0, 1.0, 1.0, 3.0, 3.0, 2.0, 3.0, 2.0, 4.0, 1.0, 1.0, 2.0, 3.0, 4.0, 2.0, 3.0, 3.0, 3.0, 3.0, 1.0, 3.0, 2.0, 2.0, 2.0, 1.0, 3.0, 3.0, 5.0, 5.0, 5.0, 3.0, 2.0, 2.0, 2.0, 2.0, 2.0, 3.0, 2.0, 6.0, 3.0, 3.0, 7.0, 2.0, 1.0, 2.0, 2.0, 3.0, 3.0, 3.0, 2.0, 2.0, 3.0, 3.0, 3.0, 4.0, 3.0, 5.0, 4.0, 2.0, 1.0, 2.0, 1.0, 3.0, 3.0, 4.0, 4.0, 3.0, 3.0, 1.0, 1.0, 2.0, 4.0, 4.0, 3.0, 2.0, 3.0, 1.0, 1.0, 3.0, 2.0, 1.0, 2.0, 2.0, 2.0, 3.0, 4.0, 2.0, 4.0, 4.0, 5.0, 3.0, 4.0, 2.0, 2.0, 1.0, 2.0, 1.0, 1.0, 2.0, 3.0, 1.0, 3.0, 5.0, 3.0, 4.0, 3.0, 4.0, 2.0, 4.0, 2.0, 2.0, 6.0, 2.0, 4.0, 0.0, 2.0, 0.0, 1.0, 2.0, 1.0, 1.0, 2.0, 1.0, 3.0, 2.0, 1.0, 1.0, 1.0, 2.0, 2.0, 5.0, 3.0, 5.0, 3.0, 2.0, 2.0, 3.0, 3.0, 2.0, 2.0, 1.0, 4.0, 1.0, 1.0, 1.0, 3.0, 2.0, 3.0, 3.0, 4.0, 1.0, 2.0, 1.0, 3.0, 0.0, 2.0, 0.0, 1.0, 4.0, 5.0, 2.0, 4.0, 2.0, 2.0, 3.0, 4.0, 2.0, 3.0, 2.0, 3.0, 5.0, 3.0, 4.0, 4.0, 3.0, 2.0, 2.0, 3.0, 4.0, 3.0, 4.0, 7.0, 3.0, 2.0, 5.0, 4.0, 1.0, 1.0, 5.0, 5.0, 4.0, 3.0, 4.0, 3.0, 5.0, 5.0, 6.0, 0.0, 3.0, 2.0, 4.0, 2.0, 2.0, 4.0, 4.0, 7.0, 0.0, 0.0, 1.0, 0.0, 2.0, 2.0, 0.0, 4.0, 1.0, 2.0, 2.0, 1.0, 4.0, 2.0, 3.0, 1.0, 2.0, 2.0, 3.0, 2.0, 2.0, 1.0, 1.0, 1.0, 2.0, 4.0, 2.0, 1.0, 2.0, 1.0, 1.0, 1.0, 1.0, 2.0, 1.0, 4.0, 1.0, 2.0, 3.0, 2.0, 2.0, 4.0, 2.0, 2.0, 2.0, 2.0, 1.0, 2.0, 4.0, 1.0, 3.0, 5.0, 2.0, 3.0, 2.0, 3.0, 2.0, 1.0, 2.0, 2.0, 6.0, 8.0, 7.0, 5.0, 2.0, 3.0, 4.0, 2.0, 1.0, 2.0, 5.0, 4.0, 3.0, 2.0, 1.0, 4.0, 3.0, 3.0, 4.0, 4.0, 4.0, 3.0, 4.0, 4.0, 4.0, 3.0, 6.0, 6.0, 1.0, 1.0, 1.0, 1.0, 3.0, 1.0, 2.0, 3.0, 3.0, 2.0, 5.0, 1.0, 3.0, 2.0, 2.0, 1.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.13370446989414325, "mean_inference_ms": 0.39058151210440983, "mean_action_processing_ms": 0.029163678378545804, "mean_env_wait_ms": 0.4034155056626384, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 1421280, "timesteps_this_iter": 0, "agent_timesteps_total": 5685120, "timers": {"sample_time_ms": 5077.641, "sample_throughput": 992.587, "load_time_ms": 0.166, "load_throughput": 30425003.109, "learn_time_ms": 127.398, "learn_throughput": 39561.101, "update_time_ms": 2.505}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 382.2332763671875, "policy_entropy": 7661.3580322265625, "policy_loss": 83.75801086425781, "vf_loss": 103.32219886779785}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 1421280, "num_agent_steps_sampled": 5685120, "num_steps_trained": 1421280, "num_agent_steps_trained": 5685120, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 2840, "training_iteration": 141, "trial_id": "71426_00000", "experiment_id": "84bca2f7b35f43248fca18d21abe2ebf", "date": "2024-06-12_03-10-04", "timestamp": 1718129404, "time_this_iter_s": 10.128066062927246, "time_total_s": 1451.618509054184, "pid": 363902, "hostname": "DESKTOP-LQ219J4", "node_ip": "192.168.46.185", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 20, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 5000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 500, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Base_Model", "custom_model_config": {"env": "rware", "env_args": {"n_agents": 4, "column_height": 1, "max_inactivity_steps": null, "max_steps": 500, "fast_obs": true, "msg_bits": 0, "sensor_range": 1, "shelf_rows": 1, "shelf_columns": 3, "request_queue_size": 4, "reward_type": "RewardType.INDIVIDUAL", "map_name": "customized_map", "map_size": "tiny", "difficulty": "medium"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": true, "force_coop": false, "local_mode": true, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 4, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 100, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64}, "algorithm": "ia2c", "space_obs": "Dict(obs:Box([-100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100.], [100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.], (112,), float32))", "space_act": "Discrete(5)", "num_agents": 4, "episode_limit": 500, "policy_mapping_info": {"all_scenario": {"description": "rware all scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2", "agent_3"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "rware_customized_map", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 10, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.IA2CTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_il.<locals>.<lambda> at 0x7f38086450d0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "grad_clip": 40.0, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "microbatch_size": null}, "time_since_restore": 1451.618509054184, "timesteps_since_restore": 0, "iterations_since_restore": 141, "perf": {"cpu_util_percent": 4.1, "ram_util_percent": 71.95}}
{"episode_reward_max": 26.0, "episode_reward_min": 1.0, "episode_reward_mean": 10.65, "episode_len_mean": 500.0, "episode_media": {}, "episodes_this_iter": 20, "policy_reward_min": {"shared_policy": 0.0}, "policy_reward_max": {"shared_policy": 8.0}, "policy_reward_mean": {"shared_policy": 2.6625}, "custom_metrics": {}, "hist_stats": {"episode_reward": [6.0, 14.0, 12.0, 9.0, 10.0, 10.0, 11.0, 9.0, 8.0, 18.0, 9.0, 9.0, 19.0, 7.0, 11.0, 11.0, 16.0, 6.0, 14.0, 8.0, 13.0, 7.0, 8.0, 11.0, 15.0, 11.0, 5.0, 9.0, 15.0, 12.0, 14.0, 3.0, 6.0, 7.0, 6.0, 16.0, 10.0, 9.0, 6.0, 12.0, 7.0, 3.0, 15.0, 11.0, 10.0, 16.0, 10.0, 18.0, 14.0, 12.0, 14.0, 16.0, 11.0, 17.0, 1.0, 8.0, 6.0, 10.0, 9.0, 5.0, 9.0, 5.0, 8.0, 8.0, 10.0, 7.0, 13.0, 10.0, 7.0, 26.0, 11.0, 12.0, 10.0, 14.0, 15.0, 19.0, 4.0, 9.0, 11.0, 8.0, 9.0, 14.0, 13.0, 13.0, 8.0, 15.0, 17.0, 11.0, 15.0, 11.0, 8.0, 13.0, 13.0, 13.0, 3.0, 11.0, 14.0, 10.0, 3.0, 10.0], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500], "policy_shared_policy_reward": [2.0, 1.0, 2.0, 1.0, 2.0, 4.0, 4.0, 4.0, 4.0, 4.0, 3.0, 1.0, 1.0, 3.0, 3.0, 2.0, 3.0, 2.0, 4.0, 1.0, 1.0, 2.0, 3.0, 4.0, 2.0, 3.0, 3.0, 3.0, 3.0, 1.0, 3.0, 2.0, 2.0, 2.0, 1.0, 3.0, 3.0, 5.0, 5.0, 5.0, 3.0, 2.0, 2.0, 2.0, 2.0, 2.0, 3.0, 2.0, 6.0, 3.0, 3.0, 7.0, 2.0, 1.0, 2.0, 2.0, 3.0, 3.0, 3.0, 2.0, 2.0, 3.0, 3.0, 3.0, 4.0, 3.0, 5.0, 4.0, 2.0, 1.0, 2.0, 1.0, 3.0, 3.0, 4.0, 4.0, 3.0, 3.0, 1.0, 1.0, 2.0, 4.0, 4.0, 3.0, 2.0, 3.0, 1.0, 1.0, 3.0, 2.0, 1.0, 2.0, 2.0, 2.0, 3.0, 4.0, 2.0, 4.0, 4.0, 5.0, 3.0, 4.0, 2.0, 2.0, 1.0, 2.0, 1.0, 1.0, 2.0, 3.0, 1.0, 3.0, 5.0, 3.0, 4.0, 3.0, 4.0, 2.0, 4.0, 2.0, 2.0, 6.0, 2.0, 4.0, 0.0, 2.0, 0.0, 1.0, 2.0, 1.0, 1.0, 2.0, 1.0, 3.0, 2.0, 1.0, 1.0, 1.0, 2.0, 2.0, 5.0, 3.0, 5.0, 3.0, 2.0, 2.0, 3.0, 3.0, 2.0, 2.0, 1.0, 4.0, 1.0, 1.0, 1.0, 3.0, 2.0, 3.0, 3.0, 4.0, 1.0, 2.0, 1.0, 3.0, 0.0, 2.0, 0.0, 1.0, 4.0, 5.0, 2.0, 4.0, 2.0, 2.0, 3.0, 4.0, 2.0, 3.0, 2.0, 3.0, 5.0, 3.0, 4.0, 4.0, 3.0, 2.0, 2.0, 3.0, 4.0, 3.0, 4.0, 7.0, 3.0, 2.0, 5.0, 4.0, 1.0, 1.0, 5.0, 5.0, 4.0, 3.0, 4.0, 3.0, 5.0, 5.0, 6.0, 0.0, 3.0, 2.0, 4.0, 2.0, 2.0, 4.0, 4.0, 7.0, 0.0, 0.0, 1.0, 0.0, 2.0, 2.0, 0.0, 4.0, 1.0, 2.0, 2.0, 1.0, 4.0, 2.0, 3.0, 1.0, 2.0, 2.0, 3.0, 2.0, 2.0, 1.0, 1.0, 1.0, 2.0, 4.0, 2.0, 1.0, 2.0, 1.0, 1.0, 1.0, 1.0, 2.0, 1.0, 4.0, 1.0, 2.0, 3.0, 2.0, 2.0, 4.0, 2.0, 2.0, 2.0, 2.0, 1.0, 2.0, 4.0, 1.0, 3.0, 5.0, 2.0, 3.0, 2.0, 3.0, 2.0, 1.0, 2.0, 2.0, 6.0, 8.0, 7.0, 5.0, 2.0, 3.0, 4.0, 2.0, 1.0, 2.0, 5.0, 4.0, 3.0, 2.0, 1.0, 4.0, 3.0, 3.0, 4.0, 4.0, 4.0, 3.0, 4.0, 4.0, 4.0, 3.0, 6.0, 6.0, 1.0, 1.0, 1.0, 1.0, 3.0, 1.0, 2.0, 3.0, 3.0, 2.0, 5.0, 1.0, 3.0, 2.0, 2.0, 1.0, 4.0, 1.0, 2.0, 2.0, 3.0, 4.0, 5.0, 2.0, 3.0, 2.0, 3.0, 5.0, 4.0, 4.0, 2.0, 3.0, 0.0, 4.0, 1.0, 3.0, 3.0, 5.0, 4.0, 3.0, 1.0, 5.0, 6.0, 5.0, 3.0, 2.0, 3.0, 3.0, 4.0, 4.0, 2.0, 5.0, 3.0, 3.0, 4.0, 1.0, 3.0, 0.0, 2.0, 3.0, 3.0, 3.0, 5.0, 2.0, 4.0, 3.0, 2.0, 4.0, 2.0, 3.0, 3.0, 5.0, 0.0, 1.0, 1.0, 1.0, 1.0, 4.0, 4.0, 2.0, 2.0, 6.0, 3.0, 3.0, 3.0, 3.0, 2.0, 2.0, 1.0, 1.0, 1.0, 0.0, 3.0, 2.0, 2.0, 3.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.13371009109081622, "mean_inference_ms": 0.39056937670469344, "mean_action_processing_ms": 0.029162493054444835, "mean_env_wait_ms": 0.4033767394840582, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 1431360, "timesteps_this_iter": 0, "agent_timesteps_total": 5725440, "timers": {"sample_time_ms": 5092.61, "sample_throughput": 989.669, "load_time_ms": 0.172, "load_throughput": 29360128.0, "learn_time_ms": 127.971, "learn_throughput": 39383.789, "update_time_ms": 2.574}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 471.3014831542969, "policy_entropy": 7733.7357177734375, "policy_loss": -36.27012920379639, "vf_loss": 66.41094779968262}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 1431360, "num_agent_steps_sampled": 5725440, "num_steps_trained": 1431360, "num_agent_steps_trained": 5725440, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 2860, "training_iteration": 142, "trial_id": "71426_00000", "experiment_id": "84bca2f7b35f43248fca18d21abe2ebf", "date": "2024-06-12_03-10-15", "timestamp": 1718129415, "time_this_iter_s": 10.225664854049683, "time_total_s": 1461.8441739082336, "pid": 363902, "hostname": "DESKTOP-LQ219J4", "node_ip": "192.168.46.185", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 20, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 5000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 500, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Base_Model", "custom_model_config": {"env": "rware", "env_args": {"n_agents": 4, "column_height": 1, "max_inactivity_steps": null, "max_steps": 500, "fast_obs": true, "msg_bits": 0, "sensor_range": 1, "shelf_rows": 1, "shelf_columns": 3, "request_queue_size": 4, "reward_type": "RewardType.INDIVIDUAL", "map_name": "customized_map", "map_size": "tiny", "difficulty": "medium"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": true, "force_coop": false, "local_mode": true, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 4, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 100, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64}, "algorithm": "ia2c", "space_obs": "Dict(obs:Box([-100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100.], [100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.], (112,), float32))", "space_act": "Discrete(5)", "num_agents": 4, "episode_limit": 500, "policy_mapping_info": {"all_scenario": {"description": "rware all scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2", "agent_3"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "rware_customized_map", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 10, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.IA2CTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_il.<locals>.<lambda> at 0x7f3808645b80>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "grad_clip": 40.0, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "microbatch_size": null}, "time_since_restore": 1461.8441739082336, "timesteps_since_restore": 0, "iterations_since_restore": 142, "perf": {"cpu_util_percent": 4.2, "ram_util_percent": 72.24666666666666}}
{"episode_reward_max": 26.0, "episode_reward_min": 1.0, "episode_reward_mean": 10.31, "episode_len_mean": 500.0, "episode_media": {}, "episodes_this_iter": 20, "policy_reward_min": {"shared_policy": 0.0}, "policy_reward_max": {"shared_policy": 8.0}, "policy_reward_mean": {"shared_policy": 2.5775}, "custom_metrics": {}, "hist_stats": {"episode_reward": [13.0, 7.0, 8.0, 11.0, 15.0, 11.0, 5.0, 9.0, 15.0, 12.0, 14.0, 3.0, 6.0, 7.0, 6.0, 16.0, 10.0, 9.0, 6.0, 12.0, 7.0, 3.0, 15.0, 11.0, 10.0, 16.0, 10.0, 18.0, 14.0, 12.0, 14.0, 16.0, 11.0, 17.0, 1.0, 8.0, 6.0, 10.0, 9.0, 5.0, 9.0, 5.0, 8.0, 8.0, 10.0, 7.0, 13.0, 10.0, 7.0, 26.0, 11.0, 12.0, 10.0, 14.0, 15.0, 19.0, 4.0, 9.0, 11.0, 8.0, 9.0, 14.0, 13.0, 13.0, 8.0, 15.0, 17.0, 11.0, 15.0, 11.0, 8.0, 13.0, 13.0, 13.0, 3.0, 11.0, 14.0, 10.0, 3.0, 10.0, 11.0, 12.0, 9.0, 6.0, 5.0, 10.0, 12.0, 10.0, 10.0, 6.0, 16.0, 16.0, 3.0, 11.0, 5.0, 8.0, 10.0, 6.0, 12.0, 5.0], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500], "policy_shared_policy_reward": [2.0, 4.0, 4.0, 3.0, 2.0, 3.0, 1.0, 1.0, 3.0, 2.0, 1.0, 2.0, 2.0, 2.0, 3.0, 4.0, 2.0, 4.0, 4.0, 5.0, 3.0, 4.0, 2.0, 2.0, 1.0, 2.0, 1.0, 1.0, 2.0, 3.0, 1.0, 3.0, 5.0, 3.0, 4.0, 3.0, 4.0, 2.0, 4.0, 2.0, 2.0, 6.0, 2.0, 4.0, 0.0, 2.0, 0.0, 1.0, 2.0, 1.0, 1.0, 2.0, 1.0, 3.0, 2.0, 1.0, 1.0, 1.0, 2.0, 2.0, 5.0, 3.0, 5.0, 3.0, 2.0, 2.0, 3.0, 3.0, 2.0, 2.0, 1.0, 4.0, 1.0, 1.0, 1.0, 3.0, 2.0, 3.0, 3.0, 4.0, 1.0, 2.0, 1.0, 3.0, 0.0, 2.0, 0.0, 1.0, 4.0, 5.0, 2.0, 4.0, 2.0, 2.0, 3.0, 4.0, 2.0, 3.0, 2.0, 3.0, 5.0, 3.0, 4.0, 4.0, 3.0, 2.0, 2.0, 3.0, 4.0, 3.0, 4.0, 7.0, 3.0, 2.0, 5.0, 4.0, 1.0, 1.0, 5.0, 5.0, 4.0, 3.0, 4.0, 3.0, 5.0, 5.0, 6.0, 0.0, 3.0, 2.0, 4.0, 2.0, 2.0, 4.0, 4.0, 7.0, 0.0, 0.0, 1.0, 0.0, 2.0, 2.0, 0.0, 4.0, 1.0, 2.0, 2.0, 1.0, 4.0, 2.0, 3.0, 1.0, 2.0, 2.0, 3.0, 2.0, 2.0, 1.0, 1.0, 1.0, 2.0, 4.0, 2.0, 1.0, 2.0, 1.0, 1.0, 1.0, 1.0, 2.0, 1.0, 4.0, 1.0, 2.0, 3.0, 2.0, 2.0, 4.0, 2.0, 2.0, 2.0, 2.0, 1.0, 2.0, 4.0, 1.0, 3.0, 5.0, 2.0, 3.0, 2.0, 3.0, 2.0, 1.0, 2.0, 2.0, 6.0, 8.0, 7.0, 5.0, 2.0, 3.0, 4.0, 2.0, 1.0, 2.0, 5.0, 4.0, 3.0, 2.0, 1.0, 4.0, 3.0, 3.0, 4.0, 4.0, 4.0, 3.0, 4.0, 4.0, 4.0, 3.0, 6.0, 6.0, 1.0, 1.0, 1.0, 1.0, 3.0, 1.0, 2.0, 3.0, 3.0, 2.0, 5.0, 1.0, 3.0, 2.0, 2.0, 1.0, 4.0, 1.0, 2.0, 2.0, 3.0, 4.0, 5.0, 2.0, 3.0, 2.0, 3.0, 5.0, 4.0, 4.0, 2.0, 3.0, 0.0, 4.0, 1.0, 3.0, 3.0, 5.0, 4.0, 3.0, 1.0, 5.0, 6.0, 5.0, 3.0, 2.0, 3.0, 3.0, 4.0, 4.0, 2.0, 5.0, 3.0, 3.0, 4.0, 1.0, 3.0, 0.0, 2.0, 3.0, 3.0, 3.0, 5.0, 2.0, 4.0, 3.0, 2.0, 4.0, 2.0, 3.0, 3.0, 5.0, 0.0, 1.0, 1.0, 1.0, 1.0, 4.0, 4.0, 2.0, 2.0, 6.0, 3.0, 3.0, 3.0, 3.0, 2.0, 2.0, 1.0, 1.0, 1.0, 0.0, 3.0, 2.0, 2.0, 3.0, 3.0, 2.0, 4.0, 2.0, 2.0, 2.0, 3.0, 5.0, 2.0, 3.0, 3.0, 1.0, 3.0, 0.0, 2.0, 1.0, 2.0, 1.0, 2.0, 0.0, 3.0, 2.0, 3.0, 2.0, 3.0, 2.0, 2.0, 5.0, 4.0, 2.0, 2.0, 2.0, 2.0, 3.0, 4.0, 1.0, 1.0, 2.0, 1.0, 2.0, 4.0, 3.0, 6.0, 3.0, 4.0, 5.0, 5.0, 2.0, 1.0, 1.0, 0.0, 1.0, 2.0, 3.0, 4.0, 2.0, 1.0, 1.0, 2.0, 1.0, 2.0, 0.0, 3.0, 3.0, 2.0, 2.0, 3.0, 3.0, 1.0, 2.0, 2.0, 1.0, 3.0, 4.0, 3.0, 2.0, 1.0, 1.0, 2.0, 1.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.13371414424502512, "mean_inference_ms": 0.39055165253920465, "mean_action_processing_ms": 0.02916099080202348, "mean_env_wait_ms": 0.4033446747100085, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 1441440, "timesteps_this_iter": 0, "agent_timesteps_total": 5765760, "timers": {"sample_time_ms": 5091.896, "sample_throughput": 989.808, "load_time_ms": 0.171, "load_throughput": 29425518.04, "learn_time_ms": 127.603, "learn_throughput": 39497.443, "update_time_ms": 2.569}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 729.9115600585938, "policy_entropy": 7738.758056640625, "policy_loss": -47.85466957092285, "vf_loss": 72.97500705718994}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 1441440, "num_agent_steps_sampled": 5765760, "num_steps_trained": 1441440, "num_agent_steps_trained": 5765760, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 2880, "training_iteration": 143, "trial_id": "71426_00000", "experiment_id": "84bca2f7b35f43248fca18d21abe2ebf", "date": "2024-06-12_03-10-25", "timestamp": 1718129425, "time_this_iter_s": 10.07148003578186, "time_total_s": 1471.9156539440155, "pid": 363902, "hostname": "DESKTOP-LQ219J4", "node_ip": "192.168.46.185", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 20, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 5000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 500, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Base_Model", "custom_model_config": {"env": "rware", "env_args": {"n_agents": 4, "column_height": 1, "max_inactivity_steps": null, "max_steps": 500, "fast_obs": true, "msg_bits": 0, "sensor_range": 1, "shelf_rows": 1, "shelf_columns": 3, "request_queue_size": 4, "reward_type": "RewardType.INDIVIDUAL", "map_name": "customized_map", "map_size": "tiny", "difficulty": "medium"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": true, "force_coop": false, "local_mode": true, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 4, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 100, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64}, "algorithm": "ia2c", "space_obs": "Dict(obs:Box([-100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100.], [100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.], (112,), float32))", "space_act": "Discrete(5)", "num_agents": 4, "episode_limit": 500, "policy_mapping_info": {"all_scenario": {"description": "rware all scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2", "agent_3"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "rware_customized_map", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 10, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.IA2CTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_il.<locals>.<lambda> at 0x7f380824d310>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "grad_clip": 40.0, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "microbatch_size": null}, "time_since_restore": 1471.9156539440155, "timesteps_since_restore": 0, "iterations_since_restore": 143, "perf": {"cpu_util_percent": 4.364285714285715, "ram_util_percent": 72.5}}
{"episode_reward_max": 26.0, "episode_reward_min": 1.0, "episode_reward_mean": 10.42, "episode_len_mean": 500.0, "episode_media": {}, "episodes_this_iter": 20, "policy_reward_min": {"shared_policy": 0.0}, "policy_reward_max": {"shared_policy": 8.0}, "policy_reward_mean": {"shared_policy": 2.605}, "custom_metrics": {}, "hist_stats": {"episode_reward": [7.0, 3.0, 15.0, 11.0, 10.0, 16.0, 10.0, 18.0, 14.0, 12.0, 14.0, 16.0, 11.0, 17.0, 1.0, 8.0, 6.0, 10.0, 9.0, 5.0, 9.0, 5.0, 8.0, 8.0, 10.0, 7.0, 13.0, 10.0, 7.0, 26.0, 11.0, 12.0, 10.0, 14.0, 15.0, 19.0, 4.0, 9.0, 11.0, 8.0, 9.0, 14.0, 13.0, 13.0, 8.0, 15.0, 17.0, 11.0, 15.0, 11.0, 8.0, 13.0, 13.0, 13.0, 3.0, 11.0, 14.0, 10.0, 3.0, 10.0, 11.0, 12.0, 9.0, 6.0, 5.0, 10.0, 12.0, 10.0, 10.0, 6.0, 16.0, 16.0, 3.0, 11.0, 5.0, 8.0, 10.0, 6.0, 12.0, 5.0, 8.0, 11.0, 6.0, 10.0, 11.0, 9.0, 8.0, 6.0, 7.0, 2.0, 12.0, 14.0, 16.0, 7.0, 20.0, 16.0, 4.0, 13.0, 18.0, 8.0], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500], "policy_shared_policy_reward": [1.0, 2.0, 1.0, 3.0, 0.0, 2.0, 0.0, 1.0, 4.0, 5.0, 2.0, 4.0, 2.0, 2.0, 3.0, 4.0, 2.0, 3.0, 2.0, 3.0, 5.0, 3.0, 4.0, 4.0, 3.0, 2.0, 2.0, 3.0, 4.0, 3.0, 4.0, 7.0, 3.0, 2.0, 5.0, 4.0, 1.0, 1.0, 5.0, 5.0, 4.0, 3.0, 4.0, 3.0, 5.0, 5.0, 6.0, 0.0, 3.0, 2.0, 4.0, 2.0, 2.0, 4.0, 4.0, 7.0, 0.0, 0.0, 1.0, 0.0, 2.0, 2.0, 0.0, 4.0, 1.0, 2.0, 2.0, 1.0, 4.0, 2.0, 3.0, 1.0, 2.0, 2.0, 3.0, 2.0, 2.0, 1.0, 1.0, 1.0, 2.0, 4.0, 2.0, 1.0, 2.0, 1.0, 1.0, 1.0, 1.0, 2.0, 1.0, 4.0, 1.0, 2.0, 3.0, 2.0, 2.0, 4.0, 2.0, 2.0, 2.0, 2.0, 1.0, 2.0, 4.0, 1.0, 3.0, 5.0, 2.0, 3.0, 2.0, 3.0, 2.0, 1.0, 2.0, 2.0, 6.0, 8.0, 7.0, 5.0, 2.0, 3.0, 4.0, 2.0, 1.0, 2.0, 5.0, 4.0, 3.0, 2.0, 1.0, 4.0, 3.0, 3.0, 4.0, 4.0, 4.0, 3.0, 4.0, 4.0, 4.0, 3.0, 6.0, 6.0, 1.0, 1.0, 1.0, 1.0, 3.0, 1.0, 2.0, 3.0, 3.0, 2.0, 5.0, 1.0, 3.0, 2.0, 2.0, 1.0, 4.0, 1.0, 2.0, 2.0, 3.0, 4.0, 5.0, 2.0, 3.0, 2.0, 3.0, 5.0, 4.0, 4.0, 2.0, 3.0, 0.0, 4.0, 1.0, 3.0, 3.0, 5.0, 4.0, 3.0, 1.0, 5.0, 6.0, 5.0, 3.0, 2.0, 3.0, 3.0, 4.0, 4.0, 2.0, 5.0, 3.0, 3.0, 4.0, 1.0, 3.0, 0.0, 2.0, 3.0, 3.0, 3.0, 5.0, 2.0, 4.0, 3.0, 2.0, 4.0, 2.0, 3.0, 3.0, 5.0, 0.0, 1.0, 1.0, 1.0, 1.0, 4.0, 4.0, 2.0, 2.0, 6.0, 3.0, 3.0, 3.0, 3.0, 2.0, 2.0, 1.0, 1.0, 1.0, 0.0, 3.0, 2.0, 2.0, 3.0, 3.0, 2.0, 4.0, 2.0, 2.0, 2.0, 3.0, 5.0, 2.0, 3.0, 3.0, 1.0, 3.0, 0.0, 2.0, 1.0, 2.0, 1.0, 2.0, 0.0, 3.0, 2.0, 3.0, 2.0, 3.0, 2.0, 2.0, 5.0, 4.0, 2.0, 2.0, 2.0, 2.0, 3.0, 4.0, 1.0, 1.0, 2.0, 1.0, 2.0, 4.0, 3.0, 6.0, 3.0, 4.0, 5.0, 5.0, 2.0, 1.0, 1.0, 0.0, 1.0, 2.0, 3.0, 4.0, 2.0, 1.0, 1.0, 2.0, 1.0, 2.0, 0.0, 3.0, 3.0, 2.0, 2.0, 3.0, 3.0, 1.0, 2.0, 2.0, 1.0, 3.0, 4.0, 3.0, 2.0, 1.0, 1.0, 2.0, 1.0, 2.0, 3.0, 1.0, 2.0, 3.0, 2.0, 3.0, 3.0, 1.0, 1.0, 2.0, 2.0, 4.0, 2.0, 3.0, 1.0, 3.0, 4.0, 3.0, 1.0, 4.0, 2.0, 2.0, 1.0, 1.0, 1.0, 3.0, 3.0, 1.0, 1.0, 2.0, 2.0, 2.0, 3.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 3.0, 3.0, 2.0, 4.0, 4.0, 3.0, 4.0, 3.0, 5.0, 5.0, 1.0, 5.0, 2.0, 2.0, 1.0, 2.0, 6.0, 4.0, 6.0, 4.0, 1.0, 4.0, 6.0, 5.0, 1.0, 1.0, 1.0, 1.0, 4.0, 3.0, 3.0, 3.0, 5.0, 3.0, 3.0, 7.0, 2.0, 3.0, 1.0, 2.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.13371368047987733, "mean_inference_ms": 0.3905241413738027, "mean_action_processing_ms": 0.02915876734200096, "mean_env_wait_ms": 0.4032972543793702, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 1451520, "timesteps_this_iter": 0, "agent_timesteps_total": 5806080, "timers": {"sample_time_ms": 5068.806, "sample_throughput": 994.317, "load_time_ms": 0.17, "load_throughput": 29615147.324, "learn_time_ms": 126.117, "learn_throughput": 39962.842, "update_time_ms": 2.533}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 591.7310180664062, "policy_entropy": 7789.1748046875, "policy_loss": -22.92469882965088, "vf_loss": 76.3780517578125}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 1451520, "num_agent_steps_sampled": 5806080, "num_steps_trained": 1451520, "num_agent_steps_trained": 5806080, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 2900, "training_iteration": 144, "trial_id": "71426_00000", "experiment_id": "84bca2f7b35f43248fca18d21abe2ebf", "date": "2024-06-12_03-10-35", "timestamp": 1718129435, "time_this_iter_s": 10.037810325622559, "time_total_s": 1481.953464269638, "pid": 363902, "hostname": "DESKTOP-LQ219J4", "node_ip": "192.168.46.185", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 20, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 5000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 500, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Base_Model", "custom_model_config": {"env": "rware", "env_args": {"n_agents": 4, "column_height": 1, "max_inactivity_steps": null, "max_steps": 500, "fast_obs": true, "msg_bits": 0, "sensor_range": 1, "shelf_rows": 1, "shelf_columns": 3, "request_queue_size": 4, "reward_type": "RewardType.INDIVIDUAL", "map_name": "customized_map", "map_size": "tiny", "difficulty": "medium"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": true, "force_coop": false, "local_mode": true, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 4, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 100, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64}, "algorithm": "ia2c", "space_obs": "Dict(obs:Box([-100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100.], [100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.], (112,), float32))", "space_act": "Discrete(5)", "num_agents": 4, "episode_limit": 500, "policy_mapping_info": {"all_scenario": {"description": "rware all scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2", "agent_3"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "rware_customized_map", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 10, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.IA2CTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_il.<locals>.<lambda> at 0x7f38086450d0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "grad_clip": 40.0, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "microbatch_size": null}, "time_since_restore": 1481.953464269638, "timesteps_since_restore": 0, "iterations_since_restore": 144, "perf": {"cpu_util_percent": 4.246666666666666, "ram_util_percent": 72.79999999999998}}
{"episode_reward_max": 26.0, "episode_reward_min": 2.0, "episode_reward_mean": 10.19, "episode_len_mean": 500.0, "episode_media": {}, "episodes_this_iter": 20, "policy_reward_min": {"shared_policy": 0.0}, "policy_reward_max": {"shared_policy": 8.0}, "policy_reward_mean": {"shared_policy": 2.5475}, "custom_metrics": {}, "hist_stats": {"episode_reward": [9.0, 5.0, 8.0, 8.0, 10.0, 7.0, 13.0, 10.0, 7.0, 26.0, 11.0, 12.0, 10.0, 14.0, 15.0, 19.0, 4.0, 9.0, 11.0, 8.0, 9.0, 14.0, 13.0, 13.0, 8.0, 15.0, 17.0, 11.0, 15.0, 11.0, 8.0, 13.0, 13.0, 13.0, 3.0, 11.0, 14.0, 10.0, 3.0, 10.0, 11.0, 12.0, 9.0, 6.0, 5.0, 10.0, 12.0, 10.0, 10.0, 6.0, 16.0, 16.0, 3.0, 11.0, 5.0, 8.0, 10.0, 6.0, 12.0, 5.0, 8.0, 11.0, 6.0, 10.0, 11.0, 9.0, 8.0, 6.0, 7.0, 2.0, 12.0, 14.0, 16.0, 7.0, 20.0, 16.0, 4.0, 13.0, 18.0, 8.0, 4.0, 18.0, 14.0, 7.0, 13.0, 6.0, 12.0, 8.0, 11.0, 10.0, 10.0, 10.0, 13.0, 13.0, 9.0, 6.0, 6.0, 6.0, 5.0, 9.0], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500], "policy_shared_policy_reward": [2.0, 4.0, 2.0, 1.0, 2.0, 1.0, 1.0, 1.0, 1.0, 2.0, 1.0, 4.0, 1.0, 2.0, 3.0, 2.0, 2.0, 4.0, 2.0, 2.0, 2.0, 2.0, 1.0, 2.0, 4.0, 1.0, 3.0, 5.0, 2.0, 3.0, 2.0, 3.0, 2.0, 1.0, 2.0, 2.0, 6.0, 8.0, 7.0, 5.0, 2.0, 3.0, 4.0, 2.0, 1.0, 2.0, 5.0, 4.0, 3.0, 2.0, 1.0, 4.0, 3.0, 3.0, 4.0, 4.0, 4.0, 3.0, 4.0, 4.0, 4.0, 3.0, 6.0, 6.0, 1.0, 1.0, 1.0, 1.0, 3.0, 1.0, 2.0, 3.0, 3.0, 2.0, 5.0, 1.0, 3.0, 2.0, 2.0, 1.0, 4.0, 1.0, 2.0, 2.0, 3.0, 4.0, 5.0, 2.0, 3.0, 2.0, 3.0, 5.0, 4.0, 4.0, 2.0, 3.0, 0.0, 4.0, 1.0, 3.0, 3.0, 5.0, 4.0, 3.0, 1.0, 5.0, 6.0, 5.0, 3.0, 2.0, 3.0, 3.0, 4.0, 4.0, 2.0, 5.0, 3.0, 3.0, 4.0, 1.0, 3.0, 0.0, 2.0, 3.0, 3.0, 3.0, 5.0, 2.0, 4.0, 3.0, 2.0, 4.0, 2.0, 3.0, 3.0, 5.0, 0.0, 1.0, 1.0, 1.0, 1.0, 4.0, 4.0, 2.0, 2.0, 6.0, 3.0, 3.0, 3.0, 3.0, 2.0, 2.0, 1.0, 1.0, 1.0, 0.0, 3.0, 2.0, 2.0, 3.0, 3.0, 2.0, 4.0, 2.0, 2.0, 2.0, 3.0, 5.0, 2.0, 3.0, 3.0, 1.0, 3.0, 0.0, 2.0, 1.0, 2.0, 1.0, 2.0, 0.0, 3.0, 2.0, 3.0, 2.0, 3.0, 2.0, 2.0, 5.0, 4.0, 2.0, 2.0, 2.0, 2.0, 3.0, 4.0, 1.0, 1.0, 2.0, 1.0, 2.0, 4.0, 3.0, 6.0, 3.0, 4.0, 5.0, 5.0, 2.0, 1.0, 1.0, 0.0, 1.0, 2.0, 3.0, 4.0, 2.0, 1.0, 1.0, 2.0, 1.0, 2.0, 0.0, 3.0, 3.0, 2.0, 2.0, 3.0, 3.0, 1.0, 2.0, 2.0, 1.0, 3.0, 4.0, 3.0, 2.0, 1.0, 1.0, 2.0, 1.0, 2.0, 3.0, 1.0, 2.0, 3.0, 2.0, 3.0, 3.0, 1.0, 1.0, 2.0, 2.0, 4.0, 2.0, 3.0, 1.0, 3.0, 4.0, 3.0, 1.0, 4.0, 2.0, 2.0, 1.0, 1.0, 1.0, 3.0, 3.0, 1.0, 1.0, 2.0, 2.0, 2.0, 3.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 3.0, 3.0, 2.0, 4.0, 4.0, 3.0, 4.0, 3.0, 5.0, 5.0, 1.0, 5.0, 2.0, 2.0, 1.0, 2.0, 6.0, 4.0, 6.0, 4.0, 1.0, 4.0, 6.0, 5.0, 1.0, 1.0, 1.0, 1.0, 4.0, 3.0, 3.0, 3.0, 5.0, 3.0, 3.0, 7.0, 2.0, 3.0, 1.0, 2.0, 1.0, 1.0, 2.0, 0.0, 4.0, 4.0, 5.0, 5.0, 1.0, 4.0, 6.0, 3.0, 3.0, 1.0, 1.0, 2.0, 4.0, 3.0, 3.0, 3.0, 2.0, 1.0, 1.0, 2.0, 4.0, 5.0, 2.0, 1.0, 2.0, 2.0, 2.0, 2.0, 1.0, 3.0, 4.0, 3.0, 1.0, 4.0, 2.0, 3.0, 2.0, 3.0, 2.0, 3.0, 3.0, 3.0, 3.0, 1.0, 3.0, 5.0, 2.0, 3.0, 3.0, 4.0, 3.0, 3.0, 1.0, 4.0, 2.0, 2.0, 2.0, 1.0, 2.0, 1.0, 1.0, 2.0, 2.0, 1.0, 1.0, 1.0, 2.0, 2.0, 1.0, 2.0, 1.0, 1.0, 2.0, 3.0, 2.0, 2.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.13371658892014687, "mean_inference_ms": 0.3905058369160021, "mean_action_processing_ms": 0.029156972744783963, "mean_env_wait_ms": 0.4032546117862832, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 1461600, "timesteps_this_iter": 0, "agent_timesteps_total": 5846400, "timers": {"sample_time_ms": 5081.796, "sample_throughput": 991.775, "load_time_ms": 0.171, "load_throughput": 29429614.59, "learn_time_ms": 126.828, "learn_throughput": 39738.918, "update_time_ms": 2.539}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 363.12030029296875, "policy_entropy": 7675.0191650390625, "policy_loss": -12.170940399169922, "vf_loss": 75.4364128112793}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 1461600, "num_agent_steps_sampled": 5846400, "num_steps_trained": 1461600, "num_agent_steps_trained": 5846400, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 2920, "training_iteration": 145, "trial_id": "71426_00000", "experiment_id": "84bca2f7b35f43248fca18d21abe2ebf", "date": "2024-06-12_03-10-45", "timestamp": 1718129445, "time_this_iter_s": 10.280902862548828, "time_total_s": 1492.234367132187, "pid": 363902, "hostname": "DESKTOP-LQ219J4", "node_ip": "192.168.46.185", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 20, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 5000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 500, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Base_Model", "custom_model_config": {"env": "rware", "env_args": {"n_agents": 4, "column_height": 1, "max_inactivity_steps": null, "max_steps": 500, "fast_obs": true, "msg_bits": 0, "sensor_range": 1, "shelf_rows": 1, "shelf_columns": 3, "request_queue_size": 4, "reward_type": "RewardType.INDIVIDUAL", "map_name": "customized_map", "map_size": "tiny", "difficulty": "medium"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": true, "force_coop": false, "local_mode": true, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 4, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 100, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64}, "algorithm": "ia2c", "space_obs": "Dict(obs:Box([-100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100.], [100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.], (112,), float32))", "space_act": "Discrete(5)", "num_agents": 4, "episode_limit": 500, "policy_mapping_info": {"all_scenario": {"description": "rware all scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2", "agent_3"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "rware_customized_map", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 10, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.IA2CTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_il.<locals>.<lambda> at 0x7f3808645b80>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "grad_clip": 40.0, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "microbatch_size": null}, "time_since_restore": 1492.234367132187, "timesteps_since_restore": 0, "iterations_since_restore": 145, "perf": {"cpu_util_percent": 4.135714285714285, "ram_util_percent": 73.05000000000001}}
{"episode_reward_max": 20.0, "episode_reward_min": 2.0, "episode_reward_mean": 10.29, "episode_len_mean": 500.0, "episode_media": {}, "episodes_this_iter": 20, "policy_reward_min": {"shared_policy": 0.0}, "policy_reward_max": {"shared_policy": 7.0}, "policy_reward_mean": {"shared_policy": 2.5725}, "custom_metrics": {}, "hist_stats": {"episode_reward": [9.0, 14.0, 13.0, 13.0, 8.0, 15.0, 17.0, 11.0, 15.0, 11.0, 8.0, 13.0, 13.0, 13.0, 3.0, 11.0, 14.0, 10.0, 3.0, 10.0, 11.0, 12.0, 9.0, 6.0, 5.0, 10.0, 12.0, 10.0, 10.0, 6.0, 16.0, 16.0, 3.0, 11.0, 5.0, 8.0, 10.0, 6.0, 12.0, 5.0, 8.0, 11.0, 6.0, 10.0, 11.0, 9.0, 8.0, 6.0, 7.0, 2.0, 12.0, 14.0, 16.0, 7.0, 20.0, 16.0, 4.0, 13.0, 18.0, 8.0, 4.0, 18.0, 14.0, 7.0, 13.0, 6.0, 12.0, 8.0, 11.0, 10.0, 10.0, 10.0, 13.0, 13.0, 9.0, 6.0, 6.0, 6.0, 5.0, 9.0, 9.0, 6.0, 12.0, 12.0, 16.0, 11.0, 17.0, 17.0, 10.0, 11.0, 8.0, 16.0, 4.0, 12.0, 12.0, 14.0, 8.0, 12.0, 8.0, 11.0], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500], "policy_shared_policy_reward": [4.0, 1.0, 2.0, 2.0, 3.0, 4.0, 5.0, 2.0, 3.0, 2.0, 3.0, 5.0, 4.0, 4.0, 2.0, 3.0, 0.0, 4.0, 1.0, 3.0, 3.0, 5.0, 4.0, 3.0, 1.0, 5.0, 6.0, 5.0, 3.0, 2.0, 3.0, 3.0, 4.0, 4.0, 2.0, 5.0, 3.0, 3.0, 4.0, 1.0, 3.0, 0.0, 2.0, 3.0, 3.0, 3.0, 5.0, 2.0, 4.0, 3.0, 2.0, 4.0, 2.0, 3.0, 3.0, 5.0, 0.0, 1.0, 1.0, 1.0, 1.0, 4.0, 4.0, 2.0, 2.0, 6.0, 3.0, 3.0, 3.0, 3.0, 2.0, 2.0, 1.0, 1.0, 1.0, 0.0, 3.0, 2.0, 2.0, 3.0, 3.0, 2.0, 4.0, 2.0, 2.0, 2.0, 3.0, 5.0, 2.0, 3.0, 3.0, 1.0, 3.0, 0.0, 2.0, 1.0, 2.0, 1.0, 2.0, 0.0, 3.0, 2.0, 3.0, 2.0, 3.0, 2.0, 2.0, 5.0, 4.0, 2.0, 2.0, 2.0, 2.0, 3.0, 4.0, 1.0, 1.0, 2.0, 1.0, 2.0, 4.0, 3.0, 6.0, 3.0, 4.0, 5.0, 5.0, 2.0, 1.0, 1.0, 0.0, 1.0, 2.0, 3.0, 4.0, 2.0, 1.0, 1.0, 2.0, 1.0, 2.0, 0.0, 3.0, 3.0, 2.0, 2.0, 3.0, 3.0, 1.0, 2.0, 2.0, 1.0, 3.0, 4.0, 3.0, 2.0, 1.0, 1.0, 2.0, 1.0, 2.0, 3.0, 1.0, 2.0, 3.0, 2.0, 3.0, 3.0, 1.0, 1.0, 2.0, 2.0, 4.0, 2.0, 3.0, 1.0, 3.0, 4.0, 3.0, 1.0, 4.0, 2.0, 2.0, 1.0, 1.0, 1.0, 3.0, 3.0, 1.0, 1.0, 2.0, 2.0, 2.0, 3.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 3.0, 3.0, 2.0, 4.0, 4.0, 3.0, 4.0, 3.0, 5.0, 5.0, 1.0, 5.0, 2.0, 2.0, 1.0, 2.0, 6.0, 4.0, 6.0, 4.0, 1.0, 4.0, 6.0, 5.0, 1.0, 1.0, 1.0, 1.0, 4.0, 3.0, 3.0, 3.0, 5.0, 3.0, 3.0, 7.0, 2.0, 3.0, 1.0, 2.0, 1.0, 1.0, 2.0, 0.0, 4.0, 4.0, 5.0, 5.0, 1.0, 4.0, 6.0, 3.0, 3.0, 1.0, 1.0, 2.0, 4.0, 3.0, 3.0, 3.0, 2.0, 1.0, 1.0, 2.0, 4.0, 5.0, 2.0, 1.0, 2.0, 2.0, 2.0, 2.0, 1.0, 3.0, 4.0, 3.0, 1.0, 4.0, 2.0, 3.0, 2.0, 3.0, 2.0, 3.0, 3.0, 3.0, 3.0, 1.0, 3.0, 5.0, 2.0, 3.0, 3.0, 4.0, 3.0, 3.0, 1.0, 4.0, 2.0, 2.0, 2.0, 1.0, 2.0, 1.0, 1.0, 2.0, 2.0, 1.0, 1.0, 1.0, 2.0, 2.0, 1.0, 2.0, 1.0, 1.0, 2.0, 3.0, 2.0, 2.0, 2.0, 2.0, 3.0, 2.0, 1.0, 2.0, 2.0, 1.0, 3.0, 2.0, 4.0, 3.0, 5.0, 2.0, 3.0, 2.0, 4.0, 3.0, 4.0, 5.0, 4.0, 3.0, 2.0, 2.0, 4.0, 4.0, 5.0, 4.0, 5.0, 5.0, 3.0, 4.0, 3.0, 2.0, 2.0, 3.0, 2.0, 4.0, 3.0, 2.0, 4.0, 2.0, 0.0, 2.0, 4.0, 5.0, 3.0, 4.0, 2.0, 1.0, 1.0, 0.0, 2.0, 4.0, 3.0, 3.0, 3.0, 3.0, 2.0, 4.0, 2.0, 4.0, 3.0, 5.0, 4.0, 1.0, 3.0, 0.0, 4.0, 2.0, 2.0, 4.0, 4.0, 1.0, 1.0, 2.0, 3.0, 4.0, 2.0, 2.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.13370885354820625, "mean_inference_ms": 0.39048743373028183, "mean_action_processing_ms": 0.029155159555565052, "mean_env_wait_ms": 0.40322183256104793, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 1471680, "timesteps_this_iter": 0, "agent_timesteps_total": 5886720, "timers": {"sample_time_ms": 5079.027, "sample_throughput": 992.316, "load_time_ms": 0.166, "load_throughput": 30368182.962, "learn_time_ms": 125.394, "learn_throughput": 40193.307, "update_time_ms": 2.451}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 459.90423583984375, "policy_entropy": 7615.2247314453125, "policy_loss": 53.586100578308105, "vf_loss": 91.6898193359375}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 1471680, "num_agent_steps_sampled": 5886720, "num_steps_trained": 1471680, "num_agent_steps_trained": 5886720, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 2940, "training_iteration": 146, "trial_id": "71426_00000", "experiment_id": "84bca2f7b35f43248fca18d21abe2ebf", "date": "2024-06-12_03-10-55", "timestamp": 1718129455, "time_this_iter_s": 10.084897518157959, "time_total_s": 1502.3192646503448, "pid": 363902, "hostname": "DESKTOP-LQ219J4", "node_ip": "192.168.46.185", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 20, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 5000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 500, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Base_Model", "custom_model_config": {"env": "rware", "env_args": {"n_agents": 4, "column_height": 1, "max_inactivity_steps": null, "max_steps": 500, "fast_obs": true, "msg_bits": 0, "sensor_range": 1, "shelf_rows": 1, "shelf_columns": 3, "request_queue_size": 4, "reward_type": "RewardType.INDIVIDUAL", "map_name": "customized_map", "map_size": "tiny", "difficulty": "medium"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": true, "force_coop": false, "local_mode": true, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 4, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 100, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64}, "algorithm": "ia2c", "space_obs": "Dict(obs:Box([-100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100.], [100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.], (112,), float32))", "space_act": "Discrete(5)", "num_agents": 4, "episode_limit": 500, "policy_mapping_info": {"all_scenario": {"description": "rware all scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2", "agent_3"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "rware_customized_map", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 10, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.IA2CTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_il.<locals>.<lambda> at 0x7f38306aa940>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "grad_clip": 40.0, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "microbatch_size": null}, "time_since_restore": 1502.3192646503448, "timesteps_since_restore": 0, "iterations_since_restore": 146, "perf": {"cpu_util_percent": 4.16, "ram_util_percent": 73.32666666666665}}
{"episode_reward_max": 20.0, "episode_reward_min": 2.0, "episode_reward_mean": 9.71, "episode_len_mean": 500.0, "episode_media": {}, "episodes_this_iter": 20, "policy_reward_min": {"shared_policy": 0.0}, "policy_reward_max": {"shared_policy": 7.0}, "policy_reward_mean": {"shared_policy": 2.4275}, "custom_metrics": {}, "hist_stats": {"episode_reward": [11.0, 12.0, 9.0, 6.0, 5.0, 10.0, 12.0, 10.0, 10.0, 6.0, 16.0, 16.0, 3.0, 11.0, 5.0, 8.0, 10.0, 6.0, 12.0, 5.0, 8.0, 11.0, 6.0, 10.0, 11.0, 9.0, 8.0, 6.0, 7.0, 2.0, 12.0, 14.0, 16.0, 7.0, 20.0, 16.0, 4.0, 13.0, 18.0, 8.0, 4.0, 18.0, 14.0, 7.0, 13.0, 6.0, 12.0, 8.0, 11.0, 10.0, 10.0, 10.0, 13.0, 13.0, 9.0, 6.0, 6.0, 6.0, 5.0, 9.0, 9.0, 6.0, 12.0, 12.0, 16.0, 11.0, 17.0, 17.0, 10.0, 11.0, 8.0, 16.0, 4.0, 12.0, 12.0, 14.0, 8.0, 12.0, 8.0, 11.0, 14.0, 6.0, 4.0, 10.0, 14.0, 3.0, 10.0, 4.0, 13.0, 7.0, 5.0, 9.0, 8.0, 9.0, 10.0, 8.0, 5.0, 11.0, 7.0, 9.0], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500], "policy_shared_policy_reward": [3.0, 2.0, 4.0, 2.0, 2.0, 2.0, 3.0, 5.0, 2.0, 3.0, 3.0, 1.0, 3.0, 0.0, 2.0, 1.0, 2.0, 1.0, 2.0, 0.0, 3.0, 2.0, 3.0, 2.0, 3.0, 2.0, 2.0, 5.0, 4.0, 2.0, 2.0, 2.0, 2.0, 3.0, 4.0, 1.0, 1.0, 2.0, 1.0, 2.0, 4.0, 3.0, 6.0, 3.0, 4.0, 5.0, 5.0, 2.0, 1.0, 1.0, 0.0, 1.0, 2.0, 3.0, 4.0, 2.0, 1.0, 1.0, 2.0, 1.0, 2.0, 0.0, 3.0, 3.0, 2.0, 2.0, 3.0, 3.0, 1.0, 2.0, 2.0, 1.0, 3.0, 4.0, 3.0, 2.0, 1.0, 1.0, 2.0, 1.0, 2.0, 3.0, 1.0, 2.0, 3.0, 2.0, 3.0, 3.0, 1.0, 1.0, 2.0, 2.0, 4.0, 2.0, 3.0, 1.0, 3.0, 4.0, 3.0, 1.0, 4.0, 2.0, 2.0, 1.0, 1.0, 1.0, 3.0, 3.0, 1.0, 1.0, 2.0, 2.0, 2.0, 3.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 3.0, 3.0, 2.0, 4.0, 4.0, 3.0, 4.0, 3.0, 5.0, 5.0, 1.0, 5.0, 2.0, 2.0, 1.0, 2.0, 6.0, 4.0, 6.0, 4.0, 1.0, 4.0, 6.0, 5.0, 1.0, 1.0, 1.0, 1.0, 4.0, 3.0, 3.0, 3.0, 5.0, 3.0, 3.0, 7.0, 2.0, 3.0, 1.0, 2.0, 1.0, 1.0, 2.0, 0.0, 4.0, 4.0, 5.0, 5.0, 1.0, 4.0, 6.0, 3.0, 3.0, 1.0, 1.0, 2.0, 4.0, 3.0, 3.0, 3.0, 2.0, 1.0, 1.0, 2.0, 4.0, 5.0, 2.0, 1.0, 2.0, 2.0, 2.0, 2.0, 1.0, 3.0, 4.0, 3.0, 1.0, 4.0, 2.0, 3.0, 2.0, 3.0, 2.0, 3.0, 3.0, 3.0, 3.0, 1.0, 3.0, 5.0, 2.0, 3.0, 3.0, 4.0, 3.0, 3.0, 1.0, 4.0, 2.0, 2.0, 2.0, 1.0, 2.0, 1.0, 1.0, 2.0, 2.0, 1.0, 1.0, 1.0, 2.0, 2.0, 1.0, 2.0, 1.0, 1.0, 2.0, 3.0, 2.0, 2.0, 2.0, 2.0, 3.0, 2.0, 1.0, 2.0, 2.0, 1.0, 3.0, 2.0, 4.0, 3.0, 5.0, 2.0, 3.0, 2.0, 4.0, 3.0, 4.0, 5.0, 4.0, 3.0, 2.0, 2.0, 4.0, 4.0, 5.0, 4.0, 5.0, 5.0, 3.0, 4.0, 3.0, 2.0, 2.0, 3.0, 2.0, 4.0, 3.0, 2.0, 4.0, 2.0, 0.0, 2.0, 4.0, 5.0, 3.0, 4.0, 2.0, 1.0, 1.0, 0.0, 2.0, 4.0, 3.0, 3.0, 3.0, 3.0, 2.0, 4.0, 2.0, 4.0, 3.0, 5.0, 4.0, 1.0, 3.0, 0.0, 4.0, 2.0, 2.0, 4.0, 4.0, 1.0, 1.0, 2.0, 3.0, 4.0, 2.0, 2.0, 3.0, 4.0, 3.0, 4.0, 1.0, 1.0, 2.0, 2.0, 0.0, 1.0, 1.0, 2.0, 3.0, 3.0, 0.0, 4.0, 5.0, 4.0, 2.0, 3.0, 0.0, 1.0, 1.0, 1.0, 2.0, 4.0, 0.0, 4.0, 1.0, 1.0, 1.0, 1.0, 4.0, 4.0, 2.0, 3.0, 3.0, 1.0, 1.0, 2.0, 2.0, 1.0, 1.0, 1.0, 3.0, 2.0, 3.0, 1.0, 2.0, 1.0, 3.0, 2.0, 1.0, 2.0, 4.0, 2.0, 3.0, 2.0, 2.0, 3.0, 1.0, 3.0, 2.0, 2.0, 1.0, 2.0, 0.0, 2.0, 3.0, 2.0, 3.0, 3.0, 2.0, 2.0, 0.0, 3.0, 3.0, 2.0, 2.0, 2.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.1336992255348874, "mean_inference_ms": 0.3904639554697216, "mean_action_processing_ms": 0.029152858688954345, "mean_env_wait_ms": 0.4031858725416643, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 1481760, "timesteps_this_iter": 0, "agent_timesteps_total": 5927040, "timers": {"sample_time_ms": 5069.926, "sample_throughput": 994.097, "load_time_ms": 0.159, "load_throughput": 31769299.91, "learn_time_ms": 125.122, "learn_throughput": 40280.732, "update_time_ms": 2.41}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 317.7965087890625, "policy_entropy": 7652.448486328125, "policy_loss": -7.937699317932129, "vf_loss": 72.82526683807373}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 1481760, "num_agent_steps_sampled": 5927040, "num_steps_trained": 1481760, "num_agent_steps_trained": 5927040, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 2960, "training_iteration": 147, "trial_id": "71426_00000", "experiment_id": "84bca2f7b35f43248fca18d21abe2ebf", "date": "2024-06-12_03-11-05", "timestamp": 1718129465, "time_this_iter_s": 10.14297342300415, "time_total_s": 1512.462238073349, "pid": 363902, "hostname": "DESKTOP-LQ219J4", "node_ip": "192.168.46.185", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 20, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 5000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 500, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Base_Model", "custom_model_config": {"env": "rware", "env_args": {"n_agents": 4, "column_height": 1, "max_inactivity_steps": null, "max_steps": 500, "fast_obs": true, "msg_bits": 0, "sensor_range": 1, "shelf_rows": 1, "shelf_columns": 3, "request_queue_size": 4, "reward_type": "RewardType.INDIVIDUAL", "map_name": "customized_map", "map_size": "tiny", "difficulty": "medium"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": true, "force_coop": false, "local_mode": true, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 4, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 100, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64}, "algorithm": "ia2c", "space_obs": "Dict(obs:Box([-100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100.], [100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.], (112,), float32))", "space_act": "Discrete(5)", "num_agents": 4, "episode_limit": 500, "policy_mapping_info": {"all_scenario": {"description": "rware all scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2", "agent_3"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "rware_customized_map", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 10, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.IA2CTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_il.<locals>.<lambda> at 0x7f382806e9d0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "grad_clip": 40.0, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "microbatch_size": null}, "time_since_restore": 1512.462238073349, "timesteps_since_restore": 0, "iterations_since_restore": 147, "perf": {"cpu_util_percent": 4.242857142857143, "ram_util_percent": 73.60000000000001}}
{"episode_reward_max": 20.0, "episode_reward_min": 2.0, "episode_reward_mean": 10.22, "episode_len_mean": 500.0, "episode_media": {}, "episodes_this_iter": 20, "policy_reward_min": {"shared_policy": 0.0}, "policy_reward_max": {"shared_policy": 7.0}, "policy_reward_mean": {"shared_policy": 2.555}, "custom_metrics": {}, "hist_stats": {"episode_reward": [8.0, 11.0, 6.0, 10.0, 11.0, 9.0, 8.0, 6.0, 7.0, 2.0, 12.0, 14.0, 16.0, 7.0, 20.0, 16.0, 4.0, 13.0, 18.0, 8.0, 4.0, 18.0, 14.0, 7.0, 13.0, 6.0, 12.0, 8.0, 11.0, 10.0, 10.0, 10.0, 13.0, 13.0, 9.0, 6.0, 6.0, 6.0, 5.0, 9.0, 9.0, 6.0, 12.0, 12.0, 16.0, 11.0, 17.0, 17.0, 10.0, 11.0, 8.0, 16.0, 4.0, 12.0, 12.0, 14.0, 8.0, 12.0, 8.0, 11.0, 14.0, 6.0, 4.0, 10.0, 14.0, 3.0, 10.0, 4.0, 13.0, 7.0, 5.0, 9.0, 8.0, 9.0, 10.0, 8.0, 5.0, 11.0, 7.0, 9.0, 11.0, 18.0, 10.0, 15.0, 14.0, 9.0, 9.0, 8.0, 17.0, 9.0, 10.0, 6.0, 9.0, 8.0, 18.0, 15.0, 9.0, 12.0, 18.0, 9.0], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500], "policy_shared_policy_reward": [2.0, 3.0, 1.0, 2.0, 3.0, 2.0, 3.0, 3.0, 1.0, 1.0, 2.0, 2.0, 4.0, 2.0, 3.0, 1.0, 3.0, 4.0, 3.0, 1.0, 4.0, 2.0, 2.0, 1.0, 1.0, 1.0, 3.0, 3.0, 1.0, 1.0, 2.0, 2.0, 2.0, 3.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 3.0, 3.0, 2.0, 4.0, 4.0, 3.0, 4.0, 3.0, 5.0, 5.0, 1.0, 5.0, 2.0, 2.0, 1.0, 2.0, 6.0, 4.0, 6.0, 4.0, 1.0, 4.0, 6.0, 5.0, 1.0, 1.0, 1.0, 1.0, 4.0, 3.0, 3.0, 3.0, 5.0, 3.0, 3.0, 7.0, 2.0, 3.0, 1.0, 2.0, 1.0, 1.0, 2.0, 0.0, 4.0, 4.0, 5.0, 5.0, 1.0, 4.0, 6.0, 3.0, 3.0, 1.0, 1.0, 2.0, 4.0, 3.0, 3.0, 3.0, 2.0, 1.0, 1.0, 2.0, 4.0, 5.0, 2.0, 1.0, 2.0, 2.0, 2.0, 2.0, 1.0, 3.0, 4.0, 3.0, 1.0, 4.0, 2.0, 3.0, 2.0, 3.0, 2.0, 3.0, 3.0, 3.0, 3.0, 1.0, 3.0, 5.0, 2.0, 3.0, 3.0, 4.0, 3.0, 3.0, 1.0, 4.0, 2.0, 2.0, 2.0, 1.0, 2.0, 1.0, 1.0, 2.0, 2.0, 1.0, 1.0, 1.0, 2.0, 2.0, 1.0, 2.0, 1.0, 1.0, 2.0, 3.0, 2.0, 2.0, 2.0, 2.0, 3.0, 2.0, 1.0, 2.0, 2.0, 1.0, 3.0, 2.0, 4.0, 3.0, 5.0, 2.0, 3.0, 2.0, 4.0, 3.0, 4.0, 5.0, 4.0, 3.0, 2.0, 2.0, 4.0, 4.0, 5.0, 4.0, 5.0, 5.0, 3.0, 4.0, 3.0, 2.0, 2.0, 3.0, 2.0, 4.0, 3.0, 2.0, 4.0, 2.0, 0.0, 2.0, 4.0, 5.0, 3.0, 4.0, 2.0, 1.0, 1.0, 0.0, 2.0, 4.0, 3.0, 3.0, 3.0, 3.0, 2.0, 4.0, 2.0, 4.0, 3.0, 5.0, 4.0, 1.0, 3.0, 0.0, 4.0, 2.0, 2.0, 4.0, 4.0, 1.0, 1.0, 2.0, 3.0, 4.0, 2.0, 2.0, 3.0, 4.0, 3.0, 4.0, 1.0, 1.0, 2.0, 2.0, 0.0, 1.0, 1.0, 2.0, 3.0, 3.0, 0.0, 4.0, 5.0, 4.0, 2.0, 3.0, 0.0, 1.0, 1.0, 1.0, 2.0, 4.0, 0.0, 4.0, 1.0, 1.0, 1.0, 1.0, 4.0, 4.0, 2.0, 3.0, 3.0, 1.0, 1.0, 2.0, 2.0, 1.0, 1.0, 1.0, 3.0, 2.0, 3.0, 1.0, 2.0, 1.0, 3.0, 2.0, 1.0, 2.0, 4.0, 2.0, 3.0, 2.0, 2.0, 3.0, 1.0, 3.0, 2.0, 2.0, 1.0, 2.0, 0.0, 2.0, 3.0, 2.0, 3.0, 3.0, 2.0, 2.0, 0.0, 3.0, 3.0, 2.0, 2.0, 2.0, 2.0, 4.0, 3.0, 2.0, 6.0, 5.0, 3.0, 4.0, 1.0, 2.0, 3.0, 4.0, 3.0, 4.0, 4.0, 4.0, 3.0, 3.0, 3.0, 5.0, 3.0, 3.0, 2.0, 1.0, 1.0, 4.0, 2.0, 2.0, 1.0, 2.0, 2.0, 3.0, 4.0, 5.0, 3.0, 5.0, 2.0, 2.0, 1.0, 4.0, 1.0, 4.0, 2.0, 3.0, 0.0, 2.0, 2.0, 2.0, 2.0, 3.0, 2.0, 2.0, 2.0, 3.0, 2.0, 1.0, 4.0, 3.0, 6.0, 5.0, 3.0, 4.0, 3.0, 5.0, 2.0, 3.0, 3.0, 1.0, 4.0, 4.0, 2.0, 2.0, 5.0, 4.0, 5.0, 4.0, 2.0, 1.0, 3.0, 3.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.13370091649760638, "mean_inference_ms": 0.3904704870064657, "mean_action_processing_ms": 0.029153014183243533, "mean_env_wait_ms": 0.40317401248821305, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 1491840, "timesteps_this_iter": 0, "agent_timesteps_total": 5967360, "timers": {"sample_time_ms": 5123.421, "sample_throughput": 983.718, "load_time_ms": 0.164, "load_throughput": 30734649.84, "learn_time_ms": 126.994, "learn_throughput": 39686.798, "update_time_ms": 2.4}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 529.943359375, "policy_entropy": 7706.798583984375, "policy_loss": 74.66114234924316, "vf_loss": 89.69582557678223}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 1491840, "num_agent_steps_sampled": 5967360, "num_steps_trained": 1491840, "num_agent_steps_trained": 5967360, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 2980, "training_iteration": 148, "trial_id": "71426_00000", "experiment_id": "84bca2f7b35f43248fca18d21abe2ebf", "date": "2024-06-12_03-11-16", "timestamp": 1718129476, "time_this_iter_s": 10.614942789077759, "time_total_s": 1523.0771808624268, "pid": 363902, "hostname": "DESKTOP-LQ219J4", "node_ip": "192.168.46.185", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 20, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 5000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 500, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Base_Model", "custom_model_config": {"env": "rware", "env_args": {"n_agents": 4, "column_height": 1, "max_inactivity_steps": null, "max_steps": 500, "fast_obs": true, "msg_bits": 0, "sensor_range": 1, "shelf_rows": 1, "shelf_columns": 3, "request_queue_size": 4, "reward_type": "RewardType.INDIVIDUAL", "map_name": "customized_map", "map_size": "tiny", "difficulty": "medium"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": true, "force_coop": false, "local_mode": true, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 4, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 100, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64}, "algorithm": "ia2c", "space_obs": "Dict(obs:Box([-100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100.], [100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.], (112,), float32))", "space_act": "Discrete(5)", "num_agents": 4, "episode_limit": 500, "policy_mapping_info": {"all_scenario": {"description": "rware all scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2", "agent_3"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "rware_customized_map", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 10, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.IA2CTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_il.<locals>.<lambda> at 0x7f38082f8c10>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "grad_clip": 40.0, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "microbatch_size": null}, "time_since_restore": 1523.0771808624268, "timesteps_since_restore": 0, "iterations_since_restore": 148, "perf": {"cpu_util_percent": 4.513333333333334, "ram_util_percent": 73.89333333333335}}
{"episode_reward_max": 19.0, "episode_reward_min": 3.0, "episode_reward_mean": 10.37, "episode_len_mean": 500.0, "episode_media": {}, "episodes_this_iter": 20, "policy_reward_min": {"shared_policy": 0.0}, "policy_reward_max": {"shared_policy": 6.0}, "policy_reward_mean": {"shared_policy": 2.5925}, "custom_metrics": {}, "hist_stats": {"episode_reward": [4.0, 18.0, 14.0, 7.0, 13.0, 6.0, 12.0, 8.0, 11.0, 10.0, 10.0, 10.0, 13.0, 13.0, 9.0, 6.0, 6.0, 6.0, 5.0, 9.0, 9.0, 6.0, 12.0, 12.0, 16.0, 11.0, 17.0, 17.0, 10.0, 11.0, 8.0, 16.0, 4.0, 12.0, 12.0, 14.0, 8.0, 12.0, 8.0, 11.0, 14.0, 6.0, 4.0, 10.0, 14.0, 3.0, 10.0, 4.0, 13.0, 7.0, 5.0, 9.0, 8.0, 9.0, 10.0, 8.0, 5.0, 11.0, 7.0, 9.0, 11.0, 18.0, 10.0, 15.0, 14.0, 9.0, 9.0, 8.0, 17.0, 9.0, 10.0, 6.0, 9.0, 8.0, 18.0, 15.0, 9.0, 12.0, 18.0, 9.0, 6.0, 15.0, 8.0, 4.0, 15.0, 6.0, 10.0, 14.0, 11.0, 15.0, 7.0, 9.0, 11.0, 9.0, 19.0, 14.0, 13.0, 9.0, 14.0, 12.0], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500], "policy_shared_policy_reward": [1.0, 1.0, 2.0, 0.0, 4.0, 4.0, 5.0, 5.0, 1.0, 4.0, 6.0, 3.0, 3.0, 1.0, 1.0, 2.0, 4.0, 3.0, 3.0, 3.0, 2.0, 1.0, 1.0, 2.0, 4.0, 5.0, 2.0, 1.0, 2.0, 2.0, 2.0, 2.0, 1.0, 3.0, 4.0, 3.0, 1.0, 4.0, 2.0, 3.0, 2.0, 3.0, 2.0, 3.0, 3.0, 3.0, 3.0, 1.0, 3.0, 5.0, 2.0, 3.0, 3.0, 4.0, 3.0, 3.0, 1.0, 4.0, 2.0, 2.0, 2.0, 1.0, 2.0, 1.0, 1.0, 2.0, 2.0, 1.0, 1.0, 1.0, 2.0, 2.0, 1.0, 2.0, 1.0, 1.0, 2.0, 3.0, 2.0, 2.0, 2.0, 2.0, 3.0, 2.0, 1.0, 2.0, 2.0, 1.0, 3.0, 2.0, 4.0, 3.0, 5.0, 2.0, 3.0, 2.0, 4.0, 3.0, 4.0, 5.0, 4.0, 3.0, 2.0, 2.0, 4.0, 4.0, 5.0, 4.0, 5.0, 5.0, 3.0, 4.0, 3.0, 2.0, 2.0, 3.0, 2.0, 4.0, 3.0, 2.0, 4.0, 2.0, 0.0, 2.0, 4.0, 5.0, 3.0, 4.0, 2.0, 1.0, 1.0, 0.0, 2.0, 4.0, 3.0, 3.0, 3.0, 3.0, 2.0, 4.0, 2.0, 4.0, 3.0, 5.0, 4.0, 1.0, 3.0, 0.0, 4.0, 2.0, 2.0, 4.0, 4.0, 1.0, 1.0, 2.0, 3.0, 4.0, 2.0, 2.0, 3.0, 4.0, 3.0, 4.0, 1.0, 1.0, 2.0, 2.0, 0.0, 1.0, 1.0, 2.0, 3.0, 3.0, 0.0, 4.0, 5.0, 4.0, 2.0, 3.0, 0.0, 1.0, 1.0, 1.0, 2.0, 4.0, 0.0, 4.0, 1.0, 1.0, 1.0, 1.0, 4.0, 4.0, 2.0, 3.0, 3.0, 1.0, 1.0, 2.0, 2.0, 1.0, 1.0, 1.0, 3.0, 2.0, 3.0, 1.0, 2.0, 1.0, 3.0, 2.0, 1.0, 2.0, 4.0, 2.0, 3.0, 2.0, 2.0, 3.0, 1.0, 3.0, 2.0, 2.0, 1.0, 2.0, 0.0, 2.0, 3.0, 2.0, 3.0, 3.0, 2.0, 2.0, 0.0, 3.0, 3.0, 2.0, 2.0, 2.0, 2.0, 4.0, 3.0, 2.0, 6.0, 5.0, 3.0, 4.0, 1.0, 2.0, 3.0, 4.0, 3.0, 4.0, 4.0, 4.0, 3.0, 3.0, 3.0, 5.0, 3.0, 3.0, 2.0, 1.0, 1.0, 4.0, 2.0, 2.0, 1.0, 2.0, 2.0, 3.0, 4.0, 5.0, 3.0, 5.0, 2.0, 2.0, 1.0, 4.0, 1.0, 4.0, 2.0, 3.0, 0.0, 2.0, 2.0, 2.0, 2.0, 3.0, 2.0, 2.0, 2.0, 3.0, 2.0, 1.0, 4.0, 3.0, 6.0, 5.0, 3.0, 4.0, 3.0, 5.0, 2.0, 3.0, 3.0, 1.0, 4.0, 4.0, 2.0, 2.0, 5.0, 4.0, 5.0, 4.0, 2.0, 1.0, 3.0, 3.0, 2.0, 1.0, 2.0, 1.0, 5.0, 3.0, 3.0, 4.0, 1.0, 4.0, 1.0, 2.0, 1.0, 1.0, 1.0, 1.0, 3.0, 3.0, 6.0, 3.0, 2.0, 2.0, 1.0, 1.0, 2.0, 3.0, 3.0, 2.0, 3.0, 4.0, 3.0, 4.0, 3.0, 3.0, 3.0, 2.0, 5.0, 3.0, 3.0, 4.0, 1.0, 2.0, 3.0, 1.0, 2.0, 2.0, 3.0, 2.0, 1.0, 2.0, 4.0, 4.0, 3.0, 1.0, 2.0, 3.0, 6.0, 3.0, 4.0, 6.0, 2.0, 4.0, 4.0, 4.0, 3.0, 3.0, 4.0, 3.0, 3.0, 3.0, 2.0, 1.0, 4.0, 5.0, 3.0, 2.0, 2.0, 2.0, 4.0, 4.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.1337111904093961, "mean_inference_ms": 0.39050006844459356, "mean_action_processing_ms": 0.029154685817556727, "mean_env_wait_ms": 0.4031909275464137, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 1501920, "timesteps_this_iter": 0, "agent_timesteps_total": 6007680, "timers": {"sample_time_ms": 5171.548, "sample_throughput": 974.563, "load_time_ms": 0.166, "load_throughput": 30355100.747, "learn_time_ms": 127.8, "learn_throughput": 39436.719, "update_time_ms": 2.441}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 410.0057373046875, "policy_entropy": 7712.315185546875, "policy_loss": 79.91596269607544, "vf_loss": 92.35044193267822}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 1501920, "num_agent_steps_sampled": 6007680, "num_steps_trained": 1501920, "num_agent_steps_trained": 6007680, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 3000, "training_iteration": 149, "trial_id": "71426_00000", "experiment_id": "84bca2f7b35f43248fca18d21abe2ebf", "date": "2024-06-12_03-11-27", "timestamp": 1718129487, "time_this_iter_s": 10.517523288726807, "time_total_s": 1533.5947041511536, "pid": 363902, "hostname": "DESKTOP-LQ219J4", "node_ip": "192.168.46.185", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 20, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 5000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 500, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Base_Model", "custom_model_config": {"env": "rware", "env_args": {"n_agents": 4, "column_height": 1, "max_inactivity_steps": null, "max_steps": 500, "fast_obs": true, "msg_bits": 0, "sensor_range": 1, "shelf_rows": 1, "shelf_columns": 3, "request_queue_size": 4, "reward_type": "RewardType.INDIVIDUAL", "map_name": "customized_map", "map_size": "tiny", "difficulty": "medium"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": true, "force_coop": false, "local_mode": true, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 4, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 100, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64}, "algorithm": "ia2c", "space_obs": "Dict(obs:Box([-100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100.], [100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.], (112,), float32))", "space_act": "Discrete(5)", "num_agents": 4, "episode_limit": 500, "policy_mapping_info": {"all_scenario": {"description": "rware all scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2", "agent_3"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "rware_customized_map", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 10, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.IA2CTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_il.<locals>.<lambda> at 0x7f38086515e0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "grad_clip": 40.0, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "microbatch_size": null}, "time_since_restore": 1533.5947041511536, "timesteps_since_restore": 0, "iterations_since_restore": 149, "perf": {"cpu_util_percent": 4.359999999999999, "ram_util_percent": 74.20000000000002}}
{"episode_reward_max": 19.0, "episode_reward_min": 3.0, "episode_reward_mean": 10.55, "episode_len_mean": 500.0, "episode_media": {}, "episodes_this_iter": 24, "policy_reward_min": {"shared_policy": 0.0}, "policy_reward_max": {"shared_policy": 7.0}, "policy_reward_mean": {"shared_policy": 2.6375}, "custom_metrics": {}, "hist_stats": {"episode_reward": [16.0, 11.0, 17.0, 17.0, 10.0, 11.0, 8.0, 16.0, 4.0, 12.0, 12.0, 14.0, 8.0, 12.0, 8.0, 11.0, 14.0, 6.0, 4.0, 10.0, 14.0, 3.0, 10.0, 4.0, 13.0, 7.0, 5.0, 9.0, 8.0, 9.0, 10.0, 8.0, 5.0, 11.0, 7.0, 9.0, 11.0, 18.0, 10.0, 15.0, 14.0, 9.0, 9.0, 8.0, 17.0, 9.0, 10.0, 6.0, 9.0, 8.0, 18.0, 15.0, 9.0, 12.0, 18.0, 9.0, 6.0, 15.0, 8.0, 4.0, 15.0, 6.0, 10.0, 14.0, 11.0, 15.0, 7.0, 9.0, 11.0, 9.0, 19.0, 14.0, 13.0, 9.0, 14.0, 12.0, 11.0, 5.0, 9.0, 4.0, 13.0, 12.0, 8.0, 8.0, 14.0, 17.0, 11.0, 12.0, 8.0, 7.0, 15.0, 5.0, 12.0, 8.0, 18.0, 10.0, 14.0, 13.0, 6.0, 7.0], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500], "policy_shared_policy_reward": [4.0, 3.0, 4.0, 5.0, 4.0, 3.0, 2.0, 2.0, 4.0, 4.0, 5.0, 4.0, 5.0, 5.0, 3.0, 4.0, 3.0, 2.0, 2.0, 3.0, 2.0, 4.0, 3.0, 2.0, 4.0, 2.0, 0.0, 2.0, 4.0, 5.0, 3.0, 4.0, 2.0, 1.0, 1.0, 0.0, 2.0, 4.0, 3.0, 3.0, 3.0, 3.0, 2.0, 4.0, 2.0, 4.0, 3.0, 5.0, 4.0, 1.0, 3.0, 0.0, 4.0, 2.0, 2.0, 4.0, 4.0, 1.0, 1.0, 2.0, 3.0, 4.0, 2.0, 2.0, 3.0, 4.0, 3.0, 4.0, 1.0, 1.0, 2.0, 2.0, 0.0, 1.0, 1.0, 2.0, 3.0, 3.0, 0.0, 4.0, 5.0, 4.0, 2.0, 3.0, 0.0, 1.0, 1.0, 1.0, 2.0, 4.0, 0.0, 4.0, 1.0, 1.0, 1.0, 1.0, 4.0, 4.0, 2.0, 3.0, 3.0, 1.0, 1.0, 2.0, 2.0, 1.0, 1.0, 1.0, 3.0, 2.0, 3.0, 1.0, 2.0, 1.0, 3.0, 2.0, 1.0, 2.0, 4.0, 2.0, 3.0, 2.0, 2.0, 3.0, 1.0, 3.0, 2.0, 2.0, 1.0, 2.0, 0.0, 2.0, 3.0, 2.0, 3.0, 3.0, 2.0, 2.0, 0.0, 3.0, 3.0, 2.0, 2.0, 2.0, 2.0, 4.0, 3.0, 2.0, 6.0, 5.0, 3.0, 4.0, 1.0, 2.0, 3.0, 4.0, 3.0, 4.0, 4.0, 4.0, 3.0, 3.0, 3.0, 5.0, 3.0, 3.0, 2.0, 1.0, 1.0, 4.0, 2.0, 2.0, 1.0, 2.0, 2.0, 3.0, 4.0, 5.0, 3.0, 5.0, 2.0, 2.0, 1.0, 4.0, 1.0, 4.0, 2.0, 3.0, 0.0, 2.0, 2.0, 2.0, 2.0, 3.0, 2.0, 2.0, 2.0, 3.0, 2.0, 1.0, 4.0, 3.0, 6.0, 5.0, 3.0, 4.0, 3.0, 5.0, 2.0, 3.0, 3.0, 1.0, 4.0, 4.0, 2.0, 2.0, 5.0, 4.0, 5.0, 4.0, 2.0, 1.0, 3.0, 3.0, 2.0, 1.0, 2.0, 1.0, 5.0, 3.0, 3.0, 4.0, 1.0, 4.0, 1.0, 2.0, 1.0, 1.0, 1.0, 1.0, 3.0, 3.0, 6.0, 3.0, 2.0, 2.0, 1.0, 1.0, 2.0, 3.0, 3.0, 2.0, 3.0, 4.0, 3.0, 4.0, 3.0, 3.0, 3.0, 2.0, 5.0, 3.0, 3.0, 4.0, 1.0, 2.0, 3.0, 1.0, 2.0, 2.0, 3.0, 2.0, 1.0, 2.0, 4.0, 4.0, 3.0, 1.0, 2.0, 3.0, 6.0, 3.0, 4.0, 6.0, 2.0, 4.0, 4.0, 4.0, 3.0, 3.0, 4.0, 3.0, 3.0, 3.0, 2.0, 1.0, 4.0, 5.0, 3.0, 2.0, 2.0, 2.0, 4.0, 4.0, 2.0, 3.0, 4.0, 2.0, 1.0, 1.0, 2.0, 1.0, 2.0, 2.0, 3.0, 2.0, 1.0, 1.0, 1.0, 1.0, 2.0, 3.0, 5.0, 3.0, 2.0, 3.0, 2.0, 5.0, 2.0, 2.0, 3.0, 1.0, 1.0, 2.0, 2.0, 3.0, 4.0, 4.0, 4.0, 2.0, 4.0, 4.0, 5.0, 4.0, 4.0, 2.0, 2.0, 3.0, 3.0, 2.0, 3.0, 4.0, 3.0, 2.0, 1.0, 2.0, 3.0, 1.0, 2.0, 1.0, 2.0, 5.0, 3.0, 5.0, 0.0, 1.0, 2.0, 2.0, 3.0, 2.0, 5.0, 2.0, 0.0, 1.0, 4.0, 3.0, 2.0, 5.0, 4.0, 7.0, 3.0, 2.0, 2.0, 3.0, 3.0, 2.0, 4.0, 5.0, 4.0, 4.0, 2.0, 3.0, 2.0, 1.0, 2.0, 1.0, 3.0, 2.0, 2.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.13370325971425956, "mean_inference_ms": 0.39051041585655955, "mean_action_processing_ms": 0.02915325686036228, "mean_env_wait_ms": 0.4031598322819457, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 1512000, "timesteps_this_iter": 0, "agent_timesteps_total": 6048000, "timers": {"sample_time_ms": 5171.963, "sample_throughput": 974.485, "load_time_ms": 0.165, "load_throughput": 30504029.091, "learn_time_ms": 128.647, "learn_throughput": 39176.902, "update_time_ms": 2.486}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 501.5877685546875, "policy_entropy": 7736.5152587890625, "policy_loss": -68.75336503982544, "vf_loss": 75.74958038330078}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 1512000, "num_agent_steps_sampled": 6048000, "num_steps_trained": 1512000, "num_agent_steps_trained": 6048000, "num_steps_trained_this_iter": 0}, "evaluation": {"episode_reward_max": 17.0, "episode_reward_min": 3.0, "episode_reward_mean": 10.1, "episode_len_mean": 500.0, "episode_media": {}, "episodes_this_iter": 10, "policy_reward_min": {"shared_policy": 0.0}, "policy_reward_max": {"shared_policy": 5.0}, "policy_reward_mean": {"shared_policy": 2.525}, "custom_metrics": {}, "hist_stats": {"episode_reward": [3.0, 6.0, 6.0, 16.0, 4.0, 17.0, 13.0, 15.0, 12.0, 9.0], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500], "policy_shared_policy_reward": [2.0, 1.0, 0.0, 0.0, 2.0, 1.0, 1.0, 2.0, 1.0, 0.0, 3.0, 2.0, 2.0, 4.0, 5.0, 5.0, 1.0, 1.0, 1.0, 1.0, 5.0, 2.0, 5.0, 5.0, 2.0, 3.0, 3.0, 5.0, 1.0, 4.0, 5.0, 5.0, 3.0, 2.0, 3.0, 4.0, 2.0, 3.0, 2.0, 2.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.09493603403429517, "mean_inference_ms": 0.4122495476416481, "mean_action_processing_ms": 0.02895348167889882, "mean_env_wait_ms": 0.41062074870667803, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}}, "done": false, "episodes_total": 3024, "training_iteration": 150, "trial_id": "71426_00000", "experiment_id": "84bca2f7b35f43248fca18d21abe2ebf", "date": "2024-06-12_03-11-42", "timestamp": 1718129502, "time_this_iter_s": 15.243191957473755, "time_total_s": 1548.8378961086273, "pid": 363902, "hostname": "DESKTOP-LQ219J4", "node_ip": "192.168.46.185", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 20, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 5000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 500, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Base_Model", "custom_model_config": {"env": "rware", "env_args": {"n_agents": 4, "column_height": 1, "max_inactivity_steps": null, "max_steps": 500, "fast_obs": true, "msg_bits": 0, "sensor_range": 1, "shelf_rows": 1, "shelf_columns": 3, "request_queue_size": 4, "reward_type": "RewardType.INDIVIDUAL", "map_name": "customized_map", "map_size": "tiny", "difficulty": "medium"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": true, "force_coop": false, "local_mode": true, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 4, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 100, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64}, "algorithm": "ia2c", "space_obs": "Dict(obs:Box([-100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100.], [100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.], (112,), float32))", "space_act": "Discrete(5)", "num_agents": 4, "episode_limit": 500, "policy_mapping_info": {"all_scenario": {"description": "rware all scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2", "agent_3"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "rware_customized_map", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 10, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.IA2CTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_il.<locals>.<lambda> at 0x7f38086c10d0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "grad_clip": 40.0, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "microbatch_size": null}, "time_since_restore": 1548.8378961086273, "timesteps_since_restore": 0, "iterations_since_restore": 150, "perf": {"cpu_util_percent": 4.5227272727272725, "ram_util_percent": 74.56363636363638}}
{"episode_reward_max": 19.0, "episode_reward_min": 2.0, "episode_reward_mean": 10.33, "episode_len_mean": 500.0, "episode_media": {}, "episodes_this_iter": 8, "policy_reward_min": {"shared_policy": 0.0}, "policy_reward_max": {"shared_policy": 7.0}, "policy_reward_mean": {"shared_policy": 2.5825}, "custom_metrics": {}, "hist_stats": {"episode_reward": [4.0, 12.0, 12.0, 14.0, 8.0, 12.0, 8.0, 11.0, 14.0, 6.0, 4.0, 10.0, 14.0, 3.0, 10.0, 4.0, 13.0, 7.0, 5.0, 9.0, 8.0, 9.0, 10.0, 8.0, 5.0, 11.0, 7.0, 9.0, 11.0, 18.0, 10.0, 15.0, 14.0, 9.0, 9.0, 8.0, 17.0, 9.0, 10.0, 6.0, 9.0, 8.0, 18.0, 15.0, 9.0, 12.0, 18.0, 9.0, 6.0, 15.0, 8.0, 4.0, 15.0, 6.0, 10.0, 14.0, 11.0, 15.0, 7.0, 9.0, 11.0, 9.0, 19.0, 14.0, 13.0, 9.0, 14.0, 12.0, 11.0, 5.0, 9.0, 4.0, 13.0, 12.0, 8.0, 8.0, 14.0, 17.0, 11.0, 12.0, 8.0, 7.0, 15.0, 5.0, 12.0, 8.0, 18.0, 10.0, 14.0, 13.0, 6.0, 7.0, 9.0, 10.0, 12.0, 13.0, 2.0, 15.0, 11.0, 12.0], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500], "policy_shared_policy_reward": [2.0, 1.0, 1.0, 0.0, 2.0, 4.0, 3.0, 3.0, 3.0, 3.0, 2.0, 4.0, 2.0, 4.0, 3.0, 5.0, 4.0, 1.0, 3.0, 0.0, 4.0, 2.0, 2.0, 4.0, 4.0, 1.0, 1.0, 2.0, 3.0, 4.0, 2.0, 2.0, 3.0, 4.0, 3.0, 4.0, 1.0, 1.0, 2.0, 2.0, 0.0, 1.0, 1.0, 2.0, 3.0, 3.0, 0.0, 4.0, 5.0, 4.0, 2.0, 3.0, 0.0, 1.0, 1.0, 1.0, 2.0, 4.0, 0.0, 4.0, 1.0, 1.0, 1.0, 1.0, 4.0, 4.0, 2.0, 3.0, 3.0, 1.0, 1.0, 2.0, 2.0, 1.0, 1.0, 1.0, 3.0, 2.0, 3.0, 1.0, 2.0, 1.0, 3.0, 2.0, 1.0, 2.0, 4.0, 2.0, 3.0, 2.0, 2.0, 3.0, 1.0, 3.0, 2.0, 2.0, 1.0, 2.0, 0.0, 2.0, 3.0, 2.0, 3.0, 3.0, 2.0, 2.0, 0.0, 3.0, 3.0, 2.0, 2.0, 2.0, 2.0, 4.0, 3.0, 2.0, 6.0, 5.0, 3.0, 4.0, 1.0, 2.0, 3.0, 4.0, 3.0, 4.0, 4.0, 4.0, 3.0, 3.0, 3.0, 5.0, 3.0, 3.0, 2.0, 1.0, 1.0, 4.0, 2.0, 2.0, 1.0, 2.0, 2.0, 3.0, 4.0, 5.0, 3.0, 5.0, 2.0, 2.0, 1.0, 4.0, 1.0, 4.0, 2.0, 3.0, 0.0, 2.0, 2.0, 2.0, 2.0, 3.0, 2.0, 2.0, 2.0, 3.0, 2.0, 1.0, 4.0, 3.0, 6.0, 5.0, 3.0, 4.0, 3.0, 5.0, 2.0, 3.0, 3.0, 1.0, 4.0, 4.0, 2.0, 2.0, 5.0, 4.0, 5.0, 4.0, 2.0, 1.0, 3.0, 3.0, 2.0, 1.0, 2.0, 1.0, 5.0, 3.0, 3.0, 4.0, 1.0, 4.0, 1.0, 2.0, 1.0, 1.0, 1.0, 1.0, 3.0, 3.0, 6.0, 3.0, 2.0, 2.0, 1.0, 1.0, 2.0, 3.0, 3.0, 2.0, 3.0, 4.0, 3.0, 4.0, 3.0, 3.0, 3.0, 2.0, 5.0, 3.0, 3.0, 4.0, 1.0, 2.0, 3.0, 1.0, 2.0, 2.0, 3.0, 2.0, 1.0, 2.0, 4.0, 4.0, 3.0, 1.0, 2.0, 3.0, 6.0, 3.0, 4.0, 6.0, 2.0, 4.0, 4.0, 4.0, 3.0, 3.0, 4.0, 3.0, 3.0, 3.0, 2.0, 1.0, 4.0, 5.0, 3.0, 2.0, 2.0, 2.0, 4.0, 4.0, 2.0, 3.0, 4.0, 2.0, 1.0, 1.0, 2.0, 1.0, 2.0, 2.0, 3.0, 2.0, 1.0, 1.0, 1.0, 1.0, 2.0, 3.0, 5.0, 3.0, 2.0, 3.0, 2.0, 5.0, 2.0, 2.0, 3.0, 1.0, 1.0, 2.0, 2.0, 3.0, 4.0, 4.0, 4.0, 2.0, 4.0, 4.0, 5.0, 4.0, 4.0, 2.0, 2.0, 3.0, 3.0, 2.0, 3.0, 4.0, 3.0, 2.0, 1.0, 2.0, 3.0, 1.0, 2.0, 1.0, 2.0, 5.0, 3.0, 5.0, 0.0, 1.0, 2.0, 2.0, 3.0, 2.0, 5.0, 2.0, 0.0, 1.0, 4.0, 3.0, 2.0, 5.0, 4.0, 7.0, 3.0, 2.0, 2.0, 3.0, 3.0, 2.0, 4.0, 5.0, 4.0, 4.0, 2.0, 3.0, 2.0, 1.0, 2.0, 1.0, 3.0, 2.0, 2.0, 0.0, 3.0, 2.0, 2.0, 2.0, 4.0, 2.0, 2.0, 2.0, 4.0, 4.0, 3.0, 1.0, 3.0, 2.0, 3.0, 5.0, 0.0, 1.0, 0.0, 1.0, 5.0, 4.0, 5.0, 1.0, 2.0, 4.0, 2.0, 3.0, 3.0, 3.0, 4.0, 2.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.13372702665740832, "mean_inference_ms": 0.39053485778819236, "mean_action_processing_ms": 0.029154598068931586, "mean_env_wait_ms": 0.40316598629199807, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 1517040, "timesteps_this_iter": 0, "agent_timesteps_total": 6068160, "timers": {"sample_time_ms": 5704.18, "sample_throughput": 883.563, "load_time_ms": 0.164, "load_throughput": 30672217.295, "learn_time_ms": 129.265, "learn_throughput": 38989.709, "update_time_ms": 2.497}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 308.4324951171875, "policy_entropy": 7724.046142578125, "policy_loss": 27.859294891357422, "vf_loss": 79.54176902770996}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 1517040, "num_agent_steps_sampled": 6068160, "num_steps_trained": 1517040, "num_agent_steps_trained": 6068160, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 3032, "training_iteration": 151, "trial_id": "71426_00000", "experiment_id": "84bca2f7b35f43248fca18d21abe2ebf", "date": "2024-06-12_03-11-47", "timestamp": 1718129507, "time_this_iter_s": 5.367852210998535, "time_total_s": 1554.2057483196259, "pid": 363902, "hostname": "DESKTOP-LQ219J4", "node_ip": "192.168.46.185", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 20, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 5000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 500, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Base_Model", "custom_model_config": {"env": "rware", "env_args": {"n_agents": 4, "column_height": 1, "max_inactivity_steps": null, "max_steps": 500, "fast_obs": true, "msg_bits": 0, "sensor_range": 1, "shelf_rows": 1, "shelf_columns": 3, "request_queue_size": 4, "reward_type": "RewardType.INDIVIDUAL", "map_name": "customized_map", "map_size": "tiny", "difficulty": "medium"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": true, "force_coop": false, "local_mode": true, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 4, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 100, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64}, "algorithm": "ia2c", "space_obs": "Dict(obs:Box([-100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100.], [100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.], (112,), float32))", "space_act": "Discrete(5)", "num_agents": 4, "episode_limit": 500, "policy_mapping_info": {"all_scenario": {"description": "rware all scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2", "agent_3"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "rware_customized_map", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 10, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.IA2CTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_il.<locals>.<lambda> at 0x7f38280b24c0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "grad_clip": 40.0, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "microbatch_size": null}, "time_since_restore": 1554.2057483196259, "timesteps_since_restore": 0, "iterations_since_restore": 151, "perf": {"cpu_util_percent": 4.425, "ram_util_percent": 74.7}}
{"episode_reward_max": 22.0, "episode_reward_min": 1.0, "episode_reward_mean": 10.92, "episode_len_mean": 500.0, "episode_media": {}, "episodes_this_iter": 20, "policy_reward_min": {"shared_policy": 0.0}, "policy_reward_max": {"shared_policy": 8.0}, "policy_reward_mean": {"shared_policy": 2.73}, "custom_metrics": {}, "hist_stats": {"episode_reward": [8.0, 9.0, 10.0, 8.0, 5.0, 11.0, 7.0, 9.0, 11.0, 18.0, 10.0, 15.0, 14.0, 9.0, 9.0, 8.0, 17.0, 9.0, 10.0, 6.0, 9.0, 8.0, 18.0, 15.0, 9.0, 12.0, 18.0, 9.0, 6.0, 15.0, 8.0, 4.0, 15.0, 6.0, 10.0, 14.0, 11.0, 15.0, 7.0, 9.0, 11.0, 9.0, 19.0, 14.0, 13.0, 9.0, 14.0, 12.0, 11.0, 5.0, 9.0, 4.0, 13.0, 12.0, 8.0, 8.0, 14.0, 17.0, 11.0, 12.0, 8.0, 7.0, 15.0, 5.0, 12.0, 8.0, 18.0, 10.0, 14.0, 13.0, 6.0, 7.0, 9.0, 10.0, 12.0, 13.0, 2.0, 15.0, 11.0, 12.0, 18.0, 13.0, 14.0, 14.0, 11.0, 10.0, 1.0, 10.0, 5.0, 8.0, 12.0, 13.0, 19.0, 19.0, 10.0, 11.0, 22.0, 14.0, 7.0, 8.0], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500], "policy_shared_policy_reward": [2.0, 1.0, 3.0, 2.0, 1.0, 2.0, 4.0, 2.0, 3.0, 2.0, 2.0, 3.0, 1.0, 3.0, 2.0, 2.0, 1.0, 2.0, 0.0, 2.0, 3.0, 2.0, 3.0, 3.0, 2.0, 2.0, 0.0, 3.0, 3.0, 2.0, 2.0, 2.0, 2.0, 4.0, 3.0, 2.0, 6.0, 5.0, 3.0, 4.0, 1.0, 2.0, 3.0, 4.0, 3.0, 4.0, 4.0, 4.0, 3.0, 3.0, 3.0, 5.0, 3.0, 3.0, 2.0, 1.0, 1.0, 4.0, 2.0, 2.0, 1.0, 2.0, 2.0, 3.0, 4.0, 5.0, 3.0, 5.0, 2.0, 2.0, 1.0, 4.0, 1.0, 4.0, 2.0, 3.0, 0.0, 2.0, 2.0, 2.0, 2.0, 3.0, 2.0, 2.0, 2.0, 3.0, 2.0, 1.0, 4.0, 3.0, 6.0, 5.0, 3.0, 4.0, 3.0, 5.0, 2.0, 3.0, 3.0, 1.0, 4.0, 4.0, 2.0, 2.0, 5.0, 4.0, 5.0, 4.0, 2.0, 1.0, 3.0, 3.0, 2.0, 1.0, 2.0, 1.0, 5.0, 3.0, 3.0, 4.0, 1.0, 4.0, 1.0, 2.0, 1.0, 1.0, 1.0, 1.0, 3.0, 3.0, 6.0, 3.0, 2.0, 2.0, 1.0, 1.0, 2.0, 3.0, 3.0, 2.0, 3.0, 4.0, 3.0, 4.0, 3.0, 3.0, 3.0, 2.0, 5.0, 3.0, 3.0, 4.0, 1.0, 2.0, 3.0, 1.0, 2.0, 2.0, 3.0, 2.0, 1.0, 2.0, 4.0, 4.0, 3.0, 1.0, 2.0, 3.0, 6.0, 3.0, 4.0, 6.0, 2.0, 4.0, 4.0, 4.0, 3.0, 3.0, 4.0, 3.0, 3.0, 3.0, 2.0, 1.0, 4.0, 5.0, 3.0, 2.0, 2.0, 2.0, 4.0, 4.0, 2.0, 3.0, 4.0, 2.0, 1.0, 1.0, 2.0, 1.0, 2.0, 2.0, 3.0, 2.0, 1.0, 1.0, 1.0, 1.0, 2.0, 3.0, 5.0, 3.0, 2.0, 3.0, 2.0, 5.0, 2.0, 2.0, 3.0, 1.0, 1.0, 2.0, 2.0, 3.0, 4.0, 4.0, 4.0, 2.0, 4.0, 4.0, 5.0, 4.0, 4.0, 2.0, 2.0, 3.0, 3.0, 2.0, 3.0, 4.0, 3.0, 2.0, 1.0, 2.0, 3.0, 1.0, 2.0, 1.0, 2.0, 5.0, 3.0, 5.0, 0.0, 1.0, 2.0, 2.0, 3.0, 2.0, 5.0, 2.0, 0.0, 1.0, 4.0, 3.0, 2.0, 5.0, 4.0, 7.0, 3.0, 2.0, 2.0, 3.0, 3.0, 2.0, 4.0, 5.0, 4.0, 4.0, 2.0, 3.0, 2.0, 1.0, 2.0, 1.0, 3.0, 2.0, 2.0, 0.0, 3.0, 2.0, 2.0, 2.0, 4.0, 2.0, 2.0, 2.0, 4.0, 4.0, 3.0, 1.0, 3.0, 2.0, 3.0, 5.0, 0.0, 1.0, 0.0, 1.0, 5.0, 4.0, 5.0, 1.0, 2.0, 4.0, 2.0, 3.0, 3.0, 3.0, 4.0, 2.0, 5.0, 4.0, 4.0, 5.0, 3.0, 4.0, 3.0, 3.0, 3.0, 3.0, 6.0, 2.0, 2.0, 6.0, 4.0, 2.0, 3.0, 4.0, 3.0, 1.0, 4.0, 3.0, 1.0, 2.0, 1.0, 0.0, 0.0, 0.0, 1.0, 3.0, 3.0, 3.0, 2.0, 1.0, 1.0, 1.0, 1.0, 2.0, 3.0, 2.0, 4.0, 4.0, 1.0, 3.0, 5.0, 3.0, 2.0, 3.0, 3.0, 4.0, 6.0, 6.0, 8.0, 4.0, 2.0, 5.0, 3.0, 2.0, 2.0, 3.0, 3.0, 4.0, 3.0, 1.0, 7.0, 7.0, 2.0, 6.0, 3.0, 4.0, 6.0, 1.0, 2.0, 1.0, 1.0, 3.0, 2.0, 1.0, 4.0, 1.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.13375888567623803, "mean_inference_ms": 0.3906303816113402, "mean_action_processing_ms": 0.029160618333337763, "mean_env_wait_ms": 0.4032463261891778, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 1527120, "timesteps_this_iter": 0, "agent_timesteps_total": 6108480, "timers": {"sample_time_ms": 5793.672, "sample_throughput": 869.915, "load_time_ms": 0.163, "load_throughput": 30842270.441, "learn_time_ms": 129.853, "learn_throughput": 38813.245, "update_time_ms": 2.475}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 283.4510803222656, "policy_entropy": 7630.1287841796875, "policy_loss": -0.8363757133483887, "vf_loss": 71.52380657196045}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 1527120, "num_agent_steps_sampled": 6108480, "num_steps_trained": 1527120, "num_agent_steps_trained": 6108480, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 3052, "training_iteration": 152, "trial_id": "71426_00000", "experiment_id": "84bca2f7b35f43248fca18d21abe2ebf", "date": "2024-06-12_03-11-58", "timestamp": 1718129518, "time_this_iter_s": 11.02337646484375, "time_total_s": 1565.2291247844696, "pid": 363902, "hostname": "DESKTOP-LQ219J4", "node_ip": "192.168.46.185", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 20, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 5000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 500, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Base_Model", "custom_model_config": {"env": "rware", "env_args": {"n_agents": 4, "column_height": 1, "max_inactivity_steps": null, "max_steps": 500, "fast_obs": true, "msg_bits": 0, "sensor_range": 1, "shelf_rows": 1, "shelf_columns": 3, "request_queue_size": 4, "reward_type": "RewardType.INDIVIDUAL", "map_name": "customized_map", "map_size": "tiny", "difficulty": "medium"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": true, "force_coop": false, "local_mode": true, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 4, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 100, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64}, "algorithm": "ia2c", "space_obs": "Dict(obs:Box([-100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100.], [100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.], (112,), float32))", "space_act": "Discrete(5)", "num_agents": 4, "episode_limit": 500, "policy_mapping_info": {"all_scenario": {"description": "rware all scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2", "agent_3"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "rware_customized_map", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 10, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.IA2CTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_il.<locals>.<lambda> at 0x7f38086c1ca0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "grad_clip": 40.0, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "microbatch_size": null}, "time_since_restore": 1565.2291247844696, "timesteps_since_restore": 0, "iterations_since_restore": 152, "perf": {"cpu_util_percent": 4.393750000000001, "ram_util_percent": 74.86875}}
{"episode_reward_max": 24.0, "episode_reward_min": 1.0, "episode_reward_mean": 11.24, "episode_len_mean": 500.0, "episode_media": {}, "episodes_this_iter": 20, "policy_reward_min": {"shared_policy": 0.0}, "policy_reward_max": {"shared_policy": 8.0}, "policy_reward_mean": {"shared_policy": 2.81}, "custom_metrics": {}, "hist_stats": {"episode_reward": [9.0, 8.0, 18.0, 15.0, 9.0, 12.0, 18.0, 9.0, 6.0, 15.0, 8.0, 4.0, 15.0, 6.0, 10.0, 14.0, 11.0, 15.0, 7.0, 9.0, 11.0, 9.0, 19.0, 14.0, 13.0, 9.0, 14.0, 12.0, 11.0, 5.0, 9.0, 4.0, 13.0, 12.0, 8.0, 8.0, 14.0, 17.0, 11.0, 12.0, 8.0, 7.0, 15.0, 5.0, 12.0, 8.0, 18.0, 10.0, 14.0, 13.0, 6.0, 7.0, 9.0, 10.0, 12.0, 13.0, 2.0, 15.0, 11.0, 12.0, 18.0, 13.0, 14.0, 14.0, 11.0, 10.0, 1.0, 10.0, 5.0, 8.0, 12.0, 13.0, 19.0, 19.0, 10.0, 11.0, 22.0, 14.0, 7.0, 8.0, 14.0, 10.0, 19.0, 13.0, 3.0, 18.0, 11.0, 9.0, 14.0, 8.0, 6.0, 4.0, 17.0, 10.0, 24.0, 12.0, 6.0, 10.0, 14.0, 13.0], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500], "policy_shared_policy_reward": [2.0, 3.0, 2.0, 2.0, 2.0, 3.0, 2.0, 1.0, 4.0, 3.0, 6.0, 5.0, 3.0, 4.0, 3.0, 5.0, 2.0, 3.0, 3.0, 1.0, 4.0, 4.0, 2.0, 2.0, 5.0, 4.0, 5.0, 4.0, 2.0, 1.0, 3.0, 3.0, 2.0, 1.0, 2.0, 1.0, 5.0, 3.0, 3.0, 4.0, 1.0, 4.0, 1.0, 2.0, 1.0, 1.0, 1.0, 1.0, 3.0, 3.0, 6.0, 3.0, 2.0, 2.0, 1.0, 1.0, 2.0, 3.0, 3.0, 2.0, 3.0, 4.0, 3.0, 4.0, 3.0, 3.0, 3.0, 2.0, 5.0, 3.0, 3.0, 4.0, 1.0, 2.0, 3.0, 1.0, 2.0, 2.0, 3.0, 2.0, 1.0, 2.0, 4.0, 4.0, 3.0, 1.0, 2.0, 3.0, 6.0, 3.0, 4.0, 6.0, 2.0, 4.0, 4.0, 4.0, 3.0, 3.0, 4.0, 3.0, 3.0, 3.0, 2.0, 1.0, 4.0, 5.0, 3.0, 2.0, 2.0, 2.0, 4.0, 4.0, 2.0, 3.0, 4.0, 2.0, 1.0, 1.0, 2.0, 1.0, 2.0, 2.0, 3.0, 2.0, 1.0, 1.0, 1.0, 1.0, 2.0, 3.0, 5.0, 3.0, 2.0, 3.0, 2.0, 5.0, 2.0, 2.0, 3.0, 1.0, 1.0, 2.0, 2.0, 3.0, 4.0, 4.0, 4.0, 2.0, 4.0, 4.0, 5.0, 4.0, 4.0, 2.0, 2.0, 3.0, 3.0, 2.0, 3.0, 4.0, 3.0, 2.0, 1.0, 2.0, 3.0, 1.0, 2.0, 1.0, 2.0, 5.0, 3.0, 5.0, 0.0, 1.0, 2.0, 2.0, 3.0, 2.0, 5.0, 2.0, 0.0, 1.0, 4.0, 3.0, 2.0, 5.0, 4.0, 7.0, 3.0, 2.0, 2.0, 3.0, 3.0, 2.0, 4.0, 5.0, 4.0, 4.0, 2.0, 3.0, 2.0, 1.0, 2.0, 1.0, 3.0, 2.0, 2.0, 0.0, 3.0, 2.0, 2.0, 2.0, 4.0, 2.0, 2.0, 2.0, 4.0, 4.0, 3.0, 1.0, 3.0, 2.0, 3.0, 5.0, 0.0, 1.0, 0.0, 1.0, 5.0, 4.0, 5.0, 1.0, 2.0, 4.0, 2.0, 3.0, 3.0, 3.0, 4.0, 2.0, 5.0, 4.0, 4.0, 5.0, 3.0, 4.0, 3.0, 3.0, 3.0, 3.0, 6.0, 2.0, 2.0, 6.0, 4.0, 2.0, 3.0, 4.0, 3.0, 1.0, 4.0, 3.0, 1.0, 2.0, 1.0, 0.0, 0.0, 0.0, 1.0, 3.0, 3.0, 3.0, 2.0, 1.0, 1.0, 1.0, 1.0, 2.0, 3.0, 2.0, 4.0, 4.0, 1.0, 3.0, 5.0, 3.0, 2.0, 3.0, 3.0, 4.0, 6.0, 6.0, 8.0, 4.0, 2.0, 5.0, 3.0, 2.0, 2.0, 3.0, 3.0, 4.0, 3.0, 1.0, 7.0, 7.0, 2.0, 6.0, 3.0, 4.0, 6.0, 1.0, 2.0, 1.0, 1.0, 3.0, 2.0, 1.0, 4.0, 1.0, 1.0, 4.0, 4.0, 5.0, 2.0, 2.0, 3.0, 3.0, 6.0, 5.0, 6.0, 2.0, 2.0, 4.0, 3.0, 4.0, 2.0, 0.0, 0.0, 1.0, 4.0, 5.0, 4.0, 5.0, 3.0, 2.0, 4.0, 2.0, 3.0, 1.0, 2.0, 3.0, 5.0, 3.0, 3.0, 3.0, 1.0, 0.0, 4.0, 3.0, 1.0, 3.0, 1.0, 1.0, 2.0, 1.0, 0.0, 1.0, 5.0, 6.0, 3.0, 3.0, 3.0, 3.0, 2.0, 2.0, 7.0, 6.0, 6.0, 5.0, 4.0, 4.0, 2.0, 2.0, 1.0, 3.0, 0.0, 2.0, 2.0, 3.0, 2.0, 3.0, 4.0, 3.0, 5.0, 2.0, 3.0, 3.0, 3.0, 4.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.1337952664308952, "mean_inference_ms": 0.39073898707724725, "mean_action_processing_ms": 0.029167267454550824, "mean_env_wait_ms": 0.4033485361419718, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 1537200, "timesteps_this_iter": 0, "agent_timesteps_total": 6148800, "timers": {"sample_time_ms": 5821.698, "sample_throughput": 865.727, "load_time_ms": 0.16, "load_throughput": 31452599.554, "learn_time_ms": 130.986, "learn_throughput": 38477.381, "update_time_ms": 2.521}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 344.94281005859375, "policy_entropy": 7615.6788330078125, "policy_loss": 47.63600730895996, "vf_loss": 83.68766689300537}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 1537200, "num_agent_steps_sampled": 6148800, "num_steps_trained": 1537200, "num_agent_steps_trained": 6148800, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 3072, "training_iteration": 153, "trial_id": "71426_00000", "experiment_id": "84bca2f7b35f43248fca18d21abe2ebf", "date": "2024-06-12_03-12-09", "timestamp": 1718129529, "time_this_iter_s": 10.735817193984985, "time_total_s": 1575.9649419784546, "pid": 363902, "hostname": "DESKTOP-LQ219J4", "node_ip": "192.168.46.185", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 20, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 5000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 500, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Base_Model", "custom_model_config": {"env": "rware", "env_args": {"n_agents": 4, "column_height": 1, "max_inactivity_steps": null, "max_steps": 500, "fast_obs": true, "msg_bits": 0, "sensor_range": 1, "shelf_rows": 1, "shelf_columns": 3, "request_queue_size": 4, "reward_type": "RewardType.INDIVIDUAL", "map_name": "customized_map", "map_size": "tiny", "difficulty": "medium"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": true, "force_coop": false, "local_mode": true, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 4, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 100, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64}, "algorithm": "ia2c", "space_obs": "Dict(obs:Box([-100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100.], [100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.], (112,), float32))", "space_act": "Discrete(5)", "num_agents": 4, "episode_limit": 500, "policy_mapping_info": {"all_scenario": {"description": "rware all scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2", "agent_3"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "rware_customized_map", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 10, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.IA2CTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_il.<locals>.<lambda> at 0x7f382806ea60>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "grad_clip": 40.0, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "microbatch_size": null}, "time_since_restore": 1575.9649419784546, "timesteps_since_restore": 0, "iterations_since_restore": 153, "perf": {"cpu_util_percent": 4.24, "ram_util_percent": 75.19333333333336}}
{"episode_reward_max": 25.0, "episode_reward_min": 1.0, "episode_reward_mean": 11.54, "episode_len_mean": 500.0, "episode_media": {}, "episodes_this_iter": 20, "policy_reward_min": {"shared_policy": 0.0}, "policy_reward_max": {"shared_policy": 8.0}, "policy_reward_mean": {"shared_policy": 2.885}, "custom_metrics": {}, "hist_stats": {"episode_reward": [11.0, 9.0, 19.0, 14.0, 13.0, 9.0, 14.0, 12.0, 11.0, 5.0, 9.0, 4.0, 13.0, 12.0, 8.0, 8.0, 14.0, 17.0, 11.0, 12.0, 8.0, 7.0, 15.0, 5.0, 12.0, 8.0, 18.0, 10.0, 14.0, 13.0, 6.0, 7.0, 9.0, 10.0, 12.0, 13.0, 2.0, 15.0, 11.0, 12.0, 18.0, 13.0, 14.0, 14.0, 11.0, 10.0, 1.0, 10.0, 5.0, 8.0, 12.0, 13.0, 19.0, 19.0, 10.0, 11.0, 22.0, 14.0, 7.0, 8.0, 14.0, 10.0, 19.0, 13.0, 3.0, 18.0, 11.0, 9.0, 14.0, 8.0, 6.0, 4.0, 17.0, 10.0, 24.0, 12.0, 6.0, 10.0, 14.0, 13.0, 5.0, 15.0, 5.0, 14.0, 6.0, 19.0, 21.0, 12.0, 18.0, 6.0, 7.0, 11.0, 19.0, 6.0, 18.0, 8.0, 6.0, 25.0, 15.0, 12.0], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500], "policy_shared_policy_reward": [1.0, 2.0, 4.0, 4.0, 3.0, 1.0, 2.0, 3.0, 6.0, 3.0, 4.0, 6.0, 2.0, 4.0, 4.0, 4.0, 3.0, 3.0, 4.0, 3.0, 3.0, 3.0, 2.0, 1.0, 4.0, 5.0, 3.0, 2.0, 2.0, 2.0, 4.0, 4.0, 2.0, 3.0, 4.0, 2.0, 1.0, 1.0, 2.0, 1.0, 2.0, 2.0, 3.0, 2.0, 1.0, 1.0, 1.0, 1.0, 2.0, 3.0, 5.0, 3.0, 2.0, 3.0, 2.0, 5.0, 2.0, 2.0, 3.0, 1.0, 1.0, 2.0, 2.0, 3.0, 4.0, 4.0, 4.0, 2.0, 4.0, 4.0, 5.0, 4.0, 4.0, 2.0, 2.0, 3.0, 3.0, 2.0, 3.0, 4.0, 3.0, 2.0, 1.0, 2.0, 3.0, 1.0, 2.0, 1.0, 2.0, 5.0, 3.0, 5.0, 0.0, 1.0, 2.0, 2.0, 3.0, 2.0, 5.0, 2.0, 0.0, 1.0, 4.0, 3.0, 2.0, 5.0, 4.0, 7.0, 3.0, 2.0, 2.0, 3.0, 3.0, 2.0, 4.0, 5.0, 4.0, 4.0, 2.0, 3.0, 2.0, 1.0, 2.0, 1.0, 3.0, 2.0, 2.0, 0.0, 3.0, 2.0, 2.0, 2.0, 4.0, 2.0, 2.0, 2.0, 4.0, 4.0, 3.0, 1.0, 3.0, 2.0, 3.0, 5.0, 0.0, 1.0, 0.0, 1.0, 5.0, 4.0, 5.0, 1.0, 2.0, 4.0, 2.0, 3.0, 3.0, 3.0, 4.0, 2.0, 5.0, 4.0, 4.0, 5.0, 3.0, 4.0, 3.0, 3.0, 3.0, 3.0, 6.0, 2.0, 2.0, 6.0, 4.0, 2.0, 3.0, 4.0, 3.0, 1.0, 4.0, 3.0, 1.0, 2.0, 1.0, 0.0, 0.0, 0.0, 1.0, 3.0, 3.0, 3.0, 2.0, 1.0, 1.0, 1.0, 1.0, 2.0, 3.0, 2.0, 4.0, 4.0, 1.0, 3.0, 5.0, 3.0, 2.0, 3.0, 3.0, 4.0, 6.0, 6.0, 8.0, 4.0, 2.0, 5.0, 3.0, 2.0, 2.0, 3.0, 3.0, 4.0, 3.0, 1.0, 7.0, 7.0, 2.0, 6.0, 3.0, 4.0, 6.0, 1.0, 2.0, 1.0, 1.0, 3.0, 2.0, 1.0, 4.0, 1.0, 1.0, 4.0, 4.0, 5.0, 2.0, 2.0, 3.0, 3.0, 6.0, 5.0, 6.0, 2.0, 2.0, 4.0, 3.0, 4.0, 2.0, 0.0, 0.0, 1.0, 4.0, 5.0, 4.0, 5.0, 3.0, 2.0, 4.0, 2.0, 3.0, 1.0, 2.0, 3.0, 5.0, 3.0, 3.0, 3.0, 1.0, 0.0, 4.0, 3.0, 1.0, 3.0, 1.0, 1.0, 2.0, 1.0, 0.0, 1.0, 5.0, 6.0, 3.0, 3.0, 3.0, 3.0, 2.0, 2.0, 7.0, 6.0, 6.0, 5.0, 4.0, 4.0, 2.0, 2.0, 1.0, 3.0, 0.0, 2.0, 2.0, 3.0, 2.0, 3.0, 4.0, 3.0, 5.0, 2.0, 3.0, 3.0, 3.0, 4.0, 2.0, 0.0, 2.0, 1.0, 5.0, 2.0, 3.0, 5.0, 1.0, 1.0, 2.0, 1.0, 4.0, 3.0, 3.0, 4.0, 1.0, 2.0, 1.0, 2.0, 6.0, 4.0, 4.0, 5.0, 4.0, 6.0, 7.0, 4.0, 2.0, 2.0, 5.0, 3.0, 5.0, 3.0, 5.0, 5.0, 2.0, 2.0, 1.0, 1.0, 1.0, 3.0, 2.0, 1.0, 1.0, 6.0, 0.0, 4.0, 4.0, 3.0, 5.0, 7.0, 2.0, 1.0, 0.0, 3.0, 5.0, 7.0, 3.0, 3.0, 4.0, 1.0, 2.0, 1.0, 2.0, 1.0, 1.0, 2.0, 4.0, 7.0, 7.0, 7.0, 4.0, 2.0, 5.0, 4.0, 4.0, 2.0, 4.0, 2.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.1338355474224196, "mean_inference_ms": 0.3908615471251521, "mean_action_processing_ms": 0.02917474316461482, "mean_env_wait_ms": 0.40346568650546316, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 1547280, "timesteps_this_iter": 0, "agent_timesteps_total": 6189120, "timers": {"sample_time_ms": 5869.42, "sample_throughput": 858.688, "load_time_ms": 0.162, "load_throughput": 31087194.353, "learn_time_ms": 134.902, "learn_throughput": 37360.395, "update_time_ms": 2.578}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 502.4990234375, "policy_entropy": 7685.861328125, "policy_loss": -13.423622131347656, "vf_loss": 90.32259368896484}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 1547280, "num_agent_steps_sampled": 6189120, "num_steps_trained": 1547280, "num_agent_steps_trained": 6189120, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 3092, "training_iteration": 154, "trial_id": "71426_00000", "experiment_id": "84bca2f7b35f43248fca18d21abe2ebf", "date": "2024-06-12_03-12-20", "timestamp": 1718129540, "time_this_iter_s": 10.900810241699219, "time_total_s": 1586.8657522201538, "pid": 363902, "hostname": "DESKTOP-LQ219J4", "node_ip": "192.168.46.185", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 20, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 5000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 500, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Base_Model", "custom_model_config": {"env": "rware", "env_args": {"n_agents": 4, "column_height": 1, "max_inactivity_steps": null, "max_steps": 500, "fast_obs": true, "msg_bits": 0, "sensor_range": 1, "shelf_rows": 1, "shelf_columns": 3, "request_queue_size": 4, "reward_type": "RewardType.INDIVIDUAL", "map_name": "customized_map", "map_size": "tiny", "difficulty": "medium"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": true, "force_coop": false, "local_mode": true, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 4, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 100, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64}, "algorithm": "ia2c", "space_obs": "Dict(obs:Box([-100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100.], [100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.], (112,), float32))", "space_act": "Discrete(5)", "num_agents": 4, "episode_limit": 500, "policy_mapping_info": {"all_scenario": {"description": "rware all scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2", "agent_3"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "rware_customized_map", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 10, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.IA2CTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_il.<locals>.<lambda> at 0x7f383066a940>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "grad_clip": 40.0, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "microbatch_size": null}, "time_since_restore": 1586.8657522201538, "timesteps_since_restore": 0, "iterations_since_restore": 154, "perf": {"cpu_util_percent": 4.24, "ram_util_percent": 75.4}}
{"episode_reward_max": 25.0, "episode_reward_min": 0.0, "episode_reward_mean": 11.12, "episode_len_mean": 500.0, "episode_media": {}, "episodes_this_iter": 20, "policy_reward_min": {"shared_policy": 0.0}, "policy_reward_max": {"shared_policy": 8.0}, "policy_reward_mean": {"shared_policy": 2.78}, "custom_metrics": {}, "hist_stats": {"episode_reward": [8.0, 7.0, 15.0, 5.0, 12.0, 8.0, 18.0, 10.0, 14.0, 13.0, 6.0, 7.0, 9.0, 10.0, 12.0, 13.0, 2.0, 15.0, 11.0, 12.0, 18.0, 13.0, 14.0, 14.0, 11.0, 10.0, 1.0, 10.0, 5.0, 8.0, 12.0, 13.0, 19.0, 19.0, 10.0, 11.0, 22.0, 14.0, 7.0, 8.0, 14.0, 10.0, 19.0, 13.0, 3.0, 18.0, 11.0, 9.0, 14.0, 8.0, 6.0, 4.0, 17.0, 10.0, 24.0, 12.0, 6.0, 10.0, 14.0, 13.0, 5.0, 15.0, 5.0, 14.0, 6.0, 19.0, 21.0, 12.0, 18.0, 6.0, 7.0, 11.0, 19.0, 6.0, 18.0, 8.0, 6.0, 25.0, 15.0, 12.0, 15.0, 4.0, 14.0, 12.0, 15.0, 15.0, 8.0, 8.0, 0.0, 13.0, 17.0, 3.0, 3.0, 6.0, 10.0, 6.0, 10.0, 9.0, 6.0, 9.0], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500], "policy_shared_policy_reward": [3.0, 2.0, 1.0, 2.0, 3.0, 1.0, 2.0, 1.0, 2.0, 5.0, 3.0, 5.0, 0.0, 1.0, 2.0, 2.0, 3.0, 2.0, 5.0, 2.0, 0.0, 1.0, 4.0, 3.0, 2.0, 5.0, 4.0, 7.0, 3.0, 2.0, 2.0, 3.0, 3.0, 2.0, 4.0, 5.0, 4.0, 4.0, 2.0, 3.0, 2.0, 1.0, 2.0, 1.0, 3.0, 2.0, 2.0, 0.0, 3.0, 2.0, 2.0, 2.0, 4.0, 2.0, 2.0, 2.0, 4.0, 4.0, 3.0, 1.0, 3.0, 2.0, 3.0, 5.0, 0.0, 1.0, 0.0, 1.0, 5.0, 4.0, 5.0, 1.0, 2.0, 4.0, 2.0, 3.0, 3.0, 3.0, 4.0, 2.0, 5.0, 4.0, 4.0, 5.0, 3.0, 4.0, 3.0, 3.0, 3.0, 3.0, 6.0, 2.0, 2.0, 6.0, 4.0, 2.0, 3.0, 4.0, 3.0, 1.0, 4.0, 3.0, 1.0, 2.0, 1.0, 0.0, 0.0, 0.0, 1.0, 3.0, 3.0, 3.0, 2.0, 1.0, 1.0, 1.0, 1.0, 2.0, 3.0, 2.0, 4.0, 4.0, 1.0, 3.0, 5.0, 3.0, 2.0, 3.0, 3.0, 4.0, 6.0, 6.0, 8.0, 4.0, 2.0, 5.0, 3.0, 2.0, 2.0, 3.0, 3.0, 4.0, 3.0, 1.0, 7.0, 7.0, 2.0, 6.0, 3.0, 4.0, 6.0, 1.0, 2.0, 1.0, 1.0, 3.0, 2.0, 1.0, 4.0, 1.0, 1.0, 4.0, 4.0, 5.0, 2.0, 2.0, 3.0, 3.0, 6.0, 5.0, 6.0, 2.0, 2.0, 4.0, 3.0, 4.0, 2.0, 0.0, 0.0, 1.0, 4.0, 5.0, 4.0, 5.0, 3.0, 2.0, 4.0, 2.0, 3.0, 1.0, 2.0, 3.0, 5.0, 3.0, 3.0, 3.0, 1.0, 0.0, 4.0, 3.0, 1.0, 3.0, 1.0, 1.0, 2.0, 1.0, 0.0, 1.0, 5.0, 6.0, 3.0, 3.0, 3.0, 3.0, 2.0, 2.0, 7.0, 6.0, 6.0, 5.0, 4.0, 4.0, 2.0, 2.0, 1.0, 3.0, 0.0, 2.0, 2.0, 3.0, 2.0, 3.0, 4.0, 3.0, 5.0, 2.0, 3.0, 3.0, 3.0, 4.0, 2.0, 0.0, 2.0, 1.0, 5.0, 2.0, 3.0, 5.0, 1.0, 1.0, 2.0, 1.0, 4.0, 3.0, 3.0, 4.0, 1.0, 2.0, 1.0, 2.0, 6.0, 4.0, 4.0, 5.0, 4.0, 6.0, 7.0, 4.0, 2.0, 2.0, 5.0, 3.0, 5.0, 3.0, 5.0, 5.0, 2.0, 2.0, 1.0, 1.0, 1.0, 3.0, 2.0, 1.0, 1.0, 6.0, 0.0, 4.0, 4.0, 3.0, 5.0, 7.0, 2.0, 1.0, 0.0, 3.0, 5.0, 7.0, 3.0, 3.0, 4.0, 1.0, 2.0, 1.0, 2.0, 1.0, 1.0, 2.0, 4.0, 7.0, 7.0, 7.0, 4.0, 2.0, 5.0, 4.0, 4.0, 2.0, 4.0, 2.0, 3.0, 6.0, 4.0, 2.0, 2.0, 0.0, 1.0, 1.0, 3.0, 4.0, 5.0, 2.0, 5.0, 2.0, 2.0, 3.0, 4.0, 5.0, 3.0, 3.0, 4.0, 3.0, 5.0, 3.0, 1.0, 3.0, 1.0, 3.0, 3.0, 1.0, 1.0, 3.0, 0.0, 0.0, 0.0, 0.0, 3.0, 3.0, 1.0, 6.0, 4.0, 4.0, 5.0, 4.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 2.0, 1.0, 1.0, 2.0, 2.0, 3.0, 2.0, 3.0, 1.0, 1.0, 2.0, 2.0, 2.0, 3.0, 3.0, 2.0, 3.0, 2.0, 2.0, 2.0, 1.0, 2.0, 2.0, 1.0, 2.0, 2.0, 2.0, 3.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.13389751818293769, "mean_inference_ms": 0.39101938065470165, "mean_action_processing_ms": 0.02918255810713349, "mean_env_wait_ms": 0.4036011805597886, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 1557360, "timesteps_this_iter": 0, "agent_timesteps_total": 6229440, "timers": {"sample_time_ms": 5931.732, "sample_throughput": 849.668, "load_time_ms": 0.169, "load_throughput": 29904218.645, "learn_time_ms": 133.983, "learn_throughput": 37616.715, "update_time_ms": 2.573}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 306.06524658203125, "policy_entropy": 7718.603271484375, "policy_loss": -30.215725898742676, "vf_loss": 77.5485258102417}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 1557360, "num_agent_steps_sampled": 6229440, "num_steps_trained": 1557360, "num_agent_steps_trained": 6229440, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 3112, "training_iteration": 155, "trial_id": "71426_00000", "experiment_id": "84bca2f7b35f43248fca18d21abe2ebf", "date": "2024-06-12_03-12-31", "timestamp": 1718129551, "time_this_iter_s": 11.141926527023315, "time_total_s": 1598.0076787471771, "pid": 363902, "hostname": "DESKTOP-LQ219J4", "node_ip": "192.168.46.185", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 20, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 5000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 500, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Base_Model", "custom_model_config": {"env": "rware", "env_args": {"n_agents": 4, "column_height": 1, "max_inactivity_steps": null, "max_steps": 500, "fast_obs": true, "msg_bits": 0, "sensor_range": 1, "shelf_rows": 1, "shelf_columns": 3, "request_queue_size": 4, "reward_type": "RewardType.INDIVIDUAL", "map_name": "customized_map", "map_size": "tiny", "difficulty": "medium"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": true, "force_coop": false, "local_mode": true, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 4, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 100, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64}, "algorithm": "ia2c", "space_obs": "Dict(obs:Box([-100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100.], [100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.], (112,), float32))", "space_act": "Discrete(5)", "num_agents": 4, "episode_limit": 500, "policy_mapping_info": {"all_scenario": {"description": "rware all scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2", "agent_3"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "rware_customized_map", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 10, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.IA2CTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_il.<locals>.<lambda> at 0x7f38081d5f70>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "grad_clip": 40.0, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "microbatch_size": null}, "time_since_restore": 1598.0076787471771, "timesteps_since_restore": 0, "iterations_since_restore": 155, "perf": {"cpu_util_percent": 4.23125, "ram_util_percent": 75.7}}
{"episode_reward_max": 27.0, "episode_reward_min": 0.0, "episode_reward_mean": 11.87, "episode_len_mean": 500.0, "episode_media": {}, "episodes_this_iter": 20, "policy_reward_min": {"shared_policy": 0.0}, "policy_reward_max": {"shared_policy": 8.0}, "policy_reward_mean": {"shared_policy": 2.9675}, "custom_metrics": {}, "hist_stats": {"episode_reward": [18.0, 13.0, 14.0, 14.0, 11.0, 10.0, 1.0, 10.0, 5.0, 8.0, 12.0, 13.0, 19.0, 19.0, 10.0, 11.0, 22.0, 14.0, 7.0, 8.0, 14.0, 10.0, 19.0, 13.0, 3.0, 18.0, 11.0, 9.0, 14.0, 8.0, 6.0, 4.0, 17.0, 10.0, 24.0, 12.0, 6.0, 10.0, 14.0, 13.0, 5.0, 15.0, 5.0, 14.0, 6.0, 19.0, 21.0, 12.0, 18.0, 6.0, 7.0, 11.0, 19.0, 6.0, 18.0, 8.0, 6.0, 25.0, 15.0, 12.0, 15.0, 4.0, 14.0, 12.0, 15.0, 15.0, 8.0, 8.0, 0.0, 13.0, 17.0, 3.0, 3.0, 6.0, 10.0, 6.0, 10.0, 9.0, 6.0, 9.0, 8.0, 9.0, 19.0, 14.0, 14.0, 13.0, 6.0, 14.0, 8.0, 17.0, 9.0, 8.0, 8.0, 27.0, 23.0, 20.0, 19.0, 20.0, 8.0, 18.0], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500], "policy_shared_policy_reward": [5.0, 4.0, 4.0, 5.0, 3.0, 4.0, 3.0, 3.0, 3.0, 3.0, 6.0, 2.0, 2.0, 6.0, 4.0, 2.0, 3.0, 4.0, 3.0, 1.0, 4.0, 3.0, 1.0, 2.0, 1.0, 0.0, 0.0, 0.0, 1.0, 3.0, 3.0, 3.0, 2.0, 1.0, 1.0, 1.0, 1.0, 2.0, 3.0, 2.0, 4.0, 4.0, 1.0, 3.0, 5.0, 3.0, 2.0, 3.0, 3.0, 4.0, 6.0, 6.0, 8.0, 4.0, 2.0, 5.0, 3.0, 2.0, 2.0, 3.0, 3.0, 4.0, 3.0, 1.0, 7.0, 7.0, 2.0, 6.0, 3.0, 4.0, 6.0, 1.0, 2.0, 1.0, 1.0, 3.0, 2.0, 1.0, 4.0, 1.0, 1.0, 4.0, 4.0, 5.0, 2.0, 2.0, 3.0, 3.0, 6.0, 5.0, 6.0, 2.0, 2.0, 4.0, 3.0, 4.0, 2.0, 0.0, 0.0, 1.0, 4.0, 5.0, 4.0, 5.0, 3.0, 2.0, 4.0, 2.0, 3.0, 1.0, 2.0, 3.0, 5.0, 3.0, 3.0, 3.0, 1.0, 0.0, 4.0, 3.0, 1.0, 3.0, 1.0, 1.0, 2.0, 1.0, 0.0, 1.0, 5.0, 6.0, 3.0, 3.0, 3.0, 3.0, 2.0, 2.0, 7.0, 6.0, 6.0, 5.0, 4.0, 4.0, 2.0, 2.0, 1.0, 3.0, 0.0, 2.0, 2.0, 3.0, 2.0, 3.0, 4.0, 3.0, 5.0, 2.0, 3.0, 3.0, 3.0, 4.0, 2.0, 0.0, 2.0, 1.0, 5.0, 2.0, 3.0, 5.0, 1.0, 1.0, 2.0, 1.0, 4.0, 3.0, 3.0, 4.0, 1.0, 2.0, 1.0, 2.0, 6.0, 4.0, 4.0, 5.0, 4.0, 6.0, 7.0, 4.0, 2.0, 2.0, 5.0, 3.0, 5.0, 3.0, 5.0, 5.0, 2.0, 2.0, 1.0, 1.0, 1.0, 3.0, 2.0, 1.0, 1.0, 6.0, 0.0, 4.0, 4.0, 3.0, 5.0, 7.0, 2.0, 1.0, 0.0, 3.0, 5.0, 7.0, 3.0, 3.0, 4.0, 1.0, 2.0, 1.0, 2.0, 1.0, 1.0, 2.0, 4.0, 7.0, 7.0, 7.0, 4.0, 2.0, 5.0, 4.0, 4.0, 2.0, 4.0, 2.0, 3.0, 6.0, 4.0, 2.0, 2.0, 0.0, 1.0, 1.0, 3.0, 4.0, 5.0, 2.0, 5.0, 2.0, 2.0, 3.0, 4.0, 5.0, 3.0, 3.0, 4.0, 3.0, 5.0, 3.0, 1.0, 3.0, 1.0, 3.0, 3.0, 1.0, 1.0, 3.0, 0.0, 0.0, 0.0, 0.0, 3.0, 3.0, 1.0, 6.0, 4.0, 4.0, 5.0, 4.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 2.0, 1.0, 1.0, 2.0, 2.0, 3.0, 2.0, 3.0, 1.0, 1.0, 2.0, 2.0, 2.0, 3.0, 3.0, 2.0, 3.0, 2.0, 2.0, 2.0, 1.0, 2.0, 2.0, 1.0, 2.0, 2.0, 2.0, 3.0, 3.0, 2.0, 2.0, 1.0, 2.0, 2.0, 1.0, 4.0, 6.0, 5.0, 4.0, 4.0, 4.0, 2.0, 2.0, 6.0, 4.0, 3.0, 1.0, 6.0, 5.0, 4.0, 2.0, 2.0, 2.0, 0.0, 2.0, 2.0, 3.0, 4.0, 4.0, 3.0, 3.0, 1.0, 3.0, 1.0, 4.0, 6.0, 3.0, 4.0, 2.0, 3.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 3.0, 1.0, 2.0, 2.0, 7.0, 7.0, 8.0, 5.0, 5.0, 7.0, 5.0, 6.0, 7.0, 3.0, 7.0, 3.0, 7.0, 3.0, 4.0, 5.0, 3.0, 6.0, 6.0, 5.0, 2.0, 3.0, 1.0, 2.0, 4.0, 4.0, 5.0, 5.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.13396678792463507, "mean_inference_ms": 0.3911975543529945, "mean_action_processing_ms": 0.02919711162429284, "mean_env_wait_ms": 0.4038136317731001, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 1567440, "timesteps_this_iter": 0, "agent_timesteps_total": 6269760, "timers": {"sample_time_ms": 5398.412, "sample_throughput": 933.608, "load_time_ms": 0.174, "load_throughput": 28914364.875, "learn_time_ms": 134.348, "learn_throughput": 37514.565, "update_time_ms": 2.561}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 464.701171875, "policy_entropy": 7524.058837890625, "policy_loss": 174.25795459747314, "vf_loss": 128.85114669799805}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 1567440, "num_agent_steps_sampled": 6269760, "num_steps_trained": 1567440, "num_agent_steps_trained": 6269760, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 3132, "training_iteration": 156, "trial_id": "71426_00000", "experiment_id": "84bca2f7b35f43248fca18d21abe2ebf", "date": "2024-06-12_03-12-41", "timestamp": 1718129561, "time_this_iter_s": 10.107089757919312, "time_total_s": 1608.1147685050964, "pid": 363902, "hostname": "DESKTOP-LQ219J4", "node_ip": "192.168.46.185", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 20, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 5000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 500, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Base_Model", "custom_model_config": {"env": "rware", "env_args": {"n_agents": 4, "column_height": 1, "max_inactivity_steps": null, "max_steps": 500, "fast_obs": true, "msg_bits": 0, "sensor_range": 1, "shelf_rows": 1, "shelf_columns": 3, "request_queue_size": 4, "reward_type": "RewardType.INDIVIDUAL", "map_name": "customized_map", "map_size": "tiny", "difficulty": "medium"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": true, "force_coop": false, "local_mode": true, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 4, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 100, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64}, "algorithm": "ia2c", "space_obs": "Dict(obs:Box([-100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100.], [100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.], (112,), float32))", "space_act": "Discrete(5)", "num_agents": 4, "episode_limit": 500, "policy_mapping_info": {"all_scenario": {"description": "rware all scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2", "agent_3"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "rware_customized_map", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 10, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.IA2CTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_il.<locals>.<lambda> at 0x7f383066a8b0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "grad_clip": 40.0, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "microbatch_size": null}, "time_since_restore": 1608.1147685050964, "timesteps_since_restore": 0, "iterations_since_restore": 156, "perf": {"cpu_util_percent": 4.073333333333333, "ram_util_percent": 76.0}}
{"episode_reward_max": 27.0, "episode_reward_min": 0.0, "episode_reward_mean": 11.56, "episode_len_mean": 500.0, "episode_media": {}, "episodes_this_iter": 20, "policy_reward_min": {"shared_policy": 0.0}, "policy_reward_max": {"shared_policy": 8.0}, "policy_reward_mean": {"shared_policy": 2.89}, "custom_metrics": {}, "hist_stats": {"episode_reward": [14.0, 10.0, 19.0, 13.0, 3.0, 18.0, 11.0, 9.0, 14.0, 8.0, 6.0, 4.0, 17.0, 10.0, 24.0, 12.0, 6.0, 10.0, 14.0, 13.0, 5.0, 15.0, 5.0, 14.0, 6.0, 19.0, 21.0, 12.0, 18.0, 6.0, 7.0, 11.0, 19.0, 6.0, 18.0, 8.0, 6.0, 25.0, 15.0, 12.0, 15.0, 4.0, 14.0, 12.0, 15.0, 15.0, 8.0, 8.0, 0.0, 13.0, 17.0, 3.0, 3.0, 6.0, 10.0, 6.0, 10.0, 9.0, 6.0, 9.0, 8.0, 9.0, 19.0, 14.0, 14.0, 13.0, 6.0, 14.0, 8.0, 17.0, 9.0, 8.0, 8.0, 27.0, 23.0, 20.0, 19.0, 20.0, 8.0, 18.0, 17.0, 9.0, 10.0, 7.0, 11.0, 12.0, 14.0, 2.0, 7.0, 14.0, 12.0, 10.0, 14.0, 2.0, 5.0, 2.0, 19.0, 11.0, 16.0, 14.0], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500], "policy_shared_policy_reward": [1.0, 4.0, 4.0, 5.0, 2.0, 2.0, 3.0, 3.0, 6.0, 5.0, 6.0, 2.0, 2.0, 4.0, 3.0, 4.0, 2.0, 0.0, 0.0, 1.0, 4.0, 5.0, 4.0, 5.0, 3.0, 2.0, 4.0, 2.0, 3.0, 1.0, 2.0, 3.0, 5.0, 3.0, 3.0, 3.0, 1.0, 0.0, 4.0, 3.0, 1.0, 3.0, 1.0, 1.0, 2.0, 1.0, 0.0, 1.0, 5.0, 6.0, 3.0, 3.0, 3.0, 3.0, 2.0, 2.0, 7.0, 6.0, 6.0, 5.0, 4.0, 4.0, 2.0, 2.0, 1.0, 3.0, 0.0, 2.0, 2.0, 3.0, 2.0, 3.0, 4.0, 3.0, 5.0, 2.0, 3.0, 3.0, 3.0, 4.0, 2.0, 0.0, 2.0, 1.0, 5.0, 2.0, 3.0, 5.0, 1.0, 1.0, 2.0, 1.0, 4.0, 3.0, 3.0, 4.0, 1.0, 2.0, 1.0, 2.0, 6.0, 4.0, 4.0, 5.0, 4.0, 6.0, 7.0, 4.0, 2.0, 2.0, 5.0, 3.0, 5.0, 3.0, 5.0, 5.0, 2.0, 2.0, 1.0, 1.0, 1.0, 3.0, 2.0, 1.0, 1.0, 6.0, 0.0, 4.0, 4.0, 3.0, 5.0, 7.0, 2.0, 1.0, 0.0, 3.0, 5.0, 7.0, 3.0, 3.0, 4.0, 1.0, 2.0, 1.0, 2.0, 1.0, 1.0, 2.0, 4.0, 7.0, 7.0, 7.0, 4.0, 2.0, 5.0, 4.0, 4.0, 2.0, 4.0, 2.0, 3.0, 6.0, 4.0, 2.0, 2.0, 0.0, 1.0, 1.0, 3.0, 4.0, 5.0, 2.0, 5.0, 2.0, 2.0, 3.0, 4.0, 5.0, 3.0, 3.0, 4.0, 3.0, 5.0, 3.0, 1.0, 3.0, 1.0, 3.0, 3.0, 1.0, 1.0, 3.0, 0.0, 0.0, 0.0, 0.0, 3.0, 3.0, 1.0, 6.0, 4.0, 4.0, 5.0, 4.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 2.0, 1.0, 1.0, 2.0, 2.0, 3.0, 2.0, 3.0, 1.0, 1.0, 2.0, 2.0, 2.0, 3.0, 3.0, 2.0, 3.0, 2.0, 2.0, 2.0, 1.0, 2.0, 2.0, 1.0, 2.0, 2.0, 2.0, 3.0, 3.0, 2.0, 2.0, 1.0, 2.0, 2.0, 1.0, 4.0, 6.0, 5.0, 4.0, 4.0, 4.0, 2.0, 2.0, 6.0, 4.0, 3.0, 1.0, 6.0, 5.0, 4.0, 2.0, 2.0, 2.0, 0.0, 2.0, 2.0, 3.0, 4.0, 4.0, 3.0, 3.0, 1.0, 3.0, 1.0, 4.0, 6.0, 3.0, 4.0, 2.0, 3.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 3.0, 1.0, 2.0, 2.0, 7.0, 7.0, 8.0, 5.0, 5.0, 7.0, 5.0, 6.0, 7.0, 3.0, 7.0, 3.0, 7.0, 3.0, 4.0, 5.0, 3.0, 6.0, 6.0, 5.0, 2.0, 3.0, 1.0, 2.0, 4.0, 4.0, 5.0, 5.0, 3.0, 7.0, 5.0, 2.0, 1.0, 2.0, 2.0, 4.0, 2.0, 2.0, 3.0, 3.0, 1.0, 1.0, 4.0, 1.0, 2.0, 2.0, 4.0, 3.0, 3.0, 4.0, 3.0, 2.0, 4.0, 4.0, 3.0, 3.0, 0.0, 1.0, 0.0, 1.0, 1.0, 2.0, 3.0, 1.0, 2.0, 4.0, 3.0, 5.0, 4.0, 1.0, 4.0, 3.0, 1.0, 3.0, 3.0, 3.0, 3.0, 4.0, 3.0, 4.0, 1.0, 1.0, 0.0, 0.0, 3.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 7.0, 5.0, 5.0, 2.0, 3.0, 2.0, 2.0, 4.0, 5.0, 3.0, 5.0, 3.0, 3.0, 3.0, 4.0, 4.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.1340085594695498, "mean_inference_ms": 0.3912899271872584, "mean_action_processing_ms": 0.029202520109018755, "mean_env_wait_ms": 0.4038848300059992, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 1577520, "timesteps_this_iter": 0, "agent_timesteps_total": 6310080, "timers": {"sample_time_ms": 5307.341, "sample_throughput": 949.628, "load_time_ms": 0.18, "load_throughput": 28013904.267, "learn_time_ms": 134.092, "learn_throughput": 37586.096, "update_time_ms": 2.582}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 415.80120849609375, "policy_entropy": 7559.7545166015625, "policy_loss": -51.92385387420654, "vf_loss": 75.25150966644287}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 1577520, "num_agent_steps_sampled": 6310080, "num_steps_trained": 1577520, "num_agent_steps_trained": 6310080, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 3152, "training_iteration": 157, "trial_id": "71426_00000", "experiment_id": "84bca2f7b35f43248fca18d21abe2ebf", "date": "2024-06-12_03-12-51", "timestamp": 1718129571, "time_this_iter_s": 10.098962783813477, "time_total_s": 1618.21373128891, "pid": 363902, "hostname": "DESKTOP-LQ219J4", "node_ip": "192.168.46.185", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 20, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 5000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 500, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Base_Model", "custom_model_config": {"env": "rware", "env_args": {"n_agents": 4, "column_height": 1, "max_inactivity_steps": null, "max_steps": 500, "fast_obs": true, "msg_bits": 0, "sensor_range": 1, "shelf_rows": 1, "shelf_columns": 3, "request_queue_size": 4, "reward_type": "RewardType.INDIVIDUAL", "map_name": "customized_map", "map_size": "tiny", "difficulty": "medium"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": true, "force_coop": false, "local_mode": true, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 4, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 100, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64}, "algorithm": "ia2c", "space_obs": "Dict(obs:Box([-100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100.], [100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.], (112,), float32))", "space_act": "Discrete(5)", "num_agents": 4, "episode_limit": 500, "policy_mapping_info": {"all_scenario": {"description": "rware all scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2", "agent_3"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "rware_customized_map", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 10, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.IA2CTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_il.<locals>.<lambda> at 0x7f38082f8670>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "grad_clip": 40.0, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "microbatch_size": null}, "time_since_restore": 1618.21373128891, "timesteps_since_restore": 0, "iterations_since_restore": 157, "perf": {"cpu_util_percent": 4.414285714285715, "ram_util_percent": 76.29999999999998}}
{"episode_reward_max": 27.0, "episode_reward_min": 0.0, "episode_reward_mean": 11.55, "episode_len_mean": 500.0, "episode_media": {}, "episodes_this_iter": 20, "policy_reward_min": {"shared_policy": 0.0}, "policy_reward_max": {"shared_policy": 8.0}, "policy_reward_mean": {"shared_policy": 2.8875}, "custom_metrics": {}, "hist_stats": {"episode_reward": [5.0, 15.0, 5.0, 14.0, 6.0, 19.0, 21.0, 12.0, 18.0, 6.0, 7.0, 11.0, 19.0, 6.0, 18.0, 8.0, 6.0, 25.0, 15.0, 12.0, 15.0, 4.0, 14.0, 12.0, 15.0, 15.0, 8.0, 8.0, 0.0, 13.0, 17.0, 3.0, 3.0, 6.0, 10.0, 6.0, 10.0, 9.0, 6.0, 9.0, 8.0, 9.0, 19.0, 14.0, 14.0, 13.0, 6.0, 14.0, 8.0, 17.0, 9.0, 8.0, 8.0, 27.0, 23.0, 20.0, 19.0, 20.0, 8.0, 18.0, 17.0, 9.0, 10.0, 7.0, 11.0, 12.0, 14.0, 2.0, 7.0, 14.0, 12.0, 10.0, 14.0, 2.0, 5.0, 2.0, 19.0, 11.0, 16.0, 14.0, 7.0, 5.0, 19.0, 7.0, 12.0, 12.0, 9.0, 19.0, 12.0, 8.0, 19.0, 11.0, 10.0, 19.0, 5.0, 11.0, 10.0, 7.0, 15.0, 17.0], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500], "policy_shared_policy_reward": [2.0, 0.0, 2.0, 1.0, 5.0, 2.0, 3.0, 5.0, 1.0, 1.0, 2.0, 1.0, 4.0, 3.0, 3.0, 4.0, 1.0, 2.0, 1.0, 2.0, 6.0, 4.0, 4.0, 5.0, 4.0, 6.0, 7.0, 4.0, 2.0, 2.0, 5.0, 3.0, 5.0, 3.0, 5.0, 5.0, 2.0, 2.0, 1.0, 1.0, 1.0, 3.0, 2.0, 1.0, 1.0, 6.0, 0.0, 4.0, 4.0, 3.0, 5.0, 7.0, 2.0, 1.0, 0.0, 3.0, 5.0, 7.0, 3.0, 3.0, 4.0, 1.0, 2.0, 1.0, 2.0, 1.0, 1.0, 2.0, 4.0, 7.0, 7.0, 7.0, 4.0, 2.0, 5.0, 4.0, 4.0, 2.0, 4.0, 2.0, 3.0, 6.0, 4.0, 2.0, 2.0, 0.0, 1.0, 1.0, 3.0, 4.0, 5.0, 2.0, 5.0, 2.0, 2.0, 3.0, 4.0, 5.0, 3.0, 3.0, 4.0, 3.0, 5.0, 3.0, 1.0, 3.0, 1.0, 3.0, 3.0, 1.0, 1.0, 3.0, 0.0, 0.0, 0.0, 0.0, 3.0, 3.0, 1.0, 6.0, 4.0, 4.0, 5.0, 4.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 2.0, 1.0, 1.0, 2.0, 2.0, 3.0, 2.0, 3.0, 1.0, 1.0, 2.0, 2.0, 2.0, 3.0, 3.0, 2.0, 3.0, 2.0, 2.0, 2.0, 1.0, 2.0, 2.0, 1.0, 2.0, 2.0, 2.0, 3.0, 3.0, 2.0, 2.0, 1.0, 2.0, 2.0, 1.0, 4.0, 6.0, 5.0, 4.0, 4.0, 4.0, 2.0, 2.0, 6.0, 4.0, 3.0, 1.0, 6.0, 5.0, 4.0, 2.0, 2.0, 2.0, 0.0, 2.0, 2.0, 3.0, 4.0, 4.0, 3.0, 3.0, 1.0, 3.0, 1.0, 4.0, 6.0, 3.0, 4.0, 2.0, 3.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 3.0, 1.0, 2.0, 2.0, 7.0, 7.0, 8.0, 5.0, 5.0, 7.0, 5.0, 6.0, 7.0, 3.0, 7.0, 3.0, 7.0, 3.0, 4.0, 5.0, 3.0, 6.0, 6.0, 5.0, 2.0, 3.0, 1.0, 2.0, 4.0, 4.0, 5.0, 5.0, 3.0, 7.0, 5.0, 2.0, 1.0, 2.0, 2.0, 4.0, 2.0, 2.0, 3.0, 3.0, 1.0, 1.0, 4.0, 1.0, 2.0, 2.0, 4.0, 3.0, 3.0, 4.0, 3.0, 2.0, 4.0, 4.0, 3.0, 3.0, 0.0, 1.0, 0.0, 1.0, 1.0, 2.0, 3.0, 1.0, 2.0, 4.0, 3.0, 5.0, 4.0, 1.0, 4.0, 3.0, 1.0, 3.0, 3.0, 3.0, 3.0, 4.0, 3.0, 4.0, 1.0, 1.0, 0.0, 0.0, 3.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 7.0, 5.0, 5.0, 2.0, 3.0, 2.0, 2.0, 4.0, 5.0, 3.0, 5.0, 3.0, 3.0, 3.0, 4.0, 4.0, 2.0, 2.0, 2.0, 1.0, 1.0, 0.0, 2.0, 2.0, 6.0, 6.0, 3.0, 4.0, 3.0, 1.0, 1.0, 2.0, 3.0, 2.0, 3.0, 4.0, 3.0, 3.0, 3.0, 3.0, 2.0, 2.0, 2.0, 3.0, 6.0, 4.0, 5.0, 4.0, 4.0, 2.0, 4.0, 2.0, 1.0, 2.0, 3.0, 2.0, 6.0, 5.0, 5.0, 3.0, 2.0, 5.0, 2.0, 2.0, 4.0, 2.0, 2.0, 2.0, 7.0, 5.0, 4.0, 3.0, 1.0, 1.0, 1.0, 2.0, 2.0, 3.0, 3.0, 3.0, 4.0, 1.0, 3.0, 2.0, 0.0, 1.0, 2.0, 4.0, 4.0, 3.0, 3.0, 5.0, 3.0, 4.0, 6.0, 4.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.1340379120914469, "mean_inference_ms": 0.3913467001324725, "mean_action_processing_ms": 0.029205572758699436, "mean_env_wait_ms": 0.4039227891107214, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 1587600, "timesteps_this_iter": 0, "agent_timesteps_total": 6350400, "timers": {"sample_time_ms": 5241.827, "sample_throughput": 961.497, "load_time_ms": 0.18, "load_throughput": 28062248.984, "learn_time_ms": 131.714, "learn_throughput": 38264.597, "update_time_ms": 2.506}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 519.2381591796875, "policy_entropy": 7710.2359619140625, "policy_loss": -8.910410404205322, "vf_loss": 76.31421279907227}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 1587600, "num_agent_steps_sampled": 6350400, "num_steps_trained": 1587600, "num_agent_steps_trained": 6350400, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 3172, "training_iteration": 158, "trial_id": "71426_00000", "experiment_id": "84bca2f7b35f43248fca18d21abe2ebf", "date": "2024-06-12_03-13-01", "timestamp": 1718129581, "time_this_iter_s": 10.063692808151245, "time_total_s": 1628.2774240970612, "pid": 363902, "hostname": "DESKTOP-LQ219J4", "node_ip": "192.168.46.185", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 20, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 5000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 500, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Base_Model", "custom_model_config": {"env": "rware", "env_args": {"n_agents": 4, "column_height": 1, "max_inactivity_steps": null, "max_steps": 500, "fast_obs": true, "msg_bits": 0, "sensor_range": 1, "shelf_rows": 1, "shelf_columns": 3, "request_queue_size": 4, "reward_type": "RewardType.INDIVIDUAL", "map_name": "customized_map", "map_size": "tiny", "difficulty": "medium"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": true, "force_coop": false, "local_mode": true, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 4, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 100, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64}, "algorithm": "ia2c", "space_obs": "Dict(obs:Box([-100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100.], [100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.], (112,), float32))", "space_act": "Discrete(5)", "num_agents": 4, "episode_limit": 500, "policy_mapping_info": {"all_scenario": {"description": "rware all scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2", "agent_3"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "rware_customized_map", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 10, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.IA2CTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_il.<locals>.<lambda> at 0x7f380805f940>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "grad_clip": 40.0, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "microbatch_size": null}, "time_since_restore": 1628.2774240970612, "timesteps_since_restore": 0, "iterations_since_restore": 158, "perf": {"cpu_util_percent": 4.1, "ram_util_percent": 76.62000000000002}}
{"episode_reward_max": 27.0, "episode_reward_min": 0.0, "episode_reward_mean": 11.6, "episode_len_mean": 500.0, "episode_media": {}, "episodes_this_iter": 20, "policy_reward_min": {"shared_policy": 0.0}, "policy_reward_max": {"shared_policy": 8.0}, "policy_reward_mean": {"shared_policy": 2.9}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 4.0, 14.0, 12.0, 15.0, 15.0, 8.0, 8.0, 0.0, 13.0, 17.0, 3.0, 3.0, 6.0, 10.0, 6.0, 10.0, 9.0, 6.0, 9.0, 8.0, 9.0, 19.0, 14.0, 14.0, 13.0, 6.0, 14.0, 8.0, 17.0, 9.0, 8.0, 8.0, 27.0, 23.0, 20.0, 19.0, 20.0, 8.0, 18.0, 17.0, 9.0, 10.0, 7.0, 11.0, 12.0, 14.0, 2.0, 7.0, 14.0, 12.0, 10.0, 14.0, 2.0, 5.0, 2.0, 19.0, 11.0, 16.0, 14.0, 7.0, 5.0, 19.0, 7.0, 12.0, 12.0, 9.0, 19.0, 12.0, 8.0, 19.0, 11.0, 10.0, 19.0, 5.0, 11.0, 10.0, 7.0, 15.0, 17.0, 6.0, 10.0, 17.0, 3.0, 16.0, 10.0, 11.0, 22.0, 8.0, 12.0, 12.0, 16.0, 18.0, 16.0, 10.0, 8.0, 13.0, 11.0, 17.0, 17.0], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500], "policy_shared_policy_reward": [3.0, 6.0, 4.0, 2.0, 2.0, 0.0, 1.0, 1.0, 3.0, 4.0, 5.0, 2.0, 5.0, 2.0, 2.0, 3.0, 4.0, 5.0, 3.0, 3.0, 4.0, 3.0, 5.0, 3.0, 1.0, 3.0, 1.0, 3.0, 3.0, 1.0, 1.0, 3.0, 0.0, 0.0, 0.0, 0.0, 3.0, 3.0, 1.0, 6.0, 4.0, 4.0, 5.0, 4.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 2.0, 1.0, 1.0, 2.0, 2.0, 3.0, 2.0, 3.0, 1.0, 1.0, 2.0, 2.0, 2.0, 3.0, 3.0, 2.0, 3.0, 2.0, 2.0, 2.0, 1.0, 2.0, 2.0, 1.0, 2.0, 2.0, 2.0, 3.0, 3.0, 2.0, 2.0, 1.0, 2.0, 2.0, 1.0, 4.0, 6.0, 5.0, 4.0, 4.0, 4.0, 2.0, 2.0, 6.0, 4.0, 3.0, 1.0, 6.0, 5.0, 4.0, 2.0, 2.0, 2.0, 0.0, 2.0, 2.0, 3.0, 4.0, 4.0, 3.0, 3.0, 1.0, 3.0, 1.0, 4.0, 6.0, 3.0, 4.0, 2.0, 3.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 3.0, 1.0, 2.0, 2.0, 7.0, 7.0, 8.0, 5.0, 5.0, 7.0, 5.0, 6.0, 7.0, 3.0, 7.0, 3.0, 7.0, 3.0, 4.0, 5.0, 3.0, 6.0, 6.0, 5.0, 2.0, 3.0, 1.0, 2.0, 4.0, 4.0, 5.0, 5.0, 3.0, 7.0, 5.0, 2.0, 1.0, 2.0, 2.0, 4.0, 2.0, 2.0, 3.0, 3.0, 1.0, 1.0, 4.0, 1.0, 2.0, 2.0, 4.0, 3.0, 3.0, 4.0, 3.0, 2.0, 4.0, 4.0, 3.0, 3.0, 0.0, 1.0, 0.0, 1.0, 1.0, 2.0, 3.0, 1.0, 2.0, 4.0, 3.0, 5.0, 4.0, 1.0, 4.0, 3.0, 1.0, 3.0, 3.0, 3.0, 3.0, 4.0, 3.0, 4.0, 1.0, 1.0, 0.0, 0.0, 3.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 7.0, 5.0, 5.0, 2.0, 3.0, 2.0, 2.0, 4.0, 5.0, 3.0, 5.0, 3.0, 3.0, 3.0, 4.0, 4.0, 2.0, 2.0, 2.0, 1.0, 1.0, 0.0, 2.0, 2.0, 6.0, 6.0, 3.0, 4.0, 3.0, 1.0, 1.0, 2.0, 3.0, 2.0, 3.0, 4.0, 3.0, 3.0, 3.0, 3.0, 2.0, 2.0, 2.0, 3.0, 6.0, 4.0, 5.0, 4.0, 4.0, 2.0, 4.0, 2.0, 1.0, 2.0, 3.0, 2.0, 6.0, 5.0, 5.0, 3.0, 2.0, 5.0, 2.0, 2.0, 4.0, 2.0, 2.0, 2.0, 7.0, 5.0, 4.0, 3.0, 1.0, 1.0, 1.0, 2.0, 2.0, 3.0, 3.0, 3.0, 4.0, 1.0, 3.0, 2.0, 0.0, 1.0, 2.0, 4.0, 4.0, 3.0, 3.0, 5.0, 3.0, 4.0, 6.0, 4.0, 1.0, 1.0, 3.0, 1.0, 3.0, 3.0, 2.0, 2.0, 4.0, 5.0, 3.0, 5.0, 0.0, 1.0, 1.0, 1.0, 5.0, 4.0, 3.0, 4.0, 3.0, 1.0, 3.0, 3.0, 2.0, 2.0, 4.0, 3.0, 7.0, 2.0, 6.0, 7.0, 2.0, 2.0, 3.0, 1.0, 3.0, 2.0, 4.0, 3.0, 5.0, 4.0, 1.0, 2.0, 5.0, 5.0, 3.0, 3.0, 4.0, 5.0, 5.0, 4.0, 3.0, 4.0, 5.0, 4.0, 1.0, 2.0, 4.0, 3.0, 3.0, 2.0, 1.0, 2.0, 4.0, 3.0, 3.0, 3.0, 2.0, 4.0, 2.0, 3.0, 4.0, 5.0, 4.0, 4.0, 4.0, 5.0, 5.0, 3.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.1340535031584668, "mean_inference_ms": 0.39136193975289907, "mean_action_processing_ms": 0.02920590653223253, "mean_env_wait_ms": 0.40391360850999886, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 1597680, "timesteps_this_iter": 0, "agent_timesteps_total": 6390720, "timers": {"sample_time_ms": 5154.689, "sample_throughput": 977.751, "load_time_ms": 0.179, "load_throughput": 28114499.481, "learn_time_ms": 128.784, "learn_throughput": 39135.314, "update_time_ms": 2.431}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 299.85235595703125, "policy_entropy": 7778.4483642578125, "policy_loss": 14.943755090236664, "vf_loss": 87.79761409759521}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 1597680, "num_agent_steps_sampled": 6390720, "num_steps_trained": 1597680, "num_agent_steps_trained": 6390720, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 3192, "training_iteration": 159, "trial_id": "71426_00000", "experiment_id": "84bca2f7b35f43248fca18d21abe2ebf", "date": "2024-06-12_03-13-11", "timestamp": 1718129591, "time_this_iter_s": 10.036182403564453, "time_total_s": 1638.3136065006256, "pid": 363902, "hostname": "DESKTOP-LQ219J4", "node_ip": "192.168.46.185", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 20, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 5000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 500, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Base_Model", "custom_model_config": {"env": "rware", "env_args": {"n_agents": 4, "column_height": 1, "max_inactivity_steps": null, "max_steps": 500, "fast_obs": true, "msg_bits": 0, "sensor_range": 1, "shelf_rows": 1, "shelf_columns": 3, "request_queue_size": 4, "reward_type": "RewardType.INDIVIDUAL", "map_name": "customized_map", "map_size": "tiny", "difficulty": "medium"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": true, "force_coop": false, "local_mode": true, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 4, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 100, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64}, "algorithm": "ia2c", "space_obs": "Dict(obs:Box([-100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100.], [100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.], (112,), float32))", "space_act": "Discrete(5)", "num_agents": 4, "episode_limit": 500, "policy_mapping_info": {"all_scenario": {"description": "rware all scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2", "agent_3"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "rware_customized_map", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 10, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.IA2CTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_il.<locals>.<lambda> at 0x7f380824d040>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "grad_clip": 40.0, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "microbatch_size": null}, "time_since_restore": 1638.3136065006256, "timesteps_since_restore": 0, "iterations_since_restore": 159, "perf": {"cpu_util_percent": 4.171428571428571, "ram_util_percent": 76.82142857142856}}
{"episode_reward_max": 27.0, "episode_reward_min": 2.0, "episode_reward_mean": 11.99, "episode_len_mean": 500.0, "episode_media": {}, "episodes_this_iter": 20, "policy_reward_min": {"shared_policy": 0.0}, "policy_reward_max": {"shared_policy": 9.0}, "policy_reward_mean": {"shared_policy": 2.9975}, "custom_metrics": {}, "hist_stats": {"episode_reward": [8.0, 9.0, 19.0, 14.0, 14.0, 13.0, 6.0, 14.0, 8.0, 17.0, 9.0, 8.0, 8.0, 27.0, 23.0, 20.0, 19.0, 20.0, 8.0, 18.0, 17.0, 9.0, 10.0, 7.0, 11.0, 12.0, 14.0, 2.0, 7.0, 14.0, 12.0, 10.0, 14.0, 2.0, 5.0, 2.0, 19.0, 11.0, 16.0, 14.0, 7.0, 5.0, 19.0, 7.0, 12.0, 12.0, 9.0, 19.0, 12.0, 8.0, 19.0, 11.0, 10.0, 19.0, 5.0, 11.0, 10.0, 7.0, 15.0, 17.0, 6.0, 10.0, 17.0, 3.0, 16.0, 10.0, 11.0, 22.0, 8.0, 12.0, 12.0, 16.0, 18.0, 16.0, 10.0, 8.0, 13.0, 11.0, 17.0, 17.0, 2.0, 11.0, 12.0, 15.0, 7.0, 11.0, 5.0, 13.0, 7.0, 9.0, 10.0, 11.0, 18.0, 17.0, 12.0, 7.0, 7.0, 10.0, 27.0, 11.0], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500], "policy_shared_policy_reward": [3.0, 2.0, 2.0, 1.0, 2.0, 2.0, 1.0, 4.0, 6.0, 5.0, 4.0, 4.0, 4.0, 2.0, 2.0, 6.0, 4.0, 3.0, 1.0, 6.0, 5.0, 4.0, 2.0, 2.0, 2.0, 0.0, 2.0, 2.0, 3.0, 4.0, 4.0, 3.0, 3.0, 1.0, 3.0, 1.0, 4.0, 6.0, 3.0, 4.0, 2.0, 3.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 3.0, 1.0, 2.0, 2.0, 7.0, 7.0, 8.0, 5.0, 5.0, 7.0, 5.0, 6.0, 7.0, 3.0, 7.0, 3.0, 7.0, 3.0, 4.0, 5.0, 3.0, 6.0, 6.0, 5.0, 2.0, 3.0, 1.0, 2.0, 4.0, 4.0, 5.0, 5.0, 3.0, 7.0, 5.0, 2.0, 1.0, 2.0, 2.0, 4.0, 2.0, 2.0, 3.0, 3.0, 1.0, 1.0, 4.0, 1.0, 2.0, 2.0, 4.0, 3.0, 3.0, 4.0, 3.0, 2.0, 4.0, 4.0, 3.0, 3.0, 0.0, 1.0, 0.0, 1.0, 1.0, 2.0, 3.0, 1.0, 2.0, 4.0, 3.0, 5.0, 4.0, 1.0, 4.0, 3.0, 1.0, 3.0, 3.0, 3.0, 3.0, 4.0, 3.0, 4.0, 1.0, 1.0, 0.0, 0.0, 3.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 7.0, 5.0, 5.0, 2.0, 3.0, 2.0, 2.0, 4.0, 5.0, 3.0, 5.0, 3.0, 3.0, 3.0, 4.0, 4.0, 2.0, 2.0, 2.0, 1.0, 1.0, 0.0, 2.0, 2.0, 6.0, 6.0, 3.0, 4.0, 3.0, 1.0, 1.0, 2.0, 3.0, 2.0, 3.0, 4.0, 3.0, 3.0, 3.0, 3.0, 2.0, 2.0, 2.0, 3.0, 6.0, 4.0, 5.0, 4.0, 4.0, 2.0, 4.0, 2.0, 1.0, 2.0, 3.0, 2.0, 6.0, 5.0, 5.0, 3.0, 2.0, 5.0, 2.0, 2.0, 4.0, 2.0, 2.0, 2.0, 7.0, 5.0, 4.0, 3.0, 1.0, 1.0, 1.0, 2.0, 2.0, 3.0, 3.0, 3.0, 4.0, 1.0, 3.0, 2.0, 0.0, 1.0, 2.0, 4.0, 4.0, 3.0, 3.0, 5.0, 3.0, 4.0, 6.0, 4.0, 1.0, 1.0, 3.0, 1.0, 3.0, 3.0, 2.0, 2.0, 4.0, 5.0, 3.0, 5.0, 0.0, 1.0, 1.0, 1.0, 5.0, 4.0, 3.0, 4.0, 3.0, 1.0, 3.0, 3.0, 2.0, 2.0, 4.0, 3.0, 7.0, 2.0, 6.0, 7.0, 2.0, 2.0, 3.0, 1.0, 3.0, 2.0, 4.0, 3.0, 5.0, 4.0, 1.0, 2.0, 5.0, 5.0, 3.0, 3.0, 4.0, 5.0, 5.0, 4.0, 3.0, 4.0, 5.0, 4.0, 1.0, 2.0, 4.0, 3.0, 3.0, 2.0, 1.0, 2.0, 4.0, 3.0, 3.0, 3.0, 2.0, 4.0, 2.0, 3.0, 4.0, 5.0, 4.0, 4.0, 4.0, 5.0, 5.0, 3.0, 1.0, 1.0, 0.0, 0.0, 2.0, 4.0, 2.0, 3.0, 1.0, 4.0, 3.0, 4.0, 4.0, 2.0, 6.0, 3.0, 0.0, 3.0, 2.0, 2.0, 2.0, 3.0, 3.0, 3.0, 2.0, 1.0, 1.0, 1.0, 2.0, 4.0, 4.0, 3.0, 2.0, 4.0, 1.0, 0.0, 3.0, 2.0, 1.0, 3.0, 3.0, 3.0, 3.0, 1.0, 3.0, 3.0, 2.0, 3.0, 2.0, 3.0, 8.0, 5.0, 5.0, 5.0, 3.0, 4.0, 2.0, 2.0, 6.0, 2.0, 3.0, 2.0, 1.0, 1.0, 1.0, 1.0, 2.0, 3.0, 3.0, 1.0, 2.0, 4.0, 8.0, 4.0, 6.0, 9.0, 1.0, 3.0, 3.0, 4.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.13403861696935096, "mean_inference_ms": 0.3913230520680388, "mean_action_processing_ms": 0.029202965793581236, "mean_env_wait_ms": 0.4038618425769302, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 1607760, "timesteps_this_iter": 0, "agent_timesteps_total": 6431040, "timers": {"sample_time_ms": 5050.228, "sample_throughput": 997.975, "load_time_ms": 0.172, "load_throughput": 29246392.031, "learn_time_ms": 130.365, "learn_throughput": 38660.771, "update_time_ms": 2.437}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 730.1544189453125, "policy_entropy": 7725.37548828125, "policy_loss": 37.86040687561035, "vf_loss": 84.23188638687134}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 1607760, "num_agent_steps_sampled": 6431040, "num_steps_trained": 1607760, "num_agent_steps_trained": 6431040, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 3212, "training_iteration": 160, "trial_id": "71426_00000", "experiment_id": "84bca2f7b35f43248fca18d21abe2ebf", "date": "2024-06-12_03-13-22", "timestamp": 1718129602, "time_this_iter_s": 10.12313461303711, "time_total_s": 1648.4367411136627, "pid": 363902, "hostname": "DESKTOP-LQ219J4", "node_ip": "192.168.46.185", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 20, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 5000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 500, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Base_Model", "custom_model_config": {"env": "rware", "env_args": {"n_agents": 4, "column_height": 1, "max_inactivity_steps": null, "max_steps": 500, "fast_obs": true, "msg_bits": 0, "sensor_range": 1, "shelf_rows": 1, "shelf_columns": 3, "request_queue_size": 4, "reward_type": "RewardType.INDIVIDUAL", "map_name": "customized_map", "map_size": "tiny", "difficulty": "medium"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": true, "force_coop": false, "local_mode": true, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 4, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 100, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64}, "algorithm": "ia2c", "space_obs": "Dict(obs:Box([-100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100.], [100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.], (112,), float32))", "space_act": "Discrete(5)", "num_agents": 4, "episode_limit": 500, "policy_mapping_info": {"all_scenario": {"description": "rware all scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2", "agent_3"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "rware_customized_map", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 10, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.IA2CTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_il.<locals>.<lambda> at 0x7f38086c1e50>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "grad_clip": 40.0, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "microbatch_size": null}, "time_since_restore": 1648.4367411136627, "timesteps_since_restore": 0, "iterations_since_restore": 160, "perf": {"cpu_util_percent": 4.307142857142858, "ram_util_percent": 77.00714285714287}}
{"episode_reward_max": 27.0, "episode_reward_min": 2.0, "episode_reward_mean": 11.64, "episode_len_mean": 500.0, "episode_media": {}, "episodes_this_iter": 20, "policy_reward_min": {"shared_policy": 0.0}, "policy_reward_max": {"shared_policy": 9.0}, "policy_reward_mean": {"shared_policy": 2.91}, "custom_metrics": {}, "hist_stats": {"episode_reward": [17.0, 9.0, 10.0, 7.0, 11.0, 12.0, 14.0, 2.0, 7.0, 14.0, 12.0, 10.0, 14.0, 2.0, 5.0, 2.0, 19.0, 11.0, 16.0, 14.0, 7.0, 5.0, 19.0, 7.0, 12.0, 12.0, 9.0, 19.0, 12.0, 8.0, 19.0, 11.0, 10.0, 19.0, 5.0, 11.0, 10.0, 7.0, 15.0, 17.0, 6.0, 10.0, 17.0, 3.0, 16.0, 10.0, 11.0, 22.0, 8.0, 12.0, 12.0, 16.0, 18.0, 16.0, 10.0, 8.0, 13.0, 11.0, 17.0, 17.0, 2.0, 11.0, 12.0, 15.0, 7.0, 11.0, 5.0, 13.0, 7.0, 9.0, 10.0, 11.0, 18.0, 17.0, 12.0, 7.0, 7.0, 10.0, 27.0, 11.0, 10.0, 15.0, 11.0, 22.0, 16.0, 7.0, 12.0, 7.0, 16.0, 21.0, 7.0, 9.0, 8.0, 15.0, 13.0, 6.0, 16.0, 13.0, 9.0, 14.0], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500], "policy_shared_policy_reward": [3.0, 7.0, 5.0, 2.0, 1.0, 2.0, 2.0, 4.0, 2.0, 2.0, 3.0, 3.0, 1.0, 1.0, 4.0, 1.0, 2.0, 2.0, 4.0, 3.0, 3.0, 4.0, 3.0, 2.0, 4.0, 4.0, 3.0, 3.0, 0.0, 1.0, 0.0, 1.0, 1.0, 2.0, 3.0, 1.0, 2.0, 4.0, 3.0, 5.0, 4.0, 1.0, 4.0, 3.0, 1.0, 3.0, 3.0, 3.0, 3.0, 4.0, 3.0, 4.0, 1.0, 1.0, 0.0, 0.0, 3.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 7.0, 5.0, 5.0, 2.0, 3.0, 2.0, 2.0, 4.0, 5.0, 3.0, 5.0, 3.0, 3.0, 3.0, 4.0, 4.0, 2.0, 2.0, 2.0, 1.0, 1.0, 0.0, 2.0, 2.0, 6.0, 6.0, 3.0, 4.0, 3.0, 1.0, 1.0, 2.0, 3.0, 2.0, 3.0, 4.0, 3.0, 3.0, 3.0, 3.0, 2.0, 2.0, 2.0, 3.0, 6.0, 4.0, 5.0, 4.0, 4.0, 2.0, 4.0, 2.0, 1.0, 2.0, 3.0, 2.0, 6.0, 5.0, 5.0, 3.0, 2.0, 5.0, 2.0, 2.0, 4.0, 2.0, 2.0, 2.0, 7.0, 5.0, 4.0, 3.0, 1.0, 1.0, 1.0, 2.0, 2.0, 3.0, 3.0, 3.0, 4.0, 1.0, 3.0, 2.0, 0.0, 1.0, 2.0, 4.0, 4.0, 3.0, 3.0, 5.0, 3.0, 4.0, 6.0, 4.0, 1.0, 1.0, 3.0, 1.0, 3.0, 3.0, 2.0, 2.0, 4.0, 5.0, 3.0, 5.0, 0.0, 1.0, 1.0, 1.0, 5.0, 4.0, 3.0, 4.0, 3.0, 1.0, 3.0, 3.0, 2.0, 2.0, 4.0, 3.0, 7.0, 2.0, 6.0, 7.0, 2.0, 2.0, 3.0, 1.0, 3.0, 2.0, 4.0, 3.0, 5.0, 4.0, 1.0, 2.0, 5.0, 5.0, 3.0, 3.0, 4.0, 5.0, 5.0, 4.0, 3.0, 4.0, 5.0, 4.0, 1.0, 2.0, 4.0, 3.0, 3.0, 2.0, 1.0, 2.0, 4.0, 3.0, 3.0, 3.0, 2.0, 4.0, 2.0, 3.0, 4.0, 5.0, 4.0, 4.0, 4.0, 5.0, 5.0, 3.0, 1.0, 1.0, 0.0, 0.0, 2.0, 4.0, 2.0, 3.0, 1.0, 4.0, 3.0, 4.0, 4.0, 2.0, 6.0, 3.0, 0.0, 3.0, 2.0, 2.0, 2.0, 3.0, 3.0, 3.0, 2.0, 1.0, 1.0, 1.0, 2.0, 4.0, 4.0, 3.0, 2.0, 4.0, 1.0, 0.0, 3.0, 2.0, 1.0, 3.0, 3.0, 3.0, 3.0, 1.0, 3.0, 3.0, 2.0, 3.0, 2.0, 3.0, 8.0, 5.0, 5.0, 5.0, 3.0, 4.0, 2.0, 2.0, 6.0, 2.0, 3.0, 2.0, 1.0, 1.0, 1.0, 1.0, 2.0, 3.0, 3.0, 1.0, 2.0, 4.0, 8.0, 4.0, 6.0, 9.0, 1.0, 3.0, 3.0, 4.0, 4.0, 2.0, 3.0, 1.0, 4.0, 4.0, 2.0, 5.0, 4.0, 3.0, 2.0, 2.0, 3.0, 7.0, 7.0, 5.0, 2.0, 6.0, 4.0, 4.0, 1.0, 2.0, 2.0, 2.0, 3.0, 2.0, 4.0, 3.0, 2.0, 2.0, 1.0, 2.0, 4.0, 6.0, 1.0, 5.0, 6.0, 6.0, 4.0, 5.0, 2.0, 2.0, 2.0, 1.0, 3.0, 2.0, 4.0, 0.0, 3.0, 2.0, 2.0, 1.0, 4.0, 3.0, 5.0, 3.0, 3.0, 4.0, 2.0, 4.0, 1.0, 2.0, 1.0, 2.0, 5.0, 2.0, 5.0, 4.0, 3.0, 4.0, 4.0, 2.0, 2.0, 2.0, 3.0, 2.0, 4.0, 3.0, 2.0, 5.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.13403397097366326, "mean_inference_ms": 0.3912857820033887, "mean_action_processing_ms": 0.029200255752183234, "mean_env_wait_ms": 0.40380989943090095, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 1617840, "timesteps_this_iter": 0, "agent_timesteps_total": 6471360, "timers": {"sample_time_ms": 5065.259, "sample_throughput": 995.013, "load_time_ms": 0.168, "load_throughput": 29972057.507, "learn_time_ms": 132.259, "learn_throughput": 38107.079, "update_time_ms": 2.464}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 702.2796630859375, "policy_entropy": 7546.446533203125, "policy_loss": 203.3838987350464, "vf_loss": 111.92842102050781}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 1617840, "num_agent_steps_sampled": 6471360, "num_steps_trained": 1617840, "num_agent_steps_trained": 6471360, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 3232, "training_iteration": 161, "trial_id": "71426_00000", "experiment_id": "84bca2f7b35f43248fca18d21abe2ebf", "date": "2024-06-12_03-13-32", "timestamp": 1718129612, "time_this_iter_s": 10.264721870422363, "time_total_s": 1658.701462984085, "pid": 363902, "hostname": "DESKTOP-LQ219J4", "node_ip": "192.168.46.185", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 20, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 5000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 500, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Base_Model", "custom_model_config": {"env": "rware", "env_args": {"n_agents": 4, "column_height": 1, "max_inactivity_steps": null, "max_steps": 500, "fast_obs": true, "msg_bits": 0, "sensor_range": 1, "shelf_rows": 1, "shelf_columns": 3, "request_queue_size": 4, "reward_type": "RewardType.INDIVIDUAL", "map_name": "customized_map", "map_size": "tiny", "difficulty": "medium"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": true, "force_coop": false, "local_mode": true, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 4, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 100, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64}, "algorithm": "ia2c", "space_obs": "Dict(obs:Box([-100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100.], [100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.], (112,), float32))", "space_act": "Discrete(5)", "num_agents": 4, "episode_limit": 500, "policy_mapping_info": {"all_scenario": {"description": "rware all scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2", "agent_3"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "rware_customized_map", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 10, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.IA2CTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_il.<locals>.<lambda> at 0x7f3808060940>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "grad_clip": 40.0, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "microbatch_size": null}, "time_since_restore": 1658.701462984085, "timesteps_since_restore": 0, "iterations_since_restore": 161, "perf": {"cpu_util_percent": 4.286666666666666, "ram_util_percent": 77.02666666666667}}
{"episode_reward_max": 27.0, "episode_reward_min": 2.0, "episode_reward_mean": 12.61, "episode_len_mean": 500.0, "episode_media": {}, "episodes_this_iter": 20, "policy_reward_min": {"shared_policy": 0.0}, "policy_reward_max": {"shared_policy": 9.0}, "policy_reward_mean": {"shared_policy": 3.1525}, "custom_metrics": {}, "hist_stats": {"episode_reward": [7.0, 5.0, 19.0, 7.0, 12.0, 12.0, 9.0, 19.0, 12.0, 8.0, 19.0, 11.0, 10.0, 19.0, 5.0, 11.0, 10.0, 7.0, 15.0, 17.0, 6.0, 10.0, 17.0, 3.0, 16.0, 10.0, 11.0, 22.0, 8.0, 12.0, 12.0, 16.0, 18.0, 16.0, 10.0, 8.0, 13.0, 11.0, 17.0, 17.0, 2.0, 11.0, 12.0, 15.0, 7.0, 11.0, 5.0, 13.0, 7.0, 9.0, 10.0, 11.0, 18.0, 17.0, 12.0, 7.0, 7.0, 10.0, 27.0, 11.0, 10.0, 15.0, 11.0, 22.0, 16.0, 7.0, 12.0, 7.0, 16.0, 21.0, 7.0, 9.0, 8.0, 15.0, 13.0, 6.0, 16.0, 13.0, 9.0, 14.0, 12.0, 17.0, 15.0, 15.0, 14.0, 13.0, 19.0, 13.0, 15.0, 18.0, 20.0, 22.0, 12.0, 17.0, 11.0, 17.0, 12.0, 21.0, 13.0, 9.0], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500], "policy_shared_policy_reward": [2.0, 2.0, 2.0, 1.0, 1.0, 0.0, 2.0, 2.0, 6.0, 6.0, 3.0, 4.0, 3.0, 1.0, 1.0, 2.0, 3.0, 2.0, 3.0, 4.0, 3.0, 3.0, 3.0, 3.0, 2.0, 2.0, 2.0, 3.0, 6.0, 4.0, 5.0, 4.0, 4.0, 2.0, 4.0, 2.0, 1.0, 2.0, 3.0, 2.0, 6.0, 5.0, 5.0, 3.0, 2.0, 5.0, 2.0, 2.0, 4.0, 2.0, 2.0, 2.0, 7.0, 5.0, 4.0, 3.0, 1.0, 1.0, 1.0, 2.0, 2.0, 3.0, 3.0, 3.0, 4.0, 1.0, 3.0, 2.0, 0.0, 1.0, 2.0, 4.0, 4.0, 3.0, 3.0, 5.0, 3.0, 4.0, 6.0, 4.0, 1.0, 1.0, 3.0, 1.0, 3.0, 3.0, 2.0, 2.0, 4.0, 5.0, 3.0, 5.0, 0.0, 1.0, 1.0, 1.0, 5.0, 4.0, 3.0, 4.0, 3.0, 1.0, 3.0, 3.0, 2.0, 2.0, 4.0, 3.0, 7.0, 2.0, 6.0, 7.0, 2.0, 2.0, 3.0, 1.0, 3.0, 2.0, 4.0, 3.0, 5.0, 4.0, 1.0, 2.0, 5.0, 5.0, 3.0, 3.0, 4.0, 5.0, 5.0, 4.0, 3.0, 4.0, 5.0, 4.0, 1.0, 2.0, 4.0, 3.0, 3.0, 2.0, 1.0, 2.0, 4.0, 3.0, 3.0, 3.0, 2.0, 4.0, 2.0, 3.0, 4.0, 5.0, 4.0, 4.0, 4.0, 5.0, 5.0, 3.0, 1.0, 1.0, 0.0, 0.0, 2.0, 4.0, 2.0, 3.0, 1.0, 4.0, 3.0, 4.0, 4.0, 2.0, 6.0, 3.0, 0.0, 3.0, 2.0, 2.0, 2.0, 3.0, 3.0, 3.0, 2.0, 1.0, 1.0, 1.0, 2.0, 4.0, 4.0, 3.0, 2.0, 4.0, 1.0, 0.0, 3.0, 2.0, 1.0, 3.0, 3.0, 3.0, 3.0, 1.0, 3.0, 3.0, 2.0, 3.0, 2.0, 3.0, 8.0, 5.0, 5.0, 5.0, 3.0, 4.0, 2.0, 2.0, 6.0, 2.0, 3.0, 2.0, 1.0, 1.0, 1.0, 1.0, 2.0, 3.0, 3.0, 1.0, 2.0, 4.0, 8.0, 4.0, 6.0, 9.0, 1.0, 3.0, 3.0, 4.0, 4.0, 2.0, 3.0, 1.0, 4.0, 4.0, 2.0, 5.0, 4.0, 3.0, 2.0, 2.0, 3.0, 7.0, 7.0, 5.0, 2.0, 6.0, 4.0, 4.0, 1.0, 2.0, 2.0, 2.0, 3.0, 2.0, 4.0, 3.0, 2.0, 2.0, 1.0, 2.0, 4.0, 6.0, 1.0, 5.0, 6.0, 6.0, 4.0, 5.0, 2.0, 2.0, 2.0, 1.0, 3.0, 2.0, 4.0, 0.0, 3.0, 2.0, 2.0, 1.0, 4.0, 3.0, 5.0, 3.0, 3.0, 4.0, 2.0, 4.0, 1.0, 2.0, 1.0, 2.0, 5.0, 2.0, 5.0, 4.0, 3.0, 4.0, 4.0, 2.0, 2.0, 2.0, 3.0, 2.0, 4.0, 3.0, 2.0, 5.0, 3.0, 3.0, 3.0, 3.0, 5.0, 5.0, 4.0, 3.0, 3.0, 3.0, 6.0, 3.0, 5.0, 3.0, 3.0, 4.0, 3.0, 6.0, 3.0, 2.0, 3.0, 4.0, 4.0, 2.0, 5.0, 6.0, 4.0, 4.0, 2.0, 4.0, 3.0, 4.0, 5.0, 3.0, 3.0, 4.0, 6.0, 4.0, 4.0, 4.0, 2.0, 5.0, 6.0, 7.0, 6.0, 6.0, 6.0, 4.0, 3.0, 2.0, 4.0, 3.0, 4.0, 4.0, 4.0, 5.0, 2.0, 2.0, 3.0, 4.0, 5.0, 4.0, 3.0, 5.0, 4.0, 2.0, 3.0, 3.0, 3.0, 7.0, 4.0, 7.0, 2.0, 5.0, 3.0, 3.0, 3.0, 1.0, 2.0, 3.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.13403253975554985, "mean_inference_ms": 0.3912545076320976, "mean_action_processing_ms": 0.02919797531363005, "mean_env_wait_ms": 0.40376171001990285, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 1627920, "timesteps_this_iter": 0, "agent_timesteps_total": 6511680, "timers": {"sample_time_ms": 5081.159, "sample_throughput": 991.9, "load_time_ms": 0.164, "load_throughput": 30824281.365, "learn_time_ms": 136.669, "learn_throughput": 36877.357, "update_time_ms": 2.451}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 560.1393432617188, "policy_entropy": 7512.2869873046875, "policy_loss": 3.6410961151123047, "vf_loss": 97.22737789154053}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 1627920, "num_agent_steps_sampled": 6511680, "num_steps_trained": 1627920, "num_agent_steps_trained": 6511680, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 3252, "training_iteration": 162, "trial_id": "71426_00000", "experiment_id": "84bca2f7b35f43248fca18d21abe2ebf", "date": "2024-06-12_03-13-42", "timestamp": 1718129622, "time_this_iter_s": 10.267037868499756, "time_total_s": 1668.9685008525848, "pid": 363902, "hostname": "DESKTOP-LQ219J4", "node_ip": "192.168.46.185", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 20, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 5000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 500, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Base_Model", "custom_model_config": {"env": "rware", "env_args": {"n_agents": 4, "column_height": 1, "max_inactivity_steps": null, "max_steps": 500, "fast_obs": true, "msg_bits": 0, "sensor_range": 1, "shelf_rows": 1, "shelf_columns": 3, "request_queue_size": 4, "reward_type": "RewardType.INDIVIDUAL", "map_name": "customized_map", "map_size": "tiny", "difficulty": "medium"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": true, "force_coop": false, "local_mode": true, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 4, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 100, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64}, "algorithm": "ia2c", "space_obs": "Dict(obs:Box([-100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100.], [100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.], (112,), float32))", "space_act": "Discrete(5)", "num_agents": 4, "episode_limit": 500, "policy_mapping_info": {"all_scenario": {"description": "rware all scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2", "agent_3"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "rware_customized_map", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 10, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.IA2CTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_il.<locals>.<lambda> at 0x7f383066a8b0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "grad_clip": 40.0, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "microbatch_size": null}, "time_since_restore": 1668.9685008525848, "timesteps_since_restore": 0, "iterations_since_restore": 162, "perf": {"cpu_util_percent": 4.293333333333334, "ram_util_percent": 77.30000000000001}}
{"episode_reward_max": 27.0, "episode_reward_min": 2.0, "episode_reward_mean": 12.87, "episode_len_mean": 500.0, "episode_media": {}, "episodes_this_iter": 24, "policy_reward_min": {"shared_policy": 0.0}, "policy_reward_max": {"shared_policy": 9.0}, "policy_reward_mean": {"shared_policy": 3.2175}, "custom_metrics": {}, "hist_stats": {"episode_reward": [16.0, 10.0, 11.0, 22.0, 8.0, 12.0, 12.0, 16.0, 18.0, 16.0, 10.0, 8.0, 13.0, 11.0, 17.0, 17.0, 2.0, 11.0, 12.0, 15.0, 7.0, 11.0, 5.0, 13.0, 7.0, 9.0, 10.0, 11.0, 18.0, 17.0, 12.0, 7.0, 7.0, 10.0, 27.0, 11.0, 10.0, 15.0, 11.0, 22.0, 16.0, 7.0, 12.0, 7.0, 16.0, 21.0, 7.0, 9.0, 8.0, 15.0, 13.0, 6.0, 16.0, 13.0, 9.0, 14.0, 12.0, 17.0, 15.0, 15.0, 14.0, 13.0, 19.0, 13.0, 15.0, 18.0, 20.0, 22.0, 12.0, 17.0, 11.0, 17.0, 12.0, 21.0, 13.0, 9.0, 16.0, 17.0, 14.0, 13.0, 13.0, 9.0, 10.0, 15.0, 16.0, 12.0, 15.0, 14.0, 11.0, 12.0, 10.0, 8.0, 14.0, 9.0, 8.0, 19.0, 18.0, 4.0, 12.0, 7.0], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500], "policy_shared_policy_reward": [5.0, 4.0, 3.0, 4.0, 3.0, 1.0, 3.0, 3.0, 2.0, 2.0, 4.0, 3.0, 7.0, 2.0, 6.0, 7.0, 2.0, 2.0, 3.0, 1.0, 3.0, 2.0, 4.0, 3.0, 5.0, 4.0, 1.0, 2.0, 5.0, 5.0, 3.0, 3.0, 4.0, 5.0, 5.0, 4.0, 3.0, 4.0, 5.0, 4.0, 1.0, 2.0, 4.0, 3.0, 3.0, 2.0, 1.0, 2.0, 4.0, 3.0, 3.0, 3.0, 2.0, 4.0, 2.0, 3.0, 4.0, 5.0, 4.0, 4.0, 4.0, 5.0, 5.0, 3.0, 1.0, 1.0, 0.0, 0.0, 2.0, 4.0, 2.0, 3.0, 1.0, 4.0, 3.0, 4.0, 4.0, 2.0, 6.0, 3.0, 0.0, 3.0, 2.0, 2.0, 2.0, 3.0, 3.0, 3.0, 2.0, 1.0, 1.0, 1.0, 2.0, 4.0, 4.0, 3.0, 2.0, 4.0, 1.0, 0.0, 3.0, 2.0, 1.0, 3.0, 3.0, 3.0, 3.0, 1.0, 3.0, 3.0, 2.0, 3.0, 2.0, 3.0, 8.0, 5.0, 5.0, 5.0, 3.0, 4.0, 2.0, 2.0, 6.0, 2.0, 3.0, 2.0, 1.0, 1.0, 1.0, 1.0, 2.0, 3.0, 3.0, 1.0, 2.0, 4.0, 8.0, 4.0, 6.0, 9.0, 1.0, 3.0, 3.0, 4.0, 4.0, 2.0, 3.0, 1.0, 4.0, 4.0, 2.0, 5.0, 4.0, 3.0, 2.0, 2.0, 3.0, 7.0, 7.0, 5.0, 2.0, 6.0, 4.0, 4.0, 1.0, 2.0, 2.0, 2.0, 3.0, 2.0, 4.0, 3.0, 2.0, 2.0, 1.0, 2.0, 4.0, 6.0, 1.0, 5.0, 6.0, 6.0, 4.0, 5.0, 2.0, 2.0, 2.0, 1.0, 3.0, 2.0, 4.0, 0.0, 3.0, 2.0, 2.0, 1.0, 4.0, 3.0, 5.0, 3.0, 3.0, 4.0, 2.0, 4.0, 1.0, 2.0, 1.0, 2.0, 5.0, 2.0, 5.0, 4.0, 3.0, 4.0, 4.0, 2.0, 2.0, 2.0, 3.0, 2.0, 4.0, 3.0, 2.0, 5.0, 3.0, 3.0, 3.0, 3.0, 5.0, 5.0, 4.0, 3.0, 3.0, 3.0, 6.0, 3.0, 5.0, 3.0, 3.0, 4.0, 3.0, 6.0, 3.0, 2.0, 3.0, 4.0, 4.0, 2.0, 5.0, 6.0, 4.0, 4.0, 2.0, 4.0, 3.0, 4.0, 5.0, 3.0, 3.0, 4.0, 6.0, 4.0, 4.0, 4.0, 2.0, 5.0, 6.0, 7.0, 6.0, 6.0, 6.0, 4.0, 3.0, 2.0, 4.0, 3.0, 4.0, 4.0, 4.0, 5.0, 2.0, 2.0, 3.0, 4.0, 5.0, 4.0, 3.0, 5.0, 4.0, 2.0, 3.0, 3.0, 3.0, 7.0, 4.0, 7.0, 2.0, 5.0, 3.0, 3.0, 3.0, 1.0, 2.0, 3.0, 3.0, 5.0, 5.0, 3.0, 6.0, 4.0, 3.0, 4.0, 5.0, 3.0, 4.0, 2.0, 4.0, 3.0, 2.0, 4.0, 3.0, 1.0, 5.0, 4.0, 3.0, 2.0, 1.0, 3.0, 3.0, 2.0, 3.0, 2.0, 3.0, 5.0, 3.0, 4.0, 4.0, 3.0, 7.0, 2.0, 2.0, 3.0, 5.0, 2.0, 5.0, 4.0, 3.0, 3.0, 3.0, 4.0, 3.0, 4.0, 3.0, 3.0, 5.0, 0.0, 3.0, 4.0, 3.0, 2.0, 2.0, 2.0, 3.0, 3.0, 4.0, 1.0, 0.0, 3.0, 4.0, 4.0, 2.0, 4.0, 2.0, 3.0, 2.0, 2.0, 3.0, 2.0, 1.0, 2.0, 6.0, 2.0, 4.0, 7.0, 3.0, 3.0, 5.0, 7.0, 1.0, 1.0, 1.0, 1.0, 4.0, 3.0, 4.0, 1.0, 3.0, 0.0, 2.0, 2.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.13401429399287518, "mean_inference_ms": 0.391197314069746, "mean_action_processing_ms": 0.029192084111800413, "mean_env_wait_ms": 0.40366522967009316, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 1638000, "timesteps_this_iter": 0, "agent_timesteps_total": 6552000, "timers": {"sample_time_ms": 5084.684, "sample_throughput": 991.212, "load_time_ms": 0.172, "load_throughput": 29384615.179, "learn_time_ms": 143.106, "learn_throughput": 35218.542, "update_time_ms": 2.51}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 661.84033203125, "policy_entropy": 7689.1446533203125, "policy_loss": -95.29183578491211, "vf_loss": 80.27413940429688}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 1638000, "num_agent_steps_sampled": 6552000, "num_steps_trained": 1638000, "num_agent_steps_trained": 6552000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 3276, "training_iteration": 163, "trial_id": "71426_00000", "experiment_id": "84bca2f7b35f43248fca18d21abe2ebf", "date": "2024-06-12_03-13-52", "timestamp": 1718129632, "time_this_iter_s": 10.137293338775635, "time_total_s": 1679.1057941913605, "pid": 363902, "hostname": "DESKTOP-LQ219J4", "node_ip": "192.168.46.185", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 20, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 5000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 500, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Base_Model", "custom_model_config": {"env": "rware", "env_args": {"n_agents": 4, "column_height": 1, "max_inactivity_steps": null, "max_steps": 500, "fast_obs": true, "msg_bits": 0, "sensor_range": 1, "shelf_rows": 1, "shelf_columns": 3, "request_queue_size": 4, "reward_type": "RewardType.INDIVIDUAL", "map_name": "customized_map", "map_size": "tiny", "difficulty": "medium"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": true, "force_coop": false, "local_mode": true, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 4, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 100, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64}, "algorithm": "ia2c", "space_obs": "Dict(obs:Box([-100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100.], [100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.], (112,), float32))", "space_act": "Discrete(5)", "num_agents": 4, "episode_limit": 500, "policy_mapping_info": {"all_scenario": {"description": "rware all scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2", "agent_3"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "rware_customized_map", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 10, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.IA2CTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_il.<locals>.<lambda> at 0x7f38281ee430>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "grad_clip": 40.0, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "microbatch_size": null}, "time_since_restore": 1679.1057941913605, "timesteps_since_restore": 0, "iterations_since_restore": 163, "perf": {"cpu_util_percent": 4.3, "ram_util_percent": 77.58571428571429}}
{"episode_reward_max": 27.0, "episode_reward_min": 3.0, "episode_reward_mean": 12.67, "episode_len_mean": 500.0, "episode_media": {}, "episodes_this_iter": 20, "policy_reward_min": {"shared_policy": 0.0}, "policy_reward_max": {"shared_policy": 9.0}, "policy_reward_mean": {"shared_policy": 3.1675}, "custom_metrics": {}, "hist_stats": {"episode_reward": [7.0, 11.0, 5.0, 13.0, 7.0, 9.0, 10.0, 11.0, 18.0, 17.0, 12.0, 7.0, 7.0, 10.0, 27.0, 11.0, 10.0, 15.0, 11.0, 22.0, 16.0, 7.0, 12.0, 7.0, 16.0, 21.0, 7.0, 9.0, 8.0, 15.0, 13.0, 6.0, 16.0, 13.0, 9.0, 14.0, 12.0, 17.0, 15.0, 15.0, 14.0, 13.0, 19.0, 13.0, 15.0, 18.0, 20.0, 22.0, 12.0, 17.0, 11.0, 17.0, 12.0, 21.0, 13.0, 9.0, 16.0, 17.0, 14.0, 13.0, 13.0, 9.0, 10.0, 15.0, 16.0, 12.0, 15.0, 14.0, 11.0, 12.0, 10.0, 8.0, 14.0, 9.0, 8.0, 19.0, 18.0, 4.0, 12.0, 7.0, 21.0, 9.0, 10.0, 7.0, 17.0, 10.0, 5.0, 9.0, 3.0, 13.0, 16.0, 11.0, 10.0, 5.0, 18.0, 18.0, 11.0, 21.0, 13.0, 10.0], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500], "policy_shared_policy_reward": [0.0, 3.0, 2.0, 2.0, 2.0, 3.0, 3.0, 3.0, 2.0, 1.0, 1.0, 1.0, 2.0, 4.0, 4.0, 3.0, 2.0, 4.0, 1.0, 0.0, 3.0, 2.0, 1.0, 3.0, 3.0, 3.0, 3.0, 1.0, 3.0, 3.0, 2.0, 3.0, 2.0, 3.0, 8.0, 5.0, 5.0, 5.0, 3.0, 4.0, 2.0, 2.0, 6.0, 2.0, 3.0, 2.0, 1.0, 1.0, 1.0, 1.0, 2.0, 3.0, 3.0, 1.0, 2.0, 4.0, 8.0, 4.0, 6.0, 9.0, 1.0, 3.0, 3.0, 4.0, 4.0, 2.0, 3.0, 1.0, 4.0, 4.0, 2.0, 5.0, 4.0, 3.0, 2.0, 2.0, 3.0, 7.0, 7.0, 5.0, 2.0, 6.0, 4.0, 4.0, 1.0, 2.0, 2.0, 2.0, 3.0, 2.0, 4.0, 3.0, 2.0, 2.0, 1.0, 2.0, 4.0, 6.0, 1.0, 5.0, 6.0, 6.0, 4.0, 5.0, 2.0, 2.0, 2.0, 1.0, 3.0, 2.0, 4.0, 0.0, 3.0, 2.0, 2.0, 1.0, 4.0, 3.0, 5.0, 3.0, 3.0, 4.0, 2.0, 4.0, 1.0, 2.0, 1.0, 2.0, 5.0, 2.0, 5.0, 4.0, 3.0, 4.0, 4.0, 2.0, 2.0, 2.0, 3.0, 2.0, 4.0, 3.0, 2.0, 5.0, 3.0, 3.0, 3.0, 3.0, 5.0, 5.0, 4.0, 3.0, 3.0, 3.0, 6.0, 3.0, 5.0, 3.0, 3.0, 4.0, 3.0, 6.0, 3.0, 2.0, 3.0, 4.0, 4.0, 2.0, 5.0, 6.0, 4.0, 4.0, 2.0, 4.0, 3.0, 4.0, 5.0, 3.0, 3.0, 4.0, 6.0, 4.0, 4.0, 4.0, 2.0, 5.0, 6.0, 7.0, 6.0, 6.0, 6.0, 4.0, 3.0, 2.0, 4.0, 3.0, 4.0, 4.0, 4.0, 5.0, 2.0, 2.0, 3.0, 4.0, 5.0, 4.0, 3.0, 5.0, 4.0, 2.0, 3.0, 3.0, 3.0, 7.0, 4.0, 7.0, 2.0, 5.0, 3.0, 3.0, 3.0, 1.0, 2.0, 3.0, 3.0, 5.0, 5.0, 3.0, 6.0, 4.0, 3.0, 4.0, 5.0, 3.0, 4.0, 2.0, 4.0, 3.0, 2.0, 4.0, 3.0, 1.0, 5.0, 4.0, 3.0, 2.0, 1.0, 3.0, 3.0, 2.0, 3.0, 2.0, 3.0, 5.0, 3.0, 4.0, 4.0, 3.0, 7.0, 2.0, 2.0, 3.0, 5.0, 2.0, 5.0, 4.0, 3.0, 3.0, 3.0, 4.0, 3.0, 4.0, 3.0, 3.0, 5.0, 0.0, 3.0, 4.0, 3.0, 2.0, 2.0, 2.0, 3.0, 3.0, 4.0, 1.0, 0.0, 3.0, 4.0, 4.0, 2.0, 4.0, 2.0, 3.0, 2.0, 2.0, 3.0, 2.0, 1.0, 2.0, 6.0, 2.0, 4.0, 7.0, 3.0, 3.0, 5.0, 7.0, 1.0, 1.0, 1.0, 1.0, 4.0, 3.0, 4.0, 1.0, 3.0, 0.0, 2.0, 2.0, 7.0, 5.0, 6.0, 3.0, 3.0, 1.0, 3.0, 2.0, 3.0, 2.0, 1.0, 4.0, 1.0, 4.0, 2.0, 0.0, 6.0, 4.0, 3.0, 4.0, 3.0, 2.0, 3.0, 2.0, 2.0, 1.0, 2.0, 0.0, 4.0, 2.0, 2.0, 1.0, 1.0, 2.0, 0.0, 0.0, 2.0, 5.0, 3.0, 3.0, 6.0, 4.0, 3.0, 3.0, 4.0, 0.0, 5.0, 2.0, 2.0, 3.0, 2.0, 3.0, 0.0, 2.0, 2.0, 1.0, 5.0, 4.0, 6.0, 3.0, 5.0, 5.0, 5.0, 3.0, 3.0, 3.0, 4.0, 1.0, 5.0, 4.0, 4.0, 8.0, 1.0, 3.0, 5.0, 4.0, 2.0, 3.0, 3.0, 2.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.13401493163777664, "mean_inference_ms": 0.39117564386923864, "mean_action_processing_ms": 0.029190516494972955, "mean_env_wait_ms": 0.40362045980881966, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 1648080, "timesteps_this_iter": 0, "agent_timesteps_total": 6592320, "timers": {"sample_time_ms": 5102.733, "sample_throughput": 987.706, "load_time_ms": 0.171, "load_throughput": 29396874.093, "learn_time_ms": 148.523, "learn_throughput": 33934.144, "update_time_ms": 2.509}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 588.0601196289062, "policy_entropy": 7707.094482421875, "policy_loss": -80.58003664016724, "vf_loss": 85.80410957336426}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 1648080, "num_agent_steps_sampled": 6592320, "num_steps_trained": 1648080, "num_agent_steps_trained": 6592320, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 3296, "training_iteration": 164, "trial_id": "71426_00000", "experiment_id": "84bca2f7b35f43248fca18d21abe2ebf", "date": "2024-06-12_03-14-03", "timestamp": 1718129643, "time_this_iter_s": 10.212631225585938, "time_total_s": 1689.3184254169464, "pid": 363902, "hostname": "DESKTOP-LQ219J4", "node_ip": "192.168.46.185", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 20, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 5000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 500, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Base_Model", "custom_model_config": {"env": "rware", "env_args": {"n_agents": 4, "column_height": 1, "max_inactivity_steps": null, "max_steps": 500, "fast_obs": true, "msg_bits": 0, "sensor_range": 1, "shelf_rows": 1, "shelf_columns": 3, "request_queue_size": 4, "reward_type": "RewardType.INDIVIDUAL", "map_name": "customized_map", "map_size": "tiny", "difficulty": "medium"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": true, "force_coop": false, "local_mode": true, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 4, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 100, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64}, "algorithm": "ia2c", "space_obs": "Dict(obs:Box([-100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100.], [100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.], (112,), float32))", "space_act": "Discrete(5)", "num_agents": 4, "episode_limit": 500, "policy_mapping_info": {"all_scenario": {"description": "rware all scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2", "agent_3"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "rware_customized_map", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 10, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.IA2CTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_il.<locals>.<lambda> at 0x7f38082f8310>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "grad_clip": 40.0, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "microbatch_size": null}, "time_since_restore": 1689.3184254169464, "timesteps_since_restore": 0, "iterations_since_restore": 164, "perf": {"cpu_util_percent": 4.246666666666667, "ram_util_percent": 77.88666666666667}}
{"episode_reward_max": 22.0, "episode_reward_min": 3.0, "episode_reward_mean": 12.75, "episode_len_mean": 500.0, "episode_media": {}, "episodes_this_iter": 20, "policy_reward_min": {"shared_policy": 0.0}, "policy_reward_max": {"shared_policy": 8.0}, "policy_reward_mean": {"shared_policy": 3.1875}, "custom_metrics": {}, "hist_stats": {"episode_reward": [16.0, 7.0, 12.0, 7.0, 16.0, 21.0, 7.0, 9.0, 8.0, 15.0, 13.0, 6.0, 16.0, 13.0, 9.0, 14.0, 12.0, 17.0, 15.0, 15.0, 14.0, 13.0, 19.0, 13.0, 15.0, 18.0, 20.0, 22.0, 12.0, 17.0, 11.0, 17.0, 12.0, 21.0, 13.0, 9.0, 16.0, 17.0, 14.0, 13.0, 13.0, 9.0, 10.0, 15.0, 16.0, 12.0, 15.0, 14.0, 11.0, 12.0, 10.0, 8.0, 14.0, 9.0, 8.0, 19.0, 18.0, 4.0, 12.0, 7.0, 21.0, 9.0, 10.0, 7.0, 17.0, 10.0, 5.0, 9.0, 3.0, 13.0, 16.0, 11.0, 10.0, 5.0, 18.0, 18.0, 11.0, 21.0, 13.0, 10.0, 18.0, 8.0, 9.0, 19.0, 17.0, 11.0, 4.0, 8.0, 20.0, 12.0, 6.0, 18.0, 13.0, 19.0, 6.0, 11.0, 12.0, 13.0, 17.0, 7.0], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500], "policy_shared_policy_reward": [2.0, 6.0, 4.0, 4.0, 1.0, 2.0, 2.0, 2.0, 3.0, 2.0, 4.0, 3.0, 2.0, 2.0, 1.0, 2.0, 4.0, 6.0, 1.0, 5.0, 6.0, 6.0, 4.0, 5.0, 2.0, 2.0, 2.0, 1.0, 3.0, 2.0, 4.0, 0.0, 3.0, 2.0, 2.0, 1.0, 4.0, 3.0, 5.0, 3.0, 3.0, 4.0, 2.0, 4.0, 1.0, 2.0, 1.0, 2.0, 5.0, 2.0, 5.0, 4.0, 3.0, 4.0, 4.0, 2.0, 2.0, 2.0, 3.0, 2.0, 4.0, 3.0, 2.0, 5.0, 3.0, 3.0, 3.0, 3.0, 5.0, 5.0, 4.0, 3.0, 3.0, 3.0, 6.0, 3.0, 5.0, 3.0, 3.0, 4.0, 3.0, 6.0, 3.0, 2.0, 3.0, 4.0, 4.0, 2.0, 5.0, 6.0, 4.0, 4.0, 2.0, 4.0, 3.0, 4.0, 5.0, 3.0, 3.0, 4.0, 6.0, 4.0, 4.0, 4.0, 2.0, 5.0, 6.0, 7.0, 6.0, 6.0, 6.0, 4.0, 3.0, 2.0, 4.0, 3.0, 4.0, 4.0, 4.0, 5.0, 2.0, 2.0, 3.0, 4.0, 5.0, 4.0, 3.0, 5.0, 4.0, 2.0, 3.0, 3.0, 3.0, 7.0, 4.0, 7.0, 2.0, 5.0, 3.0, 3.0, 3.0, 1.0, 2.0, 3.0, 3.0, 5.0, 5.0, 3.0, 6.0, 4.0, 3.0, 4.0, 5.0, 3.0, 4.0, 2.0, 4.0, 3.0, 2.0, 4.0, 3.0, 1.0, 5.0, 4.0, 3.0, 2.0, 1.0, 3.0, 3.0, 2.0, 3.0, 2.0, 3.0, 5.0, 3.0, 4.0, 4.0, 3.0, 7.0, 2.0, 2.0, 3.0, 5.0, 2.0, 5.0, 4.0, 3.0, 3.0, 3.0, 4.0, 3.0, 4.0, 3.0, 3.0, 5.0, 0.0, 3.0, 4.0, 3.0, 2.0, 2.0, 2.0, 3.0, 3.0, 4.0, 1.0, 0.0, 3.0, 4.0, 4.0, 2.0, 4.0, 2.0, 3.0, 2.0, 2.0, 3.0, 2.0, 1.0, 2.0, 6.0, 2.0, 4.0, 7.0, 3.0, 3.0, 5.0, 7.0, 1.0, 1.0, 1.0, 1.0, 4.0, 3.0, 4.0, 1.0, 3.0, 0.0, 2.0, 2.0, 7.0, 5.0, 6.0, 3.0, 3.0, 1.0, 3.0, 2.0, 3.0, 2.0, 1.0, 4.0, 1.0, 4.0, 2.0, 0.0, 6.0, 4.0, 3.0, 4.0, 3.0, 2.0, 3.0, 2.0, 2.0, 1.0, 2.0, 0.0, 4.0, 2.0, 2.0, 1.0, 1.0, 2.0, 0.0, 0.0, 2.0, 5.0, 3.0, 3.0, 6.0, 4.0, 3.0, 3.0, 4.0, 0.0, 5.0, 2.0, 2.0, 3.0, 2.0, 3.0, 0.0, 2.0, 2.0, 1.0, 5.0, 4.0, 6.0, 3.0, 5.0, 5.0, 5.0, 3.0, 3.0, 3.0, 4.0, 1.0, 5.0, 4.0, 4.0, 8.0, 1.0, 3.0, 5.0, 4.0, 2.0, 3.0, 3.0, 2.0, 6.0, 3.0, 4.0, 5.0, 1.0, 1.0, 4.0, 2.0, 3.0, 2.0, 2.0, 2.0, 5.0, 5.0, 5.0, 4.0, 4.0, 3.0, 6.0, 4.0, 2.0, 4.0, 2.0, 3.0, 1.0, 1.0, 2.0, 0.0, 2.0, 3.0, 1.0, 2.0, 5.0, 4.0, 5.0, 6.0, 3.0, 2.0, 4.0, 3.0, 0.0, 2.0, 2.0, 2.0, 6.0, 5.0, 4.0, 3.0, 2.0, 3.0, 5.0, 3.0, 6.0, 5.0, 4.0, 4.0, 3.0, 2.0, 0.0, 1.0, 2.0, 2.0, 3.0, 4.0, 3.0, 1.0, 4.0, 4.0, 3.0, 3.0, 5.0, 2.0, 4.0, 4.0, 5.0, 4.0, 2.0, 3.0, 1.0, 1.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.1340183909934728, "mean_inference_ms": 0.39116270106179385, "mean_action_processing_ms": 0.029189495079005673, "mean_env_wait_ms": 0.4035856572697101, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 1658160, "timesteps_this_iter": 0, "agent_timesteps_total": 6632640, "timers": {"sample_time_ms": 5132.754, "sample_throughput": 981.929, "load_time_ms": 0.174, "load_throughput": 28942075.794, "learn_time_ms": 154.178, "learn_throughput": 32689.575, "update_time_ms": 2.487}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 435.9001159667969, "policy_entropy": 7638.6500244140625, "policy_loss": 19.326982498168945, "vf_loss": 105.91605567932129}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 1658160, "num_agent_steps_sampled": 6632640, "num_steps_trained": 1658160, "num_agent_steps_trained": 6632640, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 3316, "training_iteration": 165, "trial_id": "71426_00000", "experiment_id": "84bca2f7b35f43248fca18d21abe2ebf", "date": "2024-06-12_03-14-13", "timestamp": 1718129653, "time_this_iter_s": 10.420257329940796, "time_total_s": 1699.7386827468872, "pid": 363902, "hostname": "DESKTOP-LQ219J4", "node_ip": "192.168.46.185", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 20, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 5000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 500, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Base_Model", "custom_model_config": {"env": "rware", "env_args": {"n_agents": 4, "column_height": 1, "max_inactivity_steps": null, "max_steps": 500, "fast_obs": true, "msg_bits": 0, "sensor_range": 1, "shelf_rows": 1, "shelf_columns": 3, "request_queue_size": 4, "reward_type": "RewardType.INDIVIDUAL", "map_name": "customized_map", "map_size": "tiny", "difficulty": "medium"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": true, "force_coop": false, "local_mode": true, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 4, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 100, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64}, "algorithm": "ia2c", "space_obs": "Dict(obs:Box([-100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100.], [100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.], (112,), float32))", "space_act": "Discrete(5)", "num_agents": 4, "episode_limit": 500, "policy_mapping_info": {"all_scenario": {"description": "rware all scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2", "agent_3"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "rware_customized_map", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 10, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.IA2CTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_il.<locals>.<lambda> at 0x7f383066a8b0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "grad_clip": 40.0, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "microbatch_size": null}, "time_since_restore": 1699.7386827468872, "timesteps_since_restore": 0, "iterations_since_restore": 165, "perf": {"cpu_util_percent": 4.526666666666666, "ram_util_percent": 78.16666666666669}}
{"episode_reward_max": 23.0, "episode_reward_min": 3.0, "episode_reward_mean": 12.73, "episode_len_mean": 500.0, "episode_media": {}, "episodes_this_iter": 20, "policy_reward_min": {"shared_policy": 0.0}, "policy_reward_max": {"shared_policy": 8.0}, "policy_reward_mean": {"shared_policy": 3.1825}, "custom_metrics": {}, "hist_stats": {"episode_reward": [14.0, 13.0, 19.0, 13.0, 15.0, 18.0, 20.0, 22.0, 12.0, 17.0, 11.0, 17.0, 12.0, 21.0, 13.0, 9.0, 16.0, 17.0, 14.0, 13.0, 13.0, 9.0, 10.0, 15.0, 16.0, 12.0, 15.0, 14.0, 11.0, 12.0, 10.0, 8.0, 14.0, 9.0, 8.0, 19.0, 18.0, 4.0, 12.0, 7.0, 21.0, 9.0, 10.0, 7.0, 17.0, 10.0, 5.0, 9.0, 3.0, 13.0, 16.0, 11.0, 10.0, 5.0, 18.0, 18.0, 11.0, 21.0, 13.0, 10.0, 18.0, 8.0, 9.0, 19.0, 17.0, 11.0, 4.0, 8.0, 20.0, 12.0, 6.0, 18.0, 13.0, 19.0, 6.0, 11.0, 12.0, 13.0, 17.0, 7.0, 8.0, 10.0, 21.0, 13.0, 15.0, 5.0, 3.0, 12.0, 12.0, 7.0, 12.0, 17.0, 11.0, 18.0, 13.0, 7.0, 23.0, 14.0, 14.0, 11.0], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500], "policy_shared_policy_reward": [3.0, 6.0, 3.0, 2.0, 3.0, 4.0, 4.0, 2.0, 5.0, 6.0, 4.0, 4.0, 2.0, 4.0, 3.0, 4.0, 5.0, 3.0, 3.0, 4.0, 6.0, 4.0, 4.0, 4.0, 2.0, 5.0, 6.0, 7.0, 6.0, 6.0, 6.0, 4.0, 3.0, 2.0, 4.0, 3.0, 4.0, 4.0, 4.0, 5.0, 2.0, 2.0, 3.0, 4.0, 5.0, 4.0, 3.0, 5.0, 4.0, 2.0, 3.0, 3.0, 3.0, 7.0, 4.0, 7.0, 2.0, 5.0, 3.0, 3.0, 3.0, 1.0, 2.0, 3.0, 3.0, 5.0, 5.0, 3.0, 6.0, 4.0, 3.0, 4.0, 5.0, 3.0, 4.0, 2.0, 4.0, 3.0, 2.0, 4.0, 3.0, 1.0, 5.0, 4.0, 3.0, 2.0, 1.0, 3.0, 3.0, 2.0, 3.0, 2.0, 3.0, 5.0, 3.0, 4.0, 4.0, 3.0, 7.0, 2.0, 2.0, 3.0, 5.0, 2.0, 5.0, 4.0, 3.0, 3.0, 3.0, 4.0, 3.0, 4.0, 3.0, 3.0, 5.0, 0.0, 3.0, 4.0, 3.0, 2.0, 2.0, 2.0, 3.0, 3.0, 4.0, 1.0, 0.0, 3.0, 4.0, 4.0, 2.0, 4.0, 2.0, 3.0, 2.0, 2.0, 3.0, 2.0, 1.0, 2.0, 6.0, 2.0, 4.0, 7.0, 3.0, 3.0, 5.0, 7.0, 1.0, 1.0, 1.0, 1.0, 4.0, 3.0, 4.0, 1.0, 3.0, 0.0, 2.0, 2.0, 7.0, 5.0, 6.0, 3.0, 3.0, 1.0, 3.0, 2.0, 3.0, 2.0, 1.0, 4.0, 1.0, 4.0, 2.0, 0.0, 6.0, 4.0, 3.0, 4.0, 3.0, 2.0, 3.0, 2.0, 2.0, 1.0, 2.0, 0.0, 4.0, 2.0, 2.0, 1.0, 1.0, 2.0, 0.0, 0.0, 2.0, 5.0, 3.0, 3.0, 6.0, 4.0, 3.0, 3.0, 4.0, 0.0, 5.0, 2.0, 2.0, 3.0, 2.0, 3.0, 0.0, 2.0, 2.0, 1.0, 5.0, 4.0, 6.0, 3.0, 5.0, 5.0, 5.0, 3.0, 3.0, 3.0, 4.0, 1.0, 5.0, 4.0, 4.0, 8.0, 1.0, 3.0, 5.0, 4.0, 2.0, 3.0, 3.0, 2.0, 6.0, 3.0, 4.0, 5.0, 1.0, 1.0, 4.0, 2.0, 3.0, 2.0, 2.0, 2.0, 5.0, 5.0, 5.0, 4.0, 4.0, 3.0, 6.0, 4.0, 2.0, 4.0, 2.0, 3.0, 1.0, 1.0, 2.0, 0.0, 2.0, 3.0, 1.0, 2.0, 5.0, 4.0, 5.0, 6.0, 3.0, 2.0, 4.0, 3.0, 0.0, 2.0, 2.0, 2.0, 6.0, 5.0, 4.0, 3.0, 2.0, 3.0, 5.0, 3.0, 6.0, 5.0, 4.0, 4.0, 3.0, 2.0, 0.0, 1.0, 2.0, 2.0, 3.0, 4.0, 3.0, 1.0, 4.0, 4.0, 3.0, 3.0, 5.0, 2.0, 4.0, 4.0, 5.0, 4.0, 2.0, 3.0, 1.0, 1.0, 3.0, 2.0, 2.0, 1.0, 4.0, 3.0, 0.0, 3.0, 5.0, 4.0, 6.0, 6.0, 4.0, 3.0, 2.0, 4.0, 5.0, 3.0, 4.0, 3.0, 1.0, 1.0, 2.0, 1.0, 0.0, 1.0, 2.0, 0.0, 4.0, 2.0, 3.0, 3.0, 2.0, 5.0, 3.0, 2.0, 2.0, 1.0, 2.0, 2.0, 3.0, 3.0, 3.0, 3.0, 5.0, 3.0, 4.0, 5.0, 2.0, 2.0, 4.0, 3.0, 3.0, 6.0, 5.0, 4.0, 3.0, 3.0, 4.0, 3.0, 2.0, 1.0, 2.0, 2.0, 7.0, 7.0, 6.0, 3.0, 3.0, 4.0, 2.0, 5.0, 2.0, 4.0, 4.0, 4.0, 4.0, 0.0, 5.0, 2.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.13401177910576398, "mean_inference_ms": 0.39114957738892053, "mean_action_processing_ms": 0.029188442185145, "mean_env_wait_ms": 0.40355688109060295, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 1668240, "timesteps_this_iter": 0, "agent_timesteps_total": 6672960, "timers": {"sample_time_ms": 5133.992, "sample_throughput": 981.692, "load_time_ms": 0.177, "load_throughput": 28520361.792, "learn_time_ms": 164.309, "learn_throughput": 30673.913, "update_time_ms": 2.545}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 508.54864501953125, "policy_entropy": 7528.3154296875, "policy_loss": -35.63730525970459, "vf_loss": 90.48977088928223}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 1668240, "num_agent_steps_sampled": 6672960, "num_steps_trained": 1668240, "num_agent_steps_trained": 6672960, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 3336, "training_iteration": 166, "trial_id": "71426_00000", "experiment_id": "84bca2f7b35f43248fca18d21abe2ebf", "date": "2024-06-12_03-14-23", "timestamp": 1718129663, "time_this_iter_s": 10.321588277816772, "time_total_s": 1710.060271024704, "pid": 363902, "hostname": "DESKTOP-LQ219J4", "node_ip": "192.168.46.185", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 20, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 5000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 500, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Base_Model", "custom_model_config": {"env": "rware", "env_args": {"n_agents": 4, "column_height": 1, "max_inactivity_steps": null, "max_steps": 500, "fast_obs": true, "msg_bits": 0, "sensor_range": 1, "shelf_rows": 1, "shelf_columns": 3, "request_queue_size": 4, "reward_type": "RewardType.INDIVIDUAL", "map_name": "customized_map", "map_size": "tiny", "difficulty": "medium"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": true, "force_coop": false, "local_mode": true, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 4, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 100, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64}, "algorithm": "ia2c", "space_obs": "Dict(obs:Box([-100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100.], [100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.], (112,), float32))", "space_act": "Discrete(5)", "num_agents": 4, "episode_limit": 500, "policy_mapping_info": {"all_scenario": {"description": "rware all scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2", "agent_3"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "rware_customized_map", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 10, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.IA2CTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_il.<locals>.<lambda> at 0x7f38082f89d0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "grad_clip": 40.0, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "microbatch_size": null}, "time_since_restore": 1710.060271024704, "timesteps_since_restore": 0, "iterations_since_restore": 166, "perf": {"cpu_util_percent": 4.214285714285714, "ram_util_percent": 78.45000000000002}}
{"episode_reward_max": 26.0, "episode_reward_min": 3.0, "episode_reward_mean": 12.53, "episode_len_mean": 500.0, "episode_media": {}, "episodes_this_iter": 20, "policy_reward_min": {"shared_policy": 0.0}, "policy_reward_max": {"shared_policy": 8.0}, "policy_reward_mean": {"shared_policy": 3.1325}, "custom_metrics": {}, "hist_stats": {"episode_reward": [13.0, 9.0, 10.0, 15.0, 16.0, 12.0, 15.0, 14.0, 11.0, 12.0, 10.0, 8.0, 14.0, 9.0, 8.0, 19.0, 18.0, 4.0, 12.0, 7.0, 21.0, 9.0, 10.0, 7.0, 17.0, 10.0, 5.0, 9.0, 3.0, 13.0, 16.0, 11.0, 10.0, 5.0, 18.0, 18.0, 11.0, 21.0, 13.0, 10.0, 18.0, 8.0, 9.0, 19.0, 17.0, 11.0, 4.0, 8.0, 20.0, 12.0, 6.0, 18.0, 13.0, 19.0, 6.0, 11.0, 12.0, 13.0, 17.0, 7.0, 8.0, 10.0, 21.0, 13.0, 15.0, 5.0, 3.0, 12.0, 12.0, 7.0, 12.0, 17.0, 11.0, 18.0, 13.0, 7.0, 23.0, 14.0, 14.0, 11.0, 26.0, 12.0, 25.0, 24.0, 16.0, 19.0, 8.0, 7.0, 15.0, 8.0, 12.0, 4.0, 19.0, 10.0, 16.0, 10.0, 11.0, 18.0, 13.0, 13.0], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500], "policy_shared_policy_reward": [3.0, 1.0, 5.0, 4.0, 3.0, 2.0, 1.0, 3.0, 3.0, 2.0, 3.0, 2.0, 3.0, 5.0, 3.0, 4.0, 4.0, 3.0, 7.0, 2.0, 2.0, 3.0, 5.0, 2.0, 5.0, 4.0, 3.0, 3.0, 3.0, 4.0, 3.0, 4.0, 3.0, 3.0, 5.0, 0.0, 3.0, 4.0, 3.0, 2.0, 2.0, 2.0, 3.0, 3.0, 4.0, 1.0, 0.0, 3.0, 4.0, 4.0, 2.0, 4.0, 2.0, 3.0, 2.0, 2.0, 3.0, 2.0, 1.0, 2.0, 6.0, 2.0, 4.0, 7.0, 3.0, 3.0, 5.0, 7.0, 1.0, 1.0, 1.0, 1.0, 4.0, 3.0, 4.0, 1.0, 3.0, 0.0, 2.0, 2.0, 7.0, 5.0, 6.0, 3.0, 3.0, 1.0, 3.0, 2.0, 3.0, 2.0, 1.0, 4.0, 1.0, 4.0, 2.0, 0.0, 6.0, 4.0, 3.0, 4.0, 3.0, 2.0, 3.0, 2.0, 2.0, 1.0, 2.0, 0.0, 4.0, 2.0, 2.0, 1.0, 1.0, 2.0, 0.0, 0.0, 2.0, 5.0, 3.0, 3.0, 6.0, 4.0, 3.0, 3.0, 4.0, 0.0, 5.0, 2.0, 2.0, 3.0, 2.0, 3.0, 0.0, 2.0, 2.0, 1.0, 5.0, 4.0, 6.0, 3.0, 5.0, 5.0, 5.0, 3.0, 3.0, 3.0, 4.0, 1.0, 5.0, 4.0, 4.0, 8.0, 1.0, 3.0, 5.0, 4.0, 2.0, 3.0, 3.0, 2.0, 6.0, 3.0, 4.0, 5.0, 1.0, 1.0, 4.0, 2.0, 3.0, 2.0, 2.0, 2.0, 5.0, 5.0, 5.0, 4.0, 4.0, 3.0, 6.0, 4.0, 2.0, 4.0, 2.0, 3.0, 1.0, 1.0, 2.0, 0.0, 2.0, 3.0, 1.0, 2.0, 5.0, 4.0, 5.0, 6.0, 3.0, 2.0, 4.0, 3.0, 0.0, 2.0, 2.0, 2.0, 6.0, 5.0, 4.0, 3.0, 2.0, 3.0, 5.0, 3.0, 6.0, 5.0, 4.0, 4.0, 3.0, 2.0, 0.0, 1.0, 2.0, 2.0, 3.0, 4.0, 3.0, 1.0, 4.0, 4.0, 3.0, 3.0, 5.0, 2.0, 4.0, 4.0, 5.0, 4.0, 2.0, 3.0, 1.0, 1.0, 3.0, 2.0, 2.0, 1.0, 4.0, 3.0, 0.0, 3.0, 5.0, 4.0, 6.0, 6.0, 4.0, 3.0, 2.0, 4.0, 5.0, 3.0, 4.0, 3.0, 1.0, 1.0, 2.0, 1.0, 0.0, 1.0, 2.0, 0.0, 4.0, 2.0, 3.0, 3.0, 2.0, 5.0, 3.0, 2.0, 2.0, 1.0, 2.0, 2.0, 3.0, 3.0, 3.0, 3.0, 5.0, 3.0, 4.0, 5.0, 2.0, 2.0, 4.0, 3.0, 3.0, 6.0, 5.0, 4.0, 3.0, 3.0, 4.0, 3.0, 2.0, 1.0, 2.0, 2.0, 7.0, 7.0, 6.0, 3.0, 3.0, 4.0, 2.0, 5.0, 2.0, 4.0, 4.0, 4.0, 4.0, 0.0, 5.0, 2.0, 8.0, 7.0, 6.0, 5.0, 4.0, 1.0, 1.0, 6.0, 6.0, 7.0, 6.0, 6.0, 4.0, 7.0, 7.0, 6.0, 6.0, 4.0, 5.0, 1.0, 6.0, 1.0, 7.0, 5.0, 2.0, 2.0, 1.0, 3.0, 2.0, 2.0, 1.0, 2.0, 5.0, 4.0, 3.0, 3.0, 2.0, 1.0, 2.0, 3.0, 3.0, 2.0, 4.0, 3.0, 2.0, 1.0, 1.0, 0.0, 6.0, 6.0, 5.0, 2.0, 4.0, 3.0, 2.0, 1.0, 4.0, 5.0, 5.0, 2.0, 3.0, 3.0, 2.0, 2.0, 2.0, 3.0, 3.0, 3.0, 3.0, 5.0, 6.0, 4.0, 1.0, 4.0, 4.0, 4.0, 2.0, 5.0, 3.0, 3.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.1340055624281547, "mean_inference_ms": 0.3911370154391304, "mean_action_processing_ms": 0.02918772261548124, "mean_env_wait_ms": 0.4035211687036779, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 1678320, "timesteps_this_iter": 0, "agent_timesteps_total": 6713280, "timers": {"sample_time_ms": 5138.159, "sample_throughput": 980.896, "load_time_ms": 0.178, "load_throughput": 28378698.027, "learn_time_ms": 162.441, "learn_throughput": 31026.742, "update_time_ms": 2.526}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 475.55078125, "policy_entropy": 7569.134765625, "policy_loss": 8.74880576133728, "vf_loss": 129.13997268676758}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 1678320, "num_agent_steps_sampled": 6713280, "num_steps_trained": 1678320, "num_agent_steps_trained": 6713280, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 3356, "training_iteration": 167, "trial_id": "71426_00000", "experiment_id": "84bca2f7b35f43248fca18d21abe2ebf", "date": "2024-06-12_03-14-34", "timestamp": 1718129674, "time_this_iter_s": 10.213077783584595, "time_total_s": 1720.2733488082886, "pid": 363902, "hostname": "DESKTOP-LQ219J4", "node_ip": "192.168.46.185", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 20, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 5000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 500, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Base_Model", "custom_model_config": {"env": "rware", "env_args": {"n_agents": 4, "column_height": 1, "max_inactivity_steps": null, "max_steps": 500, "fast_obs": true, "msg_bits": 0, "sensor_range": 1, "shelf_rows": 1, "shelf_columns": 3, "request_queue_size": 4, "reward_type": "RewardType.INDIVIDUAL", "map_name": "customized_map", "map_size": "tiny", "difficulty": "medium"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": true, "force_coop": false, "local_mode": true, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 4, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 100, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64}, "algorithm": "ia2c", "space_obs": "Dict(obs:Box([-100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100.], [100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.], (112,), float32))", "space_act": "Discrete(5)", "num_agents": 4, "episode_limit": 500, "policy_mapping_info": {"all_scenario": {"description": "rware all scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2", "agent_3"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "rware_customized_map", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 10, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.IA2CTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_il.<locals>.<lambda> at 0x7f38082f8ca0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "grad_clip": 40.0, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "microbatch_size": null}, "time_since_restore": 1720.2733488082886, "timesteps_since_restore": 0, "iterations_since_restore": 167, "perf": {"cpu_util_percent": 4.386666666666666, "ram_util_percent": 78.70666666666668}}
{"episode_reward_max": 26.0, "episode_reward_min": 3.0, "episode_reward_mean": 12.81, "episode_len_mean": 500.0, "episode_media": {}, "episodes_this_iter": 20, "policy_reward_min": {"shared_policy": 0.0}, "policy_reward_max": {"shared_policy": 8.0}, "policy_reward_mean": {"shared_policy": 3.2025}, "custom_metrics": {}, "hist_stats": {"episode_reward": [21.0, 9.0, 10.0, 7.0, 17.0, 10.0, 5.0, 9.0, 3.0, 13.0, 16.0, 11.0, 10.0, 5.0, 18.0, 18.0, 11.0, 21.0, 13.0, 10.0, 18.0, 8.0, 9.0, 19.0, 17.0, 11.0, 4.0, 8.0, 20.0, 12.0, 6.0, 18.0, 13.0, 19.0, 6.0, 11.0, 12.0, 13.0, 17.0, 7.0, 8.0, 10.0, 21.0, 13.0, 15.0, 5.0, 3.0, 12.0, 12.0, 7.0, 12.0, 17.0, 11.0, 18.0, 13.0, 7.0, 23.0, 14.0, 14.0, 11.0, 26.0, 12.0, 25.0, 24.0, 16.0, 19.0, 8.0, 7.0, 15.0, 8.0, 12.0, 4.0, 19.0, 10.0, 16.0, 10.0, 11.0, 18.0, 13.0, 13.0, 19.0, 6.0, 16.0, 15.0, 16.0, 22.0, 8.0, 20.0, 5.0, 10.0, 12.0, 11.0, 7.0, 14.0, 16.0, 17.0, 13.0, 13.0, 11.0, 13.0], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500], "policy_shared_policy_reward": [7.0, 5.0, 6.0, 3.0, 3.0, 1.0, 3.0, 2.0, 3.0, 2.0, 1.0, 4.0, 1.0, 4.0, 2.0, 0.0, 6.0, 4.0, 3.0, 4.0, 3.0, 2.0, 3.0, 2.0, 2.0, 1.0, 2.0, 0.0, 4.0, 2.0, 2.0, 1.0, 1.0, 2.0, 0.0, 0.0, 2.0, 5.0, 3.0, 3.0, 6.0, 4.0, 3.0, 3.0, 4.0, 0.0, 5.0, 2.0, 2.0, 3.0, 2.0, 3.0, 0.0, 2.0, 2.0, 1.0, 5.0, 4.0, 6.0, 3.0, 5.0, 5.0, 5.0, 3.0, 3.0, 3.0, 4.0, 1.0, 5.0, 4.0, 4.0, 8.0, 1.0, 3.0, 5.0, 4.0, 2.0, 3.0, 3.0, 2.0, 6.0, 3.0, 4.0, 5.0, 1.0, 1.0, 4.0, 2.0, 3.0, 2.0, 2.0, 2.0, 5.0, 5.0, 5.0, 4.0, 4.0, 3.0, 6.0, 4.0, 2.0, 4.0, 2.0, 3.0, 1.0, 1.0, 2.0, 0.0, 2.0, 3.0, 1.0, 2.0, 5.0, 4.0, 5.0, 6.0, 3.0, 2.0, 4.0, 3.0, 0.0, 2.0, 2.0, 2.0, 6.0, 5.0, 4.0, 3.0, 2.0, 3.0, 5.0, 3.0, 6.0, 5.0, 4.0, 4.0, 3.0, 2.0, 0.0, 1.0, 2.0, 2.0, 3.0, 4.0, 3.0, 1.0, 4.0, 4.0, 3.0, 3.0, 5.0, 2.0, 4.0, 4.0, 5.0, 4.0, 2.0, 3.0, 1.0, 1.0, 3.0, 2.0, 2.0, 1.0, 4.0, 3.0, 0.0, 3.0, 5.0, 4.0, 6.0, 6.0, 4.0, 3.0, 2.0, 4.0, 5.0, 3.0, 4.0, 3.0, 1.0, 1.0, 2.0, 1.0, 0.0, 1.0, 2.0, 0.0, 4.0, 2.0, 3.0, 3.0, 2.0, 5.0, 3.0, 2.0, 2.0, 1.0, 2.0, 2.0, 3.0, 3.0, 3.0, 3.0, 5.0, 3.0, 4.0, 5.0, 2.0, 2.0, 4.0, 3.0, 3.0, 6.0, 5.0, 4.0, 3.0, 3.0, 4.0, 3.0, 2.0, 1.0, 2.0, 2.0, 7.0, 7.0, 6.0, 3.0, 3.0, 4.0, 2.0, 5.0, 2.0, 4.0, 4.0, 4.0, 4.0, 0.0, 5.0, 2.0, 8.0, 7.0, 6.0, 5.0, 4.0, 1.0, 1.0, 6.0, 6.0, 7.0, 6.0, 6.0, 4.0, 7.0, 7.0, 6.0, 6.0, 4.0, 5.0, 1.0, 6.0, 1.0, 7.0, 5.0, 2.0, 2.0, 1.0, 3.0, 2.0, 2.0, 1.0, 2.0, 5.0, 4.0, 3.0, 3.0, 2.0, 1.0, 2.0, 3.0, 3.0, 2.0, 4.0, 3.0, 2.0, 1.0, 1.0, 0.0, 6.0, 6.0, 5.0, 2.0, 4.0, 3.0, 2.0, 1.0, 4.0, 5.0, 5.0, 2.0, 3.0, 3.0, 2.0, 2.0, 2.0, 3.0, 3.0, 3.0, 3.0, 5.0, 6.0, 4.0, 1.0, 4.0, 4.0, 4.0, 2.0, 5.0, 3.0, 3.0, 5.0, 7.0, 2.0, 5.0, 2.0, 1.0, 3.0, 0.0, 5.0, 4.0, 4.0, 3.0, 6.0, 4.0, 3.0, 2.0, 4.0, 3.0, 4.0, 5.0, 8.0, 4.0, 4.0, 6.0, 2.0, 2.0, 2.0, 2.0, 6.0, 4.0, 6.0, 4.0, 1.0, 3.0, 0.0, 1.0, 1.0, 4.0, 3.0, 2.0, 3.0, 3.0, 4.0, 2.0, 3.0, 2.0, 4.0, 2.0, 3.0, 1.0, 1.0, 2.0, 3.0, 4.0, 5.0, 2.0, 4.0, 3.0, 5.0, 4.0, 4.0, 4.0, 5.0, 4.0, 3.0, 2.0, 4.0, 4.0, 4.0, 2.0, 4.0, 3.0, 3.0, 2.0, 3.0, 3.0, 4.0, 2.0, 4.0, 3.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.13401740292111103, "mean_inference_ms": 0.39115708458287896, "mean_action_processing_ms": 0.029190891349670817, "mean_env_wait_ms": 0.40352352018207077, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 1688400, "timesteps_this_iter": 0, "agent_timesteps_total": 6753600, "timers": {"sample_time_ms": 5169.34, "sample_throughput": 974.979, "load_time_ms": 0.169, "load_throughput": 29790434.273, "learn_time_ms": 163.923, "learn_throughput": 30746.111, "update_time_ms": 2.538}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 414.3409729003906, "policy_entropy": 7594.5709228515625, "policy_loss": -149.9702491760254, "vf_loss": 105.73849201202393}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 1688400, "num_agent_steps_sampled": 6753600, "num_steps_trained": 1688400, "num_agent_steps_trained": 6753600, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 3376, "training_iteration": 168, "trial_id": "71426_00000", "experiment_id": "84bca2f7b35f43248fca18d21abe2ebf", "date": "2024-06-12_03-14-44", "timestamp": 1718129684, "time_this_iter_s": 10.444944143295288, "time_total_s": 1730.7182929515839, "pid": 363902, "hostname": "DESKTOP-LQ219J4", "node_ip": "192.168.46.185", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 20, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 5000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 500, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Base_Model", "custom_model_config": {"env": "rware", "env_args": {"n_agents": 4, "column_height": 1, "max_inactivity_steps": null, "max_steps": 500, "fast_obs": true, "msg_bits": 0, "sensor_range": 1, "shelf_rows": 1, "shelf_columns": 3, "request_queue_size": 4, "reward_type": "RewardType.INDIVIDUAL", "map_name": "customized_map", "map_size": "tiny", "difficulty": "medium"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": true, "force_coop": false, "local_mode": true, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 4, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 100, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64}, "algorithm": "ia2c", "space_obs": "Dict(obs:Box([-100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100.], [100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.], (112,), float32))", "space_act": "Discrete(5)", "num_agents": 4, "episode_limit": 500, "policy_mapping_info": {"all_scenario": {"description": "rware all scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2", "agent_3"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "rware_customized_map", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 10, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.IA2CTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_il.<locals>.<lambda> at 0x7f382806ea60>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "grad_clip": 40.0, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "microbatch_size": null}, "time_since_restore": 1730.7182929515839, "timesteps_since_restore": 0, "iterations_since_restore": 168, "perf": {"cpu_util_percent": 4.606666666666667, "ram_util_percent": 78.97999999999999}}
{"episode_reward_max": 26.0, "episode_reward_min": 3.0, "episode_reward_mean": 12.52, "episode_len_mean": 500.0, "episode_media": {}, "episodes_this_iter": 20, "policy_reward_min": {"shared_policy": 0.0}, "policy_reward_max": {"shared_policy": 8.0}, "policy_reward_mean": {"shared_policy": 3.13}, "custom_metrics": {}, "hist_stats": {"episode_reward": [18.0, 8.0, 9.0, 19.0, 17.0, 11.0, 4.0, 8.0, 20.0, 12.0, 6.0, 18.0, 13.0, 19.0, 6.0, 11.0, 12.0, 13.0, 17.0, 7.0, 8.0, 10.0, 21.0, 13.0, 15.0, 5.0, 3.0, 12.0, 12.0, 7.0, 12.0, 17.0, 11.0, 18.0, 13.0, 7.0, 23.0, 14.0, 14.0, 11.0, 26.0, 12.0, 25.0, 24.0, 16.0, 19.0, 8.0, 7.0, 15.0, 8.0, 12.0, 4.0, 19.0, 10.0, 16.0, 10.0, 11.0, 18.0, 13.0, 13.0, 19.0, 6.0, 16.0, 15.0, 16.0, 22.0, 8.0, 20.0, 5.0, 10.0, 12.0, 11.0, 7.0, 14.0, 16.0, 17.0, 13.0, 13.0, 11.0, 13.0, 5.0, 9.0, 14.0, 13.0, 5.0, 17.0, 6.0, 15.0, 5.0, 6.0, 8.0, 12.0, 8.0, 11.0, 14.0, 11.0, 3.0, 13.0, 18.0, 15.0], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500], "policy_shared_policy_reward": [6.0, 3.0, 4.0, 5.0, 1.0, 1.0, 4.0, 2.0, 3.0, 2.0, 2.0, 2.0, 5.0, 5.0, 5.0, 4.0, 4.0, 3.0, 6.0, 4.0, 2.0, 4.0, 2.0, 3.0, 1.0, 1.0, 2.0, 0.0, 2.0, 3.0, 1.0, 2.0, 5.0, 4.0, 5.0, 6.0, 3.0, 2.0, 4.0, 3.0, 0.0, 2.0, 2.0, 2.0, 6.0, 5.0, 4.0, 3.0, 2.0, 3.0, 5.0, 3.0, 6.0, 5.0, 4.0, 4.0, 3.0, 2.0, 0.0, 1.0, 2.0, 2.0, 3.0, 4.0, 3.0, 1.0, 4.0, 4.0, 3.0, 3.0, 5.0, 2.0, 4.0, 4.0, 5.0, 4.0, 2.0, 3.0, 1.0, 1.0, 3.0, 2.0, 2.0, 1.0, 4.0, 3.0, 0.0, 3.0, 5.0, 4.0, 6.0, 6.0, 4.0, 3.0, 2.0, 4.0, 5.0, 3.0, 4.0, 3.0, 1.0, 1.0, 2.0, 1.0, 0.0, 1.0, 2.0, 0.0, 4.0, 2.0, 3.0, 3.0, 2.0, 5.0, 3.0, 2.0, 2.0, 1.0, 2.0, 2.0, 3.0, 3.0, 3.0, 3.0, 5.0, 3.0, 4.0, 5.0, 2.0, 2.0, 4.0, 3.0, 3.0, 6.0, 5.0, 4.0, 3.0, 3.0, 4.0, 3.0, 2.0, 1.0, 2.0, 2.0, 7.0, 7.0, 6.0, 3.0, 3.0, 4.0, 2.0, 5.0, 2.0, 4.0, 4.0, 4.0, 4.0, 0.0, 5.0, 2.0, 8.0, 7.0, 6.0, 5.0, 4.0, 1.0, 1.0, 6.0, 6.0, 7.0, 6.0, 6.0, 4.0, 7.0, 7.0, 6.0, 6.0, 4.0, 5.0, 1.0, 6.0, 1.0, 7.0, 5.0, 2.0, 2.0, 1.0, 3.0, 2.0, 2.0, 1.0, 2.0, 5.0, 4.0, 3.0, 3.0, 2.0, 1.0, 2.0, 3.0, 3.0, 2.0, 4.0, 3.0, 2.0, 1.0, 1.0, 0.0, 6.0, 6.0, 5.0, 2.0, 4.0, 3.0, 2.0, 1.0, 4.0, 5.0, 5.0, 2.0, 3.0, 3.0, 2.0, 2.0, 2.0, 3.0, 3.0, 3.0, 3.0, 5.0, 6.0, 4.0, 1.0, 4.0, 4.0, 4.0, 2.0, 5.0, 3.0, 3.0, 5.0, 7.0, 2.0, 5.0, 2.0, 1.0, 3.0, 0.0, 5.0, 4.0, 4.0, 3.0, 6.0, 4.0, 3.0, 2.0, 4.0, 3.0, 4.0, 5.0, 8.0, 4.0, 4.0, 6.0, 2.0, 2.0, 2.0, 2.0, 6.0, 4.0, 6.0, 4.0, 1.0, 3.0, 0.0, 1.0, 1.0, 4.0, 3.0, 2.0, 3.0, 3.0, 4.0, 2.0, 3.0, 2.0, 4.0, 2.0, 3.0, 1.0, 1.0, 2.0, 3.0, 4.0, 5.0, 2.0, 4.0, 3.0, 5.0, 4.0, 4.0, 4.0, 5.0, 4.0, 3.0, 2.0, 4.0, 4.0, 4.0, 2.0, 4.0, 3.0, 3.0, 2.0, 3.0, 3.0, 4.0, 2.0, 4.0, 3.0, 2.0, 1.0, 1.0, 1.0, 0.0, 3.0, 3.0, 3.0, 3.0, 4.0, 3.0, 4.0, 1.0, 3.0, 4.0, 5.0, 1.0, 0.0, 2.0, 2.0, 5.0, 4.0, 5.0, 3.0, 2.0, 1.0, 1.0, 2.0, 5.0, 3.0, 4.0, 3.0, 1.0, 1.0, 2.0, 1.0, 1.0, 2.0, 1.0, 2.0, 2.0, 2.0, 2.0, 2.0, 3.0, 3.0, 2.0, 4.0, 3.0, 2.0, 1.0, 2.0, 3.0, 3.0, 3.0, 2.0, 4.0, 4.0, 3.0, 3.0, 4.0, 3.0, 2.0, 2.0, 0.0, 2.0, 1.0, 0.0, 3.0, 4.0, 5.0, 1.0, 5.0, 5.0, 3.0, 5.0, 2.0, 4.0, 5.0, 4.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.13401431644186143, "mean_inference_ms": 0.3911526369787812, "mean_action_processing_ms": 0.02919051605754091, "mean_env_wait_ms": 0.40349884454138146, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 1698480, "timesteps_this_iter": 0, "agent_timesteps_total": 6793920, "timers": {"sample_time_ms": 5177.14, "sample_throughput": 973.511, "load_time_ms": 0.17, "load_throughput": 29690017.079, "learn_time_ms": 159.943, "learn_throughput": 31511.309, "update_time_ms": 2.58}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 534.7744750976562, "policy_entropy": 7704.3101806640625, "policy_loss": -151.5977029800415, "vf_loss": 106.42873191833496}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 1698480, "num_agent_steps_sampled": 6793920, "num_steps_trained": 1698480, "num_agent_steps_trained": 6793920, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 3396, "training_iteration": 169, "trial_id": "71426_00000", "experiment_id": "84bca2f7b35f43248fca18d21abe2ebf", "date": "2024-06-12_03-14-54", "timestamp": 1718129694, "time_this_iter_s": 10.225584030151367, "time_total_s": 1740.9438769817352, "pid": 363902, "hostname": "DESKTOP-LQ219J4", "node_ip": "192.168.46.185", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 20, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 5000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 500, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Base_Model", "custom_model_config": {"env": "rware", "env_args": {"n_agents": 4, "column_height": 1, "max_inactivity_steps": null, "max_steps": 500, "fast_obs": true, "msg_bits": 0, "sensor_range": 1, "shelf_rows": 1, "shelf_columns": 3, "request_queue_size": 4, "reward_type": "RewardType.INDIVIDUAL", "map_name": "customized_map", "map_size": "tiny", "difficulty": "medium"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": true, "force_coop": false, "local_mode": true, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 4, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 100, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64}, "algorithm": "ia2c", "space_obs": "Dict(obs:Box([-100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100.], [100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.], (112,), float32))", "space_act": "Discrete(5)", "num_agents": 4, "episode_limit": 500, "policy_mapping_info": {"all_scenario": {"description": "rware all scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2", "agent_3"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "rware_customized_map", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 10, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.IA2CTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_il.<locals>.<lambda> at 0x7f3808313700>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "grad_clip": 40.0, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "microbatch_size": null}, "time_since_restore": 1740.9438769817352, "timesteps_since_restore": 0, "iterations_since_restore": 169, "perf": {"cpu_util_percent": 4.449999999999999, "ram_util_percent": 79.28571428571426}}
{"episode_reward_max": 26.0, "episode_reward_min": 3.0, "episode_reward_mean": 12.35, "episode_len_mean": 500.0, "episode_media": {}, "episodes_this_iter": 20, "policy_reward_min": {"shared_policy": 0.0}, "policy_reward_max": {"shared_policy": 8.0}, "policy_reward_mean": {"shared_policy": 3.0875}, "custom_metrics": {}, "hist_stats": {"episode_reward": [8.0, 10.0, 21.0, 13.0, 15.0, 5.0, 3.0, 12.0, 12.0, 7.0, 12.0, 17.0, 11.0, 18.0, 13.0, 7.0, 23.0, 14.0, 14.0, 11.0, 26.0, 12.0, 25.0, 24.0, 16.0, 19.0, 8.0, 7.0, 15.0, 8.0, 12.0, 4.0, 19.0, 10.0, 16.0, 10.0, 11.0, 18.0, 13.0, 13.0, 19.0, 6.0, 16.0, 15.0, 16.0, 22.0, 8.0, 20.0, 5.0, 10.0, 12.0, 11.0, 7.0, 14.0, 16.0, 17.0, 13.0, 13.0, 11.0, 13.0, 5.0, 9.0, 14.0, 13.0, 5.0, 17.0, 6.0, 15.0, 5.0, 6.0, 8.0, 12.0, 8.0, 11.0, 14.0, 11.0, 3.0, 13.0, 18.0, 15.0, 14.0, 14.0, 8.0, 11.0, 5.0, 10.0, 19.0, 13.0, 11.0, 12.0, 8.0, 4.0, 14.0, 11.0, 16.0, 14.0, 11.0, 14.0, 11.0, 11.0], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500], "policy_shared_policy_reward": [3.0, 2.0, 2.0, 1.0, 4.0, 3.0, 0.0, 3.0, 5.0, 4.0, 6.0, 6.0, 4.0, 3.0, 2.0, 4.0, 5.0, 3.0, 4.0, 3.0, 1.0, 1.0, 2.0, 1.0, 0.0, 1.0, 2.0, 0.0, 4.0, 2.0, 3.0, 3.0, 2.0, 5.0, 3.0, 2.0, 2.0, 1.0, 2.0, 2.0, 3.0, 3.0, 3.0, 3.0, 5.0, 3.0, 4.0, 5.0, 2.0, 2.0, 4.0, 3.0, 3.0, 6.0, 5.0, 4.0, 3.0, 3.0, 4.0, 3.0, 2.0, 1.0, 2.0, 2.0, 7.0, 7.0, 6.0, 3.0, 3.0, 4.0, 2.0, 5.0, 2.0, 4.0, 4.0, 4.0, 4.0, 0.0, 5.0, 2.0, 8.0, 7.0, 6.0, 5.0, 4.0, 1.0, 1.0, 6.0, 6.0, 7.0, 6.0, 6.0, 4.0, 7.0, 7.0, 6.0, 6.0, 4.0, 5.0, 1.0, 6.0, 1.0, 7.0, 5.0, 2.0, 2.0, 1.0, 3.0, 2.0, 2.0, 1.0, 2.0, 5.0, 4.0, 3.0, 3.0, 2.0, 1.0, 2.0, 3.0, 3.0, 2.0, 4.0, 3.0, 2.0, 1.0, 1.0, 0.0, 6.0, 6.0, 5.0, 2.0, 4.0, 3.0, 2.0, 1.0, 4.0, 5.0, 5.0, 2.0, 3.0, 3.0, 2.0, 2.0, 2.0, 3.0, 3.0, 3.0, 3.0, 5.0, 6.0, 4.0, 1.0, 4.0, 4.0, 4.0, 2.0, 5.0, 3.0, 3.0, 5.0, 7.0, 2.0, 5.0, 2.0, 1.0, 3.0, 0.0, 5.0, 4.0, 4.0, 3.0, 6.0, 4.0, 3.0, 2.0, 4.0, 3.0, 4.0, 5.0, 8.0, 4.0, 4.0, 6.0, 2.0, 2.0, 2.0, 2.0, 6.0, 4.0, 6.0, 4.0, 1.0, 3.0, 0.0, 1.0, 1.0, 4.0, 3.0, 2.0, 3.0, 3.0, 4.0, 2.0, 3.0, 2.0, 4.0, 2.0, 3.0, 1.0, 1.0, 2.0, 3.0, 4.0, 5.0, 2.0, 4.0, 3.0, 5.0, 4.0, 4.0, 4.0, 5.0, 4.0, 3.0, 2.0, 4.0, 4.0, 4.0, 2.0, 4.0, 3.0, 3.0, 2.0, 3.0, 3.0, 4.0, 2.0, 4.0, 3.0, 2.0, 1.0, 1.0, 1.0, 0.0, 3.0, 3.0, 3.0, 3.0, 4.0, 3.0, 4.0, 1.0, 3.0, 4.0, 5.0, 1.0, 0.0, 2.0, 2.0, 5.0, 4.0, 5.0, 3.0, 2.0, 1.0, 1.0, 2.0, 5.0, 3.0, 4.0, 3.0, 1.0, 1.0, 2.0, 1.0, 1.0, 2.0, 1.0, 2.0, 2.0, 2.0, 2.0, 2.0, 3.0, 3.0, 2.0, 4.0, 3.0, 2.0, 1.0, 2.0, 3.0, 3.0, 3.0, 2.0, 4.0, 4.0, 3.0, 3.0, 4.0, 3.0, 2.0, 2.0, 0.0, 2.0, 1.0, 0.0, 3.0, 4.0, 5.0, 1.0, 5.0, 5.0, 3.0, 5.0, 2.0, 4.0, 5.0, 4.0, 3.0, 3.0, 5.0, 3.0, 2.0, 3.0, 4.0, 5.0, 3.0, 2.0, 1.0, 2.0, 1.0, 3.0, 3.0, 4.0, 1.0, 1.0, 1.0, 2.0, 3.0, 3.0, 2.0, 2.0, 7.0, 3.0, 3.0, 6.0, 3.0, 4.0, 4.0, 2.0, 2.0, 3.0, 4.0, 2.0, 3.0, 3.0, 2.0, 4.0, 3.0, 1.0, 1.0, 3.0, 2.0, 0.0, 1.0, 1.0, 6.0, 0.0, 3.0, 5.0, 1.0, 4.0, 3.0, 3.0, 4.0, 2.0, 5.0, 5.0, 4.0, 5.0, 3.0, 2.0, 2.0, 4.0, 3.0, 2.0, 5.0, 4.0, 2.0, 3.0, 5.0, 3.0, 1.0, 2.0, 4.0, 2.0, 3.0, 2.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.13401042854090878, "mean_inference_ms": 0.3911433693698082, "mean_action_processing_ms": 0.029189851208549316, "mean_env_wait_ms": 0.403464679141416, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 1708560, "timesteps_this_iter": 0, "agent_timesteps_total": 6834240, "timers": {"sample_time_ms": 5159.092, "sample_throughput": 976.916, "load_time_ms": 0.173, "load_throughput": 29109463.178, "learn_time_ms": 163.316, "learn_throughput": 30860.371, "update_time_ms": 2.605}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 351.224853515625, "policy_entropy": 7694.9747314453125, "policy_loss": -118.8964467048645, "vf_loss": 99.06635475158691}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 1708560, "num_agent_steps_sampled": 6834240, "num_steps_trained": 1708560, "num_agent_steps_trained": 6834240, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 3416, "training_iteration": 170, "trial_id": "71426_00000", "experiment_id": "84bca2f7b35f43248fca18d21abe2ebf", "date": "2024-06-12_03-15-05", "timestamp": 1718129705, "time_this_iter_s": 10.313278436660767, "time_total_s": 1751.257155418396, "pid": 363902, "hostname": "DESKTOP-LQ219J4", "node_ip": "192.168.46.185", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 20, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 5000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 500, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Base_Model", "custom_model_config": {"env": "rware", "env_args": {"n_agents": 4, "column_height": 1, "max_inactivity_steps": null, "max_steps": 500, "fast_obs": true, "msg_bits": 0, "sensor_range": 1, "shelf_rows": 1, "shelf_columns": 3, "request_queue_size": 4, "reward_type": "RewardType.INDIVIDUAL", "map_name": "customized_map", "map_size": "tiny", "difficulty": "medium"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": true, "force_coop": false, "local_mode": true, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 4, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 100, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64}, "algorithm": "ia2c", "space_obs": "Dict(obs:Box([-100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100.], [100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.], (112,), float32))", "space_act": "Discrete(5)", "num_agents": 4, "episode_limit": 500, "policy_mapping_info": {"all_scenario": {"description": "rware all scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2", "agent_3"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "rware_customized_map", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 10, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.IA2CTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_il.<locals>.<lambda> at 0x7f383066ad30>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "grad_clip": 40.0, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "microbatch_size": null}, "time_since_restore": 1751.257155418396, "timesteps_since_restore": 0, "iterations_since_restore": 170, "perf": {"cpu_util_percent": 4.633333333333334, "ram_util_percent": 79.52666666666666}}
{"episode_reward_max": 26.0, "episode_reward_min": 3.0, "episode_reward_mean": 12.34, "episode_len_mean": 500.0, "episode_media": {}, "episodes_this_iter": 20, "policy_reward_min": {"shared_policy": 0.0}, "policy_reward_max": {"shared_policy": 8.0}, "policy_reward_mean": {"shared_policy": 3.085}, "custom_metrics": {}, "hist_stats": {"episode_reward": [26.0, 12.0, 25.0, 24.0, 16.0, 19.0, 8.0, 7.0, 15.0, 8.0, 12.0, 4.0, 19.0, 10.0, 16.0, 10.0, 11.0, 18.0, 13.0, 13.0, 19.0, 6.0, 16.0, 15.0, 16.0, 22.0, 8.0, 20.0, 5.0, 10.0, 12.0, 11.0, 7.0, 14.0, 16.0, 17.0, 13.0, 13.0, 11.0, 13.0, 5.0, 9.0, 14.0, 13.0, 5.0, 17.0, 6.0, 15.0, 5.0, 6.0, 8.0, 12.0, 8.0, 11.0, 14.0, 11.0, 3.0, 13.0, 18.0, 15.0, 14.0, 14.0, 8.0, 11.0, 5.0, 10.0, 19.0, 13.0, 11.0, 12.0, 8.0, 4.0, 14.0, 11.0, 16.0, 14.0, 11.0, 14.0, 11.0, 11.0, 7.0, 16.0, 15.0, 14.0, 10.0, 15.0, 9.0, 15.0, 10.0, 16.0, 7.0, 6.0, 15.0, 14.0, 17.0, 13.0, 14.0, 15.0, 9.0, 8.0], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500], "policy_shared_policy_reward": [8.0, 7.0, 6.0, 5.0, 4.0, 1.0, 1.0, 6.0, 6.0, 7.0, 6.0, 6.0, 4.0, 7.0, 7.0, 6.0, 6.0, 4.0, 5.0, 1.0, 6.0, 1.0, 7.0, 5.0, 2.0, 2.0, 1.0, 3.0, 2.0, 2.0, 1.0, 2.0, 5.0, 4.0, 3.0, 3.0, 2.0, 1.0, 2.0, 3.0, 3.0, 2.0, 4.0, 3.0, 2.0, 1.0, 1.0, 0.0, 6.0, 6.0, 5.0, 2.0, 4.0, 3.0, 2.0, 1.0, 4.0, 5.0, 5.0, 2.0, 3.0, 3.0, 2.0, 2.0, 2.0, 3.0, 3.0, 3.0, 3.0, 5.0, 6.0, 4.0, 1.0, 4.0, 4.0, 4.0, 2.0, 5.0, 3.0, 3.0, 5.0, 7.0, 2.0, 5.0, 2.0, 1.0, 3.0, 0.0, 5.0, 4.0, 4.0, 3.0, 6.0, 4.0, 3.0, 2.0, 4.0, 3.0, 4.0, 5.0, 8.0, 4.0, 4.0, 6.0, 2.0, 2.0, 2.0, 2.0, 6.0, 4.0, 6.0, 4.0, 1.0, 3.0, 0.0, 1.0, 1.0, 4.0, 3.0, 2.0, 3.0, 3.0, 4.0, 2.0, 3.0, 2.0, 4.0, 2.0, 3.0, 1.0, 1.0, 2.0, 3.0, 4.0, 5.0, 2.0, 4.0, 3.0, 5.0, 4.0, 4.0, 4.0, 5.0, 4.0, 3.0, 2.0, 4.0, 4.0, 4.0, 2.0, 4.0, 3.0, 3.0, 2.0, 3.0, 3.0, 4.0, 2.0, 4.0, 3.0, 2.0, 1.0, 1.0, 1.0, 0.0, 3.0, 3.0, 3.0, 3.0, 4.0, 3.0, 4.0, 1.0, 3.0, 4.0, 5.0, 1.0, 0.0, 2.0, 2.0, 5.0, 4.0, 5.0, 3.0, 2.0, 1.0, 1.0, 2.0, 5.0, 3.0, 4.0, 3.0, 1.0, 1.0, 2.0, 1.0, 1.0, 2.0, 1.0, 2.0, 2.0, 2.0, 2.0, 2.0, 3.0, 3.0, 2.0, 4.0, 3.0, 2.0, 1.0, 2.0, 3.0, 3.0, 3.0, 2.0, 4.0, 4.0, 3.0, 3.0, 4.0, 3.0, 2.0, 2.0, 0.0, 2.0, 1.0, 0.0, 3.0, 4.0, 5.0, 1.0, 5.0, 5.0, 3.0, 5.0, 2.0, 4.0, 5.0, 4.0, 3.0, 3.0, 5.0, 3.0, 2.0, 3.0, 4.0, 5.0, 3.0, 2.0, 1.0, 2.0, 1.0, 3.0, 3.0, 4.0, 1.0, 1.0, 1.0, 2.0, 3.0, 3.0, 2.0, 2.0, 7.0, 3.0, 3.0, 6.0, 3.0, 4.0, 4.0, 2.0, 2.0, 3.0, 4.0, 2.0, 3.0, 3.0, 2.0, 4.0, 3.0, 1.0, 1.0, 3.0, 2.0, 0.0, 1.0, 1.0, 6.0, 0.0, 3.0, 5.0, 1.0, 4.0, 3.0, 3.0, 4.0, 2.0, 5.0, 5.0, 4.0, 5.0, 3.0, 2.0, 2.0, 4.0, 3.0, 2.0, 5.0, 4.0, 2.0, 3.0, 5.0, 3.0, 1.0, 2.0, 4.0, 2.0, 3.0, 2.0, 2.0, 1.0, 2.0, 2.0, 6.0, 4.0, 5.0, 1.0, 5.0, 4.0, 2.0, 4.0, 4.0, 3.0, 3.0, 4.0, 4.0, 2.0, 2.0, 2.0, 3.0, 2.0, 4.0, 6.0, 3.0, 2.0, 2.0, 2.0, 5.0, 6.0, 2.0, 2.0, 2.0, 5.0, 3.0, 0.0, 3.0, 2.0, 6.0, 5.0, 1.0, 3.0, 0.0, 3.0, 2.0, 2.0, 0.0, 2.0, 5.0, 2.0, 5.0, 3.0, 4.0, 2.0, 4.0, 4.0, 3.0, 4.0, 7.0, 3.0, 4.0, 4.0, 2.0, 3.0, 1.0, 5.0, 4.0, 4.0, 5.0, 3.0, 3.0, 4.0, 1.0, 3.0, 3.0, 2.0, 2.0, 2.0, 2.0, 2.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.13400641524406443, "mean_inference_ms": 0.3911337571256416, "mean_action_processing_ms": 0.029189491567959306, "mean_env_wait_ms": 0.4034311267038271, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 1718640, "timesteps_this_iter": 0, "agent_timesteps_total": 6874560, "timers": {"sample_time_ms": 5156.052, "sample_throughput": 977.492, "load_time_ms": 0.171, "load_throughput": 29487086.288, "learn_time_ms": 152.408, "learn_throughput": 33069.181, "update_time_ms": 2.524}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 479.5218811035156, "policy_entropy": 7589.1927490234375, "policy_loss": -29.10724449157715, "vf_loss": 113.39764976501465}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 1718640, "num_agent_steps_sampled": 6874560, "num_steps_trained": 1718640, "num_agent_steps_trained": 6874560, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 3436, "training_iteration": 171, "trial_id": "71426_00000", "experiment_id": "84bca2f7b35f43248fca18d21abe2ebf", "date": "2024-06-12_03-15-15", "timestamp": 1718129715, "time_this_iter_s": 10.173075675964355, "time_total_s": 1761.4302310943604, "pid": 363902, "hostname": "DESKTOP-LQ219J4", "node_ip": "192.168.46.185", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 20, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 5000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 500, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Base_Model", "custom_model_config": {"env": "rware", "env_args": {"n_agents": 4, "column_height": 1, "max_inactivity_steps": null, "max_steps": 500, "fast_obs": true, "msg_bits": 0, "sensor_range": 1, "shelf_rows": 1, "shelf_columns": 3, "request_queue_size": 4, "reward_type": "RewardType.INDIVIDUAL", "map_name": "customized_map", "map_size": "tiny", "difficulty": "medium"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": true, "force_coop": false, "local_mode": true, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 4, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 100, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64}, "algorithm": "ia2c", "space_obs": "Dict(obs:Box([-100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100.], [100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.], (112,), float32))", "space_act": "Discrete(5)", "num_agents": 4, "episode_limit": 500, "policy_mapping_info": {"all_scenario": {"description": "rware all scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2", "agent_3"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "rware_customized_map", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 10, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.IA2CTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_il.<locals>.<lambda> at 0x7f382806ea60>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "grad_clip": 40.0, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "microbatch_size": null}, "time_since_restore": 1761.4302310943604, "timesteps_since_restore": 0, "iterations_since_restore": 171, "perf": {"cpu_util_percent": 4.486666666666667, "ram_util_percent": 79.75999999999998}}
{"episode_reward_max": 25.0, "episode_reward_min": 3.0, "episode_reward_mean": 11.84, "episode_len_mean": 500.0, "episode_media": {}, "episodes_this_iter": 20, "policy_reward_min": {"shared_policy": 0.0}, "policy_reward_max": {"shared_policy": 8.0}, "policy_reward_mean": {"shared_policy": 2.96}, "custom_metrics": {}, "hist_stats": {"episode_reward": [19.0, 6.0, 16.0, 15.0, 16.0, 22.0, 8.0, 20.0, 5.0, 10.0, 12.0, 11.0, 7.0, 14.0, 16.0, 17.0, 13.0, 13.0, 11.0, 13.0, 5.0, 9.0, 14.0, 13.0, 5.0, 17.0, 6.0, 15.0, 5.0, 6.0, 8.0, 12.0, 8.0, 11.0, 14.0, 11.0, 3.0, 13.0, 18.0, 15.0, 14.0, 14.0, 8.0, 11.0, 5.0, 10.0, 19.0, 13.0, 11.0, 12.0, 8.0, 4.0, 14.0, 11.0, 16.0, 14.0, 11.0, 14.0, 11.0, 11.0, 7.0, 16.0, 15.0, 14.0, 10.0, 15.0, 9.0, 15.0, 10.0, 16.0, 7.0, 6.0, 15.0, 14.0, 17.0, 13.0, 14.0, 15.0, 9.0, 8.0, 4.0, 25.0, 3.0, 17.0, 8.0, 11.0, 14.0, 3.0, 20.0, 6.0, 13.0, 11.0, 18.0, 11.0, 8.0, 13.0, 14.0, 16.0, 11.0, 10.0], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500], "policy_shared_policy_reward": [5.0, 7.0, 2.0, 5.0, 2.0, 1.0, 3.0, 0.0, 5.0, 4.0, 4.0, 3.0, 6.0, 4.0, 3.0, 2.0, 4.0, 3.0, 4.0, 5.0, 8.0, 4.0, 4.0, 6.0, 2.0, 2.0, 2.0, 2.0, 6.0, 4.0, 6.0, 4.0, 1.0, 3.0, 0.0, 1.0, 1.0, 4.0, 3.0, 2.0, 3.0, 3.0, 4.0, 2.0, 3.0, 2.0, 4.0, 2.0, 3.0, 1.0, 1.0, 2.0, 3.0, 4.0, 5.0, 2.0, 4.0, 3.0, 5.0, 4.0, 4.0, 4.0, 5.0, 4.0, 3.0, 2.0, 4.0, 4.0, 4.0, 2.0, 4.0, 3.0, 3.0, 2.0, 3.0, 3.0, 4.0, 2.0, 4.0, 3.0, 2.0, 1.0, 1.0, 1.0, 0.0, 3.0, 3.0, 3.0, 3.0, 4.0, 3.0, 4.0, 1.0, 3.0, 4.0, 5.0, 1.0, 0.0, 2.0, 2.0, 5.0, 4.0, 5.0, 3.0, 2.0, 1.0, 1.0, 2.0, 5.0, 3.0, 4.0, 3.0, 1.0, 1.0, 2.0, 1.0, 1.0, 2.0, 1.0, 2.0, 2.0, 2.0, 2.0, 2.0, 3.0, 3.0, 2.0, 4.0, 3.0, 2.0, 1.0, 2.0, 3.0, 3.0, 3.0, 2.0, 4.0, 4.0, 3.0, 3.0, 4.0, 3.0, 2.0, 2.0, 0.0, 2.0, 1.0, 0.0, 3.0, 4.0, 5.0, 1.0, 5.0, 5.0, 3.0, 5.0, 2.0, 4.0, 5.0, 4.0, 3.0, 3.0, 5.0, 3.0, 2.0, 3.0, 4.0, 5.0, 3.0, 2.0, 1.0, 2.0, 1.0, 3.0, 3.0, 4.0, 1.0, 1.0, 1.0, 2.0, 3.0, 3.0, 2.0, 2.0, 7.0, 3.0, 3.0, 6.0, 3.0, 4.0, 4.0, 2.0, 2.0, 3.0, 4.0, 2.0, 3.0, 3.0, 2.0, 4.0, 3.0, 1.0, 1.0, 3.0, 2.0, 0.0, 1.0, 1.0, 6.0, 0.0, 3.0, 5.0, 1.0, 4.0, 3.0, 3.0, 4.0, 2.0, 5.0, 5.0, 4.0, 5.0, 3.0, 2.0, 2.0, 4.0, 3.0, 2.0, 5.0, 4.0, 2.0, 3.0, 5.0, 3.0, 1.0, 2.0, 4.0, 2.0, 3.0, 2.0, 2.0, 1.0, 2.0, 2.0, 6.0, 4.0, 5.0, 1.0, 5.0, 4.0, 2.0, 4.0, 4.0, 3.0, 3.0, 4.0, 4.0, 2.0, 2.0, 2.0, 3.0, 2.0, 4.0, 6.0, 3.0, 2.0, 2.0, 2.0, 5.0, 6.0, 2.0, 2.0, 2.0, 5.0, 3.0, 0.0, 3.0, 2.0, 6.0, 5.0, 1.0, 3.0, 0.0, 3.0, 2.0, 2.0, 0.0, 2.0, 5.0, 2.0, 5.0, 3.0, 4.0, 2.0, 4.0, 4.0, 3.0, 4.0, 7.0, 3.0, 4.0, 4.0, 2.0, 3.0, 1.0, 5.0, 4.0, 4.0, 5.0, 3.0, 3.0, 4.0, 1.0, 3.0, 3.0, 2.0, 2.0, 2.0, 2.0, 2.0, 1.0, 1.0, 2.0, 0.0, 4.0, 8.0, 6.0, 7.0, 1.0, 1.0, 1.0, 0.0, 6.0, 6.0, 2.0, 3.0, 2.0, 3.0, 0.0, 3.0, 2.0, 4.0, 4.0, 1.0, 2.0, 6.0, 3.0, 3.0, 1.0, 1.0, 0.0, 1.0, 3.0, 8.0, 4.0, 5.0, 2.0, 2.0, 1.0, 1.0, 4.0, 3.0, 2.0, 4.0, 2.0, 2.0, 4.0, 3.0, 5.0, 4.0, 5.0, 4.0, 2.0, 3.0, 3.0, 3.0, 1.0, 3.0, 2.0, 2.0, 3.0, 4.0, 2.0, 4.0, 4.0, 1.0, 6.0, 3.0, 4.0, 3.0, 3.0, 6.0, 3.0, 2.0, 2.0, 4.0, 1.0, 4.0, 1.0, 4.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.1340015083428238, "mean_inference_ms": 0.3911205845586092, "mean_action_processing_ms": 0.029188416031478256, "mean_env_wait_ms": 0.4034047531242384, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 1728720, "timesteps_this_iter": 0, "agent_timesteps_total": 6914880, "timers": {"sample_time_ms": 5140.406, "sample_throughput": 980.467, "load_time_ms": 0.17, "load_throughput": 29619296.847, "learn_time_ms": 153.572, "learn_throughput": 32818.567, "update_time_ms": 2.521}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 403.03668212890625, "policy_entropy": 7595.853271484375, "policy_loss": -16.76790142059326, "vf_loss": 103.85967254638672}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 1728720, "num_agent_steps_sampled": 6914880, "num_steps_trained": 1728720, "num_agent_steps_trained": 6914880, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 3456, "training_iteration": 172, "trial_id": "71426_00000", "experiment_id": "84bca2f7b35f43248fca18d21abe2ebf", "date": "2024-06-12_03-15-25", "timestamp": 1718129725, "time_this_iter_s": 10.173209428787231, "time_total_s": 1771.6034405231476, "pid": 363902, "hostname": "DESKTOP-LQ219J4", "node_ip": "192.168.46.185", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 20, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 5000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 500, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Base_Model", "custom_model_config": {"env": "rware", "env_args": {"n_agents": 4, "column_height": 1, "max_inactivity_steps": null, "max_steps": 500, "fast_obs": true, "msg_bits": 0, "sensor_range": 1, "shelf_rows": 1, "shelf_columns": 3, "request_queue_size": 4, "reward_type": "RewardType.INDIVIDUAL", "map_name": "customized_map", "map_size": "tiny", "difficulty": "medium"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": true, "force_coop": false, "local_mode": true, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 4, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 100, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64}, "algorithm": "ia2c", "space_obs": "Dict(obs:Box([-100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100.], [100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.], (112,), float32))", "space_act": "Discrete(5)", "num_agents": 4, "episode_limit": 500, "policy_mapping_info": {"all_scenario": {"description": "rware all scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2", "agent_3"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "rware_customized_map", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 10, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.IA2CTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_il.<locals>.<lambda> at 0x7f38081d59d0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "grad_clip": 40.0, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "microbatch_size": null}, "time_since_restore": 1771.6034405231476, "timesteps_since_restore": 0, "iterations_since_restore": 172, "perf": {"cpu_util_percent": 4.492857142857142, "ram_util_percent": 79.95000000000002}}
{"episode_reward_max": 25.0, "episode_reward_min": 3.0, "episode_reward_mean": 11.67, "episode_len_mean": 500.0, "episode_media": {}, "episodes_this_iter": 20, "policy_reward_min": {"shared_policy": 0.0}, "policy_reward_max": {"shared_policy": 8.0}, "policy_reward_mean": {"shared_policy": 2.9175}, "custom_metrics": {}, "hist_stats": {"episode_reward": [5.0, 9.0, 14.0, 13.0, 5.0, 17.0, 6.0, 15.0, 5.0, 6.0, 8.0, 12.0, 8.0, 11.0, 14.0, 11.0, 3.0, 13.0, 18.0, 15.0, 14.0, 14.0, 8.0, 11.0, 5.0, 10.0, 19.0, 13.0, 11.0, 12.0, 8.0, 4.0, 14.0, 11.0, 16.0, 14.0, 11.0, 14.0, 11.0, 11.0, 7.0, 16.0, 15.0, 14.0, 10.0, 15.0, 9.0, 15.0, 10.0, 16.0, 7.0, 6.0, 15.0, 14.0, 17.0, 13.0, 14.0, 15.0, 9.0, 8.0, 4.0, 25.0, 3.0, 17.0, 8.0, 11.0, 14.0, 3.0, 20.0, 6.0, 13.0, 11.0, 18.0, 11.0, 8.0, 13.0, 14.0, 16.0, 11.0, 10.0, 14.0, 8.0, 8.0, 6.0, 10.0, 12.0, 7.0, 8.0, 17.0, 11.0, 11.0, 13.0, 17.0, 17.0, 18.0, 19.0, 18.0, 8.0, 10.0, 15.0], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500], "policy_shared_policy_reward": [2.0, 1.0, 1.0, 1.0, 0.0, 3.0, 3.0, 3.0, 3.0, 4.0, 3.0, 4.0, 1.0, 3.0, 4.0, 5.0, 1.0, 0.0, 2.0, 2.0, 5.0, 4.0, 5.0, 3.0, 2.0, 1.0, 1.0, 2.0, 5.0, 3.0, 4.0, 3.0, 1.0, 1.0, 2.0, 1.0, 1.0, 2.0, 1.0, 2.0, 2.0, 2.0, 2.0, 2.0, 3.0, 3.0, 2.0, 4.0, 3.0, 2.0, 1.0, 2.0, 3.0, 3.0, 3.0, 2.0, 4.0, 4.0, 3.0, 3.0, 4.0, 3.0, 2.0, 2.0, 0.0, 2.0, 1.0, 0.0, 3.0, 4.0, 5.0, 1.0, 5.0, 5.0, 3.0, 5.0, 2.0, 4.0, 5.0, 4.0, 3.0, 3.0, 5.0, 3.0, 2.0, 3.0, 4.0, 5.0, 3.0, 2.0, 1.0, 2.0, 1.0, 3.0, 3.0, 4.0, 1.0, 1.0, 1.0, 2.0, 3.0, 3.0, 2.0, 2.0, 7.0, 3.0, 3.0, 6.0, 3.0, 4.0, 4.0, 2.0, 2.0, 3.0, 4.0, 2.0, 3.0, 3.0, 2.0, 4.0, 3.0, 1.0, 1.0, 3.0, 2.0, 0.0, 1.0, 1.0, 6.0, 0.0, 3.0, 5.0, 1.0, 4.0, 3.0, 3.0, 4.0, 2.0, 5.0, 5.0, 4.0, 5.0, 3.0, 2.0, 2.0, 4.0, 3.0, 2.0, 5.0, 4.0, 2.0, 3.0, 5.0, 3.0, 1.0, 2.0, 4.0, 2.0, 3.0, 2.0, 2.0, 1.0, 2.0, 2.0, 6.0, 4.0, 5.0, 1.0, 5.0, 4.0, 2.0, 4.0, 4.0, 3.0, 3.0, 4.0, 4.0, 2.0, 2.0, 2.0, 3.0, 2.0, 4.0, 6.0, 3.0, 2.0, 2.0, 2.0, 5.0, 6.0, 2.0, 2.0, 2.0, 5.0, 3.0, 0.0, 3.0, 2.0, 6.0, 5.0, 1.0, 3.0, 0.0, 3.0, 2.0, 2.0, 0.0, 2.0, 5.0, 2.0, 5.0, 3.0, 4.0, 2.0, 4.0, 4.0, 3.0, 4.0, 7.0, 3.0, 4.0, 4.0, 2.0, 3.0, 1.0, 5.0, 4.0, 4.0, 5.0, 3.0, 3.0, 4.0, 1.0, 3.0, 3.0, 2.0, 2.0, 2.0, 2.0, 2.0, 1.0, 1.0, 2.0, 0.0, 4.0, 8.0, 6.0, 7.0, 1.0, 1.0, 1.0, 0.0, 6.0, 6.0, 2.0, 3.0, 2.0, 3.0, 0.0, 3.0, 2.0, 4.0, 4.0, 1.0, 2.0, 6.0, 3.0, 3.0, 1.0, 1.0, 0.0, 1.0, 3.0, 8.0, 4.0, 5.0, 2.0, 2.0, 1.0, 1.0, 4.0, 3.0, 2.0, 4.0, 2.0, 2.0, 4.0, 3.0, 5.0, 4.0, 5.0, 4.0, 2.0, 3.0, 3.0, 3.0, 1.0, 3.0, 2.0, 2.0, 3.0, 4.0, 2.0, 4.0, 4.0, 1.0, 6.0, 3.0, 4.0, 3.0, 3.0, 6.0, 3.0, 2.0, 2.0, 4.0, 1.0, 4.0, 1.0, 4.0, 3.0, 7.0, 2.0, 2.0, 2.0, 1.0, 3.0, 2.0, 2.0, 3.0, 1.0, 2.0, 2.0, 1.0, 2.0, 1.0, 4.0, 2.0, 3.0, 1.0, 4.0, 2.0, 3.0, 3.0, 0.0, 2.0, 4.0, 1.0, 3.0, 2.0, 2.0, 1.0, 4.0, 3.0, 4.0, 6.0, 2.0, 5.0, 1.0, 3.0, 2.0, 5.0, 2.0, 2.0, 3.0, 4.0, 1.0, 5.0, 4.0, 2.0, 6.0, 5.0, 5.0, 5.0, 2.0, 5.0, 4.0, 6.0, 3.0, 5.0, 4.0, 4.0, 4.0, 7.0, 4.0, 5.0, 5.0, 4.0, 1.0, 1.0, 3.0, 3.0, 3.0, 2.0, 2.0, 3.0, 5.0, 2.0, 5.0, 3.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.13399439669847085, "mean_inference_ms": 0.3910999446833657, "mean_action_processing_ms": 0.029186926233119453, "mean_env_wait_ms": 0.40336810310786303, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 1738800, "timesteps_this_iter": 0, "agent_timesteps_total": 6955200, "timers": {"sample_time_ms": 5112.221, "sample_throughput": 985.873, "load_time_ms": 0.174, "load_throughput": 29009595.389, "learn_time_ms": 150.886, "learn_throughput": 33402.688, "update_time_ms": 2.466}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 417.95684814453125, "policy_entropy": 7631.0853271484375, "policy_loss": -0.08205795288085938, "vf_loss": 109.86072540283203}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 1738800, "num_agent_steps_sampled": 6955200, "num_steps_trained": 1738800, "num_agent_steps_trained": 6955200, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 3476, "training_iteration": 173, "trial_id": "71426_00000", "experiment_id": "84bca2f7b35f43248fca18d21abe2ebf", "date": "2024-06-12_03-15-35", "timestamp": 1718129735, "time_this_iter_s": 10.134958267211914, "time_total_s": 1781.7383987903595, "pid": 363902, "hostname": "DESKTOP-LQ219J4", "node_ip": "192.168.46.185", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 20, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 5000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 500, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Base_Model", "custom_model_config": {"env": "rware", "env_args": {"n_agents": 4, "column_height": 1, "max_inactivity_steps": null, "max_steps": 500, "fast_obs": true, "msg_bits": 0, "sensor_range": 1, "shelf_rows": 1, "shelf_columns": 3, "request_queue_size": 4, "reward_type": "RewardType.INDIVIDUAL", "map_name": "customized_map", "map_size": "tiny", "difficulty": "medium"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": true, "force_coop": false, "local_mode": true, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 4, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 100, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64}, "algorithm": "ia2c", "space_obs": "Dict(obs:Box([-100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100.], [100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.], (112,), float32))", "space_act": "Discrete(5)", "num_agents": 4, "episode_limit": 500, "policy_mapping_info": {"all_scenario": {"description": "rware all scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2", "agent_3"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "rware_customized_map", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 10, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.IA2CTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_il.<locals>.<lambda> at 0x7f38280b24c0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "grad_clip": 40.0, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "microbatch_size": null}, "time_since_restore": 1781.7383987903595, "timesteps_since_restore": 0, "iterations_since_restore": 173, "perf": {"cpu_util_percent": 4.239999999999999, "ram_util_percent": 80.25999999999999}}
{"episode_reward_max": 25.0, "episode_reward_min": 3.0, "episode_reward_mean": 12.03, "episode_len_mean": 500.0, "episode_media": {}, "episodes_this_iter": 20, "policy_reward_min": {"shared_policy": 0.0}, "policy_reward_max": {"shared_policy": 8.0}, "policy_reward_mean": {"shared_policy": 3.0075}, "custom_metrics": {}, "hist_stats": {"episode_reward": [14.0, 14.0, 8.0, 11.0, 5.0, 10.0, 19.0, 13.0, 11.0, 12.0, 8.0, 4.0, 14.0, 11.0, 16.0, 14.0, 11.0, 14.0, 11.0, 11.0, 7.0, 16.0, 15.0, 14.0, 10.0, 15.0, 9.0, 15.0, 10.0, 16.0, 7.0, 6.0, 15.0, 14.0, 17.0, 13.0, 14.0, 15.0, 9.0, 8.0, 4.0, 25.0, 3.0, 17.0, 8.0, 11.0, 14.0, 3.0, 20.0, 6.0, 13.0, 11.0, 18.0, 11.0, 8.0, 13.0, 14.0, 16.0, 11.0, 10.0, 14.0, 8.0, 8.0, 6.0, 10.0, 12.0, 7.0, 8.0, 17.0, 11.0, 11.0, 13.0, 17.0, 17.0, 18.0, 19.0, 18.0, 8.0, 10.0, 15.0, 20.0, 10.0, 12.0, 13.0, 10.0, 12.0, 15.0, 8.0, 22.0, 10.0, 3.0, 10.0, 6.0, 11.0, 8.0, 21.0, 3.0, 14.0, 19.0, 17.0], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500], "policy_shared_policy_reward": [3.0, 3.0, 5.0, 3.0, 2.0, 3.0, 4.0, 5.0, 3.0, 2.0, 1.0, 2.0, 1.0, 3.0, 3.0, 4.0, 1.0, 1.0, 1.0, 2.0, 3.0, 3.0, 2.0, 2.0, 7.0, 3.0, 3.0, 6.0, 3.0, 4.0, 4.0, 2.0, 2.0, 3.0, 4.0, 2.0, 3.0, 3.0, 2.0, 4.0, 3.0, 1.0, 1.0, 3.0, 2.0, 0.0, 1.0, 1.0, 6.0, 0.0, 3.0, 5.0, 1.0, 4.0, 3.0, 3.0, 4.0, 2.0, 5.0, 5.0, 4.0, 5.0, 3.0, 2.0, 2.0, 4.0, 3.0, 2.0, 5.0, 4.0, 2.0, 3.0, 5.0, 3.0, 1.0, 2.0, 4.0, 2.0, 3.0, 2.0, 2.0, 1.0, 2.0, 2.0, 6.0, 4.0, 5.0, 1.0, 5.0, 4.0, 2.0, 4.0, 4.0, 3.0, 3.0, 4.0, 4.0, 2.0, 2.0, 2.0, 3.0, 2.0, 4.0, 6.0, 3.0, 2.0, 2.0, 2.0, 5.0, 6.0, 2.0, 2.0, 2.0, 5.0, 3.0, 0.0, 3.0, 2.0, 6.0, 5.0, 1.0, 3.0, 0.0, 3.0, 2.0, 2.0, 0.0, 2.0, 5.0, 2.0, 5.0, 3.0, 4.0, 2.0, 4.0, 4.0, 3.0, 4.0, 7.0, 3.0, 4.0, 4.0, 2.0, 3.0, 1.0, 5.0, 4.0, 4.0, 5.0, 3.0, 3.0, 4.0, 1.0, 3.0, 3.0, 2.0, 2.0, 2.0, 2.0, 2.0, 1.0, 1.0, 2.0, 0.0, 4.0, 8.0, 6.0, 7.0, 1.0, 1.0, 1.0, 0.0, 6.0, 6.0, 2.0, 3.0, 2.0, 3.0, 0.0, 3.0, 2.0, 4.0, 4.0, 1.0, 2.0, 6.0, 3.0, 3.0, 1.0, 1.0, 0.0, 1.0, 3.0, 8.0, 4.0, 5.0, 2.0, 2.0, 1.0, 1.0, 4.0, 3.0, 2.0, 4.0, 2.0, 2.0, 4.0, 3.0, 5.0, 4.0, 5.0, 4.0, 2.0, 3.0, 3.0, 3.0, 1.0, 3.0, 2.0, 2.0, 3.0, 4.0, 2.0, 4.0, 4.0, 1.0, 6.0, 3.0, 4.0, 3.0, 3.0, 6.0, 3.0, 2.0, 2.0, 4.0, 1.0, 4.0, 1.0, 4.0, 3.0, 7.0, 2.0, 2.0, 2.0, 1.0, 3.0, 2.0, 2.0, 3.0, 1.0, 2.0, 2.0, 1.0, 2.0, 1.0, 4.0, 2.0, 3.0, 1.0, 4.0, 2.0, 3.0, 3.0, 0.0, 2.0, 4.0, 1.0, 3.0, 2.0, 2.0, 1.0, 4.0, 3.0, 4.0, 6.0, 2.0, 5.0, 1.0, 3.0, 2.0, 5.0, 2.0, 2.0, 3.0, 4.0, 1.0, 5.0, 4.0, 2.0, 6.0, 5.0, 5.0, 5.0, 2.0, 5.0, 4.0, 6.0, 3.0, 5.0, 4.0, 4.0, 4.0, 7.0, 4.0, 5.0, 5.0, 4.0, 1.0, 1.0, 3.0, 3.0, 3.0, 2.0, 2.0, 3.0, 5.0, 2.0, 5.0, 3.0, 6.0, 4.0, 6.0, 4.0, 4.0, 2.0, 3.0, 1.0, 3.0, 3.0, 3.0, 3.0, 5.0, 4.0, 2.0, 2.0, 2.0, 2.0, 4.0, 2.0, 2.0, 4.0, 1.0, 5.0, 5.0, 5.0, 4.0, 1.0, 2.0, 2.0, 1.0, 3.0, 7.0, 5.0, 6.0, 4.0, 4.0, 2.0, 2.0, 2.0, 0.0, 1.0, 1.0, 1.0, 3.0, 3.0, 2.0, 2.0, 3.0, 1.0, 1.0, 1.0, 2.0, 2.0, 2.0, 5.0, 1.0, 2.0, 2.0, 3.0, 5.0, 5.0, 6.0, 5.0, 0.0, 1.0, 1.0, 1.0, 4.0, 2.0, 4.0, 4.0, 4.0, 5.0, 4.0, 6.0, 5.0, 5.0, 5.0, 2.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.1339862236624266, "mean_inference_ms": 0.3910756873097223, "mean_action_processing_ms": 0.029185218471474234, "mean_env_wait_ms": 0.4033262926517086, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 1748880, "timesteps_this_iter": 0, "agent_timesteps_total": 6995520, "timers": {"sample_time_ms": 5097.162, "sample_throughput": 988.785, "load_time_ms": 0.173, "load_throughput": 29185823.775, "learn_time_ms": 159.777, "learn_throughput": 31543.979, "update_time_ms": 2.431}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 386.62042236328125, "policy_entropy": 7578.5357666015625, "policy_loss": -5.555083990097046, "vf_loss": 104.0633316040039}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 1748880, "num_agent_steps_sampled": 6995520, "num_steps_trained": 1748880, "num_agent_steps_trained": 6995520, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 3496, "training_iteration": 174, "trial_id": "71426_00000", "experiment_id": "84bca2f7b35f43248fca18d21abe2ebf", "date": "2024-06-12_03-15-45", "timestamp": 1718129745, "time_this_iter_s": 10.196291208267212, "time_total_s": 1791.9346899986267, "pid": 363902, "hostname": "DESKTOP-LQ219J4", "node_ip": "192.168.46.185", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 20, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 5000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 500, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Base_Model", "custom_model_config": {"env": "rware", "env_args": {"n_agents": 4, "column_height": 1, "max_inactivity_steps": null, "max_steps": 500, "fast_obs": true, "msg_bits": 0, "sensor_range": 1, "shelf_rows": 1, "shelf_columns": 3, "request_queue_size": 4, "reward_type": "RewardType.INDIVIDUAL", "map_name": "customized_map", "map_size": "tiny", "difficulty": "medium"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": true, "force_coop": false, "local_mode": true, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 4, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 100, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64}, "algorithm": "ia2c", "space_obs": "Dict(obs:Box([-100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100.], [100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.], (112,), float32))", "space_act": "Discrete(5)", "num_agents": 4, "episode_limit": 500, "policy_mapping_info": {"all_scenario": {"description": "rware all scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2", "agent_3"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "rware_customized_map", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 10, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.IA2CTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_il.<locals>.<lambda> at 0x7f38086c1d30>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "grad_clip": 40.0, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "microbatch_size": null}, "time_since_restore": 1791.9346899986267, "timesteps_since_restore": 0, "iterations_since_restore": 174, "perf": {"cpu_util_percent": 4.221428571428571, "ram_util_percent": 80.49285714285715}}
{"episode_reward_max": 30.0, "episode_reward_min": 3.0, "episode_reward_mean": 12.96, "episode_len_mean": 500.0, "episode_media": {}, "episodes_this_iter": 20, "policy_reward_min": {"shared_policy": 0.0}, "policy_reward_max": {"shared_policy": 9.0}, "policy_reward_mean": {"shared_policy": 3.24}, "custom_metrics": {}, "hist_stats": {"episode_reward": [7.0, 16.0, 15.0, 14.0, 10.0, 15.0, 9.0, 15.0, 10.0, 16.0, 7.0, 6.0, 15.0, 14.0, 17.0, 13.0, 14.0, 15.0, 9.0, 8.0, 4.0, 25.0, 3.0, 17.0, 8.0, 11.0, 14.0, 3.0, 20.0, 6.0, 13.0, 11.0, 18.0, 11.0, 8.0, 13.0, 14.0, 16.0, 11.0, 10.0, 14.0, 8.0, 8.0, 6.0, 10.0, 12.0, 7.0, 8.0, 17.0, 11.0, 11.0, 13.0, 17.0, 17.0, 18.0, 19.0, 18.0, 8.0, 10.0, 15.0, 20.0, 10.0, 12.0, 13.0, 10.0, 12.0, 15.0, 8.0, 22.0, 10.0, 3.0, 10.0, 6.0, 11.0, 8.0, 21.0, 3.0, 14.0, 19.0, 17.0, 10.0, 10.0, 13.0, 28.0, 22.0, 30.0, 11.0, 13.0, 12.0, 22.0, 14.0, 29.0, 13.0, 23.0, 17.0, 6.0, 5.0, 6.0, 21.0, 19.0], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500], "policy_shared_policy_reward": [2.0, 1.0, 2.0, 2.0, 6.0, 4.0, 5.0, 1.0, 5.0, 4.0, 2.0, 4.0, 4.0, 3.0, 3.0, 4.0, 4.0, 2.0, 2.0, 2.0, 3.0, 2.0, 4.0, 6.0, 3.0, 2.0, 2.0, 2.0, 5.0, 6.0, 2.0, 2.0, 2.0, 5.0, 3.0, 0.0, 3.0, 2.0, 6.0, 5.0, 1.0, 3.0, 0.0, 3.0, 2.0, 2.0, 0.0, 2.0, 5.0, 2.0, 5.0, 3.0, 4.0, 2.0, 4.0, 4.0, 3.0, 4.0, 7.0, 3.0, 4.0, 4.0, 2.0, 3.0, 1.0, 5.0, 4.0, 4.0, 5.0, 3.0, 3.0, 4.0, 1.0, 3.0, 3.0, 2.0, 2.0, 2.0, 2.0, 2.0, 1.0, 1.0, 2.0, 0.0, 4.0, 8.0, 6.0, 7.0, 1.0, 1.0, 1.0, 0.0, 6.0, 6.0, 2.0, 3.0, 2.0, 3.0, 0.0, 3.0, 2.0, 4.0, 4.0, 1.0, 2.0, 6.0, 3.0, 3.0, 1.0, 1.0, 0.0, 1.0, 3.0, 8.0, 4.0, 5.0, 2.0, 2.0, 1.0, 1.0, 4.0, 3.0, 2.0, 4.0, 2.0, 2.0, 4.0, 3.0, 5.0, 4.0, 5.0, 4.0, 2.0, 3.0, 3.0, 3.0, 1.0, 3.0, 2.0, 2.0, 3.0, 4.0, 2.0, 4.0, 4.0, 1.0, 6.0, 3.0, 4.0, 3.0, 3.0, 6.0, 3.0, 2.0, 2.0, 4.0, 1.0, 4.0, 1.0, 4.0, 3.0, 7.0, 2.0, 2.0, 2.0, 1.0, 3.0, 2.0, 2.0, 3.0, 1.0, 2.0, 2.0, 1.0, 2.0, 1.0, 4.0, 2.0, 3.0, 1.0, 4.0, 2.0, 3.0, 3.0, 0.0, 2.0, 4.0, 1.0, 3.0, 2.0, 2.0, 1.0, 4.0, 3.0, 4.0, 6.0, 2.0, 5.0, 1.0, 3.0, 2.0, 5.0, 2.0, 2.0, 3.0, 4.0, 1.0, 5.0, 4.0, 2.0, 6.0, 5.0, 5.0, 5.0, 2.0, 5.0, 4.0, 6.0, 3.0, 5.0, 4.0, 4.0, 4.0, 7.0, 4.0, 5.0, 5.0, 4.0, 1.0, 1.0, 3.0, 3.0, 3.0, 2.0, 2.0, 3.0, 5.0, 2.0, 5.0, 3.0, 6.0, 4.0, 6.0, 4.0, 4.0, 2.0, 3.0, 1.0, 3.0, 3.0, 3.0, 3.0, 5.0, 4.0, 2.0, 2.0, 2.0, 2.0, 4.0, 2.0, 2.0, 4.0, 1.0, 5.0, 5.0, 5.0, 4.0, 1.0, 2.0, 2.0, 1.0, 3.0, 7.0, 5.0, 6.0, 4.0, 4.0, 2.0, 2.0, 2.0, 0.0, 1.0, 1.0, 1.0, 3.0, 3.0, 2.0, 2.0, 3.0, 1.0, 1.0, 1.0, 2.0, 2.0, 2.0, 5.0, 1.0, 2.0, 2.0, 3.0, 5.0, 5.0, 6.0, 5.0, 0.0, 1.0, 1.0, 1.0, 4.0, 2.0, 4.0, 4.0, 4.0, 5.0, 4.0, 6.0, 5.0, 5.0, 5.0, 2.0, 3.0, 2.0, 2.0, 3.0, 1.0, 2.0, 3.0, 4.0, 3.0, 3.0, 3.0, 4.0, 5.0, 8.0, 7.0, 8.0, 5.0, 7.0, 5.0, 5.0, 9.0, 7.0, 8.0, 6.0, 2.0, 3.0, 3.0, 3.0, 3.0, 3.0, 5.0, 2.0, 4.0, 3.0, 2.0, 3.0, 4.0, 6.0, 5.0, 7.0, 5.0, 3.0, 2.0, 4.0, 5.0, 7.0, 8.0, 9.0, 3.0, 3.0, 3.0, 4.0, 5.0, 8.0, 5.0, 5.0, 5.0, 6.0, 2.0, 4.0, 3.0, 1.0, 1.0, 1.0, 2.0, 0.0, 2.0, 1.0, 2.0, 1.0, 2.0, 1.0, 8.0, 3.0, 4.0, 6.0, 6.0, 3.0, 6.0, 4.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.13397803174356684, "mean_inference_ms": 0.39106356000368264, "mean_action_processing_ms": 0.0291836414174121, "mean_env_wait_ms": 0.4032826035218956, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 1758960, "timesteps_this_iter": 0, "agent_timesteps_total": 7035840, "timers": {"sample_time_ms": 5111.946, "sample_throughput": 985.926, "load_time_ms": 0.171, "load_throughput": 29478862.307, "learn_time_ms": 151.982, "learn_throughput": 33161.791, "update_time_ms": 2.398}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 676.0337524414062, "policy_entropy": 7501.641845703125, "policy_loss": 144.01937866210938, "vf_loss": 148.24690055847168}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 1758960, "num_agent_steps_sampled": 7035840, "num_steps_trained": 1758960, "num_agent_steps_trained": 7035840, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 3516, "training_iteration": 175, "trial_id": "71426_00000", "experiment_id": "84bca2f7b35f43248fca18d21abe2ebf", "date": "2024-06-12_03-15-56", "timestamp": 1718129756, "time_this_iter_s": 10.306690216064453, "time_total_s": 1802.2413802146912, "pid": 363902, "hostname": "DESKTOP-LQ219J4", "node_ip": "192.168.46.185", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 20, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 5000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 500, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Base_Model", "custom_model_config": {"env": "rware", "env_args": {"n_agents": 4, "column_height": 1, "max_inactivity_steps": null, "max_steps": 500, "fast_obs": true, "msg_bits": 0, "sensor_range": 1, "shelf_rows": 1, "shelf_columns": 3, "request_queue_size": 4, "reward_type": "RewardType.INDIVIDUAL", "map_name": "customized_map", "map_size": "tiny", "difficulty": "medium"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": true, "force_coop": false, "local_mode": true, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 4, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 100, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64}, "algorithm": "ia2c", "space_obs": "Dict(obs:Box([-100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100.], [100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.], (112,), float32))", "space_act": "Discrete(5)", "num_agents": 4, "episode_limit": 500, "policy_mapping_info": {"all_scenario": {"description": "rware all scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2", "agent_3"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "rware_customized_map", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 10, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.IA2CTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_il.<locals>.<lambda> at 0x7f38081d5f70>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "grad_clip": 40.0, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "microbatch_size": null}, "time_since_restore": 1802.2413802146912, "timesteps_since_restore": 0, "iterations_since_restore": 175, "perf": {"cpu_util_percent": 4.84, "ram_util_percent": 80.78666666666665}}
{"episode_reward_max": 30.0, "episode_reward_min": 3.0, "episode_reward_mean": 13.53, "episode_len_mean": 500.0, "episode_media": {}, "episodes_this_iter": 20, "policy_reward_min": {"shared_policy": 0.0}, "policy_reward_max": {"shared_policy": 10.0}, "policy_reward_mean": {"shared_policy": 3.3825}, "custom_metrics": {}, "hist_stats": {"episode_reward": [4.0, 25.0, 3.0, 17.0, 8.0, 11.0, 14.0, 3.0, 20.0, 6.0, 13.0, 11.0, 18.0, 11.0, 8.0, 13.0, 14.0, 16.0, 11.0, 10.0, 14.0, 8.0, 8.0, 6.0, 10.0, 12.0, 7.0, 8.0, 17.0, 11.0, 11.0, 13.0, 17.0, 17.0, 18.0, 19.0, 18.0, 8.0, 10.0, 15.0, 20.0, 10.0, 12.0, 13.0, 10.0, 12.0, 15.0, 8.0, 22.0, 10.0, 3.0, 10.0, 6.0, 11.0, 8.0, 21.0, 3.0, 14.0, 19.0, 17.0, 10.0, 10.0, 13.0, 28.0, 22.0, 30.0, 11.0, 13.0, 12.0, 22.0, 14.0, 29.0, 13.0, 23.0, 17.0, 6.0, 5.0, 6.0, 21.0, 19.0, 15.0, 28.0, 17.0, 23.0, 15.0, 12.0, 15.0, 16.0, 11.0, 12.0, 9.0, 12.0, 15.0, 13.0, 12.0, 17.0, 18.0, 14.0, 14.0, 14.0], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500], "policy_shared_policy_reward": [1.0, 1.0, 2.0, 0.0, 4.0, 8.0, 6.0, 7.0, 1.0, 1.0, 1.0, 0.0, 6.0, 6.0, 2.0, 3.0, 2.0, 3.0, 0.0, 3.0, 2.0, 4.0, 4.0, 1.0, 2.0, 6.0, 3.0, 3.0, 1.0, 1.0, 0.0, 1.0, 3.0, 8.0, 4.0, 5.0, 2.0, 2.0, 1.0, 1.0, 4.0, 3.0, 2.0, 4.0, 2.0, 2.0, 4.0, 3.0, 5.0, 4.0, 5.0, 4.0, 2.0, 3.0, 3.0, 3.0, 1.0, 3.0, 2.0, 2.0, 3.0, 4.0, 2.0, 4.0, 4.0, 1.0, 6.0, 3.0, 4.0, 3.0, 3.0, 6.0, 3.0, 2.0, 2.0, 4.0, 1.0, 4.0, 1.0, 4.0, 3.0, 7.0, 2.0, 2.0, 2.0, 1.0, 3.0, 2.0, 2.0, 3.0, 1.0, 2.0, 2.0, 1.0, 2.0, 1.0, 4.0, 2.0, 3.0, 1.0, 4.0, 2.0, 3.0, 3.0, 0.0, 2.0, 4.0, 1.0, 3.0, 2.0, 2.0, 1.0, 4.0, 3.0, 4.0, 6.0, 2.0, 5.0, 1.0, 3.0, 2.0, 5.0, 2.0, 2.0, 3.0, 4.0, 1.0, 5.0, 4.0, 2.0, 6.0, 5.0, 5.0, 5.0, 2.0, 5.0, 4.0, 6.0, 3.0, 5.0, 4.0, 4.0, 4.0, 7.0, 4.0, 5.0, 5.0, 4.0, 1.0, 1.0, 3.0, 3.0, 3.0, 2.0, 2.0, 3.0, 5.0, 2.0, 5.0, 3.0, 6.0, 4.0, 6.0, 4.0, 4.0, 2.0, 3.0, 1.0, 3.0, 3.0, 3.0, 3.0, 5.0, 4.0, 2.0, 2.0, 2.0, 2.0, 4.0, 2.0, 2.0, 4.0, 1.0, 5.0, 5.0, 5.0, 4.0, 1.0, 2.0, 2.0, 1.0, 3.0, 7.0, 5.0, 6.0, 4.0, 4.0, 2.0, 2.0, 2.0, 0.0, 1.0, 1.0, 1.0, 3.0, 3.0, 2.0, 2.0, 3.0, 1.0, 1.0, 1.0, 2.0, 2.0, 2.0, 5.0, 1.0, 2.0, 2.0, 3.0, 5.0, 5.0, 6.0, 5.0, 0.0, 1.0, 1.0, 1.0, 4.0, 2.0, 4.0, 4.0, 4.0, 5.0, 4.0, 6.0, 5.0, 5.0, 5.0, 2.0, 3.0, 2.0, 2.0, 3.0, 1.0, 2.0, 3.0, 4.0, 3.0, 3.0, 3.0, 4.0, 5.0, 8.0, 7.0, 8.0, 5.0, 7.0, 5.0, 5.0, 9.0, 7.0, 8.0, 6.0, 2.0, 3.0, 3.0, 3.0, 3.0, 3.0, 5.0, 2.0, 4.0, 3.0, 2.0, 3.0, 4.0, 6.0, 5.0, 7.0, 5.0, 3.0, 2.0, 4.0, 5.0, 7.0, 8.0, 9.0, 3.0, 3.0, 3.0, 4.0, 5.0, 8.0, 5.0, 5.0, 5.0, 6.0, 2.0, 4.0, 3.0, 1.0, 1.0, 1.0, 2.0, 0.0, 2.0, 1.0, 2.0, 1.0, 2.0, 1.0, 8.0, 3.0, 4.0, 6.0, 6.0, 3.0, 6.0, 4.0, 3.0, 5.0, 3.0, 4.0, 10.0, 4.0, 8.0, 6.0, 4.0, 4.0, 5.0, 4.0, 6.0, 6.0, 5.0, 6.0, 3.0, 5.0, 5.0, 2.0, 4.0, 2.0, 3.0, 3.0, 5.0, 2.0, 3.0, 5.0, 3.0, 4.0, 4.0, 5.0, 2.0, 2.0, 3.0, 4.0, 4.0, 2.0, 4.0, 2.0, 2.0, 1.0, 4.0, 2.0, 4.0, 4.0, 1.0, 3.0, 5.0, 4.0, 4.0, 2.0, 3.0, 3.0, 4.0, 3.0, 3.0, 5.0, 2.0, 2.0, 5.0, 3.0, 3.0, 6.0, 4.0, 4.0, 4.0, 6.0, 3.0, 5.0, 4.0, 2.0, 1.0, 4.0, 4.0, 5.0, 4.0, 3.0, 2.0, 5.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.13397193016823838, "mean_inference_ms": 0.3910543207184039, "mean_action_processing_ms": 0.029182296650223566, "mean_env_wait_ms": 0.403241948044475, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 1769040, "timesteps_this_iter": 0, "agent_timesteps_total": 7076160, "timers": {"sample_time_ms": 5114.599, "sample_throughput": 985.414, "load_time_ms": 0.18, "load_throughput": 27965725.837, "learn_time_ms": 165.624, "learn_throughput": 30430.364, "update_time_ms": 2.377}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 307.99737548828125, "policy_entropy": 7454.115478515625, "policy_loss": 8.639311790466309, "vf_loss": 103.52412605285645}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 1769040, "num_agent_steps_sampled": 7076160, "num_steps_trained": 1769040, "num_agent_steps_trained": 7076160, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 3536, "training_iteration": 176, "trial_id": "71426_00000", "experiment_id": "84bca2f7b35f43248fca18d21abe2ebf", "date": "2024-06-12_03-16-06", "timestamp": 1718129766, "time_this_iter_s": 10.38106918334961, "time_total_s": 1812.6224493980408, "pid": 363902, "hostname": "DESKTOP-LQ219J4", "node_ip": "192.168.46.185", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 20, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 5000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 500, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Base_Model", "custom_model_config": {"env": "rware", "env_args": {"n_agents": 4, "column_height": 1, "max_inactivity_steps": null, "max_steps": 500, "fast_obs": true, "msg_bits": 0, "sensor_range": 1, "shelf_rows": 1, "shelf_columns": 3, "request_queue_size": 4, "reward_type": "RewardType.INDIVIDUAL", "map_name": "customized_map", "map_size": "tiny", "difficulty": "medium"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": true, "force_coop": false, "local_mode": true, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 4, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 100, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64}, "algorithm": "ia2c", "space_obs": "Dict(obs:Box([-100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100.], [100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.], (112,), float32))", "space_act": "Discrete(5)", "num_agents": 4, "episode_limit": 500, "policy_mapping_info": {"all_scenario": {"description": "rware all scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2", "agent_3"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "rware_customized_map", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 10, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.IA2CTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_il.<locals>.<lambda> at 0x7f38081d5d30>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "grad_clip": 40.0, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "microbatch_size": null}, "time_since_restore": 1812.6224493980408, "timesteps_since_restore": 0, "iterations_since_restore": 176, "perf": {"cpu_util_percent": 4.173333333333333, "ram_util_percent": 81.08666666666666}}
{"episode_reward_max": 30.0, "episode_reward_min": 3.0, "episode_reward_mean": 13.88, "episode_len_mean": 500.0, "episode_media": {}, "episodes_this_iter": 20, "policy_reward_min": {"shared_policy": 0.0}, "policy_reward_max": {"shared_policy": 10.0}, "policy_reward_mean": {"shared_policy": 3.47}, "custom_metrics": {}, "hist_stats": {"episode_reward": [14.0, 8.0, 8.0, 6.0, 10.0, 12.0, 7.0, 8.0, 17.0, 11.0, 11.0, 13.0, 17.0, 17.0, 18.0, 19.0, 18.0, 8.0, 10.0, 15.0, 20.0, 10.0, 12.0, 13.0, 10.0, 12.0, 15.0, 8.0, 22.0, 10.0, 3.0, 10.0, 6.0, 11.0, 8.0, 21.0, 3.0, 14.0, 19.0, 17.0, 10.0, 10.0, 13.0, 28.0, 22.0, 30.0, 11.0, 13.0, 12.0, 22.0, 14.0, 29.0, 13.0, 23.0, 17.0, 6.0, 5.0, 6.0, 21.0, 19.0, 15.0, 28.0, 17.0, 23.0, 15.0, 12.0, 15.0, 16.0, 11.0, 12.0, 9.0, 12.0, 15.0, 13.0, 12.0, 17.0, 18.0, 14.0, 14.0, 14.0, 25.0, 9.0, 11.0, 13.0, 15.0, 7.0, 27.0, 16.0, 20.0, 13.0, 7.0, 12.0, 10.0, 10.0, 17.0, 18.0, 13.0, 4.0, 14.0, 10.0], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500], "policy_shared_policy_reward": [3.0, 7.0, 2.0, 2.0, 2.0, 1.0, 3.0, 2.0, 2.0, 3.0, 1.0, 2.0, 2.0, 1.0, 2.0, 1.0, 4.0, 2.0, 3.0, 1.0, 4.0, 2.0, 3.0, 3.0, 0.0, 2.0, 4.0, 1.0, 3.0, 2.0, 2.0, 1.0, 4.0, 3.0, 4.0, 6.0, 2.0, 5.0, 1.0, 3.0, 2.0, 5.0, 2.0, 2.0, 3.0, 4.0, 1.0, 5.0, 4.0, 2.0, 6.0, 5.0, 5.0, 5.0, 2.0, 5.0, 4.0, 6.0, 3.0, 5.0, 4.0, 4.0, 4.0, 7.0, 4.0, 5.0, 5.0, 4.0, 1.0, 1.0, 3.0, 3.0, 3.0, 2.0, 2.0, 3.0, 5.0, 2.0, 5.0, 3.0, 6.0, 4.0, 6.0, 4.0, 4.0, 2.0, 3.0, 1.0, 3.0, 3.0, 3.0, 3.0, 5.0, 4.0, 2.0, 2.0, 2.0, 2.0, 4.0, 2.0, 2.0, 4.0, 1.0, 5.0, 5.0, 5.0, 4.0, 1.0, 2.0, 2.0, 1.0, 3.0, 7.0, 5.0, 6.0, 4.0, 4.0, 2.0, 2.0, 2.0, 0.0, 1.0, 1.0, 1.0, 3.0, 3.0, 2.0, 2.0, 3.0, 1.0, 1.0, 1.0, 2.0, 2.0, 2.0, 5.0, 1.0, 2.0, 2.0, 3.0, 5.0, 5.0, 6.0, 5.0, 0.0, 1.0, 1.0, 1.0, 4.0, 2.0, 4.0, 4.0, 4.0, 5.0, 4.0, 6.0, 5.0, 5.0, 5.0, 2.0, 3.0, 2.0, 2.0, 3.0, 1.0, 2.0, 3.0, 4.0, 3.0, 3.0, 3.0, 4.0, 5.0, 8.0, 7.0, 8.0, 5.0, 7.0, 5.0, 5.0, 9.0, 7.0, 8.0, 6.0, 2.0, 3.0, 3.0, 3.0, 3.0, 3.0, 5.0, 2.0, 4.0, 3.0, 2.0, 3.0, 4.0, 6.0, 5.0, 7.0, 5.0, 3.0, 2.0, 4.0, 5.0, 7.0, 8.0, 9.0, 3.0, 3.0, 3.0, 4.0, 5.0, 8.0, 5.0, 5.0, 5.0, 6.0, 2.0, 4.0, 3.0, 1.0, 1.0, 1.0, 2.0, 0.0, 2.0, 1.0, 2.0, 1.0, 2.0, 1.0, 8.0, 3.0, 4.0, 6.0, 6.0, 3.0, 6.0, 4.0, 3.0, 5.0, 3.0, 4.0, 10.0, 4.0, 8.0, 6.0, 4.0, 4.0, 5.0, 4.0, 6.0, 6.0, 5.0, 6.0, 3.0, 5.0, 5.0, 2.0, 4.0, 2.0, 3.0, 3.0, 5.0, 2.0, 3.0, 5.0, 3.0, 4.0, 4.0, 5.0, 2.0, 2.0, 3.0, 4.0, 4.0, 2.0, 4.0, 2.0, 2.0, 1.0, 4.0, 2.0, 4.0, 4.0, 1.0, 3.0, 5.0, 4.0, 4.0, 2.0, 3.0, 3.0, 4.0, 3.0, 3.0, 5.0, 2.0, 2.0, 5.0, 3.0, 3.0, 6.0, 4.0, 4.0, 4.0, 6.0, 3.0, 5.0, 4.0, 2.0, 1.0, 4.0, 4.0, 5.0, 4.0, 3.0, 2.0, 5.0, 6.0, 7.0, 5.0, 7.0, 0.0, 3.0, 2.0, 4.0, 3.0, 2.0, 3.0, 3.0, 2.0, 5.0, 2.0, 4.0, 2.0, 4.0, 3.0, 6.0, 2.0, 2.0, 2.0, 1.0, 7.0, 5.0, 8.0, 7.0, 5.0, 4.0, 2.0, 5.0, 4.0, 4.0, 6.0, 6.0, 2.0, 4.0, 2.0, 5.0, 2.0, 2.0, 1.0, 2.0, 2.0, 4.0, 3.0, 3.0, 1.0, 4.0, 2.0, 3.0, 2.0, 3.0, 2.0, 3.0, 6.0, 6.0, 2.0, 3.0, 6.0, 4.0, 3.0, 5.0, 4.0, 4.0, 2.0, 3.0, 1.0, 1.0, 2.0, 0.0, 5.0, 3.0, 4.0, 2.0, 2.0, 2.0, 4.0, 2.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.13396644450481002, "mean_inference_ms": 0.3910464449866477, "mean_action_processing_ms": 0.029181210891752227, "mean_env_wait_ms": 0.4032012423360869, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 1779120, "timesteps_this_iter": 0, "agent_timesteps_total": 7116480, "timers": {"sample_time_ms": 5132.244, "sample_throughput": 982.027, "load_time_ms": 0.182, "load_throughput": 27723661.849, "learn_time_ms": 177.87, "learn_throughput": 28335.352, "update_time_ms": 2.419}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 758.0338134765625, "policy_entropy": 7504.244384765625, "policy_loss": -11.806352615356445, "vf_loss": 105.75557327270508}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 1779120, "num_agent_steps_sampled": 7116480, "num_steps_trained": 1779120, "num_agent_steps_trained": 7116480, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 3556, "training_iteration": 177, "trial_id": "71426_00000", "experiment_id": "84bca2f7b35f43248fca18d21abe2ebf", "date": "2024-06-12_03-16-16", "timestamp": 1718129776, "time_this_iter_s": 10.337007999420166, "time_total_s": 1822.959457397461, "pid": 363902, "hostname": "DESKTOP-LQ219J4", "node_ip": "192.168.46.185", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 20, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 5000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 500, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Base_Model", "custom_model_config": {"env": "rware", "env_args": {"n_agents": 4, "column_height": 1, "max_inactivity_steps": null, "max_steps": 500, "fast_obs": true, "msg_bits": 0, "sensor_range": 1, "shelf_rows": 1, "shelf_columns": 3, "request_queue_size": 4, "reward_type": "RewardType.INDIVIDUAL", "map_name": "customized_map", "map_size": "tiny", "difficulty": "medium"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": true, "force_coop": false, "local_mode": true, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 4, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 100, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64}, "algorithm": "ia2c", "space_obs": "Dict(obs:Box([-100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100.], [100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.], (112,), float32))", "space_act": "Discrete(5)", "num_agents": 4, "episode_limit": 500, "policy_mapping_info": {"all_scenario": {"description": "rware all scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2", "agent_3"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "rware_customized_map", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 10, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.IA2CTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_il.<locals>.<lambda> at 0x7f38082f8b80>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "grad_clip": 40.0, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "microbatch_size": null}, "time_since_restore": 1822.959457397461, "timesteps_since_restore": 0, "iterations_since_restore": 177, "perf": {"cpu_util_percent": 4.1571428571428575, "ram_util_percent": 81.35000000000001}}
{"episode_reward_max": 30.0, "episode_reward_min": 3.0, "episode_reward_mean": 14.09, "episode_len_mean": 500.0, "episode_media": {}, "episodes_this_iter": 20, "policy_reward_min": {"shared_policy": 0.0}, "policy_reward_max": {"shared_policy": 10.0}, "policy_reward_mean": {"shared_policy": 3.5225}, "custom_metrics": {}, "hist_stats": {"episode_reward": [20.0, 10.0, 12.0, 13.0, 10.0, 12.0, 15.0, 8.0, 22.0, 10.0, 3.0, 10.0, 6.0, 11.0, 8.0, 21.0, 3.0, 14.0, 19.0, 17.0, 10.0, 10.0, 13.0, 28.0, 22.0, 30.0, 11.0, 13.0, 12.0, 22.0, 14.0, 29.0, 13.0, 23.0, 17.0, 6.0, 5.0, 6.0, 21.0, 19.0, 15.0, 28.0, 17.0, 23.0, 15.0, 12.0, 15.0, 16.0, 11.0, 12.0, 9.0, 12.0, 15.0, 13.0, 12.0, 17.0, 18.0, 14.0, 14.0, 14.0, 25.0, 9.0, 11.0, 13.0, 15.0, 7.0, 27.0, 16.0, 20.0, 13.0, 7.0, 12.0, 10.0, 10.0, 17.0, 18.0, 13.0, 4.0, 14.0, 10.0, 9.0, 4.0, 20.0, 22.0, 12.0, 19.0, 5.0, 6.0, 10.0, 8.0, 10.0, 11.0, 12.0, 22.0, 27.0, 22.0, 3.0, 16.0, 14.0, 16.0], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500], "policy_shared_policy_reward": [6.0, 4.0, 6.0, 4.0, 4.0, 2.0, 3.0, 1.0, 3.0, 3.0, 3.0, 3.0, 5.0, 4.0, 2.0, 2.0, 2.0, 2.0, 4.0, 2.0, 2.0, 4.0, 1.0, 5.0, 5.0, 5.0, 4.0, 1.0, 2.0, 2.0, 1.0, 3.0, 7.0, 5.0, 6.0, 4.0, 4.0, 2.0, 2.0, 2.0, 0.0, 1.0, 1.0, 1.0, 3.0, 3.0, 2.0, 2.0, 3.0, 1.0, 1.0, 1.0, 2.0, 2.0, 2.0, 5.0, 1.0, 2.0, 2.0, 3.0, 5.0, 5.0, 6.0, 5.0, 0.0, 1.0, 1.0, 1.0, 4.0, 2.0, 4.0, 4.0, 4.0, 5.0, 4.0, 6.0, 5.0, 5.0, 5.0, 2.0, 3.0, 2.0, 2.0, 3.0, 1.0, 2.0, 3.0, 4.0, 3.0, 3.0, 3.0, 4.0, 5.0, 8.0, 7.0, 8.0, 5.0, 7.0, 5.0, 5.0, 9.0, 7.0, 8.0, 6.0, 2.0, 3.0, 3.0, 3.0, 3.0, 3.0, 5.0, 2.0, 4.0, 3.0, 2.0, 3.0, 4.0, 6.0, 5.0, 7.0, 5.0, 3.0, 2.0, 4.0, 5.0, 7.0, 8.0, 9.0, 3.0, 3.0, 3.0, 4.0, 5.0, 8.0, 5.0, 5.0, 5.0, 6.0, 2.0, 4.0, 3.0, 1.0, 1.0, 1.0, 2.0, 0.0, 2.0, 1.0, 2.0, 1.0, 2.0, 1.0, 8.0, 3.0, 4.0, 6.0, 6.0, 3.0, 6.0, 4.0, 3.0, 5.0, 3.0, 4.0, 10.0, 4.0, 8.0, 6.0, 4.0, 4.0, 5.0, 4.0, 6.0, 6.0, 5.0, 6.0, 3.0, 5.0, 5.0, 2.0, 4.0, 2.0, 3.0, 3.0, 5.0, 2.0, 3.0, 5.0, 3.0, 4.0, 4.0, 5.0, 2.0, 2.0, 3.0, 4.0, 4.0, 2.0, 4.0, 2.0, 2.0, 1.0, 4.0, 2.0, 4.0, 4.0, 1.0, 3.0, 5.0, 4.0, 4.0, 2.0, 3.0, 3.0, 4.0, 3.0, 3.0, 5.0, 2.0, 2.0, 5.0, 3.0, 3.0, 6.0, 4.0, 4.0, 4.0, 6.0, 3.0, 5.0, 4.0, 2.0, 1.0, 4.0, 4.0, 5.0, 4.0, 3.0, 2.0, 5.0, 6.0, 7.0, 5.0, 7.0, 0.0, 3.0, 2.0, 4.0, 3.0, 2.0, 3.0, 3.0, 2.0, 5.0, 2.0, 4.0, 2.0, 4.0, 3.0, 6.0, 2.0, 2.0, 2.0, 1.0, 7.0, 5.0, 8.0, 7.0, 5.0, 4.0, 2.0, 5.0, 4.0, 4.0, 6.0, 6.0, 2.0, 4.0, 2.0, 5.0, 2.0, 2.0, 1.0, 2.0, 2.0, 4.0, 3.0, 3.0, 1.0, 4.0, 2.0, 3.0, 2.0, 3.0, 2.0, 3.0, 6.0, 6.0, 2.0, 3.0, 6.0, 4.0, 3.0, 5.0, 4.0, 4.0, 2.0, 3.0, 1.0, 1.0, 2.0, 0.0, 5.0, 3.0, 4.0, 2.0, 2.0, 2.0, 4.0, 2.0, 2.0, 3.0, 4.0, 0.0, 1.0, 1.0, 1.0, 1.0, 4.0, 5.0, 6.0, 5.0, 5.0, 4.0, 7.0, 6.0, 2.0, 4.0, 2.0, 4.0, 4.0, 5.0, 6.0, 4.0, 1.0, 2.0, 1.0, 1.0, 2.0, 1.0, 2.0, 1.0, 4.0, 1.0, 2.0, 3.0, 1.0, 1.0, 2.0, 4.0, 2.0, 3.0, 3.0, 2.0, 4.0, 3.0, 2.0, 2.0, 2.0, 2.0, 4.0, 4.0, 6.0, 4.0, 5.0, 7.0, 6.0, 7.0, 9.0, 5.0, 4.0, 9.0, 3.0, 6.0, 0.0, 2.0, 1.0, 0.0, 4.0, 5.0, 4.0, 3.0, 2.0, 3.0, 5.0, 4.0, 3.0, 4.0, 4.0, 5.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.13396383307470708, "mean_inference_ms": 0.3910436317303903, "mean_action_processing_ms": 0.029180432118803532, "mean_env_wait_ms": 0.40316503095295997, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 1789200, "timesteps_this_iter": 0, "agent_timesteps_total": 7156800, "timers": {"sample_time_ms": 5156.107, "sample_throughput": 977.482, "load_time_ms": 0.182, "load_throughput": 27633061.647, "learn_time_ms": 177.28, "learn_throughput": 28429.535, "update_time_ms": 2.435}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 261.0422058105469, "policy_entropy": 7551.1617431640625, "policy_loss": 106.711745262146, "vf_loss": 133.7329330444336}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 1789200, "num_agent_steps_sampled": 7156800, "num_steps_trained": 1789200, "num_agent_steps_trained": 7156800, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 3576, "training_iteration": 178, "trial_id": "71426_00000", "experiment_id": "84bca2f7b35f43248fca18d21abe2ebf", "date": "2024-06-12_03-16-27", "timestamp": 1718129787, "time_this_iter_s": 10.243953943252563, "time_total_s": 1833.2034113407135, "pid": 363902, "hostname": "DESKTOP-LQ219J4", "node_ip": "192.168.46.185", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 20, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 5000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 500, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Base_Model", "custom_model_config": {"env": "rware", "env_args": {"n_agents": 4, "column_height": 1, "max_inactivity_steps": null, "max_steps": 500, "fast_obs": true, "msg_bits": 0, "sensor_range": 1, "shelf_rows": 1, "shelf_columns": 3, "request_queue_size": 4, "reward_type": "RewardType.INDIVIDUAL", "map_name": "customized_map", "map_size": "tiny", "difficulty": "medium"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": true, "force_coop": false, "local_mode": true, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 4, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 100, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64}, "algorithm": "ia2c", "space_obs": "Dict(obs:Box([-100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100.], [100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.], (112,), float32))", "space_act": "Discrete(5)", "num_agents": 4, "episode_limit": 500, "policy_mapping_info": {"all_scenario": {"description": "rware all scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2", "agent_3"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "rware_customized_map", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 10, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.IA2CTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_il.<locals>.<lambda> at 0x7f38086c11f0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "grad_clip": 40.0, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "microbatch_size": null}, "time_since_restore": 1833.2034113407135, "timesteps_since_restore": 0, "iterations_since_restore": 178, "perf": {"cpu_util_percent": 4.2, "ram_util_percent": 81.65333333333335}}
{"episode_reward_max": 30.0, "episode_reward_min": 3.0, "episode_reward_mean": 14.52, "episode_len_mean": 500.0, "episode_media": {}, "episodes_this_iter": 20, "policy_reward_min": {"shared_policy": 0.0}, "policy_reward_max": {"shared_policy": 10.0}, "policy_reward_mean": {"shared_policy": 3.63}, "custom_metrics": {}, "hist_stats": {"episode_reward": [10.0, 10.0, 13.0, 28.0, 22.0, 30.0, 11.0, 13.0, 12.0, 22.0, 14.0, 29.0, 13.0, 23.0, 17.0, 6.0, 5.0, 6.0, 21.0, 19.0, 15.0, 28.0, 17.0, 23.0, 15.0, 12.0, 15.0, 16.0, 11.0, 12.0, 9.0, 12.0, 15.0, 13.0, 12.0, 17.0, 18.0, 14.0, 14.0, 14.0, 25.0, 9.0, 11.0, 13.0, 15.0, 7.0, 27.0, 16.0, 20.0, 13.0, 7.0, 12.0, 10.0, 10.0, 17.0, 18.0, 13.0, 4.0, 14.0, 10.0, 9.0, 4.0, 20.0, 22.0, 12.0, 19.0, 5.0, 6.0, 10.0, 8.0, 10.0, 11.0, 12.0, 22.0, 27.0, 22.0, 3.0, 16.0, 14.0, 16.0, 28.0, 14.0, 11.0, 10.0, 12.0, 6.0, 16.0, 12.0, 19.0, 22.0, 15.0, 8.0, 23.0, 14.0, 9.0, 16.0, 4.0, 11.0, 19.0, 18.0], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500], "policy_shared_policy_reward": [3.0, 2.0, 2.0, 3.0, 1.0, 2.0, 3.0, 4.0, 3.0, 3.0, 3.0, 4.0, 5.0, 8.0, 7.0, 8.0, 5.0, 7.0, 5.0, 5.0, 9.0, 7.0, 8.0, 6.0, 2.0, 3.0, 3.0, 3.0, 3.0, 3.0, 5.0, 2.0, 4.0, 3.0, 2.0, 3.0, 4.0, 6.0, 5.0, 7.0, 5.0, 3.0, 2.0, 4.0, 5.0, 7.0, 8.0, 9.0, 3.0, 3.0, 3.0, 4.0, 5.0, 8.0, 5.0, 5.0, 5.0, 6.0, 2.0, 4.0, 3.0, 1.0, 1.0, 1.0, 2.0, 0.0, 2.0, 1.0, 2.0, 1.0, 2.0, 1.0, 8.0, 3.0, 4.0, 6.0, 6.0, 3.0, 6.0, 4.0, 3.0, 5.0, 3.0, 4.0, 10.0, 4.0, 8.0, 6.0, 4.0, 4.0, 5.0, 4.0, 6.0, 6.0, 5.0, 6.0, 3.0, 5.0, 5.0, 2.0, 4.0, 2.0, 3.0, 3.0, 5.0, 2.0, 3.0, 5.0, 3.0, 4.0, 4.0, 5.0, 2.0, 2.0, 3.0, 4.0, 4.0, 2.0, 4.0, 2.0, 2.0, 1.0, 4.0, 2.0, 4.0, 4.0, 1.0, 3.0, 5.0, 4.0, 4.0, 2.0, 3.0, 3.0, 4.0, 3.0, 3.0, 5.0, 2.0, 2.0, 5.0, 3.0, 3.0, 6.0, 4.0, 4.0, 4.0, 6.0, 3.0, 5.0, 4.0, 2.0, 1.0, 4.0, 4.0, 5.0, 4.0, 3.0, 2.0, 5.0, 6.0, 7.0, 5.0, 7.0, 0.0, 3.0, 2.0, 4.0, 3.0, 2.0, 3.0, 3.0, 2.0, 5.0, 2.0, 4.0, 2.0, 4.0, 3.0, 6.0, 2.0, 2.0, 2.0, 1.0, 7.0, 5.0, 8.0, 7.0, 5.0, 4.0, 2.0, 5.0, 4.0, 4.0, 6.0, 6.0, 2.0, 4.0, 2.0, 5.0, 2.0, 2.0, 1.0, 2.0, 2.0, 4.0, 3.0, 3.0, 1.0, 4.0, 2.0, 3.0, 2.0, 3.0, 2.0, 3.0, 6.0, 6.0, 2.0, 3.0, 6.0, 4.0, 3.0, 5.0, 4.0, 4.0, 2.0, 3.0, 1.0, 1.0, 2.0, 0.0, 5.0, 3.0, 4.0, 2.0, 2.0, 2.0, 4.0, 2.0, 2.0, 3.0, 4.0, 0.0, 1.0, 1.0, 1.0, 1.0, 4.0, 5.0, 6.0, 5.0, 5.0, 4.0, 7.0, 6.0, 2.0, 4.0, 2.0, 4.0, 4.0, 5.0, 6.0, 4.0, 1.0, 2.0, 1.0, 1.0, 2.0, 1.0, 2.0, 1.0, 4.0, 1.0, 2.0, 3.0, 1.0, 1.0, 2.0, 4.0, 2.0, 3.0, 3.0, 2.0, 4.0, 3.0, 2.0, 2.0, 2.0, 2.0, 4.0, 4.0, 6.0, 4.0, 5.0, 7.0, 6.0, 7.0, 9.0, 5.0, 4.0, 9.0, 3.0, 6.0, 0.0, 2.0, 1.0, 0.0, 4.0, 5.0, 4.0, 3.0, 2.0, 3.0, 5.0, 4.0, 3.0, 4.0, 4.0, 5.0, 6.0, 9.0, 5.0, 8.0, 5.0, 1.0, 4.0, 4.0, 3.0, 2.0, 4.0, 2.0, 2.0, 2.0, 1.0, 5.0, 3.0, 2.0, 4.0, 3.0, 2.0, 2.0, 1.0, 1.0, 4.0, 6.0, 4.0, 2.0, 1.0, 5.0, 4.0, 2.0, 6.0, 5.0, 3.0, 5.0, 5.0, 5.0, 7.0, 5.0, 3.0, 4.0, 3.0, 5.0, 4.0, 2.0, 1.0, 1.0, 6.0, 6.0, 7.0, 4.0, 2.0, 4.0, 4.0, 4.0, 1.0, 2.0, 4.0, 2.0, 3.0, 4.0, 4.0, 5.0, 1.0, 2.0, 0.0, 1.0, 2.0, 3.0, 4.0, 2.0, 5.0, 3.0, 6.0, 5.0, 7.0, 3.0, 4.0, 4.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.13396144407525948, "mean_inference_ms": 0.391041565737882, "mean_action_processing_ms": 0.0291796464524851, "mean_env_wait_ms": 0.40313052256884974, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 1799280, "timesteps_this_iter": 0, "agent_timesteps_total": 7197120, "timers": {"sample_time_ms": 5159.461, "sample_throughput": 976.846, "load_time_ms": 0.184, "load_throughput": 27428691.008, "learn_time_ms": 171.446, "learn_throughput": 29397.005, "update_time_ms": 2.461}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 432.0005798339844, "policy_entropy": 7591.011962890625, "policy_loss": 98.77814865112305, "vf_loss": 134.3521957397461}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 1799280, "num_agent_steps_sampled": 7197120, "num_steps_trained": 1799280, "num_agent_steps_trained": 7197120, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 3596, "training_iteration": 179, "trial_id": "71426_00000", "experiment_id": "84bca2f7b35f43248fca18d21abe2ebf", "date": "2024-06-12_03-16-37", "timestamp": 1718129797, "time_this_iter_s": 10.184859037399292, "time_total_s": 1843.3882703781128, "pid": 363902, "hostname": "DESKTOP-LQ219J4", "node_ip": "192.168.46.185", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 20, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 5000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 500, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Base_Model", "custom_model_config": {"env": "rware", "env_args": {"n_agents": 4, "column_height": 1, "max_inactivity_steps": null, "max_steps": 500, "fast_obs": true, "msg_bits": 0, "sensor_range": 1, "shelf_rows": 1, "shelf_columns": 3, "request_queue_size": 4, "reward_type": "RewardType.INDIVIDUAL", "map_name": "customized_map", "map_size": "tiny", "difficulty": "medium"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": true, "force_coop": false, "local_mode": true, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 4, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 100, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64}, "algorithm": "ia2c", "space_obs": "Dict(obs:Box([-100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100.], [100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.], (112,), float32))", "space_act": "Discrete(5)", "num_agents": 4, "episode_limit": 500, "policy_mapping_info": {"all_scenario": {"description": "rware all scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2", "agent_3"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "rware_customized_map", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 10, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.IA2CTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_il.<locals>.<lambda> at 0x7f3808233ca0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "grad_clip": 40.0, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "microbatch_size": null}, "time_since_restore": 1843.3882703781128, "timesteps_since_restore": 0, "iterations_since_restore": 179, "perf": {"cpu_util_percent": 4.180000000000001, "ram_util_percent": 81.88666666666667}}
{"episode_reward_max": 28.0, "episode_reward_min": 2.0, "episode_reward_mean": 14.08, "episode_len_mean": 500.0, "episode_media": {}, "episodes_this_iter": 20, "policy_reward_min": {"shared_policy": 0.0}, "policy_reward_max": {"shared_policy": 10.0}, "policy_reward_mean": {"shared_policy": 3.52}, "custom_metrics": {}, "hist_stats": {"episode_reward": [15.0, 28.0, 17.0, 23.0, 15.0, 12.0, 15.0, 16.0, 11.0, 12.0, 9.0, 12.0, 15.0, 13.0, 12.0, 17.0, 18.0, 14.0, 14.0, 14.0, 25.0, 9.0, 11.0, 13.0, 15.0, 7.0, 27.0, 16.0, 20.0, 13.0, 7.0, 12.0, 10.0, 10.0, 17.0, 18.0, 13.0, 4.0, 14.0, 10.0, 9.0, 4.0, 20.0, 22.0, 12.0, 19.0, 5.0, 6.0, 10.0, 8.0, 10.0, 11.0, 12.0, 22.0, 27.0, 22.0, 3.0, 16.0, 14.0, 16.0, 28.0, 14.0, 11.0, 10.0, 12.0, 6.0, 16.0, 12.0, 19.0, 22.0, 15.0, 8.0, 23.0, 14.0, 9.0, 16.0, 4.0, 11.0, 19.0, 18.0, 9.0, 25.0, 11.0, 13.0, 13.0, 20.0, 14.0, 14.0, 20.0, 16.0, 16.0, 6.0, 21.0, 7.0, 16.0, 16.0, 11.0, 18.0, 2.0, 12.0], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500], "policy_shared_policy_reward": [3.0, 5.0, 3.0, 4.0, 10.0, 4.0, 8.0, 6.0, 4.0, 4.0, 5.0, 4.0, 6.0, 6.0, 5.0, 6.0, 3.0, 5.0, 5.0, 2.0, 4.0, 2.0, 3.0, 3.0, 5.0, 2.0, 3.0, 5.0, 3.0, 4.0, 4.0, 5.0, 2.0, 2.0, 3.0, 4.0, 4.0, 2.0, 4.0, 2.0, 2.0, 1.0, 4.0, 2.0, 4.0, 4.0, 1.0, 3.0, 5.0, 4.0, 4.0, 2.0, 3.0, 3.0, 4.0, 3.0, 3.0, 5.0, 2.0, 2.0, 5.0, 3.0, 3.0, 6.0, 4.0, 4.0, 4.0, 6.0, 3.0, 5.0, 4.0, 2.0, 1.0, 4.0, 4.0, 5.0, 4.0, 3.0, 2.0, 5.0, 6.0, 7.0, 5.0, 7.0, 0.0, 3.0, 2.0, 4.0, 3.0, 2.0, 3.0, 3.0, 2.0, 5.0, 2.0, 4.0, 2.0, 4.0, 3.0, 6.0, 2.0, 2.0, 2.0, 1.0, 7.0, 5.0, 8.0, 7.0, 5.0, 4.0, 2.0, 5.0, 4.0, 4.0, 6.0, 6.0, 2.0, 4.0, 2.0, 5.0, 2.0, 2.0, 1.0, 2.0, 2.0, 4.0, 3.0, 3.0, 1.0, 4.0, 2.0, 3.0, 2.0, 3.0, 2.0, 3.0, 6.0, 6.0, 2.0, 3.0, 6.0, 4.0, 3.0, 5.0, 4.0, 4.0, 2.0, 3.0, 1.0, 1.0, 2.0, 0.0, 5.0, 3.0, 4.0, 2.0, 2.0, 2.0, 4.0, 2.0, 2.0, 3.0, 4.0, 0.0, 1.0, 1.0, 1.0, 1.0, 4.0, 5.0, 6.0, 5.0, 5.0, 4.0, 7.0, 6.0, 2.0, 4.0, 2.0, 4.0, 4.0, 5.0, 6.0, 4.0, 1.0, 2.0, 1.0, 1.0, 2.0, 1.0, 2.0, 1.0, 4.0, 1.0, 2.0, 3.0, 1.0, 1.0, 2.0, 4.0, 2.0, 3.0, 3.0, 2.0, 4.0, 3.0, 2.0, 2.0, 2.0, 2.0, 4.0, 4.0, 6.0, 4.0, 5.0, 7.0, 6.0, 7.0, 9.0, 5.0, 4.0, 9.0, 3.0, 6.0, 0.0, 2.0, 1.0, 0.0, 4.0, 5.0, 4.0, 3.0, 2.0, 3.0, 5.0, 4.0, 3.0, 4.0, 4.0, 5.0, 6.0, 9.0, 5.0, 8.0, 5.0, 1.0, 4.0, 4.0, 3.0, 2.0, 4.0, 2.0, 2.0, 2.0, 1.0, 5.0, 3.0, 2.0, 4.0, 3.0, 2.0, 2.0, 1.0, 1.0, 4.0, 6.0, 4.0, 2.0, 1.0, 5.0, 4.0, 2.0, 6.0, 5.0, 3.0, 5.0, 5.0, 5.0, 7.0, 5.0, 3.0, 4.0, 3.0, 5.0, 4.0, 2.0, 1.0, 1.0, 6.0, 6.0, 7.0, 4.0, 2.0, 4.0, 4.0, 4.0, 1.0, 2.0, 4.0, 2.0, 3.0, 4.0, 4.0, 5.0, 1.0, 2.0, 0.0, 1.0, 2.0, 3.0, 4.0, 2.0, 5.0, 3.0, 6.0, 5.0, 7.0, 3.0, 4.0, 4.0, 3.0, 2.0, 1.0, 3.0, 6.0, 6.0, 7.0, 6.0, 3.0, 5.0, 1.0, 2.0, 3.0, 2.0, 5.0, 3.0, 6.0, 2.0, 2.0, 3.0, 3.0, 4.0, 6.0, 7.0, 4.0, 2.0, 4.0, 4.0, 4.0, 4.0, 2.0, 4.0, 5.0, 4.0, 5.0, 6.0, 4.0, 3.0, 5.0, 4.0, 4.0, 5.0, 3.0, 4.0, 1.0, 1.0, 1.0, 3.0, 4.0, 5.0, 5.0, 7.0, 1.0, 3.0, 2.0, 1.0, 4.0, 3.0, 5.0, 4.0, 4.0, 2.0, 4.0, 6.0, 3.0, 4.0, 2.0, 2.0, 4.0, 4.0, 5.0, 5.0, 0.0, 1.0, 1.0, 0.0, 1.0, 4.0, 3.0, 4.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.13395757142500386, "mean_inference_ms": 0.39102586219444047, "mean_action_processing_ms": 0.029178713744388015, "mean_env_wait_ms": 0.40309882448842915, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 1809360, "timesteps_this_iter": 0, "agent_timesteps_total": 7237440, "timers": {"sample_time_ms": 5141.767, "sample_throughput": 980.208, "load_time_ms": 0.181, "load_throughput": 27902972.756, "learn_time_ms": 173.886, "learn_throughput": 28984.425, "update_time_ms": 2.493}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 460.812255859375, "policy_entropy": 7513.9652099609375, "policy_loss": -6.74211311340332, "vf_loss": 117.21625232696533}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 1809360, "num_agent_steps_sampled": 7237440, "num_steps_trained": 1809360, "num_agent_steps_trained": 7237440, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 3616, "training_iteration": 180, "trial_id": "71426_00000", "experiment_id": "84bca2f7b35f43248fca18d21abe2ebf", "date": "2024-06-12_03-16-47", "timestamp": 1718129807, "time_this_iter_s": 10.207715272903442, "time_total_s": 1853.5959856510162, "pid": 363902, "hostname": "DESKTOP-LQ219J4", "node_ip": "192.168.46.185", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 20, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 5000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 500, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Base_Model", "custom_model_config": {"env": "rware", "env_args": {"n_agents": 4, "column_height": 1, "max_inactivity_steps": null, "max_steps": 500, "fast_obs": true, "msg_bits": 0, "sensor_range": 1, "shelf_rows": 1, "shelf_columns": 3, "request_queue_size": 4, "reward_type": "RewardType.INDIVIDUAL", "map_name": "customized_map", "map_size": "tiny", "difficulty": "medium"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": true, "force_coop": false, "local_mode": true, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 4, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 100, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64}, "algorithm": "ia2c", "space_obs": "Dict(obs:Box([-100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100.], [100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.], (112,), float32))", "space_act": "Discrete(5)", "num_agents": 4, "episode_limit": 500, "policy_mapping_info": {"all_scenario": {"description": "rware all scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2", "agent_3"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "rware_customized_map", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 10, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.IA2CTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_il.<locals>.<lambda> at 0x7f38280b2160>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "grad_clip": 40.0, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "microbatch_size": null}, "time_since_restore": 1853.5959856510162, "timesteps_since_restore": 0, "iterations_since_restore": 180, "perf": {"cpu_util_percent": 4.142857142857143, "ram_util_percent": 82.15}}
{"episode_reward_max": 28.0, "episode_reward_min": 2.0, "episode_reward_mean": 13.74, "episode_len_mean": 500.0, "episode_media": {}, "episodes_this_iter": 20, "policy_reward_min": {"shared_policy": 0.0}, "policy_reward_max": {"shared_policy": 9.0}, "policy_reward_mean": {"shared_policy": 3.435}, "custom_metrics": {}, "hist_stats": {"episode_reward": [25.0, 9.0, 11.0, 13.0, 15.0, 7.0, 27.0, 16.0, 20.0, 13.0, 7.0, 12.0, 10.0, 10.0, 17.0, 18.0, 13.0, 4.0, 14.0, 10.0, 9.0, 4.0, 20.0, 22.0, 12.0, 19.0, 5.0, 6.0, 10.0, 8.0, 10.0, 11.0, 12.0, 22.0, 27.0, 22.0, 3.0, 16.0, 14.0, 16.0, 28.0, 14.0, 11.0, 10.0, 12.0, 6.0, 16.0, 12.0, 19.0, 22.0, 15.0, 8.0, 23.0, 14.0, 9.0, 16.0, 4.0, 11.0, 19.0, 18.0, 9.0, 25.0, 11.0, 13.0, 13.0, 20.0, 14.0, 14.0, 20.0, 16.0, 16.0, 6.0, 21.0, 7.0, 16.0, 16.0, 11.0, 18.0, 2.0, 12.0, 21.0, 12.0, 6.0, 13.0, 16.0, 17.0, 17.0, 19.0, 19.0, 10.0, 2.0, 11.0, 5.0, 9.0, 9.0, 11.0, 19.0, 24.0, 9.0, 19.0], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500], "policy_shared_policy_reward": [6.0, 7.0, 5.0, 7.0, 0.0, 3.0, 2.0, 4.0, 3.0, 2.0, 3.0, 3.0, 2.0, 5.0, 2.0, 4.0, 2.0, 4.0, 3.0, 6.0, 2.0, 2.0, 2.0, 1.0, 7.0, 5.0, 8.0, 7.0, 5.0, 4.0, 2.0, 5.0, 4.0, 4.0, 6.0, 6.0, 2.0, 4.0, 2.0, 5.0, 2.0, 2.0, 1.0, 2.0, 2.0, 4.0, 3.0, 3.0, 1.0, 4.0, 2.0, 3.0, 2.0, 3.0, 2.0, 3.0, 6.0, 6.0, 2.0, 3.0, 6.0, 4.0, 3.0, 5.0, 4.0, 4.0, 2.0, 3.0, 1.0, 1.0, 2.0, 0.0, 5.0, 3.0, 4.0, 2.0, 2.0, 2.0, 4.0, 2.0, 2.0, 3.0, 4.0, 0.0, 1.0, 1.0, 1.0, 1.0, 4.0, 5.0, 6.0, 5.0, 5.0, 4.0, 7.0, 6.0, 2.0, 4.0, 2.0, 4.0, 4.0, 5.0, 6.0, 4.0, 1.0, 2.0, 1.0, 1.0, 2.0, 1.0, 2.0, 1.0, 4.0, 1.0, 2.0, 3.0, 1.0, 1.0, 2.0, 4.0, 2.0, 3.0, 3.0, 2.0, 4.0, 3.0, 2.0, 2.0, 2.0, 2.0, 4.0, 4.0, 6.0, 4.0, 5.0, 7.0, 6.0, 7.0, 9.0, 5.0, 4.0, 9.0, 3.0, 6.0, 0.0, 2.0, 1.0, 0.0, 4.0, 5.0, 4.0, 3.0, 2.0, 3.0, 5.0, 4.0, 3.0, 4.0, 4.0, 5.0, 6.0, 9.0, 5.0, 8.0, 5.0, 1.0, 4.0, 4.0, 3.0, 2.0, 4.0, 2.0, 2.0, 2.0, 1.0, 5.0, 3.0, 2.0, 4.0, 3.0, 2.0, 2.0, 1.0, 1.0, 4.0, 6.0, 4.0, 2.0, 1.0, 5.0, 4.0, 2.0, 6.0, 5.0, 3.0, 5.0, 5.0, 5.0, 7.0, 5.0, 3.0, 4.0, 3.0, 5.0, 4.0, 2.0, 1.0, 1.0, 6.0, 6.0, 7.0, 4.0, 2.0, 4.0, 4.0, 4.0, 1.0, 2.0, 4.0, 2.0, 3.0, 4.0, 4.0, 5.0, 1.0, 2.0, 0.0, 1.0, 2.0, 3.0, 4.0, 2.0, 5.0, 3.0, 6.0, 5.0, 7.0, 3.0, 4.0, 4.0, 3.0, 2.0, 1.0, 3.0, 6.0, 6.0, 7.0, 6.0, 3.0, 5.0, 1.0, 2.0, 3.0, 2.0, 5.0, 3.0, 6.0, 2.0, 2.0, 3.0, 3.0, 4.0, 6.0, 7.0, 4.0, 2.0, 4.0, 4.0, 4.0, 4.0, 2.0, 4.0, 5.0, 4.0, 5.0, 6.0, 4.0, 3.0, 5.0, 4.0, 4.0, 5.0, 3.0, 4.0, 1.0, 1.0, 1.0, 3.0, 4.0, 5.0, 5.0, 7.0, 1.0, 3.0, 2.0, 1.0, 4.0, 3.0, 5.0, 4.0, 4.0, 2.0, 4.0, 6.0, 3.0, 4.0, 2.0, 2.0, 4.0, 4.0, 5.0, 5.0, 0.0, 1.0, 1.0, 0.0, 1.0, 4.0, 3.0, 4.0, 4.0, 6.0, 6.0, 5.0, 5.0, 1.0, 2.0, 4.0, 2.0, 2.0, 0.0, 2.0, 3.0, 4.0, 3.0, 3.0, 6.0, 3.0, 5.0, 2.0, 2.0, 5.0, 6.0, 4.0, 5.0, 4.0, 2.0, 6.0, 4.0, 5.0, 6.0, 4.0, 4.0, 2.0, 5.0, 8.0, 4.0, 2.0, 2.0, 2.0, 0.0, 1.0, 1.0, 0.0, 1.0, 4.0, 3.0, 3.0, 1.0, 0.0, 2.0, 2.0, 2.0, 2.0, 3.0, 2.0, 2.0, 1.0, 3.0, 3.0, 3.0, 1.0, 4.0, 3.0, 5.0, 3.0, 6.0, 5.0, 6.0, 8.0, 4.0, 6.0, 3.0, 2.0, 1.0, 3.0, 4.0, 5.0, 5.0, 5.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.13395246753793635, "mean_inference_ms": 0.3910090551092394, "mean_action_processing_ms": 0.029177213400656, "mean_env_wait_ms": 0.40305590954841625, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 1819440, "timesteps_this_iter": 0, "agent_timesteps_total": 7277760, "timers": {"sample_time_ms": 5131.497, "sample_throughput": 982.169, "load_time_ms": 0.191, "load_throughput": 26348363.654, "learn_time_ms": 161.354, "learn_throughput": 31235.762, "update_time_ms": 2.545}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 521.0554809570312, "policy_entropy": 7494.001708984375, "policy_loss": 6.383146286010742, "vf_loss": 111.34246635437012}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 1819440, "num_agent_steps_sampled": 7277760, "num_steps_trained": 1819440, "num_agent_steps_trained": 7277760, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 3636, "training_iteration": 181, "trial_id": "71426_00000", "experiment_id": "84bca2f7b35f43248fca18d21abe2ebf", "date": "2024-06-12_03-16-57", "timestamp": 1718129817, "time_this_iter_s": 10.144286394119263, "time_total_s": 1863.7402720451355, "pid": 363902, "hostname": "DESKTOP-LQ219J4", "node_ip": "192.168.46.185", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 20, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 5000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 500, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Base_Model", "custom_model_config": {"env": "rware", "env_args": {"n_agents": 4, "column_height": 1, "max_inactivity_steps": null, "max_steps": 500, "fast_obs": true, "msg_bits": 0, "sensor_range": 1, "shelf_rows": 1, "shelf_columns": 3, "request_queue_size": 4, "reward_type": "RewardType.INDIVIDUAL", "map_name": "customized_map", "map_size": "tiny", "difficulty": "medium"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": true, "force_coop": false, "local_mode": true, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 4, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 100, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64}, "algorithm": "ia2c", "space_obs": "Dict(obs:Box([-100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100.], [100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.], (112,), float32))", "space_act": "Discrete(5)", "num_agents": 4, "episode_limit": 500, "policy_mapping_info": {"all_scenario": {"description": "rware all scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2", "agent_3"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "rware_customized_map", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 10, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.IA2CTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_il.<locals>.<lambda> at 0x7f383066a940>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "grad_clip": 40.0, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "microbatch_size": null}, "time_since_restore": 1863.7402720451355, "timesteps_since_restore": 0, "iterations_since_restore": 181, "perf": {"cpu_util_percent": 4.286666666666666, "ram_util_percent": 82.43333333333334}}
{"episode_reward_max": 28.0, "episode_reward_min": 2.0, "episode_reward_mean": 14.28, "episode_len_mean": 500.0, "episode_media": {}, "episodes_this_iter": 20, "policy_reward_min": {"shared_policy": 0.0}, "policy_reward_max": {"shared_policy": 9.0}, "policy_reward_mean": {"shared_policy": 3.57}, "custom_metrics": {}, "hist_stats": {"episode_reward": [9.0, 4.0, 20.0, 22.0, 12.0, 19.0, 5.0, 6.0, 10.0, 8.0, 10.0, 11.0, 12.0, 22.0, 27.0, 22.0, 3.0, 16.0, 14.0, 16.0, 28.0, 14.0, 11.0, 10.0, 12.0, 6.0, 16.0, 12.0, 19.0, 22.0, 15.0, 8.0, 23.0, 14.0, 9.0, 16.0, 4.0, 11.0, 19.0, 18.0, 9.0, 25.0, 11.0, 13.0, 13.0, 20.0, 14.0, 14.0, 20.0, 16.0, 16.0, 6.0, 21.0, 7.0, 16.0, 16.0, 11.0, 18.0, 2.0, 12.0, 21.0, 12.0, 6.0, 13.0, 16.0, 17.0, 17.0, 19.0, 19.0, 10.0, 2.0, 11.0, 5.0, 9.0, 9.0, 11.0, 19.0, 24.0, 9.0, 19.0, 18.0, 24.0, 19.0, 16.0, 20.0, 9.0, 15.0, 12.0, 13.0, 10.0, 15.0, 15.0, 18.0, 23.0, 14.0, 26.0, 17.0, 24.0, 3.0, 14.0], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500], "policy_shared_policy_reward": [2.0, 3.0, 4.0, 0.0, 1.0, 1.0, 1.0, 1.0, 4.0, 5.0, 6.0, 5.0, 5.0, 4.0, 7.0, 6.0, 2.0, 4.0, 2.0, 4.0, 4.0, 5.0, 6.0, 4.0, 1.0, 2.0, 1.0, 1.0, 2.0, 1.0, 2.0, 1.0, 4.0, 1.0, 2.0, 3.0, 1.0, 1.0, 2.0, 4.0, 2.0, 3.0, 3.0, 2.0, 4.0, 3.0, 2.0, 2.0, 2.0, 2.0, 4.0, 4.0, 6.0, 4.0, 5.0, 7.0, 6.0, 7.0, 9.0, 5.0, 4.0, 9.0, 3.0, 6.0, 0.0, 2.0, 1.0, 0.0, 4.0, 5.0, 4.0, 3.0, 2.0, 3.0, 5.0, 4.0, 3.0, 4.0, 4.0, 5.0, 6.0, 9.0, 5.0, 8.0, 5.0, 1.0, 4.0, 4.0, 3.0, 2.0, 4.0, 2.0, 2.0, 2.0, 1.0, 5.0, 3.0, 2.0, 4.0, 3.0, 2.0, 2.0, 1.0, 1.0, 4.0, 6.0, 4.0, 2.0, 1.0, 5.0, 4.0, 2.0, 6.0, 5.0, 3.0, 5.0, 5.0, 5.0, 7.0, 5.0, 3.0, 4.0, 3.0, 5.0, 4.0, 2.0, 1.0, 1.0, 6.0, 6.0, 7.0, 4.0, 2.0, 4.0, 4.0, 4.0, 1.0, 2.0, 4.0, 2.0, 3.0, 4.0, 4.0, 5.0, 1.0, 2.0, 0.0, 1.0, 2.0, 3.0, 4.0, 2.0, 5.0, 3.0, 6.0, 5.0, 7.0, 3.0, 4.0, 4.0, 3.0, 2.0, 1.0, 3.0, 6.0, 6.0, 7.0, 6.0, 3.0, 5.0, 1.0, 2.0, 3.0, 2.0, 5.0, 3.0, 6.0, 2.0, 2.0, 3.0, 3.0, 4.0, 6.0, 7.0, 4.0, 2.0, 4.0, 4.0, 4.0, 4.0, 2.0, 4.0, 5.0, 4.0, 5.0, 6.0, 4.0, 3.0, 5.0, 4.0, 4.0, 5.0, 3.0, 4.0, 1.0, 1.0, 1.0, 3.0, 4.0, 5.0, 5.0, 7.0, 1.0, 3.0, 2.0, 1.0, 4.0, 3.0, 5.0, 4.0, 4.0, 2.0, 4.0, 6.0, 3.0, 4.0, 2.0, 2.0, 4.0, 4.0, 5.0, 5.0, 0.0, 1.0, 1.0, 0.0, 1.0, 4.0, 3.0, 4.0, 4.0, 6.0, 6.0, 5.0, 5.0, 1.0, 2.0, 4.0, 2.0, 2.0, 0.0, 2.0, 3.0, 4.0, 3.0, 3.0, 6.0, 3.0, 5.0, 2.0, 2.0, 5.0, 6.0, 4.0, 5.0, 4.0, 2.0, 6.0, 4.0, 5.0, 6.0, 4.0, 4.0, 2.0, 5.0, 8.0, 4.0, 2.0, 2.0, 2.0, 0.0, 1.0, 1.0, 0.0, 1.0, 4.0, 3.0, 3.0, 1.0, 0.0, 2.0, 2.0, 2.0, 2.0, 3.0, 2.0, 2.0, 1.0, 3.0, 3.0, 3.0, 1.0, 4.0, 3.0, 5.0, 3.0, 6.0, 5.0, 6.0, 8.0, 4.0, 6.0, 3.0, 2.0, 1.0, 3.0, 4.0, 5.0, 5.0, 5.0, 3.0, 6.0, 3.0, 6.0, 7.0, 4.0, 7.0, 6.0, 4.0, 6.0, 5.0, 4.0, 4.0, 3.0, 5.0, 4.0, 5.0, 4.0, 6.0, 5.0, 4.0, 2.0, 2.0, 1.0, 5.0, 3.0, 4.0, 3.0, 2.0, 3.0, 5.0, 2.0, 5.0, 2.0, 4.0, 2.0, 4.0, 3.0, 2.0, 1.0, 6.0, 3.0, 2.0, 4.0, 5.0, 2.0, 4.0, 4.0, 3.0, 7.0, 4.0, 4.0, 4.0, 7.0, 5.0, 7.0, 4.0, 2.0, 6.0, 2.0, 5.0, 9.0, 6.0, 6.0, 5.0, 4.0, 6.0, 2.0, 5.0, 7.0, 6.0, 6.0, 1.0, 0.0, 2.0, 0.0, 5.0, 4.0, 2.0, 3.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.1339502225341981, "mean_inference_ms": 0.3910011669123611, "mean_action_processing_ms": 0.029176497253679334, "mean_env_wait_ms": 0.40301951640313033, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 1829520, "timesteps_this_iter": 0, "agent_timesteps_total": 7318080, "timers": {"sample_time_ms": 5136.339, "sample_throughput": 981.244, "load_time_ms": 0.196, "load_throughput": 25704392.218, "learn_time_ms": 146.33, "learn_throughput": 34442.749, "update_time_ms": 2.603}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 345.9000244140625, "policy_entropy": 7493.36865234375, "policy_loss": 27.02238965034485, "vf_loss": 105.28132820129395}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 1829520, "num_agent_steps_sampled": 7318080, "num_steps_trained": 1829520, "num_agent_steps_trained": 7318080, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 3656, "training_iteration": 182, "trial_id": "71426_00000", "experiment_id": "84bca2f7b35f43248fca18d21abe2ebf", "date": "2024-06-12_03-17-08", "timestamp": 1718129828, "time_this_iter_s": 10.348430156707764, "time_total_s": 1874.0887022018433, "pid": 363902, "hostname": "DESKTOP-LQ219J4", "node_ip": "192.168.46.185", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 20, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 5000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 500, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Base_Model", "custom_model_config": {"env": "rware", "env_args": {"n_agents": 4, "column_height": 1, "max_inactivity_steps": null, "max_steps": 500, "fast_obs": true, "msg_bits": 0, "sensor_range": 1, "shelf_rows": 1, "shelf_columns": 3, "request_queue_size": 4, "reward_type": "RewardType.INDIVIDUAL", "map_name": "customized_map", "map_size": "tiny", "difficulty": "medium"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": true, "force_coop": false, "local_mode": true, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 4, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 100, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64}, "algorithm": "ia2c", "space_obs": "Dict(obs:Box([-100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100.], [100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.], (112,), float32))", "space_act": "Discrete(5)", "num_agents": 4, "episode_limit": 500, "policy_mapping_info": {"all_scenario": {"description": "rware all scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2", "agent_3"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "rware_customized_map", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 10, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.IA2CTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_il.<locals>.<lambda> at 0x7f38081d5af0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "grad_clip": 40.0, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "microbatch_size": null}, "time_since_restore": 1874.0887022018433, "timesteps_since_restore": 0, "iterations_since_restore": 182, "perf": {"cpu_util_percent": 4.3428571428571425, "ram_util_percent": 82.66428571428573}}
{"episode_reward_max": 28.0, "episode_reward_min": 2.0, "episode_reward_mean": 14.79, "episode_len_mean": 500.0, "episode_media": {}, "episodes_this_iter": 20, "policy_reward_min": {"shared_policy": 0.0}, "policy_reward_max": {"shared_policy": 9.0}, "policy_reward_mean": {"shared_policy": 3.6975}, "custom_metrics": {}, "hist_stats": {"episode_reward": [28.0, 14.0, 11.0, 10.0, 12.0, 6.0, 16.0, 12.0, 19.0, 22.0, 15.0, 8.0, 23.0, 14.0, 9.0, 16.0, 4.0, 11.0, 19.0, 18.0, 9.0, 25.0, 11.0, 13.0, 13.0, 20.0, 14.0, 14.0, 20.0, 16.0, 16.0, 6.0, 21.0, 7.0, 16.0, 16.0, 11.0, 18.0, 2.0, 12.0, 21.0, 12.0, 6.0, 13.0, 16.0, 17.0, 17.0, 19.0, 19.0, 10.0, 2.0, 11.0, 5.0, 9.0, 9.0, 11.0, 19.0, 24.0, 9.0, 19.0, 18.0, 24.0, 19.0, 16.0, 20.0, 9.0, 15.0, 12.0, 13.0, 10.0, 15.0, 15.0, 18.0, 23.0, 14.0, 26.0, 17.0, 24.0, 3.0, 14.0, 13.0, 17.0, 15.0, 18.0, 17.0, 12.0, 17.0, 7.0, 27.0, 11.0, 17.0, 18.0, 21.0, 19.0, 13.0, 17.0, 15.0, 25.0, 17.0, 3.0], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500], "policy_shared_policy_reward": [6.0, 9.0, 5.0, 8.0, 5.0, 1.0, 4.0, 4.0, 3.0, 2.0, 4.0, 2.0, 2.0, 2.0, 1.0, 5.0, 3.0, 2.0, 4.0, 3.0, 2.0, 2.0, 1.0, 1.0, 4.0, 6.0, 4.0, 2.0, 1.0, 5.0, 4.0, 2.0, 6.0, 5.0, 3.0, 5.0, 5.0, 5.0, 7.0, 5.0, 3.0, 4.0, 3.0, 5.0, 4.0, 2.0, 1.0, 1.0, 6.0, 6.0, 7.0, 4.0, 2.0, 4.0, 4.0, 4.0, 1.0, 2.0, 4.0, 2.0, 3.0, 4.0, 4.0, 5.0, 1.0, 2.0, 0.0, 1.0, 2.0, 3.0, 4.0, 2.0, 5.0, 3.0, 6.0, 5.0, 7.0, 3.0, 4.0, 4.0, 3.0, 2.0, 1.0, 3.0, 6.0, 6.0, 7.0, 6.0, 3.0, 5.0, 1.0, 2.0, 3.0, 2.0, 5.0, 3.0, 6.0, 2.0, 2.0, 3.0, 3.0, 4.0, 6.0, 7.0, 4.0, 2.0, 4.0, 4.0, 4.0, 4.0, 2.0, 4.0, 5.0, 4.0, 5.0, 6.0, 4.0, 3.0, 5.0, 4.0, 4.0, 5.0, 3.0, 4.0, 1.0, 1.0, 1.0, 3.0, 4.0, 5.0, 5.0, 7.0, 1.0, 3.0, 2.0, 1.0, 4.0, 3.0, 5.0, 4.0, 4.0, 2.0, 4.0, 6.0, 3.0, 4.0, 2.0, 2.0, 4.0, 4.0, 5.0, 5.0, 0.0, 1.0, 1.0, 0.0, 1.0, 4.0, 3.0, 4.0, 4.0, 6.0, 6.0, 5.0, 5.0, 1.0, 2.0, 4.0, 2.0, 2.0, 0.0, 2.0, 3.0, 4.0, 3.0, 3.0, 6.0, 3.0, 5.0, 2.0, 2.0, 5.0, 6.0, 4.0, 5.0, 4.0, 2.0, 6.0, 4.0, 5.0, 6.0, 4.0, 4.0, 2.0, 5.0, 8.0, 4.0, 2.0, 2.0, 2.0, 0.0, 1.0, 1.0, 0.0, 1.0, 4.0, 3.0, 3.0, 1.0, 0.0, 2.0, 2.0, 2.0, 2.0, 3.0, 2.0, 2.0, 1.0, 3.0, 3.0, 3.0, 1.0, 4.0, 3.0, 5.0, 3.0, 6.0, 5.0, 6.0, 8.0, 4.0, 6.0, 3.0, 2.0, 1.0, 3.0, 4.0, 5.0, 5.0, 5.0, 3.0, 6.0, 3.0, 6.0, 7.0, 4.0, 7.0, 6.0, 4.0, 6.0, 5.0, 4.0, 4.0, 3.0, 5.0, 4.0, 5.0, 4.0, 6.0, 5.0, 4.0, 2.0, 2.0, 1.0, 5.0, 3.0, 4.0, 3.0, 2.0, 3.0, 5.0, 2.0, 5.0, 2.0, 4.0, 2.0, 4.0, 3.0, 2.0, 1.0, 6.0, 3.0, 2.0, 4.0, 5.0, 2.0, 4.0, 4.0, 3.0, 7.0, 4.0, 4.0, 4.0, 7.0, 5.0, 7.0, 4.0, 2.0, 6.0, 2.0, 5.0, 9.0, 6.0, 6.0, 5.0, 4.0, 6.0, 2.0, 5.0, 7.0, 6.0, 6.0, 1.0, 0.0, 2.0, 0.0, 5.0, 4.0, 2.0, 3.0, 4.0, 5.0, 0.0, 4.0, 3.0, 5.0, 6.0, 3.0, 4.0, 3.0, 4.0, 4.0, 4.0, 3.0, 7.0, 4.0, 4.0, 5.0, 4.0, 4.0, 4.0, 3.0, 3.0, 2.0, 6.0, 6.0, 2.0, 3.0, 0.0, 2.0, 4.0, 1.0, 3.0, 7.0, 8.0, 9.0, 3.0, 4.0, 3.0, 1.0, 6.0, 4.0, 2.0, 5.0, 5.0, 6.0, 4.0, 3.0, 7.0, 6.0, 3.0, 5.0, 4.0, 6.0, 4.0, 5.0, 4.0, 3.0, 3.0, 3.0, 4.0, 5.0, 4.0, 4.0, 5.0, 2.0, 5.0, 3.0, 5.0, 6.0, 6.0, 8.0, 4.0, 3.0, 6.0, 4.0, 1.0, 0.0, 2.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.13394891888802976, "mean_inference_ms": 0.39099750203406436, "mean_action_processing_ms": 0.029176176946138773, "mean_env_wait_ms": 0.402990049163992, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 1839600, "timesteps_this_iter": 0, "agent_timesteps_total": 7358400, "timers": {"sample_time_ms": 5138.732, "sample_throughput": 980.787, "load_time_ms": 0.204, "load_throughput": 24738785.442, "learn_time_ms": 156.374, "learn_throughput": 32230.525, "update_time_ms": 2.886}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 800.2608642578125, "policy_entropy": 7437.980712890625, "policy_loss": 36.67783546447754, "vf_loss": 122.9398250579834}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 1839600, "num_agent_steps_sampled": 7358400, "num_steps_trained": 1839600, "num_agent_steps_trained": 7358400, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 3676, "training_iteration": 183, "trial_id": "71426_00000", "experiment_id": "84bca2f7b35f43248fca18d21abe2ebf", "date": "2024-06-12_03-17-18", "timestamp": 1718129838, "time_this_iter_s": 10.44829511642456, "time_total_s": 1884.5369973182678, "pid": 363902, "hostname": "DESKTOP-LQ219J4", "node_ip": "192.168.46.185", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 20, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 5000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 500, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Base_Model", "custom_model_config": {"env": "rware", "env_args": {"n_agents": 4, "column_height": 1, "max_inactivity_steps": null, "max_steps": 500, "fast_obs": true, "msg_bits": 0, "sensor_range": 1, "shelf_rows": 1, "shelf_columns": 3, "request_queue_size": 4, "reward_type": "RewardType.INDIVIDUAL", "map_name": "customized_map", "map_size": "tiny", "difficulty": "medium"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": true, "force_coop": false, "local_mode": true, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 4, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 100, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64}, "algorithm": "ia2c", "space_obs": "Dict(obs:Box([-100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100.], [100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.], (112,), float32))", "space_act": "Discrete(5)", "num_agents": 4, "episode_limit": 500, "policy_mapping_info": {"all_scenario": {"description": "rware all scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2", "agent_3"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "rware_customized_map", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 10, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.IA2CTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_il.<locals>.<lambda> at 0x7f38082f8820>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "grad_clip": 40.0, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "microbatch_size": null}, "time_since_restore": 1884.5369973182678, "timesteps_since_restore": 0, "iterations_since_restore": 183, "perf": {"cpu_util_percent": 4.133333333333334, "ram_util_percent": 82.88666666666667}}
{"episode_reward_max": 27.0, "episode_reward_min": 2.0, "episode_reward_mean": 15.13, "episode_len_mean": 500.0, "episode_media": {}, "episodes_this_iter": 20, "policy_reward_min": {"shared_policy": 0.0}, "policy_reward_max": {"shared_policy": 9.0}, "policy_reward_mean": {"shared_policy": 3.7825}, "custom_metrics": {}, "hist_stats": {"episode_reward": [9.0, 25.0, 11.0, 13.0, 13.0, 20.0, 14.0, 14.0, 20.0, 16.0, 16.0, 6.0, 21.0, 7.0, 16.0, 16.0, 11.0, 18.0, 2.0, 12.0, 21.0, 12.0, 6.0, 13.0, 16.0, 17.0, 17.0, 19.0, 19.0, 10.0, 2.0, 11.0, 5.0, 9.0, 9.0, 11.0, 19.0, 24.0, 9.0, 19.0, 18.0, 24.0, 19.0, 16.0, 20.0, 9.0, 15.0, 12.0, 13.0, 10.0, 15.0, 15.0, 18.0, 23.0, 14.0, 26.0, 17.0, 24.0, 3.0, 14.0, 13.0, 17.0, 15.0, 18.0, 17.0, 12.0, 17.0, 7.0, 27.0, 11.0, 17.0, 18.0, 21.0, 19.0, 13.0, 17.0, 15.0, 25.0, 17.0, 3.0, 11.0, 21.0, 16.0, 21.0, 12.0, 11.0, 12.0, 21.0, 11.0, 14.0, 15.0, 19.0, 19.0, 14.0, 10.0, 26.0, 8.0, 22.0, 20.0, 18.0], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500], "policy_shared_policy_reward": [3.0, 2.0, 1.0, 3.0, 6.0, 6.0, 7.0, 6.0, 3.0, 5.0, 1.0, 2.0, 3.0, 2.0, 5.0, 3.0, 6.0, 2.0, 2.0, 3.0, 3.0, 4.0, 6.0, 7.0, 4.0, 2.0, 4.0, 4.0, 4.0, 4.0, 2.0, 4.0, 5.0, 4.0, 5.0, 6.0, 4.0, 3.0, 5.0, 4.0, 4.0, 5.0, 3.0, 4.0, 1.0, 1.0, 1.0, 3.0, 4.0, 5.0, 5.0, 7.0, 1.0, 3.0, 2.0, 1.0, 4.0, 3.0, 5.0, 4.0, 4.0, 2.0, 4.0, 6.0, 3.0, 4.0, 2.0, 2.0, 4.0, 4.0, 5.0, 5.0, 0.0, 1.0, 1.0, 0.0, 1.0, 4.0, 3.0, 4.0, 4.0, 6.0, 6.0, 5.0, 5.0, 1.0, 2.0, 4.0, 2.0, 2.0, 0.0, 2.0, 3.0, 4.0, 3.0, 3.0, 6.0, 3.0, 5.0, 2.0, 2.0, 5.0, 6.0, 4.0, 5.0, 4.0, 2.0, 6.0, 4.0, 5.0, 6.0, 4.0, 4.0, 2.0, 5.0, 8.0, 4.0, 2.0, 2.0, 2.0, 0.0, 1.0, 1.0, 0.0, 1.0, 4.0, 3.0, 3.0, 1.0, 0.0, 2.0, 2.0, 2.0, 2.0, 3.0, 2.0, 2.0, 1.0, 3.0, 3.0, 3.0, 1.0, 4.0, 3.0, 5.0, 3.0, 6.0, 5.0, 6.0, 8.0, 4.0, 6.0, 3.0, 2.0, 1.0, 3.0, 4.0, 5.0, 5.0, 5.0, 3.0, 6.0, 3.0, 6.0, 7.0, 4.0, 7.0, 6.0, 4.0, 6.0, 5.0, 4.0, 4.0, 3.0, 5.0, 4.0, 5.0, 4.0, 6.0, 5.0, 4.0, 2.0, 2.0, 1.0, 5.0, 3.0, 4.0, 3.0, 2.0, 3.0, 5.0, 2.0, 5.0, 2.0, 4.0, 2.0, 4.0, 3.0, 2.0, 1.0, 6.0, 3.0, 2.0, 4.0, 5.0, 2.0, 4.0, 4.0, 3.0, 7.0, 4.0, 4.0, 4.0, 7.0, 5.0, 7.0, 4.0, 2.0, 6.0, 2.0, 5.0, 9.0, 6.0, 6.0, 5.0, 4.0, 6.0, 2.0, 5.0, 7.0, 6.0, 6.0, 1.0, 0.0, 2.0, 0.0, 5.0, 4.0, 2.0, 3.0, 4.0, 5.0, 0.0, 4.0, 3.0, 5.0, 6.0, 3.0, 4.0, 3.0, 4.0, 4.0, 4.0, 3.0, 7.0, 4.0, 4.0, 5.0, 4.0, 4.0, 4.0, 3.0, 3.0, 2.0, 6.0, 6.0, 2.0, 3.0, 0.0, 2.0, 4.0, 1.0, 3.0, 7.0, 8.0, 9.0, 3.0, 4.0, 3.0, 1.0, 6.0, 4.0, 2.0, 5.0, 5.0, 6.0, 4.0, 3.0, 7.0, 6.0, 3.0, 5.0, 4.0, 6.0, 4.0, 5.0, 4.0, 3.0, 3.0, 3.0, 4.0, 5.0, 4.0, 4.0, 5.0, 2.0, 5.0, 3.0, 5.0, 6.0, 6.0, 8.0, 4.0, 3.0, 6.0, 4.0, 1.0, 0.0, 2.0, 0.0, 3.0, 3.0, 2.0, 3.0, 4.0, 3.0, 5.0, 9.0, 4.0, 3.0, 4.0, 5.0, 4.0, 5.0, 6.0, 6.0, 3.0, 3.0, 2.0, 4.0, 4.0, 2.0, 2.0, 3.0, 3.0, 3.0, 3.0, 3.0, 5.0, 4.0, 6.0, 6.0, 1.0, 3.0, 3.0, 4.0, 5.0, 4.0, 1.0, 4.0, 4.0, 5.0, 4.0, 2.0, 3.0, 6.0, 6.0, 4.0, 8.0, 5.0, 2.0, 4.0, 4.0, 3.0, 4.0, 3.0, 3.0, 3.0, 3.0, 1.0, 3.0, 7.0, 7.0, 9.0, 2.0, 2.0, 3.0, 1.0, 6.0, 5.0, 5.0, 6.0, 6.0, 5.0, 5.0, 4.0, 6.0, 3.0, 7.0, 2.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.13394875462825187, "mean_inference_ms": 0.3909967880249491, "mean_action_processing_ms": 0.029176085179476535, "mean_env_wait_ms": 0.4029667827902088, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 1849680, "timesteps_this_iter": 0, "agent_timesteps_total": 7398720, "timers": {"sample_time_ms": 5152.617, "sample_throughput": 978.144, "load_time_ms": 0.201, "load_throughput": 25037655.052, "learn_time_ms": 166.596, "learn_throughput": 30252.752, "update_time_ms": 2.91}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 376.02935791015625, "policy_entropy": 7443.0465087890625, "policy_loss": -52.61471939086914, "vf_loss": 115.14802932739258}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 1849680, "num_agent_steps_sampled": 7398720, "num_steps_trained": 1849680, "num_agent_steps_trained": 7398720, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 3696, "training_iteration": 184, "trial_id": "71426_00000", "experiment_id": "84bca2f7b35f43248fca18d21abe2ebf", "date": "2024-06-12_03-17-28", "timestamp": 1718129848, "time_this_iter_s": 10.373014211654663, "time_total_s": 1894.9100115299225, "pid": 363902, "hostname": "DESKTOP-LQ219J4", "node_ip": "192.168.46.185", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 20, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 5000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 500, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Base_Model", "custom_model_config": {"env": "rware", "env_args": {"n_agents": 4, "column_height": 1, "max_inactivity_steps": null, "max_steps": 500, "fast_obs": true, "msg_bits": 0, "sensor_range": 1, "shelf_rows": 1, "shelf_columns": 3, "request_queue_size": 4, "reward_type": "RewardType.INDIVIDUAL", "map_name": "customized_map", "map_size": "tiny", "difficulty": "medium"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": true, "force_coop": false, "local_mode": true, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 4, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 100, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64}, "algorithm": "ia2c", "space_obs": "Dict(obs:Box([-100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100.], [100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.], (112,), float32))", "space_act": "Discrete(5)", "num_agents": 4, "episode_limit": 500, "policy_mapping_info": {"all_scenario": {"description": "rware all scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2", "agent_3"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "rware_customized_map", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 10, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.IA2CTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_il.<locals>.<lambda> at 0x7f380824d820>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "grad_clip": 40.0, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "microbatch_size": null}, "time_since_restore": 1894.9100115299225, "timesteps_since_restore": 0, "iterations_since_restore": 184, "perf": {"cpu_util_percent": 4.133333333333334, "ram_util_percent": 83.17333333333335}}
{"episode_reward_max": 28.0, "episode_reward_min": 2.0, "episode_reward_mean": 15.22, "episode_len_mean": 500.0, "episode_media": {}, "episodes_this_iter": 20, "policy_reward_min": {"shared_policy": 0.0}, "policy_reward_max": {"shared_policy": 9.0}, "policy_reward_mean": {"shared_policy": 3.805}, "custom_metrics": {}, "hist_stats": {"episode_reward": [21.0, 12.0, 6.0, 13.0, 16.0, 17.0, 17.0, 19.0, 19.0, 10.0, 2.0, 11.0, 5.0, 9.0, 9.0, 11.0, 19.0, 24.0, 9.0, 19.0, 18.0, 24.0, 19.0, 16.0, 20.0, 9.0, 15.0, 12.0, 13.0, 10.0, 15.0, 15.0, 18.0, 23.0, 14.0, 26.0, 17.0, 24.0, 3.0, 14.0, 13.0, 17.0, 15.0, 18.0, 17.0, 12.0, 17.0, 7.0, 27.0, 11.0, 17.0, 18.0, 21.0, 19.0, 13.0, 17.0, 15.0, 25.0, 17.0, 3.0, 11.0, 21.0, 16.0, 21.0, 12.0, 11.0, 12.0, 21.0, 11.0, 14.0, 15.0, 19.0, 19.0, 14.0, 10.0, 26.0, 8.0, 22.0, 20.0, 18.0, 16.0, 20.0, 14.0, 2.0, 28.0, 20.0, 17.0, 8.0, 7.0, 28.0, 12.0, 7.0, 21.0, 11.0, 9.0, 13.0, 21.0, 13.0, 16.0, 6.0], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500], "policy_shared_policy_reward": [4.0, 6.0, 6.0, 5.0, 5.0, 1.0, 2.0, 4.0, 2.0, 2.0, 0.0, 2.0, 3.0, 4.0, 3.0, 3.0, 6.0, 3.0, 5.0, 2.0, 2.0, 5.0, 6.0, 4.0, 5.0, 4.0, 2.0, 6.0, 4.0, 5.0, 6.0, 4.0, 4.0, 2.0, 5.0, 8.0, 4.0, 2.0, 2.0, 2.0, 0.0, 1.0, 1.0, 0.0, 1.0, 4.0, 3.0, 3.0, 1.0, 0.0, 2.0, 2.0, 2.0, 2.0, 3.0, 2.0, 2.0, 1.0, 3.0, 3.0, 3.0, 1.0, 4.0, 3.0, 5.0, 3.0, 6.0, 5.0, 6.0, 8.0, 4.0, 6.0, 3.0, 2.0, 1.0, 3.0, 4.0, 5.0, 5.0, 5.0, 3.0, 6.0, 3.0, 6.0, 7.0, 4.0, 7.0, 6.0, 4.0, 6.0, 5.0, 4.0, 4.0, 3.0, 5.0, 4.0, 5.0, 4.0, 6.0, 5.0, 4.0, 2.0, 2.0, 1.0, 5.0, 3.0, 4.0, 3.0, 2.0, 3.0, 5.0, 2.0, 5.0, 2.0, 4.0, 2.0, 4.0, 3.0, 2.0, 1.0, 6.0, 3.0, 2.0, 4.0, 5.0, 2.0, 4.0, 4.0, 3.0, 7.0, 4.0, 4.0, 4.0, 7.0, 5.0, 7.0, 4.0, 2.0, 6.0, 2.0, 5.0, 9.0, 6.0, 6.0, 5.0, 4.0, 6.0, 2.0, 5.0, 7.0, 6.0, 6.0, 1.0, 0.0, 2.0, 0.0, 5.0, 4.0, 2.0, 3.0, 4.0, 5.0, 0.0, 4.0, 3.0, 5.0, 6.0, 3.0, 4.0, 3.0, 4.0, 4.0, 4.0, 3.0, 7.0, 4.0, 4.0, 5.0, 4.0, 4.0, 4.0, 3.0, 3.0, 2.0, 6.0, 6.0, 2.0, 3.0, 0.0, 2.0, 4.0, 1.0, 3.0, 7.0, 8.0, 9.0, 3.0, 4.0, 3.0, 1.0, 6.0, 4.0, 2.0, 5.0, 5.0, 6.0, 4.0, 3.0, 7.0, 6.0, 3.0, 5.0, 4.0, 6.0, 4.0, 5.0, 4.0, 3.0, 3.0, 3.0, 4.0, 5.0, 4.0, 4.0, 5.0, 2.0, 5.0, 3.0, 5.0, 6.0, 6.0, 8.0, 4.0, 3.0, 6.0, 4.0, 1.0, 0.0, 2.0, 0.0, 3.0, 3.0, 2.0, 3.0, 4.0, 3.0, 5.0, 9.0, 4.0, 3.0, 4.0, 5.0, 4.0, 5.0, 6.0, 6.0, 3.0, 3.0, 2.0, 4.0, 4.0, 2.0, 2.0, 3.0, 3.0, 3.0, 3.0, 3.0, 5.0, 4.0, 6.0, 6.0, 1.0, 3.0, 3.0, 4.0, 5.0, 4.0, 1.0, 4.0, 4.0, 5.0, 4.0, 2.0, 3.0, 6.0, 6.0, 4.0, 8.0, 5.0, 2.0, 4.0, 4.0, 3.0, 4.0, 3.0, 3.0, 3.0, 3.0, 1.0, 3.0, 7.0, 7.0, 9.0, 2.0, 2.0, 3.0, 1.0, 6.0, 5.0, 5.0, 6.0, 6.0, 5.0, 5.0, 4.0, 6.0, 3.0, 7.0, 2.0, 2.0, 3.0, 5.0, 6.0, 7.0, 6.0, 3.0, 4.0, 3.0, 3.0, 4.0, 4.0, 1.0, 1.0, 0.0, 0.0, 6.0, 8.0, 8.0, 6.0, 8.0, 4.0, 6.0, 2.0, 2.0, 4.0, 6.0, 5.0, 1.0, 3.0, 2.0, 2.0, 3.0, 0.0, 3.0, 1.0, 9.0, 7.0, 5.0, 7.0, 4.0, 2.0, 4.0, 2.0, 1.0, 3.0, 1.0, 2.0, 4.0, 6.0, 6.0, 5.0, 4.0, 2.0, 4.0, 1.0, 2.0, 1.0, 4.0, 2.0, 4.0, 3.0, 3.0, 3.0, 5.0, 4.0, 7.0, 5.0, 3.0, 4.0, 1.0, 5.0, 3.0, 3.0, 5.0, 5.0, 2.0, 2.0, 1.0, 1.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.13395088187648857, "mean_inference_ms": 0.3910032578175287, "mean_action_processing_ms": 0.02917633498988499, "mean_env_wait_ms": 0.4029535340216362, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 1859760, "timesteps_this_iter": 0, "agent_timesteps_total": 7439040, "timers": {"sample_time_ms": 5180.923, "sample_throughput": 972.8, "load_time_ms": 0.205, "load_throughput": 24634998.438, "learn_time_ms": 163.765, "learn_throughput": 30775.865, "update_time_ms": 2.975}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 612.0714111328125, "policy_entropy": 7493.6287841796875, "policy_loss": -126.16075897216797, "vf_loss": 94.75224113464355}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 1859760, "num_agent_steps_sampled": 7439040, "num_steps_trained": 1859760, "num_agent_steps_trained": 7439040, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 3716, "training_iteration": 185, "trial_id": "71426_00000", "experiment_id": "84bca2f7b35f43248fca18d21abe2ebf", "date": "2024-06-12_03-17-39", "timestamp": 1718129859, "time_this_iter_s": 10.366950511932373, "time_total_s": 1905.2769620418549, "pid": 363902, "hostname": "DESKTOP-LQ219J4", "node_ip": "192.168.46.185", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 20, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 5000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 500, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Base_Model", "custom_model_config": {"env": "rware", "env_args": {"n_agents": 4, "column_height": 1, "max_inactivity_steps": null, "max_steps": 500, "fast_obs": true, "msg_bits": 0, "sensor_range": 1, "shelf_rows": 1, "shelf_columns": 3, "request_queue_size": 4, "reward_type": "RewardType.INDIVIDUAL", "map_name": "customized_map", "map_size": "tiny", "difficulty": "medium"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": true, "force_coop": false, "local_mode": true, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 4, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 100, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64}, "algorithm": "ia2c", "space_obs": "Dict(obs:Box([-100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100.], [100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.], (112,), float32))", "space_act": "Discrete(5)", "num_agents": 4, "episode_limit": 500, "policy_mapping_info": {"all_scenario": {"description": "rware all scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2", "agent_3"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "rware_customized_map", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 10, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.IA2CTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_il.<locals>.<lambda> at 0x7f38082f8ca0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "grad_clip": 40.0, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "microbatch_size": null}, "time_since_restore": 1905.2769620418549, "timesteps_since_restore": 0, "iterations_since_restore": 185, "perf": {"cpu_util_percent": 4.286666666666666, "ram_util_percent": 83.46000000000002}}
{"episode_reward_max": 28.0, "episode_reward_min": 2.0, "episode_reward_mean": 15.65, "episode_len_mean": 500.0, "episode_media": {}, "episodes_this_iter": 20, "policy_reward_min": {"shared_policy": 0.0}, "policy_reward_max": {"shared_policy": 9.0}, "policy_reward_mean": {"shared_policy": 3.9125}, "custom_metrics": {}, "hist_stats": {"episode_reward": [18.0, 24.0, 19.0, 16.0, 20.0, 9.0, 15.0, 12.0, 13.0, 10.0, 15.0, 15.0, 18.0, 23.0, 14.0, 26.0, 17.0, 24.0, 3.0, 14.0, 13.0, 17.0, 15.0, 18.0, 17.0, 12.0, 17.0, 7.0, 27.0, 11.0, 17.0, 18.0, 21.0, 19.0, 13.0, 17.0, 15.0, 25.0, 17.0, 3.0, 11.0, 21.0, 16.0, 21.0, 12.0, 11.0, 12.0, 21.0, 11.0, 14.0, 15.0, 19.0, 19.0, 14.0, 10.0, 26.0, 8.0, 22.0, 20.0, 18.0, 16.0, 20.0, 14.0, 2.0, 28.0, 20.0, 17.0, 8.0, 7.0, 28.0, 12.0, 7.0, 21.0, 11.0, 9.0, 13.0, 21.0, 13.0, 16.0, 6.0, 9.0, 13.0, 17.0, 12.0, 21.0, 16.0, 21.0, 12.0, 8.0, 18.0, 13.0, 16.0, 25.0, 18.0, 23.0, 11.0, 4.0, 12.0, 24.0, 18.0], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500], "policy_shared_policy_reward": [3.0, 6.0, 3.0, 6.0, 7.0, 4.0, 7.0, 6.0, 4.0, 6.0, 5.0, 4.0, 4.0, 3.0, 5.0, 4.0, 5.0, 4.0, 6.0, 5.0, 4.0, 2.0, 2.0, 1.0, 5.0, 3.0, 4.0, 3.0, 2.0, 3.0, 5.0, 2.0, 5.0, 2.0, 4.0, 2.0, 4.0, 3.0, 2.0, 1.0, 6.0, 3.0, 2.0, 4.0, 5.0, 2.0, 4.0, 4.0, 3.0, 7.0, 4.0, 4.0, 4.0, 7.0, 5.0, 7.0, 4.0, 2.0, 6.0, 2.0, 5.0, 9.0, 6.0, 6.0, 5.0, 4.0, 6.0, 2.0, 5.0, 7.0, 6.0, 6.0, 1.0, 0.0, 2.0, 0.0, 5.0, 4.0, 2.0, 3.0, 4.0, 5.0, 0.0, 4.0, 3.0, 5.0, 6.0, 3.0, 4.0, 3.0, 4.0, 4.0, 4.0, 3.0, 7.0, 4.0, 4.0, 5.0, 4.0, 4.0, 4.0, 3.0, 3.0, 2.0, 6.0, 6.0, 2.0, 3.0, 0.0, 2.0, 4.0, 1.0, 3.0, 7.0, 8.0, 9.0, 3.0, 4.0, 3.0, 1.0, 6.0, 4.0, 2.0, 5.0, 5.0, 6.0, 4.0, 3.0, 7.0, 6.0, 3.0, 5.0, 4.0, 6.0, 4.0, 5.0, 4.0, 3.0, 3.0, 3.0, 4.0, 5.0, 4.0, 4.0, 5.0, 2.0, 5.0, 3.0, 5.0, 6.0, 6.0, 8.0, 4.0, 3.0, 6.0, 4.0, 1.0, 0.0, 2.0, 0.0, 3.0, 3.0, 2.0, 3.0, 4.0, 3.0, 5.0, 9.0, 4.0, 3.0, 4.0, 5.0, 4.0, 5.0, 6.0, 6.0, 3.0, 3.0, 2.0, 4.0, 4.0, 2.0, 2.0, 3.0, 3.0, 3.0, 3.0, 3.0, 5.0, 4.0, 6.0, 6.0, 1.0, 3.0, 3.0, 4.0, 5.0, 4.0, 1.0, 4.0, 4.0, 5.0, 4.0, 2.0, 3.0, 6.0, 6.0, 4.0, 8.0, 5.0, 2.0, 4.0, 4.0, 3.0, 4.0, 3.0, 3.0, 3.0, 3.0, 1.0, 3.0, 7.0, 7.0, 9.0, 2.0, 2.0, 3.0, 1.0, 6.0, 5.0, 5.0, 6.0, 6.0, 5.0, 5.0, 4.0, 6.0, 3.0, 7.0, 2.0, 2.0, 3.0, 5.0, 6.0, 7.0, 6.0, 3.0, 4.0, 3.0, 3.0, 4.0, 4.0, 1.0, 1.0, 0.0, 0.0, 6.0, 8.0, 8.0, 6.0, 8.0, 4.0, 6.0, 2.0, 2.0, 4.0, 6.0, 5.0, 1.0, 3.0, 2.0, 2.0, 3.0, 0.0, 3.0, 1.0, 9.0, 7.0, 5.0, 7.0, 4.0, 2.0, 4.0, 2.0, 1.0, 3.0, 1.0, 2.0, 4.0, 6.0, 6.0, 5.0, 4.0, 2.0, 4.0, 1.0, 2.0, 1.0, 4.0, 2.0, 4.0, 3.0, 3.0, 3.0, 5.0, 4.0, 7.0, 5.0, 3.0, 4.0, 1.0, 5.0, 3.0, 3.0, 5.0, 5.0, 2.0, 2.0, 1.0, 1.0, 3.0, 2.0, 2.0, 2.0, 3.0, 3.0, 4.0, 3.0, 5.0, 4.0, 3.0, 5.0, 4.0, 3.0, 2.0, 3.0, 4.0, 4.0, 6.0, 7.0, 4.0, 4.0, 4.0, 4.0, 5.0, 3.0, 7.0, 6.0, 2.0, 4.0, 4.0, 2.0, 2.0, 3.0, 2.0, 1.0, 2.0, 6.0, 4.0, 6.0, 4.0, 4.0, 3.0, 2.0, 4.0, 4.0, 4.0, 4.0, 8.0, 5.0, 6.0, 6.0, 3.0, 5.0, 4.0, 6.0, 6.0, 7.0, 5.0, 5.0, 2.0, 4.0, 2.0, 3.0, 2.0, 1.0, 1.0, 0.0, 4.0, 1.0, 3.0, 4.0, 5.0, 6.0, 6.0, 7.0, 5.0, 5.0, 6.0, 2.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.1339525044089478, "mean_inference_ms": 0.39100979832102034, "mean_action_processing_ms": 0.02917661267342142, "mean_env_wait_ms": 0.4029483818226832, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 1869840, "timesteps_this_iter": 0, "agent_timesteps_total": 7479360, "timers": {"sample_time_ms": 5184.57, "sample_throughput": 972.115, "load_time_ms": 0.189, "load_throughput": 26691025.455, "learn_time_ms": 165.114, "learn_throughput": 30524.286, "update_time_ms": 2.965}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 781.8733520507812, "policy_entropy": 7491.823486328125, "policy_loss": 6.833399415016174, "vf_loss": 124.52232551574707}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 1869840, "num_agent_steps_sampled": 7479360, "num_steps_trained": 1869840, "num_agent_steps_trained": 7479360, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 3736, "training_iteration": 186, "trial_id": "71426_00000", "experiment_id": "84bca2f7b35f43248fca18d21abe2ebf", "date": "2024-06-12_03-17-49", "timestamp": 1718129869, "time_this_iter_s": 10.214709758758545, "time_total_s": 1915.4916718006134, "pid": 363902, "hostname": "DESKTOP-LQ219J4", "node_ip": "192.168.46.185", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 20, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 5000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 500, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Base_Model", "custom_model_config": {"env": "rware", "env_args": {"n_agents": 4, "column_height": 1, "max_inactivity_steps": null, "max_steps": 500, "fast_obs": true, "msg_bits": 0, "sensor_range": 1, "shelf_rows": 1, "shelf_columns": 3, "request_queue_size": 4, "reward_type": "RewardType.INDIVIDUAL", "map_name": "customized_map", "map_size": "tiny", "difficulty": "medium"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": true, "force_coop": false, "local_mode": true, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 4, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 100, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64}, "algorithm": "ia2c", "space_obs": "Dict(obs:Box([-100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100.], [100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.], (112,), float32))", "space_act": "Discrete(5)", "num_agents": 4, "episode_limit": 500, "policy_mapping_info": {"all_scenario": {"description": "rware all scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2", "agent_3"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "rware_customized_map", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 10, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.IA2CTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_il.<locals>.<lambda> at 0x7f38280b2160>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "grad_clip": 40.0, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "microbatch_size": null}, "time_since_restore": 1915.4916718006134, "timesteps_since_restore": 0, "iterations_since_restore": 186, "perf": {"cpu_util_percent": 4.107142857142858, "ram_util_percent": 83.73571428571427}}
{"episode_reward_max": 28.0, "episode_reward_min": 2.0, "episode_reward_mean": 15.29, "episode_len_mean": 500.0, "episode_media": {}, "episodes_this_iter": 20, "policy_reward_min": {"shared_policy": 0.0}, "policy_reward_max": {"shared_policy": 9.0}, "policy_reward_mean": {"shared_policy": 3.8225}, "custom_metrics": {}, "hist_stats": {"episode_reward": [13.0, 17.0, 15.0, 18.0, 17.0, 12.0, 17.0, 7.0, 27.0, 11.0, 17.0, 18.0, 21.0, 19.0, 13.0, 17.0, 15.0, 25.0, 17.0, 3.0, 11.0, 21.0, 16.0, 21.0, 12.0, 11.0, 12.0, 21.0, 11.0, 14.0, 15.0, 19.0, 19.0, 14.0, 10.0, 26.0, 8.0, 22.0, 20.0, 18.0, 16.0, 20.0, 14.0, 2.0, 28.0, 20.0, 17.0, 8.0, 7.0, 28.0, 12.0, 7.0, 21.0, 11.0, 9.0, 13.0, 21.0, 13.0, 16.0, 6.0, 9.0, 13.0, 17.0, 12.0, 21.0, 16.0, 21.0, 12.0, 8.0, 18.0, 13.0, 16.0, 25.0, 18.0, 23.0, 11.0, 4.0, 12.0, 24.0, 18.0, 11.0, 11.0, 8.0, 21.0, 23.0, 16.0, 6.0, 23.0, 10.0, 15.0, 21.0, 16.0, 6.0, 11.0, 16.0, 5.0, 16.0, 23.0, 13.0, 18.0], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500], "policy_shared_policy_reward": [4.0, 5.0, 0.0, 4.0, 3.0, 5.0, 6.0, 3.0, 4.0, 3.0, 4.0, 4.0, 4.0, 3.0, 7.0, 4.0, 4.0, 5.0, 4.0, 4.0, 4.0, 3.0, 3.0, 2.0, 6.0, 6.0, 2.0, 3.0, 0.0, 2.0, 4.0, 1.0, 3.0, 7.0, 8.0, 9.0, 3.0, 4.0, 3.0, 1.0, 6.0, 4.0, 2.0, 5.0, 5.0, 6.0, 4.0, 3.0, 7.0, 6.0, 3.0, 5.0, 4.0, 6.0, 4.0, 5.0, 4.0, 3.0, 3.0, 3.0, 4.0, 5.0, 4.0, 4.0, 5.0, 2.0, 5.0, 3.0, 5.0, 6.0, 6.0, 8.0, 4.0, 3.0, 6.0, 4.0, 1.0, 0.0, 2.0, 0.0, 3.0, 3.0, 2.0, 3.0, 4.0, 3.0, 5.0, 9.0, 4.0, 3.0, 4.0, 5.0, 4.0, 5.0, 6.0, 6.0, 3.0, 3.0, 2.0, 4.0, 4.0, 2.0, 2.0, 3.0, 3.0, 3.0, 3.0, 3.0, 5.0, 4.0, 6.0, 6.0, 1.0, 3.0, 3.0, 4.0, 5.0, 4.0, 1.0, 4.0, 4.0, 5.0, 4.0, 2.0, 3.0, 6.0, 6.0, 4.0, 8.0, 5.0, 2.0, 4.0, 4.0, 3.0, 4.0, 3.0, 3.0, 3.0, 3.0, 1.0, 3.0, 7.0, 7.0, 9.0, 2.0, 2.0, 3.0, 1.0, 6.0, 5.0, 5.0, 6.0, 6.0, 5.0, 5.0, 4.0, 6.0, 3.0, 7.0, 2.0, 2.0, 3.0, 5.0, 6.0, 7.0, 6.0, 3.0, 4.0, 3.0, 3.0, 4.0, 4.0, 1.0, 1.0, 0.0, 0.0, 6.0, 8.0, 8.0, 6.0, 8.0, 4.0, 6.0, 2.0, 2.0, 4.0, 6.0, 5.0, 1.0, 3.0, 2.0, 2.0, 3.0, 0.0, 3.0, 1.0, 9.0, 7.0, 5.0, 7.0, 4.0, 2.0, 4.0, 2.0, 1.0, 3.0, 1.0, 2.0, 4.0, 6.0, 6.0, 5.0, 4.0, 2.0, 4.0, 1.0, 2.0, 1.0, 4.0, 2.0, 4.0, 3.0, 3.0, 3.0, 5.0, 4.0, 7.0, 5.0, 3.0, 4.0, 1.0, 5.0, 3.0, 3.0, 5.0, 5.0, 2.0, 2.0, 1.0, 1.0, 3.0, 2.0, 2.0, 2.0, 3.0, 3.0, 4.0, 3.0, 5.0, 4.0, 3.0, 5.0, 4.0, 3.0, 2.0, 3.0, 4.0, 4.0, 6.0, 7.0, 4.0, 4.0, 4.0, 4.0, 5.0, 3.0, 7.0, 6.0, 2.0, 4.0, 4.0, 2.0, 2.0, 3.0, 2.0, 1.0, 2.0, 6.0, 4.0, 6.0, 4.0, 4.0, 3.0, 2.0, 4.0, 4.0, 4.0, 4.0, 8.0, 5.0, 6.0, 6.0, 3.0, 5.0, 4.0, 6.0, 6.0, 7.0, 5.0, 5.0, 2.0, 4.0, 2.0, 3.0, 2.0, 1.0, 1.0, 0.0, 4.0, 1.0, 3.0, 4.0, 5.0, 6.0, 6.0, 7.0, 5.0, 5.0, 6.0, 2.0, 3.0, 3.0, 3.0, 2.0, 1.0, 4.0, 3.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0, 6.0, 8.0, 5.0, 7.0, 4.0, 6.0, 6.0, 3.0, 4.0, 6.0, 3.0, 2.0, 2.0, 1.0, 1.0, 5.0, 4.0, 7.0, 7.0, 4.0, 3.0, 0.0, 3.0, 4.0, 3.0, 3.0, 5.0, 6.0, 7.0, 4.0, 4.0, 3.0, 5.0, 4.0, 4.0, 2.0, 1.0, 2.0, 1.0, 3.0, 2.0, 3.0, 3.0, 4.0, 3.0, 6.0, 3.0, 1.0, 1.0, 1.0, 2.0, 3.0, 6.0, 5.0, 2.0, 7.0, 5.0, 6.0, 5.0, 3.0, 4.0, 2.0, 4.0, 3.0, 4.0, 5.0, 6.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.1339522370602106, "mean_inference_ms": 0.3910096518652844, "mean_action_processing_ms": 0.02917624214295971, "mean_env_wait_ms": 0.40293701962078843, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 1879920, "timesteps_this_iter": 0, "agent_timesteps_total": 7519680, "timers": {"sample_time_ms": 5168.985, "sample_throughput": 975.046, "load_time_ms": 0.184, "load_throughput": 27332935.299, "learn_time_ms": 169.648, "learn_throughput": 29708.593, "update_time_ms": 2.901}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 404.8309326171875, "policy_entropy": 7526.527099609375, "policy_loss": 63.51698446273804, "vf_loss": 125.67838478088379}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 1879920, "num_agent_steps_sampled": 7519680, "num_steps_trained": 1879920, "num_agent_steps_trained": 7519680, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 3756, "training_iteration": 187, "trial_id": "71426_00000", "experiment_id": "84bca2f7b35f43248fca18d21abe2ebf", "date": "2024-06-12_03-17-59", "timestamp": 1718129879, "time_this_iter_s": 10.237536907196045, "time_total_s": 1925.7292087078094, "pid": 363902, "hostname": "DESKTOP-LQ219J4", "node_ip": "192.168.46.185", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 20, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 5000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 500, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Base_Model", "custom_model_config": {"env": "rware", "env_args": {"n_agents": 4, "column_height": 1, "max_inactivity_steps": null, "max_steps": 500, "fast_obs": true, "msg_bits": 0, "sensor_range": 1, "shelf_rows": 1, "shelf_columns": 3, "request_queue_size": 4, "reward_type": "RewardType.INDIVIDUAL", "map_name": "customized_map", "map_size": "tiny", "difficulty": "medium"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": true, "force_coop": false, "local_mode": true, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 4, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 100, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64}, "algorithm": "ia2c", "space_obs": "Dict(obs:Box([-100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100.], [100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.], (112,), float32))", "space_act": "Discrete(5)", "num_agents": 4, "episode_limit": 500, "policy_mapping_info": {"all_scenario": {"description": "rware all scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2", "agent_3"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "rware_customized_map", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 10, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.IA2CTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_il.<locals>.<lambda> at 0x7f38086c1c10>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "grad_clip": 40.0, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "microbatch_size": null}, "time_since_restore": 1925.7292087078094, "timesteps_since_restore": 0, "iterations_since_restore": 187, "perf": {"cpu_util_percent": 4.486666666666666, "ram_util_percent": 83.96666666666667}}
{"episode_reward_max": 28.0, "episode_reward_min": 2.0, "episode_reward_mean": 14.63, "episode_len_mean": 500.0, "episode_media": {}, "episodes_this_iter": 24, "policy_reward_min": {"shared_policy": 0.0}, "policy_reward_max": {"shared_policy": 9.0}, "policy_reward_mean": {"shared_policy": 3.6575}, "custom_metrics": {}, "hist_stats": {"episode_reward": [12.0, 11.0, 12.0, 21.0, 11.0, 14.0, 15.0, 19.0, 19.0, 14.0, 10.0, 26.0, 8.0, 22.0, 20.0, 18.0, 16.0, 20.0, 14.0, 2.0, 28.0, 20.0, 17.0, 8.0, 7.0, 28.0, 12.0, 7.0, 21.0, 11.0, 9.0, 13.0, 21.0, 13.0, 16.0, 6.0, 9.0, 13.0, 17.0, 12.0, 21.0, 16.0, 21.0, 12.0, 8.0, 18.0, 13.0, 16.0, 25.0, 18.0, 23.0, 11.0, 4.0, 12.0, 24.0, 18.0, 11.0, 11.0, 8.0, 21.0, 23.0, 16.0, 6.0, 23.0, 10.0, 15.0, 21.0, 16.0, 6.0, 11.0, 16.0, 5.0, 16.0, 23.0, 13.0, 18.0, 18.0, 19.0, 16.0, 2.0, 13.0, 16.0, 11.0, 13.0, 10.0, 15.0, 14.0, 23.0, 20.0, 10.0, 10.0, 16.0, 16.0, 15.0, 11.0, 10.0, 9.0, 9.0, 16.0, 10.0], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500], "policy_shared_policy_reward": [3.0, 3.0, 2.0, 4.0, 4.0, 2.0, 2.0, 3.0, 3.0, 3.0, 3.0, 3.0, 5.0, 4.0, 6.0, 6.0, 1.0, 3.0, 3.0, 4.0, 5.0, 4.0, 1.0, 4.0, 4.0, 5.0, 4.0, 2.0, 3.0, 6.0, 6.0, 4.0, 8.0, 5.0, 2.0, 4.0, 4.0, 3.0, 4.0, 3.0, 3.0, 3.0, 3.0, 1.0, 3.0, 7.0, 7.0, 9.0, 2.0, 2.0, 3.0, 1.0, 6.0, 5.0, 5.0, 6.0, 6.0, 5.0, 5.0, 4.0, 6.0, 3.0, 7.0, 2.0, 2.0, 3.0, 5.0, 6.0, 7.0, 6.0, 3.0, 4.0, 3.0, 3.0, 4.0, 4.0, 1.0, 1.0, 0.0, 0.0, 6.0, 8.0, 8.0, 6.0, 8.0, 4.0, 6.0, 2.0, 2.0, 4.0, 6.0, 5.0, 1.0, 3.0, 2.0, 2.0, 3.0, 0.0, 3.0, 1.0, 9.0, 7.0, 5.0, 7.0, 4.0, 2.0, 4.0, 2.0, 1.0, 3.0, 1.0, 2.0, 4.0, 6.0, 6.0, 5.0, 4.0, 2.0, 4.0, 1.0, 2.0, 1.0, 4.0, 2.0, 4.0, 3.0, 3.0, 3.0, 5.0, 4.0, 7.0, 5.0, 3.0, 4.0, 1.0, 5.0, 3.0, 3.0, 5.0, 5.0, 2.0, 2.0, 1.0, 1.0, 3.0, 2.0, 2.0, 2.0, 3.0, 3.0, 4.0, 3.0, 5.0, 4.0, 3.0, 5.0, 4.0, 3.0, 2.0, 3.0, 4.0, 4.0, 6.0, 7.0, 4.0, 4.0, 4.0, 4.0, 5.0, 3.0, 7.0, 6.0, 2.0, 4.0, 4.0, 2.0, 2.0, 3.0, 2.0, 1.0, 2.0, 6.0, 4.0, 6.0, 4.0, 4.0, 3.0, 2.0, 4.0, 4.0, 4.0, 4.0, 8.0, 5.0, 6.0, 6.0, 3.0, 5.0, 4.0, 6.0, 6.0, 7.0, 5.0, 5.0, 2.0, 4.0, 2.0, 3.0, 2.0, 1.0, 1.0, 0.0, 4.0, 1.0, 3.0, 4.0, 5.0, 6.0, 6.0, 7.0, 5.0, 5.0, 6.0, 2.0, 3.0, 3.0, 3.0, 2.0, 1.0, 4.0, 3.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0, 6.0, 8.0, 5.0, 7.0, 4.0, 6.0, 6.0, 3.0, 4.0, 6.0, 3.0, 2.0, 2.0, 1.0, 1.0, 5.0, 4.0, 7.0, 7.0, 4.0, 3.0, 0.0, 3.0, 4.0, 3.0, 3.0, 5.0, 6.0, 7.0, 4.0, 4.0, 3.0, 5.0, 4.0, 4.0, 2.0, 1.0, 2.0, 1.0, 3.0, 2.0, 3.0, 3.0, 4.0, 3.0, 6.0, 3.0, 1.0, 1.0, 1.0, 2.0, 3.0, 6.0, 5.0, 2.0, 7.0, 5.0, 6.0, 5.0, 3.0, 4.0, 2.0, 4.0, 3.0, 4.0, 5.0, 6.0, 5.0, 4.0, 5.0, 4.0, 4.0, 6.0, 4.0, 5.0, 4.0, 6.0, 2.0, 4.0, 0.0, 1.0, 1.0, 0.0, 3.0, 4.0, 2.0, 4.0, 4.0, 3.0, 6.0, 3.0, 3.0, 1.0, 4.0, 3.0, 5.0, 3.0, 3.0, 2.0, 3.0, 2.0, 3.0, 2.0, 5.0, 2.0, 5.0, 3.0, 2.0, 2.0, 4.0, 6.0, 6.0, 5.0, 5.0, 7.0, 8.0, 4.0, 3.0, 5.0, 2.0, 2.0, 3.0, 3.0, 2.0, 3.0, 3.0, 2.0, 3.0, 4.0, 4.0, 5.0, 5.0, 4.0, 4.0, 3.0, 6.0, 3.0, 3.0, 3.0, 4.0, 2.0, 2.0, 3.0, 4.0, 2.0, 1.0, 3.0, 3.0, 2.0, 3.0, 1.0, 1.0, 2.0, 3.0, 3.0, 4.0, 4.0, 4.0, 4.0, 4.0, 3.0, 1.0, 2.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.1339358563651869, "mean_inference_ms": 0.3909883878714237, "mean_action_processing_ms": 0.029172553768026056, "mean_env_wait_ms": 0.4028993365119049, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 1890000, "timesteps_this_iter": 0, "agent_timesteps_total": 7560000, "timers": {"sample_time_ms": 5162.815, "sample_throughput": 976.212, "load_time_ms": 0.176, "load_throughput": 28667334.093, "learn_time_ms": 159.436, "learn_throughput": 31611.466, "update_time_ms": 2.605}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 417.6586608886719, "policy_entropy": 7557.1453857421875, "policy_loss": -3.3038434982299805, "vf_loss": 131.92404174804688}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 1890000, "num_agent_steps_sampled": 7560000, "num_steps_trained": 1890000, "num_agent_steps_trained": 7560000, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 3780, "training_iteration": 188, "trial_id": "71426_00000", "experiment_id": "84bca2f7b35f43248fca18d21abe2ebf", "date": "2024-06-12_03-18-10", "timestamp": 1718129890, "time_this_iter_s": 10.310486316680908, "time_total_s": 1936.0396950244904, "pid": 363902, "hostname": "DESKTOP-LQ219J4", "node_ip": "192.168.46.185", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 20, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 5000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 500, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Base_Model", "custom_model_config": {"env": "rware", "env_args": {"n_agents": 4, "column_height": 1, "max_inactivity_steps": null, "max_steps": 500, "fast_obs": true, "msg_bits": 0, "sensor_range": 1, "shelf_rows": 1, "shelf_columns": 3, "request_queue_size": 4, "reward_type": "RewardType.INDIVIDUAL", "map_name": "customized_map", "map_size": "tiny", "difficulty": "medium"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": true, "force_coop": false, "local_mode": true, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 4, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 100, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64}, "algorithm": "ia2c", "space_obs": "Dict(obs:Box([-100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100.], [100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.], (112,), float32))", "space_act": "Discrete(5)", "num_agents": 4, "episode_limit": 500, "policy_mapping_info": {"all_scenario": {"description": "rware all scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2", "agent_3"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "rware_customized_map", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 10, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.IA2CTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_il.<locals>.<lambda> at 0x7f38086c1ca0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "grad_clip": 40.0, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "microbatch_size": null}, "time_since_restore": 1936.0396950244904, "timesteps_since_restore": 0, "iterations_since_restore": 188, "perf": {"cpu_util_percent": 4.28, "ram_util_percent": 84.25999999999999}}
{"episode_reward_max": 28.0, "episode_reward_min": 2.0, "episode_reward_mean": 14.29, "episode_len_mean": 500.0, "episode_media": {}, "episodes_this_iter": 20, "policy_reward_min": {"shared_policy": 0.0}, "policy_reward_max": {"shared_policy": 9.0}, "policy_reward_mean": {"shared_policy": 3.5725}, "custom_metrics": {}, "hist_stats": {"episode_reward": [28.0, 20.0, 17.0, 8.0, 7.0, 28.0, 12.0, 7.0, 21.0, 11.0, 9.0, 13.0, 21.0, 13.0, 16.0, 6.0, 9.0, 13.0, 17.0, 12.0, 21.0, 16.0, 21.0, 12.0, 8.0, 18.0, 13.0, 16.0, 25.0, 18.0, 23.0, 11.0, 4.0, 12.0, 24.0, 18.0, 11.0, 11.0, 8.0, 21.0, 23.0, 16.0, 6.0, 23.0, 10.0, 15.0, 21.0, 16.0, 6.0, 11.0, 16.0, 5.0, 16.0, 23.0, 13.0, 18.0, 18.0, 19.0, 16.0, 2.0, 13.0, 16.0, 11.0, 13.0, 10.0, 15.0, 14.0, 23.0, 20.0, 10.0, 10.0, 16.0, 16.0, 15.0, 11.0, 10.0, 9.0, 9.0, 16.0, 10.0, 11.0, 17.0, 11.0, 17.0, 12.0, 17.0, 20.0, 16.0, 12.0, 20.0, 4.0, 20.0, 19.0, 9.0, 11.0, 11.0, 9.0, 7.0, 13.0, 14.0], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500], "policy_shared_policy_reward": [6.0, 8.0, 8.0, 6.0, 8.0, 4.0, 6.0, 2.0, 2.0, 4.0, 6.0, 5.0, 1.0, 3.0, 2.0, 2.0, 3.0, 0.0, 3.0, 1.0, 9.0, 7.0, 5.0, 7.0, 4.0, 2.0, 4.0, 2.0, 1.0, 3.0, 1.0, 2.0, 4.0, 6.0, 6.0, 5.0, 4.0, 2.0, 4.0, 1.0, 2.0, 1.0, 4.0, 2.0, 4.0, 3.0, 3.0, 3.0, 5.0, 4.0, 7.0, 5.0, 3.0, 4.0, 1.0, 5.0, 3.0, 3.0, 5.0, 5.0, 2.0, 2.0, 1.0, 1.0, 3.0, 2.0, 2.0, 2.0, 3.0, 3.0, 4.0, 3.0, 5.0, 4.0, 3.0, 5.0, 4.0, 3.0, 2.0, 3.0, 4.0, 4.0, 6.0, 7.0, 4.0, 4.0, 4.0, 4.0, 5.0, 3.0, 7.0, 6.0, 2.0, 4.0, 4.0, 2.0, 2.0, 3.0, 2.0, 1.0, 2.0, 6.0, 4.0, 6.0, 4.0, 4.0, 3.0, 2.0, 4.0, 4.0, 4.0, 4.0, 8.0, 5.0, 6.0, 6.0, 3.0, 5.0, 4.0, 6.0, 6.0, 7.0, 5.0, 5.0, 2.0, 4.0, 2.0, 3.0, 2.0, 1.0, 1.0, 0.0, 4.0, 1.0, 3.0, 4.0, 5.0, 6.0, 6.0, 7.0, 5.0, 5.0, 6.0, 2.0, 3.0, 3.0, 3.0, 2.0, 1.0, 4.0, 3.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0, 6.0, 8.0, 5.0, 7.0, 4.0, 6.0, 6.0, 3.0, 4.0, 6.0, 3.0, 2.0, 2.0, 1.0, 1.0, 5.0, 4.0, 7.0, 7.0, 4.0, 3.0, 0.0, 3.0, 4.0, 3.0, 3.0, 5.0, 6.0, 7.0, 4.0, 4.0, 3.0, 5.0, 4.0, 4.0, 2.0, 1.0, 2.0, 1.0, 3.0, 2.0, 3.0, 3.0, 4.0, 3.0, 6.0, 3.0, 1.0, 1.0, 1.0, 2.0, 3.0, 6.0, 5.0, 2.0, 7.0, 5.0, 6.0, 5.0, 3.0, 4.0, 2.0, 4.0, 3.0, 4.0, 5.0, 6.0, 5.0, 4.0, 5.0, 4.0, 4.0, 6.0, 4.0, 5.0, 4.0, 6.0, 2.0, 4.0, 0.0, 1.0, 1.0, 0.0, 3.0, 4.0, 2.0, 4.0, 4.0, 3.0, 6.0, 3.0, 3.0, 1.0, 4.0, 3.0, 5.0, 3.0, 3.0, 2.0, 3.0, 2.0, 3.0, 2.0, 5.0, 2.0, 5.0, 3.0, 2.0, 2.0, 4.0, 6.0, 6.0, 5.0, 5.0, 7.0, 8.0, 4.0, 3.0, 5.0, 2.0, 2.0, 3.0, 3.0, 2.0, 3.0, 3.0, 2.0, 3.0, 4.0, 4.0, 5.0, 5.0, 4.0, 4.0, 3.0, 6.0, 3.0, 3.0, 3.0, 4.0, 2.0, 2.0, 3.0, 4.0, 2.0, 1.0, 3.0, 3.0, 2.0, 3.0, 1.0, 1.0, 2.0, 3.0, 3.0, 4.0, 4.0, 4.0, 4.0, 4.0, 3.0, 1.0, 2.0, 3.0, 3.0, 3.0, 2.0, 6.0, 2.0, 3.0, 6.0, 2.0, 3.0, 2.0, 4.0, 4.0, 3.0, 6.0, 4.0, 4.0, 3.0, 2.0, 3.0, 4.0, 5.0, 4.0, 4.0, 5.0, 6.0, 6.0, 3.0, 5.0, 5.0, 3.0, 3.0, 4.0, 3.0, 3.0, 2.0, 4.0, 7.0, 5.0, 4.0, 1.0, 1.0, 1.0, 1.0, 7.0, 6.0, 3.0, 4.0, 4.0, 7.0, 5.0, 3.0, 2.0, 1.0, 3.0, 3.0, 3.0, 4.0, 0.0, 4.0, 1.0, 3.0, 4.0, 3.0, 1.0, 3.0, 2.0, 3.0, 1.0, 1.0, 2.0, 3.0, 4.0, 3.0, 3.0, 3.0, 6.0, 4.0, 3.0, 1.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.13393581284650125, "mean_inference_ms": 0.39099027951811494, "mean_action_processing_ms": 0.029172493776217678, "mean_env_wait_ms": 0.4028865647636607, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 1900080, "timesteps_this_iter": 0, "agent_timesteps_total": 7600320, "timers": {"sample_time_ms": 5161.044, "sample_throughput": 976.547, "load_time_ms": 0.186, "load_throughput": 27167834.674, "learn_time_ms": 145.646, "learn_throughput": 34604.548, "update_time_ms": 2.552}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 444.8890380859375, "policy_entropy": 7598.0714111328125, "policy_loss": -74.61483478546143, "vf_loss": 104.1092700958252}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 1900080, "num_agent_steps_sampled": 7600320, "num_steps_trained": 1900080, "num_agent_steps_trained": 7600320, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 3800, "training_iteration": 189, "trial_id": "71426_00000", "experiment_id": "84bca2f7b35f43248fca18d21abe2ebf", "date": "2024-06-12_03-18-20", "timestamp": 1718129900, "time_this_iter_s": 10.27016568183899, "time_total_s": 1946.3098607063293, "pid": 363902, "hostname": "DESKTOP-LQ219J4", "node_ip": "192.168.46.185", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 20, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 5000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 500, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Base_Model", "custom_model_config": {"env": "rware", "env_args": {"n_agents": 4, "column_height": 1, "max_inactivity_steps": null, "max_steps": 500, "fast_obs": true, "msg_bits": 0, "sensor_range": 1, "shelf_rows": 1, "shelf_columns": 3, "request_queue_size": 4, "reward_type": "RewardType.INDIVIDUAL", "map_name": "customized_map", "map_size": "tiny", "difficulty": "medium"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": true, "force_coop": false, "local_mode": true, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 4, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 100, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64}, "algorithm": "ia2c", "space_obs": "Dict(obs:Box([-100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100.], [100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.], (112,), float32))", "space_act": "Discrete(5)", "num_agents": 4, "episode_limit": 500, "policy_mapping_info": {"all_scenario": {"description": "rware all scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2", "agent_3"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "rware_customized_map", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 10, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.IA2CTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_il.<locals>.<lambda> at 0x7f380824d430>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "grad_clip": 40.0, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "microbatch_size": null}, "time_since_restore": 1946.3098607063293, "timesteps_since_restore": 0, "iterations_since_restore": 189, "perf": {"cpu_util_percent": 4.264285714285714, "ram_util_percent": 84.52142857142857}}
{"episode_reward_max": 25.0, "episode_reward_min": 2.0, "episode_reward_mean": 14.24, "episode_len_mean": 500.0, "episode_media": {}, "episodes_this_iter": 20, "policy_reward_min": {"shared_policy": 0.0}, "policy_reward_max": {"shared_policy": 8.0}, "policy_reward_mean": {"shared_policy": 3.56}, "custom_metrics": {}, "hist_stats": {"episode_reward": [21.0, 16.0, 21.0, 12.0, 8.0, 18.0, 13.0, 16.0, 25.0, 18.0, 23.0, 11.0, 4.0, 12.0, 24.0, 18.0, 11.0, 11.0, 8.0, 21.0, 23.0, 16.0, 6.0, 23.0, 10.0, 15.0, 21.0, 16.0, 6.0, 11.0, 16.0, 5.0, 16.0, 23.0, 13.0, 18.0, 18.0, 19.0, 16.0, 2.0, 13.0, 16.0, 11.0, 13.0, 10.0, 15.0, 14.0, 23.0, 20.0, 10.0, 10.0, 16.0, 16.0, 15.0, 11.0, 10.0, 9.0, 9.0, 16.0, 10.0, 11.0, 17.0, 11.0, 17.0, 12.0, 17.0, 20.0, 16.0, 12.0, 20.0, 4.0, 20.0, 19.0, 9.0, 11.0, 11.0, 9.0, 7.0, 13.0, 14.0, 5.0, 16.0, 10.0, 8.0, 11.0, 19.0, 9.0, 18.0, 14.0, 13.0, 23.0, 14.0, 19.0, 15.0, 21.0, 16.0, 10.0, 11.0, 16.0, 15.0], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500], "policy_shared_policy_reward": [4.0, 4.0, 6.0, 7.0, 4.0, 4.0, 4.0, 4.0, 5.0, 3.0, 7.0, 6.0, 2.0, 4.0, 4.0, 2.0, 2.0, 3.0, 2.0, 1.0, 2.0, 6.0, 4.0, 6.0, 4.0, 4.0, 3.0, 2.0, 4.0, 4.0, 4.0, 4.0, 8.0, 5.0, 6.0, 6.0, 3.0, 5.0, 4.0, 6.0, 6.0, 7.0, 5.0, 5.0, 2.0, 4.0, 2.0, 3.0, 2.0, 1.0, 1.0, 0.0, 4.0, 1.0, 3.0, 4.0, 5.0, 6.0, 6.0, 7.0, 5.0, 5.0, 6.0, 2.0, 3.0, 3.0, 3.0, 2.0, 1.0, 4.0, 3.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0, 6.0, 8.0, 5.0, 7.0, 4.0, 6.0, 6.0, 3.0, 4.0, 6.0, 3.0, 2.0, 2.0, 1.0, 1.0, 5.0, 4.0, 7.0, 7.0, 4.0, 3.0, 0.0, 3.0, 4.0, 3.0, 3.0, 5.0, 6.0, 7.0, 4.0, 4.0, 3.0, 5.0, 4.0, 4.0, 2.0, 1.0, 2.0, 1.0, 3.0, 2.0, 3.0, 3.0, 4.0, 3.0, 6.0, 3.0, 1.0, 1.0, 1.0, 2.0, 3.0, 6.0, 5.0, 2.0, 7.0, 5.0, 6.0, 5.0, 3.0, 4.0, 2.0, 4.0, 3.0, 4.0, 5.0, 6.0, 5.0, 4.0, 5.0, 4.0, 4.0, 6.0, 4.0, 5.0, 4.0, 6.0, 2.0, 4.0, 0.0, 1.0, 1.0, 0.0, 3.0, 4.0, 2.0, 4.0, 4.0, 3.0, 6.0, 3.0, 3.0, 1.0, 4.0, 3.0, 5.0, 3.0, 3.0, 2.0, 3.0, 2.0, 3.0, 2.0, 5.0, 2.0, 5.0, 3.0, 2.0, 2.0, 4.0, 6.0, 6.0, 5.0, 5.0, 7.0, 8.0, 4.0, 3.0, 5.0, 2.0, 2.0, 3.0, 3.0, 2.0, 3.0, 3.0, 2.0, 3.0, 4.0, 4.0, 5.0, 5.0, 4.0, 4.0, 3.0, 6.0, 3.0, 3.0, 3.0, 4.0, 2.0, 2.0, 3.0, 4.0, 2.0, 1.0, 3.0, 3.0, 2.0, 3.0, 1.0, 1.0, 2.0, 3.0, 3.0, 4.0, 4.0, 4.0, 4.0, 4.0, 3.0, 1.0, 2.0, 3.0, 3.0, 3.0, 2.0, 6.0, 2.0, 3.0, 6.0, 2.0, 3.0, 2.0, 4.0, 4.0, 3.0, 6.0, 4.0, 4.0, 3.0, 2.0, 3.0, 4.0, 5.0, 4.0, 4.0, 5.0, 6.0, 6.0, 3.0, 5.0, 5.0, 3.0, 3.0, 4.0, 3.0, 3.0, 2.0, 4.0, 7.0, 5.0, 4.0, 1.0, 1.0, 1.0, 1.0, 7.0, 6.0, 3.0, 4.0, 4.0, 7.0, 5.0, 3.0, 2.0, 1.0, 3.0, 3.0, 3.0, 4.0, 0.0, 4.0, 1.0, 3.0, 4.0, 3.0, 1.0, 3.0, 2.0, 3.0, 1.0, 1.0, 2.0, 3.0, 4.0, 3.0, 3.0, 3.0, 6.0, 4.0, 3.0, 1.0, 1.0, 1.0, 2.0, 1.0, 3.0, 4.0, 5.0, 4.0, 3.0, 3.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 3.0, 5.0, 2.0, 1.0, 3.0, 4.0, 5.0, 7.0, 3.0, 1.0, 2.0, 3.0, 4.0, 2.0, 5.0, 7.0, 3.0, 4.0, 3.0, 4.0, 5.0, 4.0, 1.0, 3.0, 7.0, 4.0, 8.0, 4.0, 4.0, 4.0, 3.0, 3.0, 6.0, 5.0, 3.0, 5.0, 3.0, 3.0, 3.0, 6.0, 5.0, 4.0, 7.0, 5.0, 5.0, 5.0, 4.0, 2.0, 4.0, 2.0, 1.0, 3.0, 3.0, 2.0, 4.0, 2.0, 5.0, 3.0, 3.0, 5.0, 5.0, 4.0, 3.0, 3.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.13393423184586994, "mean_inference_ms": 0.39098939195212057, "mean_action_processing_ms": 0.029172305256271888, "mean_env_wait_ms": 0.4028621480637867, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 1910160, "timesteps_this_iter": 0, "agent_timesteps_total": 7640640, "timers": {"sample_time_ms": 5137.116, "sample_throughput": 981.095, "load_time_ms": 0.19, "load_throughput": 26553563.824, "learn_time_ms": 148.756, "learn_throughput": 33880.948, "update_time_ms": 2.484}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 386.4586181640625, "policy_entropy": 7633.4940185546875, "policy_loss": -15.751306533813477, "vf_loss": 127.49118041992188}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 1910160, "num_agent_steps_sampled": 7640640, "num_steps_trained": 1910160, "num_agent_steps_trained": 7640640, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 3820, "training_iteration": 190, "trial_id": "71426_00000", "experiment_id": "84bca2f7b35f43248fca18d21abe2ebf", "date": "2024-06-12_03-18-30", "timestamp": 1718129910, "time_this_iter_s": 10.262361288070679, "time_total_s": 1956.5722219944, "pid": 363902, "hostname": "DESKTOP-LQ219J4", "node_ip": "192.168.46.185", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 20, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 5000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 500, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Base_Model", "custom_model_config": {"env": "rware", "env_args": {"n_agents": 4, "column_height": 1, "max_inactivity_steps": null, "max_steps": 500, "fast_obs": true, "msg_bits": 0, "sensor_range": 1, "shelf_rows": 1, "shelf_columns": 3, "request_queue_size": 4, "reward_type": "RewardType.INDIVIDUAL", "map_name": "customized_map", "map_size": "tiny", "difficulty": "medium"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": true, "force_coop": false, "local_mode": true, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 4, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 100, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64}, "algorithm": "ia2c", "space_obs": "Dict(obs:Box([-100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100.], [100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.], (112,), float32))", "space_act": "Discrete(5)", "num_agents": 4, "episode_limit": 500, "policy_mapping_info": {"all_scenario": {"description": "rware all scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2", "agent_3"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "rware_customized_map", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 10, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.IA2CTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_il.<locals>.<lambda> at 0x7f3808268820>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "grad_clip": 40.0, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "microbatch_size": null}, "time_since_restore": 1956.5722219944, "timesteps_since_restore": 0, "iterations_since_restore": 190, "perf": {"cpu_util_percent": 4.333333333333333, "ram_util_percent": 84.81333333333332}}
{"episode_reward_max": 25.0, "episode_reward_min": 2.0, "episode_reward_mean": 13.59, "episode_len_mean": 500.0, "episode_media": {}, "episodes_this_iter": 20, "policy_reward_min": {"shared_policy": 0.0}, "policy_reward_max": {"shared_policy": 8.0}, "policy_reward_mean": {"shared_policy": 3.3975}, "custom_metrics": {}, "hist_stats": {"episode_reward": [23.0, 16.0, 6.0, 23.0, 10.0, 15.0, 21.0, 16.0, 6.0, 11.0, 16.0, 5.0, 16.0, 23.0, 13.0, 18.0, 18.0, 19.0, 16.0, 2.0, 13.0, 16.0, 11.0, 13.0, 10.0, 15.0, 14.0, 23.0, 20.0, 10.0, 10.0, 16.0, 16.0, 15.0, 11.0, 10.0, 9.0, 9.0, 16.0, 10.0, 11.0, 17.0, 11.0, 17.0, 12.0, 17.0, 20.0, 16.0, 12.0, 20.0, 4.0, 20.0, 19.0, 9.0, 11.0, 11.0, 9.0, 7.0, 13.0, 14.0, 5.0, 16.0, 10.0, 8.0, 11.0, 19.0, 9.0, 18.0, 14.0, 13.0, 23.0, 14.0, 19.0, 15.0, 21.0, 16.0, 10.0, 11.0, 16.0, 15.0, 8.0, 25.0, 8.0, 18.0, 8.0, 13.0, 13.0, 17.0, 11.0, 14.0, 5.0, 4.0, 10.0, 22.0, 5.0, 11.0, 5.0, 9.0, 17.0, 23.0], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500], "policy_shared_policy_reward": [7.0, 4.0, 6.0, 6.0, 3.0, 4.0, 6.0, 3.0, 2.0, 2.0, 1.0, 1.0, 5.0, 4.0, 7.0, 7.0, 4.0, 3.0, 0.0, 3.0, 4.0, 3.0, 3.0, 5.0, 6.0, 7.0, 4.0, 4.0, 3.0, 5.0, 4.0, 4.0, 2.0, 1.0, 2.0, 1.0, 3.0, 2.0, 3.0, 3.0, 4.0, 3.0, 6.0, 3.0, 1.0, 1.0, 1.0, 2.0, 3.0, 6.0, 5.0, 2.0, 7.0, 5.0, 6.0, 5.0, 3.0, 4.0, 2.0, 4.0, 3.0, 4.0, 5.0, 6.0, 5.0, 4.0, 5.0, 4.0, 4.0, 6.0, 4.0, 5.0, 4.0, 6.0, 2.0, 4.0, 0.0, 1.0, 1.0, 0.0, 3.0, 4.0, 2.0, 4.0, 4.0, 3.0, 6.0, 3.0, 3.0, 1.0, 4.0, 3.0, 5.0, 3.0, 3.0, 2.0, 3.0, 2.0, 3.0, 2.0, 5.0, 2.0, 5.0, 3.0, 2.0, 2.0, 4.0, 6.0, 6.0, 5.0, 5.0, 7.0, 8.0, 4.0, 3.0, 5.0, 2.0, 2.0, 3.0, 3.0, 2.0, 3.0, 3.0, 2.0, 3.0, 4.0, 4.0, 5.0, 5.0, 4.0, 4.0, 3.0, 6.0, 3.0, 3.0, 3.0, 4.0, 2.0, 2.0, 3.0, 4.0, 2.0, 1.0, 3.0, 3.0, 2.0, 3.0, 1.0, 1.0, 2.0, 3.0, 3.0, 4.0, 4.0, 4.0, 4.0, 4.0, 3.0, 1.0, 2.0, 3.0, 3.0, 3.0, 2.0, 6.0, 2.0, 3.0, 6.0, 2.0, 3.0, 2.0, 4.0, 4.0, 3.0, 6.0, 4.0, 4.0, 3.0, 2.0, 3.0, 4.0, 5.0, 4.0, 4.0, 5.0, 6.0, 6.0, 3.0, 5.0, 5.0, 3.0, 3.0, 4.0, 3.0, 3.0, 2.0, 4.0, 7.0, 5.0, 4.0, 1.0, 1.0, 1.0, 1.0, 7.0, 6.0, 3.0, 4.0, 4.0, 7.0, 5.0, 3.0, 2.0, 1.0, 3.0, 3.0, 3.0, 4.0, 0.0, 4.0, 1.0, 3.0, 4.0, 3.0, 1.0, 3.0, 2.0, 3.0, 1.0, 1.0, 2.0, 3.0, 4.0, 3.0, 3.0, 3.0, 6.0, 4.0, 3.0, 1.0, 1.0, 1.0, 2.0, 1.0, 3.0, 4.0, 5.0, 4.0, 3.0, 3.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 3.0, 5.0, 2.0, 1.0, 3.0, 4.0, 5.0, 7.0, 3.0, 1.0, 2.0, 3.0, 4.0, 2.0, 5.0, 7.0, 3.0, 4.0, 3.0, 4.0, 5.0, 4.0, 1.0, 3.0, 7.0, 4.0, 8.0, 4.0, 4.0, 4.0, 3.0, 3.0, 6.0, 5.0, 3.0, 5.0, 3.0, 3.0, 3.0, 6.0, 5.0, 4.0, 7.0, 5.0, 5.0, 5.0, 4.0, 2.0, 4.0, 2.0, 1.0, 3.0, 3.0, 2.0, 4.0, 2.0, 5.0, 3.0, 3.0, 5.0, 5.0, 4.0, 3.0, 3.0, 2.0, 2.0, 2.0, 2.0, 7.0, 6.0, 4.0, 8.0, 2.0, 3.0, 2.0, 1.0, 5.0, 6.0, 3.0, 4.0, 4.0, 1.0, 2.0, 1.0, 3.0, 5.0, 3.0, 2.0, 5.0, 3.0, 2.0, 3.0, 4.0, 3.0, 5.0, 5.0, 4.0, 2.0, 3.0, 2.0, 3.0, 4.0, 4.0, 3.0, 1.0, 2.0, 1.0, 1.0, 2.0, 0.0, 1.0, 1.0, 3.0, 3.0, 1.0, 3.0, 5.0, 6.0, 6.0, 5.0, 1.0, 1.0, 2.0, 1.0, 3.0, 2.0, 4.0, 2.0, 2.0, 1.0, 1.0, 1.0, 2.0, 3.0, 3.0, 1.0, 3.0, 5.0, 4.0, 5.0, 7.0, 5.0, 7.0, 4.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.13393301521197165, "mean_inference_ms": 0.3909889440519362, "mean_action_processing_ms": 0.029172434874251748, "mean_env_wait_ms": 0.40283656150085145, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 1920240, "timesteps_this_iter": 0, "agent_timesteps_total": 7680960, "timers": {"sample_time_ms": 5136.639, "sample_throughput": 981.186, "load_time_ms": 0.198, "load_throughput": 25426139.235, "learn_time_ms": 150.079, "learn_throughput": 33582.423, "update_time_ms": 2.456}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 441.6579284667969, "policy_entropy": 7547.486572265625, "policy_loss": -18.72739028930664, "vf_loss": 120.45071601867676}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 1920240, "num_agent_steps_sampled": 7680960, "num_steps_trained": 1920240, "num_agent_steps_trained": 7680960, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 3840, "training_iteration": 191, "trial_id": "71426_00000", "experiment_id": "84bca2f7b35f43248fca18d21abe2ebf", "date": "2024-06-12_03-18-40", "timestamp": 1718129920, "time_this_iter_s": 10.224142789840698, "time_total_s": 1966.7963647842407, "pid": 363902, "hostname": "DESKTOP-LQ219J4", "node_ip": "192.168.46.185", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 20, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 5000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 500, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Base_Model", "custom_model_config": {"env": "rware", "env_args": {"n_agents": 4, "column_height": 1, "max_inactivity_steps": null, "max_steps": 500, "fast_obs": true, "msg_bits": 0, "sensor_range": 1, "shelf_rows": 1, "shelf_columns": 3, "request_queue_size": 4, "reward_type": "RewardType.INDIVIDUAL", "map_name": "customized_map", "map_size": "tiny", "difficulty": "medium"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": true, "force_coop": false, "local_mode": true, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 4, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 100, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64}, "algorithm": "ia2c", "space_obs": "Dict(obs:Box([-100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100.], [100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.], (112,), float32))", "space_act": "Discrete(5)", "num_agents": 4, "episode_limit": 500, "policy_mapping_info": {"all_scenario": {"description": "rware all scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2", "agent_3"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "rware_customized_map", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 10, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.IA2CTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_il.<locals>.<lambda> at 0x7f38082688b0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "grad_clip": 40.0, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "microbatch_size": null}, "time_since_restore": 1966.7963647842407, "timesteps_since_restore": 0, "iterations_since_restore": 191, "perf": {"cpu_util_percent": 4.253333333333333, "ram_util_percent": 85.07333333333334}}
{"episode_reward_max": 28.0, "episode_reward_min": 4.0, "episode_reward_mean": 13.81, "episode_len_mean": 500.0, "episode_media": {}, "episodes_this_iter": 20, "policy_reward_min": {"shared_policy": 0.0}, "policy_reward_max": {"shared_policy": 8.0}, "policy_reward_mean": {"shared_policy": 3.4525}, "custom_metrics": {}, "hist_stats": {"episode_reward": [13.0, 16.0, 11.0, 13.0, 10.0, 15.0, 14.0, 23.0, 20.0, 10.0, 10.0, 16.0, 16.0, 15.0, 11.0, 10.0, 9.0, 9.0, 16.0, 10.0, 11.0, 17.0, 11.0, 17.0, 12.0, 17.0, 20.0, 16.0, 12.0, 20.0, 4.0, 20.0, 19.0, 9.0, 11.0, 11.0, 9.0, 7.0, 13.0, 14.0, 5.0, 16.0, 10.0, 8.0, 11.0, 19.0, 9.0, 18.0, 14.0, 13.0, 23.0, 14.0, 19.0, 15.0, 21.0, 16.0, 10.0, 11.0, 16.0, 15.0, 8.0, 25.0, 8.0, 18.0, 8.0, 13.0, 13.0, 17.0, 11.0, 14.0, 5.0, 4.0, 10.0, 22.0, 5.0, 11.0, 5.0, 9.0, 17.0, 23.0, 11.0, 9.0, 12.0, 23.0, 22.0, 13.0, 17.0, 9.0, 14.0, 10.0, 25.0, 17.0, 18.0, 16.0, 6.0, 12.0, 10.0, 28.0, 17.0, 26.0], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500], "policy_shared_policy_reward": [3.0, 4.0, 2.0, 4.0, 4.0, 3.0, 6.0, 3.0, 3.0, 1.0, 4.0, 3.0, 5.0, 3.0, 3.0, 2.0, 3.0, 2.0, 3.0, 2.0, 5.0, 2.0, 5.0, 3.0, 2.0, 2.0, 4.0, 6.0, 6.0, 5.0, 5.0, 7.0, 8.0, 4.0, 3.0, 5.0, 2.0, 2.0, 3.0, 3.0, 2.0, 3.0, 3.0, 2.0, 3.0, 4.0, 4.0, 5.0, 5.0, 4.0, 4.0, 3.0, 6.0, 3.0, 3.0, 3.0, 4.0, 2.0, 2.0, 3.0, 4.0, 2.0, 1.0, 3.0, 3.0, 2.0, 3.0, 1.0, 1.0, 2.0, 3.0, 3.0, 4.0, 4.0, 4.0, 4.0, 4.0, 3.0, 1.0, 2.0, 3.0, 3.0, 3.0, 2.0, 6.0, 2.0, 3.0, 6.0, 2.0, 3.0, 2.0, 4.0, 4.0, 3.0, 6.0, 4.0, 4.0, 3.0, 2.0, 3.0, 4.0, 5.0, 4.0, 4.0, 5.0, 6.0, 6.0, 3.0, 5.0, 5.0, 3.0, 3.0, 4.0, 3.0, 3.0, 2.0, 4.0, 7.0, 5.0, 4.0, 1.0, 1.0, 1.0, 1.0, 7.0, 6.0, 3.0, 4.0, 4.0, 7.0, 5.0, 3.0, 2.0, 1.0, 3.0, 3.0, 3.0, 4.0, 0.0, 4.0, 1.0, 3.0, 4.0, 3.0, 1.0, 3.0, 2.0, 3.0, 1.0, 1.0, 2.0, 3.0, 4.0, 3.0, 3.0, 3.0, 6.0, 4.0, 3.0, 1.0, 1.0, 1.0, 2.0, 1.0, 3.0, 4.0, 5.0, 4.0, 3.0, 3.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 3.0, 5.0, 2.0, 1.0, 3.0, 4.0, 5.0, 7.0, 3.0, 1.0, 2.0, 3.0, 4.0, 2.0, 5.0, 7.0, 3.0, 4.0, 3.0, 4.0, 5.0, 4.0, 1.0, 3.0, 7.0, 4.0, 8.0, 4.0, 4.0, 4.0, 3.0, 3.0, 6.0, 5.0, 3.0, 5.0, 3.0, 3.0, 3.0, 6.0, 5.0, 4.0, 7.0, 5.0, 5.0, 5.0, 4.0, 2.0, 4.0, 2.0, 1.0, 3.0, 3.0, 2.0, 4.0, 2.0, 5.0, 3.0, 3.0, 5.0, 5.0, 4.0, 3.0, 3.0, 2.0, 2.0, 2.0, 2.0, 7.0, 6.0, 4.0, 8.0, 2.0, 3.0, 2.0, 1.0, 5.0, 6.0, 3.0, 4.0, 4.0, 1.0, 2.0, 1.0, 3.0, 5.0, 3.0, 2.0, 5.0, 3.0, 2.0, 3.0, 4.0, 3.0, 5.0, 5.0, 4.0, 2.0, 3.0, 2.0, 3.0, 4.0, 4.0, 3.0, 1.0, 2.0, 1.0, 1.0, 2.0, 0.0, 1.0, 1.0, 3.0, 3.0, 1.0, 3.0, 5.0, 6.0, 6.0, 5.0, 1.0, 1.0, 2.0, 1.0, 3.0, 2.0, 4.0, 2.0, 2.0, 1.0, 1.0, 1.0, 2.0, 3.0, 3.0, 1.0, 3.0, 5.0, 4.0, 5.0, 7.0, 5.0, 7.0, 4.0, 4.0, 3.0, 1.0, 3.0, 2.0, 2.0, 2.0, 3.0, 3.0, 2.0, 5.0, 2.0, 5.0, 7.0, 5.0, 6.0, 5.0, 4.0, 8.0, 5.0, 4.0, 4.0, 4.0, 1.0, 6.0, 3.0, 5.0, 3.0, 3.0, 3.0, 2.0, 1.0, 2.0, 2.0, 6.0, 4.0, 3.0, 3.0, 2.0, 2.0, 6.0, 6.0, 7.0, 6.0, 5.0, 6.0, 4.0, 2.0, 5.0, 6.0, 4.0, 3.0, 4.0, 4.0, 5.0, 3.0, 1.0, 2.0, 1.0, 2.0, 4.0, 4.0, 2.0, 2.0, 3.0, 2.0, 3.0, 2.0, 6.0, 8.0, 8.0, 6.0, 6.0, 3.0, 4.0, 4.0, 4.0, 7.0, 8.0, 7.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.13393126390553572, "mean_inference_ms": 0.39099005398230974, "mean_action_processing_ms": 0.029172567296164048, "mean_env_wait_ms": 0.40280923720569656, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 1930320, "timesteps_this_iter": 0, "agent_timesteps_total": 7721280, "timers": {"sample_time_ms": 5137.119, "sample_throughput": 981.095, "load_time_ms": 0.197, "load_throughput": 25573786.789, "learn_time_ms": 150.046, "learn_throughput": 33589.739, "update_time_ms": 2.478}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 479.7027587890625, "policy_entropy": 7511.9840087890625, "policy_loss": 85.67986249923706, "vf_loss": 161.13832664489746}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 1930320, "num_agent_steps_sampled": 7721280, "num_steps_trained": 1930320, "num_agent_steps_trained": 7721280, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 3860, "training_iteration": 192, "trial_id": "71426_00000", "experiment_id": "84bca2f7b35f43248fca18d21abe2ebf", "date": "2024-06-12_03-18-51", "timestamp": 1718129931, "time_this_iter_s": 10.211395978927612, "time_total_s": 1977.0077607631683, "pid": 363902, "hostname": "DESKTOP-LQ219J4", "node_ip": "192.168.46.185", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 20, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 5000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 500, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Base_Model", "custom_model_config": {"env": "rware", "env_args": {"n_agents": 4, "column_height": 1, "max_inactivity_steps": null, "max_steps": 500, "fast_obs": true, "msg_bits": 0, "sensor_range": 1, "shelf_rows": 1, "shelf_columns": 3, "request_queue_size": 4, "reward_type": "RewardType.INDIVIDUAL", "map_name": "customized_map", "map_size": "tiny", "difficulty": "medium"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": true, "force_coop": false, "local_mode": true, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 4, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 100, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64}, "algorithm": "ia2c", "space_obs": "Dict(obs:Box([-100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100.], [100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.], (112,), float32))", "space_act": "Discrete(5)", "num_agents": 4, "episode_limit": 500, "policy_mapping_info": {"all_scenario": {"description": "rware all scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2", "agent_3"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "rware_customized_map", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 10, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.IA2CTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_il.<locals>.<lambda> at 0x7f38082f8c10>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "grad_clip": 40.0, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "microbatch_size": null}, "time_since_restore": 1977.0077607631683, "timesteps_since_restore": 0, "iterations_since_restore": 192, "perf": {"cpu_util_percent": 4.271428571428571, "ram_util_percent": 85.42857142857143}}
{"episode_reward_max": 28.0, "episode_reward_min": 3.0, "episode_reward_mean": 14.13, "episode_len_mean": 500.0, "episode_media": {}, "episodes_this_iter": 20, "policy_reward_min": {"shared_policy": 0.0}, "policy_reward_max": {"shared_policy": 10.0}, "policy_reward_mean": {"shared_policy": 3.5325}, "custom_metrics": {}, "hist_stats": {"episode_reward": [11.0, 17.0, 11.0, 17.0, 12.0, 17.0, 20.0, 16.0, 12.0, 20.0, 4.0, 20.0, 19.0, 9.0, 11.0, 11.0, 9.0, 7.0, 13.0, 14.0, 5.0, 16.0, 10.0, 8.0, 11.0, 19.0, 9.0, 18.0, 14.0, 13.0, 23.0, 14.0, 19.0, 15.0, 21.0, 16.0, 10.0, 11.0, 16.0, 15.0, 8.0, 25.0, 8.0, 18.0, 8.0, 13.0, 13.0, 17.0, 11.0, 14.0, 5.0, 4.0, 10.0, 22.0, 5.0, 11.0, 5.0, 9.0, 17.0, 23.0, 11.0, 9.0, 12.0, 23.0, 22.0, 13.0, 17.0, 9.0, 14.0, 10.0, 25.0, 17.0, 18.0, 16.0, 6.0, 12.0, 10.0, 28.0, 17.0, 26.0, 18.0, 15.0, 10.0, 19.0, 11.0, 25.0, 4.0, 13.0, 15.0, 8.0, 15.0, 9.0, 28.0, 14.0, 14.0, 13.0, 3.0, 27.0, 20.0, 18.0], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500], "policy_shared_policy_reward": [3.0, 3.0, 3.0, 2.0, 6.0, 2.0, 3.0, 6.0, 2.0, 3.0, 2.0, 4.0, 4.0, 3.0, 6.0, 4.0, 4.0, 3.0, 2.0, 3.0, 4.0, 5.0, 4.0, 4.0, 5.0, 6.0, 6.0, 3.0, 5.0, 5.0, 3.0, 3.0, 4.0, 3.0, 3.0, 2.0, 4.0, 7.0, 5.0, 4.0, 1.0, 1.0, 1.0, 1.0, 7.0, 6.0, 3.0, 4.0, 4.0, 7.0, 5.0, 3.0, 2.0, 1.0, 3.0, 3.0, 3.0, 4.0, 0.0, 4.0, 1.0, 3.0, 4.0, 3.0, 1.0, 3.0, 2.0, 3.0, 1.0, 1.0, 2.0, 3.0, 4.0, 3.0, 3.0, 3.0, 6.0, 4.0, 3.0, 1.0, 1.0, 1.0, 2.0, 1.0, 3.0, 4.0, 5.0, 4.0, 3.0, 3.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 3.0, 5.0, 2.0, 1.0, 3.0, 4.0, 5.0, 7.0, 3.0, 1.0, 2.0, 3.0, 4.0, 2.0, 5.0, 7.0, 3.0, 4.0, 3.0, 4.0, 5.0, 4.0, 1.0, 3.0, 7.0, 4.0, 8.0, 4.0, 4.0, 4.0, 3.0, 3.0, 6.0, 5.0, 3.0, 5.0, 3.0, 3.0, 3.0, 6.0, 5.0, 4.0, 7.0, 5.0, 5.0, 5.0, 4.0, 2.0, 4.0, 2.0, 1.0, 3.0, 3.0, 2.0, 4.0, 2.0, 5.0, 3.0, 3.0, 5.0, 5.0, 4.0, 3.0, 3.0, 2.0, 2.0, 2.0, 2.0, 7.0, 6.0, 4.0, 8.0, 2.0, 3.0, 2.0, 1.0, 5.0, 6.0, 3.0, 4.0, 4.0, 1.0, 2.0, 1.0, 3.0, 5.0, 3.0, 2.0, 5.0, 3.0, 2.0, 3.0, 4.0, 3.0, 5.0, 5.0, 4.0, 2.0, 3.0, 2.0, 3.0, 4.0, 4.0, 3.0, 1.0, 2.0, 1.0, 1.0, 2.0, 0.0, 1.0, 1.0, 3.0, 3.0, 1.0, 3.0, 5.0, 6.0, 6.0, 5.0, 1.0, 1.0, 2.0, 1.0, 3.0, 2.0, 4.0, 2.0, 2.0, 1.0, 1.0, 1.0, 2.0, 3.0, 3.0, 1.0, 3.0, 5.0, 4.0, 5.0, 7.0, 5.0, 7.0, 4.0, 4.0, 3.0, 1.0, 3.0, 2.0, 2.0, 2.0, 3.0, 3.0, 2.0, 5.0, 2.0, 5.0, 7.0, 5.0, 6.0, 5.0, 4.0, 8.0, 5.0, 4.0, 4.0, 4.0, 1.0, 6.0, 3.0, 5.0, 3.0, 3.0, 3.0, 2.0, 1.0, 2.0, 2.0, 6.0, 4.0, 3.0, 3.0, 2.0, 2.0, 6.0, 6.0, 7.0, 6.0, 5.0, 6.0, 4.0, 2.0, 5.0, 6.0, 4.0, 3.0, 4.0, 4.0, 5.0, 3.0, 1.0, 2.0, 1.0, 2.0, 4.0, 4.0, 2.0, 2.0, 3.0, 2.0, 3.0, 2.0, 6.0, 8.0, 8.0, 6.0, 6.0, 3.0, 4.0, 4.0, 4.0, 7.0, 8.0, 7.0, 5.0, 4.0, 6.0, 3.0, 4.0, 3.0, 3.0, 5.0, 3.0, 3.0, 2.0, 2.0, 7.0, 4.0, 2.0, 6.0, 2.0, 2.0, 4.0, 3.0, 4.0, 7.0, 7.0, 7.0, 1.0, 1.0, 1.0, 1.0, 5.0, 2.0, 3.0, 3.0, 3.0, 4.0, 5.0, 3.0, 2.0, 2.0, 2.0, 2.0, 5.0, 4.0, 3.0, 3.0, 0.0, 3.0, 3.0, 3.0, 7.0, 5.0, 10.0, 6.0, 4.0, 5.0, 3.0, 2.0, 4.0, 4.0, 2.0, 4.0, 2.0, 4.0, 4.0, 3.0, 0.0, 0.0, 1.0, 2.0, 6.0, 9.0, 6.0, 6.0, 7.0, 5.0, 5.0, 3.0, 5.0, 5.0, 4.0, 4.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.13394387808169306, "mean_inference_ms": 0.3910078752757879, "mean_action_processing_ms": 0.02917542642259174, "mean_env_wait_ms": 0.402805499129697, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 1940400, "timesteps_this_iter": 0, "agent_timesteps_total": 7761600, "timers": {"sample_time_ms": 5126.084, "sample_throughput": 983.207, "load_time_ms": 0.197, "load_throughput": 25564508.598, "learn_time_ms": 151.351, "learn_throughput": 33300.004, "update_time_ms": 2.502}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 602.4622802734375, "policy_entropy": 7510.968994140625, "policy_loss": -64.34664058685303, "vf_loss": 146.606294631958}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 1940400, "num_agent_steps_sampled": 7761600, "num_steps_trained": 1940400, "num_agent_steps_trained": 7761600, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 3880, "training_iteration": 193, "trial_id": "71426_00000", "experiment_id": "84bca2f7b35f43248fca18d21abe2ebf", "date": "2024-06-12_03-19-01", "timestamp": 1718129941, "time_this_iter_s": 10.22653603553772, "time_total_s": 1987.234296798706, "pid": 363902, "hostname": "DESKTOP-LQ219J4", "node_ip": "192.168.46.185", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 20, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 5000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 500, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Base_Model", "custom_model_config": {"env": "rware", "env_args": {"n_agents": 4, "column_height": 1, "max_inactivity_steps": null, "max_steps": 500, "fast_obs": true, "msg_bits": 0, "sensor_range": 1, "shelf_rows": 1, "shelf_columns": 3, "request_queue_size": 4, "reward_type": "RewardType.INDIVIDUAL", "map_name": "customized_map", "map_size": "tiny", "difficulty": "medium"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": true, "force_coop": false, "local_mode": true, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 4, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 100, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64}, "algorithm": "ia2c", "space_obs": "Dict(obs:Box([-100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100.], [100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.], (112,), float32))", "space_act": "Discrete(5)", "num_agents": 4, "episode_limit": 500, "policy_mapping_info": {"all_scenario": {"description": "rware all scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2", "agent_3"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "rware_customized_map", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 10, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.IA2CTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_il.<locals>.<lambda> at 0x7f38081d5af0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "grad_clip": 40.0, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "microbatch_size": null}, "time_since_restore": 1987.234296798706, "timesteps_since_restore": 0, "iterations_since_restore": 193, "perf": {"cpu_util_percent": 4.206666666666666, "ram_util_percent": 85.65333333333335}}
{"episode_reward_max": 29.0, "episode_reward_min": 3.0, "episode_reward_mean": 14.69, "episode_len_mean": 500.0, "episode_media": {}, "episodes_this_iter": 20, "policy_reward_min": {"shared_policy": 0.0}, "policy_reward_max": {"shared_policy": 11.0}, "policy_reward_mean": {"shared_policy": 3.6725}, "custom_metrics": {}, "hist_stats": {"episode_reward": [5.0, 16.0, 10.0, 8.0, 11.0, 19.0, 9.0, 18.0, 14.0, 13.0, 23.0, 14.0, 19.0, 15.0, 21.0, 16.0, 10.0, 11.0, 16.0, 15.0, 8.0, 25.0, 8.0, 18.0, 8.0, 13.0, 13.0, 17.0, 11.0, 14.0, 5.0, 4.0, 10.0, 22.0, 5.0, 11.0, 5.0, 9.0, 17.0, 23.0, 11.0, 9.0, 12.0, 23.0, 22.0, 13.0, 17.0, 9.0, 14.0, 10.0, 25.0, 17.0, 18.0, 16.0, 6.0, 12.0, 10.0, 28.0, 17.0, 26.0, 18.0, 15.0, 10.0, 19.0, 11.0, 25.0, 4.0, 13.0, 15.0, 8.0, 15.0, 9.0, 28.0, 14.0, 14.0, 13.0, 3.0, 27.0, 20.0, 18.0, 11.0, 16.0, 14.0, 11.0, 27.0, 7.0, 12.0, 11.0, 28.0, 15.0, 17.0, 26.0, 10.0, 19.0, 15.0, 18.0, 18.0, 29.0, 12.0, 10.0], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500], "policy_shared_policy_reward": [1.0, 1.0, 2.0, 1.0, 3.0, 4.0, 5.0, 4.0, 3.0, 3.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 3.0, 5.0, 2.0, 1.0, 3.0, 4.0, 5.0, 7.0, 3.0, 1.0, 2.0, 3.0, 4.0, 2.0, 5.0, 7.0, 3.0, 4.0, 3.0, 4.0, 5.0, 4.0, 1.0, 3.0, 7.0, 4.0, 8.0, 4.0, 4.0, 4.0, 3.0, 3.0, 6.0, 5.0, 3.0, 5.0, 3.0, 3.0, 3.0, 6.0, 5.0, 4.0, 7.0, 5.0, 5.0, 5.0, 4.0, 2.0, 4.0, 2.0, 1.0, 3.0, 3.0, 2.0, 4.0, 2.0, 5.0, 3.0, 3.0, 5.0, 5.0, 4.0, 3.0, 3.0, 2.0, 2.0, 2.0, 2.0, 7.0, 6.0, 4.0, 8.0, 2.0, 3.0, 2.0, 1.0, 5.0, 6.0, 3.0, 4.0, 4.0, 1.0, 2.0, 1.0, 3.0, 5.0, 3.0, 2.0, 5.0, 3.0, 2.0, 3.0, 4.0, 3.0, 5.0, 5.0, 4.0, 2.0, 3.0, 2.0, 3.0, 4.0, 4.0, 3.0, 1.0, 2.0, 1.0, 1.0, 2.0, 0.0, 1.0, 1.0, 3.0, 3.0, 1.0, 3.0, 5.0, 6.0, 6.0, 5.0, 1.0, 1.0, 2.0, 1.0, 3.0, 2.0, 4.0, 2.0, 2.0, 1.0, 1.0, 1.0, 2.0, 3.0, 3.0, 1.0, 3.0, 5.0, 4.0, 5.0, 7.0, 5.0, 7.0, 4.0, 4.0, 3.0, 1.0, 3.0, 2.0, 2.0, 2.0, 3.0, 3.0, 2.0, 5.0, 2.0, 5.0, 7.0, 5.0, 6.0, 5.0, 4.0, 8.0, 5.0, 4.0, 4.0, 4.0, 1.0, 6.0, 3.0, 5.0, 3.0, 3.0, 3.0, 2.0, 1.0, 2.0, 2.0, 6.0, 4.0, 3.0, 3.0, 2.0, 2.0, 6.0, 6.0, 7.0, 6.0, 5.0, 6.0, 4.0, 2.0, 5.0, 6.0, 4.0, 3.0, 4.0, 4.0, 5.0, 3.0, 1.0, 2.0, 1.0, 2.0, 4.0, 4.0, 2.0, 2.0, 3.0, 2.0, 3.0, 2.0, 6.0, 8.0, 8.0, 6.0, 6.0, 3.0, 4.0, 4.0, 4.0, 7.0, 8.0, 7.0, 5.0, 4.0, 6.0, 3.0, 4.0, 3.0, 3.0, 5.0, 3.0, 3.0, 2.0, 2.0, 7.0, 4.0, 2.0, 6.0, 2.0, 2.0, 4.0, 3.0, 4.0, 7.0, 7.0, 7.0, 1.0, 1.0, 1.0, 1.0, 5.0, 2.0, 3.0, 3.0, 3.0, 4.0, 5.0, 3.0, 2.0, 2.0, 2.0, 2.0, 5.0, 4.0, 3.0, 3.0, 0.0, 3.0, 3.0, 3.0, 7.0, 5.0, 10.0, 6.0, 4.0, 5.0, 3.0, 2.0, 4.0, 4.0, 2.0, 4.0, 2.0, 4.0, 4.0, 3.0, 0.0, 0.0, 1.0, 2.0, 6.0, 9.0, 6.0, 6.0, 7.0, 5.0, 5.0, 3.0, 5.0, 5.0, 4.0, 4.0, 1.0, 4.0, 3.0, 3.0, 3.0, 4.0, 5.0, 4.0, 4.0, 3.0, 1.0, 6.0, 4.0, 3.0, 2.0, 2.0, 7.0, 7.0, 6.0, 7.0, 1.0, 1.0, 2.0, 3.0, 2.0, 5.0, 4.0, 1.0, 3.0, 3.0, 3.0, 2.0, 11.0, 5.0, 6.0, 6.0, 6.0, 3.0, 3.0, 3.0, 5.0, 4.0, 3.0, 5.0, 5.0, 7.0, 5.0, 9.0, 3.0, 2.0, 3.0, 2.0, 5.0, 6.0, 5.0, 3.0, 3.0, 4.0, 2.0, 6.0, 4.0, 4.0, 6.0, 4.0, 5.0, 4.0, 4.0, 5.0, 7.0, 8.0, 6.0, 8.0, 3.0, 3.0, 2.0, 4.0, 1.0, 2.0, 3.0, 4.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.13393927793314914, "mean_inference_ms": 0.39100069679184446, "mean_action_processing_ms": 0.029174656864286632, "mean_env_wait_ms": 0.40277109746688383, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 1950480, "timesteps_this_iter": 0, "agent_timesteps_total": 7801920, "timers": {"sample_time_ms": 5117.849, "sample_throughput": 984.789, "load_time_ms": 0.192, "load_throughput": 26188419.425, "learn_time_ms": 153.918, "learn_throughput": 32744.631, "update_time_ms": 2.5}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 221.28457641601562, "policy_entropy": 7433.1341552734375, "policy_loss": -24.976731777191162, "vf_loss": 148.6614227294922}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 1950480, "num_agent_steps_sampled": 7801920, "num_steps_trained": 1950480, "num_agent_steps_trained": 7801920, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 3900, "training_iteration": 194, "trial_id": "71426_00000", "experiment_id": "84bca2f7b35f43248fca18d21abe2ebf", "date": "2024-06-12_03-19-11", "timestamp": 1718129951, "time_this_iter_s": 10.202378988265991, "time_total_s": 1997.436675786972, "pid": 363902, "hostname": "DESKTOP-LQ219J4", "node_ip": "192.168.46.185", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 20, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 5000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 500, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Base_Model", "custom_model_config": {"env": "rware", "env_args": {"n_agents": 4, "column_height": 1, "max_inactivity_steps": null, "max_steps": 500, "fast_obs": true, "msg_bits": 0, "sensor_range": 1, "shelf_rows": 1, "shelf_columns": 3, "request_queue_size": 4, "reward_type": "RewardType.INDIVIDUAL", "map_name": "customized_map", "map_size": "tiny", "difficulty": "medium"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": true, "force_coop": false, "local_mode": true, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 4, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 100, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64}, "algorithm": "ia2c", "space_obs": "Dict(obs:Box([-100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100.], [100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.], (112,), float32))", "space_act": "Discrete(5)", "num_agents": 4, "episode_limit": 500, "policy_mapping_info": {"all_scenario": {"description": "rware all scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2", "agent_3"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "rware_customized_map", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 10, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.IA2CTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_il.<locals>.<lambda> at 0x7f38082f8f70>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "grad_clip": 40.0, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "microbatch_size": null}, "time_since_restore": 1997.436675786972, "timesteps_since_restore": 0, "iterations_since_restore": 194, "perf": {"cpu_util_percent": 4.4071428571428575, "ram_util_percent": 85.97857142857143}}
{"episode_reward_max": 29.0, "episode_reward_min": 3.0, "episode_reward_mean": 15.06, "episode_len_mean": 500.0, "episode_media": {}, "episodes_this_iter": 20, "policy_reward_min": {"shared_policy": 0.0}, "policy_reward_max": {"shared_policy": 11.0}, "policy_reward_mean": {"shared_policy": 3.765}, "custom_metrics": {}, "hist_stats": {"episode_reward": [8.0, 25.0, 8.0, 18.0, 8.0, 13.0, 13.0, 17.0, 11.0, 14.0, 5.0, 4.0, 10.0, 22.0, 5.0, 11.0, 5.0, 9.0, 17.0, 23.0, 11.0, 9.0, 12.0, 23.0, 22.0, 13.0, 17.0, 9.0, 14.0, 10.0, 25.0, 17.0, 18.0, 16.0, 6.0, 12.0, 10.0, 28.0, 17.0, 26.0, 18.0, 15.0, 10.0, 19.0, 11.0, 25.0, 4.0, 13.0, 15.0, 8.0, 15.0, 9.0, 28.0, 14.0, 14.0, 13.0, 3.0, 27.0, 20.0, 18.0, 11.0, 16.0, 14.0, 11.0, 27.0, 7.0, 12.0, 11.0, 28.0, 15.0, 17.0, 26.0, 10.0, 19.0, 15.0, 18.0, 18.0, 29.0, 12.0, 10.0, 18.0, 13.0, 20.0, 15.0, 9.0, 18.0, 11.0, 13.0, 9.0, 10.0, 12.0, 25.0, 20.0, 23.0, 14.0, 15.0, 21.0, 29.0, 4.0, 21.0], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500], "policy_shared_policy_reward": [2.0, 2.0, 2.0, 2.0, 7.0, 6.0, 4.0, 8.0, 2.0, 3.0, 2.0, 1.0, 5.0, 6.0, 3.0, 4.0, 4.0, 1.0, 2.0, 1.0, 3.0, 5.0, 3.0, 2.0, 5.0, 3.0, 2.0, 3.0, 4.0, 3.0, 5.0, 5.0, 4.0, 2.0, 3.0, 2.0, 3.0, 4.0, 4.0, 3.0, 1.0, 2.0, 1.0, 1.0, 2.0, 0.0, 1.0, 1.0, 3.0, 3.0, 1.0, 3.0, 5.0, 6.0, 6.0, 5.0, 1.0, 1.0, 2.0, 1.0, 3.0, 2.0, 4.0, 2.0, 2.0, 1.0, 1.0, 1.0, 2.0, 3.0, 3.0, 1.0, 3.0, 5.0, 4.0, 5.0, 7.0, 5.0, 7.0, 4.0, 4.0, 3.0, 1.0, 3.0, 2.0, 2.0, 2.0, 3.0, 3.0, 2.0, 5.0, 2.0, 5.0, 7.0, 5.0, 6.0, 5.0, 4.0, 8.0, 5.0, 4.0, 4.0, 4.0, 1.0, 6.0, 3.0, 5.0, 3.0, 3.0, 3.0, 2.0, 1.0, 2.0, 2.0, 6.0, 4.0, 3.0, 3.0, 2.0, 2.0, 6.0, 6.0, 7.0, 6.0, 5.0, 6.0, 4.0, 2.0, 5.0, 6.0, 4.0, 3.0, 4.0, 4.0, 5.0, 3.0, 1.0, 2.0, 1.0, 2.0, 4.0, 4.0, 2.0, 2.0, 3.0, 2.0, 3.0, 2.0, 6.0, 8.0, 8.0, 6.0, 6.0, 3.0, 4.0, 4.0, 4.0, 7.0, 8.0, 7.0, 5.0, 4.0, 6.0, 3.0, 4.0, 3.0, 3.0, 5.0, 3.0, 3.0, 2.0, 2.0, 7.0, 4.0, 2.0, 6.0, 2.0, 2.0, 4.0, 3.0, 4.0, 7.0, 7.0, 7.0, 1.0, 1.0, 1.0, 1.0, 5.0, 2.0, 3.0, 3.0, 3.0, 4.0, 5.0, 3.0, 2.0, 2.0, 2.0, 2.0, 5.0, 4.0, 3.0, 3.0, 0.0, 3.0, 3.0, 3.0, 7.0, 5.0, 10.0, 6.0, 4.0, 5.0, 3.0, 2.0, 4.0, 4.0, 2.0, 4.0, 2.0, 4.0, 4.0, 3.0, 0.0, 0.0, 1.0, 2.0, 6.0, 9.0, 6.0, 6.0, 7.0, 5.0, 5.0, 3.0, 5.0, 5.0, 4.0, 4.0, 1.0, 4.0, 3.0, 3.0, 3.0, 4.0, 5.0, 4.0, 4.0, 3.0, 1.0, 6.0, 4.0, 3.0, 2.0, 2.0, 7.0, 7.0, 6.0, 7.0, 1.0, 1.0, 2.0, 3.0, 2.0, 5.0, 4.0, 1.0, 3.0, 3.0, 3.0, 2.0, 11.0, 5.0, 6.0, 6.0, 6.0, 3.0, 3.0, 3.0, 5.0, 4.0, 3.0, 5.0, 5.0, 7.0, 5.0, 9.0, 3.0, 2.0, 3.0, 2.0, 5.0, 6.0, 5.0, 3.0, 3.0, 4.0, 2.0, 6.0, 4.0, 4.0, 6.0, 4.0, 5.0, 4.0, 4.0, 5.0, 7.0, 8.0, 6.0, 8.0, 3.0, 3.0, 2.0, 4.0, 1.0, 2.0, 3.0, 4.0, 4.0, 3.0, 7.0, 4.0, 3.0, 3.0, 4.0, 3.0, 6.0, 6.0, 4.0, 4.0, 4.0, 3.0, 5.0, 3.0, 3.0, 1.0, 1.0, 4.0, 6.0, 4.0, 3.0, 5.0, 2.0, 3.0, 4.0, 2.0, 3.0, 2.0, 3.0, 5.0, 2.0, 2.0, 2.0, 3.0, 3.0, 2.0, 2.0, 3.0, 3.0, 3.0, 4.0, 2.0, 3.0, 7.0, 6.0, 9.0, 7.0, 2.0, 4.0, 7.0, 3.0, 7.0, 9.0, 4.0, 4.0, 2.0, 4.0, 4.0, 4.0, 2.0, 5.0, 4.0, 5.0, 6.0, 7.0, 3.0, 7.0, 9.0, 5.0, 8.0, 1.0, 1.0, 2.0, 0.0, 5.0, 4.0, 7.0, 5.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.13393362501801712, "mean_inference_ms": 0.39098824805345844, "mean_action_processing_ms": 0.029173692407171794, "mean_env_wait_ms": 0.4027318878890287, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 1960560, "timesteps_this_iter": 0, "agent_timesteps_total": 7842240, "timers": {"sample_time_ms": 5106.722, "sample_throughput": 986.934, "load_time_ms": 0.187, "load_throughput": 26963382.857, "learn_time_ms": 152.34, "learn_throughput": 33083.973, "update_time_ms": 2.49}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 552.0052490234375, "policy_entropy": 7504.803955078125, "policy_loss": -98.15207386016846, "vf_loss": 128.40350723266602}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 1960560, "num_agent_steps_sampled": 7842240, "num_steps_trained": 1960560, "num_agent_steps_trained": 7842240, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 3920, "training_iteration": 195, "trial_id": "71426_00000", "experiment_id": "84bca2f7b35f43248fca18d21abe2ebf", "date": "2024-06-12_03-19-21", "timestamp": 1718129961, "time_this_iter_s": 10.137981176376343, "time_total_s": 2007.5746569633484, "pid": 363902, "hostname": "DESKTOP-LQ219J4", "node_ip": "192.168.46.185", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 20, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 5000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 500, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Base_Model", "custom_model_config": {"env": "rware", "env_args": {"n_agents": 4, "column_height": 1, "max_inactivity_steps": null, "max_steps": 500, "fast_obs": true, "msg_bits": 0, "sensor_range": 1, "shelf_rows": 1, "shelf_columns": 3, "request_queue_size": 4, "reward_type": "RewardType.INDIVIDUAL", "map_name": "customized_map", "map_size": "tiny", "difficulty": "medium"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": true, "force_coop": false, "local_mode": true, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 4, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 100, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64}, "algorithm": "ia2c", "space_obs": "Dict(obs:Box([-100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100.], [100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.], (112,), float32))", "space_act": "Discrete(5)", "num_agents": 4, "episode_limit": 500, "policy_mapping_info": {"all_scenario": {"description": "rware all scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2", "agent_3"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "rware_customized_map", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 10, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.IA2CTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_il.<locals>.<lambda> at 0x7f3808268310>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "grad_clip": 40.0, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "microbatch_size": null}, "time_since_restore": 2007.5746569633484, "timesteps_since_restore": 0, "iterations_since_restore": 195, "perf": {"cpu_util_percent": 4.286666666666665, "ram_util_percent": 86.24}}
{"episode_reward_max": 29.0, "episode_reward_min": 2.0, "episode_reward_mean": 15.54, "episode_len_mean": 500.0, "episode_media": {}, "episodes_this_iter": 20, "policy_reward_min": {"shared_policy": 0.0}, "policy_reward_max": {"shared_policy": 11.0}, "policy_reward_mean": {"shared_policy": 3.885}, "custom_metrics": {}, "hist_stats": {"episode_reward": [11.0, 9.0, 12.0, 23.0, 22.0, 13.0, 17.0, 9.0, 14.0, 10.0, 25.0, 17.0, 18.0, 16.0, 6.0, 12.0, 10.0, 28.0, 17.0, 26.0, 18.0, 15.0, 10.0, 19.0, 11.0, 25.0, 4.0, 13.0, 15.0, 8.0, 15.0, 9.0, 28.0, 14.0, 14.0, 13.0, 3.0, 27.0, 20.0, 18.0, 11.0, 16.0, 14.0, 11.0, 27.0, 7.0, 12.0, 11.0, 28.0, 15.0, 17.0, 26.0, 10.0, 19.0, 15.0, 18.0, 18.0, 29.0, 12.0, 10.0, 18.0, 13.0, 20.0, 15.0, 9.0, 18.0, 11.0, 13.0, 9.0, 10.0, 12.0, 25.0, 20.0, 23.0, 14.0, 15.0, 21.0, 29.0, 4.0, 21.0, 2.0, 22.0, 9.0, 14.0, 23.0, 5.0, 12.0, 10.0, 20.0, 22.0, 15.0, 14.0, 12.0, 17.0, 20.0, 19.0, 15.0, 12.0, 13.0, 18.0], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500], "policy_shared_policy_reward": [4.0, 3.0, 1.0, 3.0, 2.0, 2.0, 2.0, 3.0, 3.0, 2.0, 5.0, 2.0, 5.0, 7.0, 5.0, 6.0, 5.0, 4.0, 8.0, 5.0, 4.0, 4.0, 4.0, 1.0, 6.0, 3.0, 5.0, 3.0, 3.0, 3.0, 2.0, 1.0, 2.0, 2.0, 6.0, 4.0, 3.0, 3.0, 2.0, 2.0, 6.0, 6.0, 7.0, 6.0, 5.0, 6.0, 4.0, 2.0, 5.0, 6.0, 4.0, 3.0, 4.0, 4.0, 5.0, 3.0, 1.0, 2.0, 1.0, 2.0, 4.0, 4.0, 2.0, 2.0, 3.0, 2.0, 3.0, 2.0, 6.0, 8.0, 8.0, 6.0, 6.0, 3.0, 4.0, 4.0, 4.0, 7.0, 8.0, 7.0, 5.0, 4.0, 6.0, 3.0, 4.0, 3.0, 3.0, 5.0, 3.0, 3.0, 2.0, 2.0, 7.0, 4.0, 2.0, 6.0, 2.0, 2.0, 4.0, 3.0, 4.0, 7.0, 7.0, 7.0, 1.0, 1.0, 1.0, 1.0, 5.0, 2.0, 3.0, 3.0, 3.0, 4.0, 5.0, 3.0, 2.0, 2.0, 2.0, 2.0, 5.0, 4.0, 3.0, 3.0, 0.0, 3.0, 3.0, 3.0, 7.0, 5.0, 10.0, 6.0, 4.0, 5.0, 3.0, 2.0, 4.0, 4.0, 2.0, 4.0, 2.0, 4.0, 4.0, 3.0, 0.0, 0.0, 1.0, 2.0, 6.0, 9.0, 6.0, 6.0, 7.0, 5.0, 5.0, 3.0, 5.0, 5.0, 4.0, 4.0, 1.0, 4.0, 3.0, 3.0, 3.0, 4.0, 5.0, 4.0, 4.0, 3.0, 1.0, 6.0, 4.0, 3.0, 2.0, 2.0, 7.0, 7.0, 6.0, 7.0, 1.0, 1.0, 2.0, 3.0, 2.0, 5.0, 4.0, 1.0, 3.0, 3.0, 3.0, 2.0, 11.0, 5.0, 6.0, 6.0, 6.0, 3.0, 3.0, 3.0, 5.0, 4.0, 3.0, 5.0, 5.0, 7.0, 5.0, 9.0, 3.0, 2.0, 3.0, 2.0, 5.0, 6.0, 5.0, 3.0, 3.0, 4.0, 2.0, 6.0, 4.0, 4.0, 6.0, 4.0, 5.0, 4.0, 4.0, 5.0, 7.0, 8.0, 6.0, 8.0, 3.0, 3.0, 2.0, 4.0, 1.0, 2.0, 3.0, 4.0, 4.0, 3.0, 7.0, 4.0, 3.0, 3.0, 4.0, 3.0, 6.0, 6.0, 4.0, 4.0, 4.0, 3.0, 5.0, 3.0, 3.0, 1.0, 1.0, 4.0, 6.0, 4.0, 3.0, 5.0, 2.0, 3.0, 4.0, 2.0, 3.0, 2.0, 3.0, 5.0, 2.0, 2.0, 2.0, 3.0, 3.0, 2.0, 2.0, 3.0, 3.0, 3.0, 4.0, 2.0, 3.0, 7.0, 6.0, 9.0, 7.0, 2.0, 4.0, 7.0, 3.0, 7.0, 9.0, 4.0, 4.0, 2.0, 4.0, 4.0, 4.0, 2.0, 5.0, 4.0, 5.0, 6.0, 7.0, 3.0, 7.0, 9.0, 5.0, 8.0, 1.0, 1.0, 2.0, 0.0, 5.0, 4.0, 7.0, 5.0, 0.0, 1.0, 0.0, 1.0, 4.0, 8.0, 5.0, 5.0, 1.0, 3.0, 3.0, 2.0, 3.0, 3.0, 4.0, 4.0, 4.0, 5.0, 7.0, 7.0, 0.0, 1.0, 2.0, 2.0, 2.0, 3.0, 5.0, 2.0, 4.0, 1.0, 2.0, 3.0, 4.0, 7.0, 5.0, 4.0, 7.0, 6.0, 4.0, 5.0, 3.0, 4.0, 4.0, 4.0, 5.0, 3.0, 4.0, 2.0, 4.0, 4.0, 1.0, 3.0, 4.0, 5.0, 4.0, 4.0, 3.0, 5.0, 5.0, 7.0, 7.0, 4.0, 5.0, 3.0, 3.0, 5.0, 3.0, 4.0, 3.0, 3.0, 3.0, 3.0, 4.0, 2.0, 4.0, 3.0, 3.0, 4.0, 5.0, 6.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.13392810239112457, "mean_inference_ms": 0.39097436348614406, "mean_action_processing_ms": 0.029172468422857967, "mean_env_wait_ms": 0.4026932118283014, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 1970640, "timesteps_this_iter": 0, "agent_timesteps_total": 7882560, "timers": {"sample_time_ms": 5107.573, "sample_throughput": 986.77, "load_time_ms": 0.176, "load_throughput": 28570471.902, "learn_time_ms": 148.854, "learn_throughput": 33858.6, "update_time_ms": 2.476}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 639.4976196289062, "policy_entropy": 7522.411865234375, "policy_loss": 141.97112846374512, "vf_loss": 140.62810516357422}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 1970640, "num_agent_steps_sampled": 7882560, "num_steps_trained": 1970640, "num_agent_steps_trained": 7882560, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 3940, "training_iteration": 196, "trial_id": "71426_00000", "experiment_id": "84bca2f7b35f43248fca18d21abe2ebf", "date": "2024-06-12_03-19-31", "timestamp": 1718129971, "time_this_iter_s": 10.188197612762451, "time_total_s": 2017.7628545761108, "pid": 363902, "hostname": "DESKTOP-LQ219J4", "node_ip": "192.168.46.185", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 20, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 5000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 500, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Base_Model", "custom_model_config": {"env": "rware", "env_args": {"n_agents": 4, "column_height": 1, "max_inactivity_steps": null, "max_steps": 500, "fast_obs": true, "msg_bits": 0, "sensor_range": 1, "shelf_rows": 1, "shelf_columns": 3, "request_queue_size": 4, "reward_type": "RewardType.INDIVIDUAL", "map_name": "customized_map", "map_size": "tiny", "difficulty": "medium"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": true, "force_coop": false, "local_mode": true, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 4, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 100, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64}, "algorithm": "ia2c", "space_obs": "Dict(obs:Box([-100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100.], [100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.], (112,), float32))", "space_act": "Discrete(5)", "num_agents": 4, "episode_limit": 500, "policy_mapping_info": {"all_scenario": {"description": "rware all scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2", "agent_3"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "rware_customized_map", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 10, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.IA2CTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_il.<locals>.<lambda> at 0x7f3808651d30>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "grad_clip": 40.0, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "microbatch_size": null}, "time_since_restore": 2017.7628545761108, "timesteps_since_restore": 0, "iterations_since_restore": 196, "perf": {"cpu_util_percent": 4.285714285714286, "ram_util_percent": 86.52857142857142}}
{"episode_reward_max": 29.0, "episode_reward_min": 2.0, "episode_reward_mean": 15.37, "episode_len_mean": 500.0, "episode_media": {}, "episodes_this_iter": 20, "policy_reward_min": {"shared_policy": 0.0}, "policy_reward_max": {"shared_policy": 11.0}, "policy_reward_mean": {"shared_policy": 3.8425}, "custom_metrics": {}, "hist_stats": {"episode_reward": [18.0, 15.0, 10.0, 19.0, 11.0, 25.0, 4.0, 13.0, 15.0, 8.0, 15.0, 9.0, 28.0, 14.0, 14.0, 13.0, 3.0, 27.0, 20.0, 18.0, 11.0, 16.0, 14.0, 11.0, 27.0, 7.0, 12.0, 11.0, 28.0, 15.0, 17.0, 26.0, 10.0, 19.0, 15.0, 18.0, 18.0, 29.0, 12.0, 10.0, 18.0, 13.0, 20.0, 15.0, 9.0, 18.0, 11.0, 13.0, 9.0, 10.0, 12.0, 25.0, 20.0, 23.0, 14.0, 15.0, 21.0, 29.0, 4.0, 21.0, 2.0, 22.0, 9.0, 14.0, 23.0, 5.0, 12.0, 10.0, 20.0, 22.0, 15.0, 14.0, 12.0, 17.0, 20.0, 19.0, 15.0, 12.0, 13.0, 18.0, 13.0, 18.0, 12.0, 17.0, 21.0, 11.0, 8.0, 18.0, 15.0, 7.0, 13.0, 6.0, 25.0, 18.0, 22.0, 12.0, 18.0, 17.0, 9.0, 18.0], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500], "policy_shared_policy_reward": [5.0, 4.0, 6.0, 3.0, 4.0, 3.0, 3.0, 5.0, 3.0, 3.0, 2.0, 2.0, 7.0, 4.0, 2.0, 6.0, 2.0, 2.0, 4.0, 3.0, 4.0, 7.0, 7.0, 7.0, 1.0, 1.0, 1.0, 1.0, 5.0, 2.0, 3.0, 3.0, 3.0, 4.0, 5.0, 3.0, 2.0, 2.0, 2.0, 2.0, 5.0, 4.0, 3.0, 3.0, 0.0, 3.0, 3.0, 3.0, 7.0, 5.0, 10.0, 6.0, 4.0, 5.0, 3.0, 2.0, 4.0, 4.0, 2.0, 4.0, 2.0, 4.0, 4.0, 3.0, 0.0, 0.0, 1.0, 2.0, 6.0, 9.0, 6.0, 6.0, 7.0, 5.0, 5.0, 3.0, 5.0, 5.0, 4.0, 4.0, 1.0, 4.0, 3.0, 3.0, 3.0, 4.0, 5.0, 4.0, 4.0, 3.0, 1.0, 6.0, 4.0, 3.0, 2.0, 2.0, 7.0, 7.0, 6.0, 7.0, 1.0, 1.0, 2.0, 3.0, 2.0, 5.0, 4.0, 1.0, 3.0, 3.0, 3.0, 2.0, 11.0, 5.0, 6.0, 6.0, 6.0, 3.0, 3.0, 3.0, 5.0, 4.0, 3.0, 5.0, 5.0, 7.0, 5.0, 9.0, 3.0, 2.0, 3.0, 2.0, 5.0, 6.0, 5.0, 3.0, 3.0, 4.0, 2.0, 6.0, 4.0, 4.0, 6.0, 4.0, 5.0, 4.0, 4.0, 5.0, 7.0, 8.0, 6.0, 8.0, 3.0, 3.0, 2.0, 4.0, 1.0, 2.0, 3.0, 4.0, 4.0, 3.0, 7.0, 4.0, 3.0, 3.0, 4.0, 3.0, 6.0, 6.0, 4.0, 4.0, 4.0, 3.0, 5.0, 3.0, 3.0, 1.0, 1.0, 4.0, 6.0, 4.0, 3.0, 5.0, 2.0, 3.0, 4.0, 2.0, 3.0, 2.0, 3.0, 5.0, 2.0, 2.0, 2.0, 3.0, 3.0, 2.0, 2.0, 3.0, 3.0, 3.0, 4.0, 2.0, 3.0, 7.0, 6.0, 9.0, 7.0, 2.0, 4.0, 7.0, 3.0, 7.0, 9.0, 4.0, 4.0, 2.0, 4.0, 4.0, 4.0, 2.0, 5.0, 4.0, 5.0, 6.0, 7.0, 3.0, 7.0, 9.0, 5.0, 8.0, 1.0, 1.0, 2.0, 0.0, 5.0, 4.0, 7.0, 5.0, 0.0, 1.0, 0.0, 1.0, 4.0, 8.0, 5.0, 5.0, 1.0, 3.0, 3.0, 2.0, 3.0, 3.0, 4.0, 4.0, 4.0, 5.0, 7.0, 7.0, 0.0, 1.0, 2.0, 2.0, 2.0, 3.0, 5.0, 2.0, 4.0, 1.0, 2.0, 3.0, 4.0, 7.0, 5.0, 4.0, 7.0, 6.0, 4.0, 5.0, 3.0, 4.0, 4.0, 4.0, 5.0, 3.0, 4.0, 2.0, 4.0, 4.0, 1.0, 3.0, 4.0, 5.0, 4.0, 4.0, 3.0, 5.0, 5.0, 7.0, 7.0, 4.0, 5.0, 3.0, 3.0, 5.0, 3.0, 4.0, 3.0, 3.0, 3.0, 3.0, 4.0, 2.0, 4.0, 3.0, 3.0, 4.0, 5.0, 6.0, 4.0, 3.0, 2.0, 4.0, 5.0, 5.0, 4.0, 4.0, 3.0, 3.0, 3.0, 3.0, 4.0, 5.0, 6.0, 2.0, 5.0, 5.0, 5.0, 6.0, 2.0, 3.0, 4.0, 2.0, 3.0, 1.0, 1.0, 3.0, 6.0, 3.0, 3.0, 6.0, 6.0, 3.0, 3.0, 3.0, 1.0, 2.0, 2.0, 2.0, 3.0, 3.0, 4.0, 3.0, 2.0, 1.0, 1.0, 2.0, 7.0, 4.0, 7.0, 7.0, 5.0, 7.0, 4.0, 2.0, 6.0, 4.0, 7.0, 5.0, 2.0, 3.0, 2.0, 5.0, 5.0, 4.0, 4.0, 5.0, 7.0, 1.0, 6.0, 3.0, 2.0, 1.0, 2.0, 4.0, 4.0, 4.0, 5.0, 5.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.13392222475035187, "mean_inference_ms": 0.3909559775696785, "mean_action_processing_ms": 0.029171074669784938, "mean_env_wait_ms": 0.4026565134127821, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 1980720, "timesteps_this_iter": 0, "agent_timesteps_total": 7922880, "timers": {"sample_time_ms": 5098.498, "sample_throughput": 988.526, "load_time_ms": 0.18, "load_throughput": 28013904.267, "learn_time_ms": 145.153, "learn_throughput": 34722.035, "update_time_ms": 2.447}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 650.7175903320312, "policy_entropy": 7550.7674560546875, "policy_loss": -73.33501052856445, "vf_loss": 134.92609786987305}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 1980720, "num_agent_steps_sampled": 7922880, "num_steps_trained": 1980720, "num_agent_steps_trained": 7922880, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 3960, "training_iteration": 197, "trial_id": "71426_00000", "experiment_id": "84bca2f7b35f43248fca18d21abe2ebf", "date": "2024-06-12_03-19-42", "timestamp": 1718129982, "time_this_iter_s": 10.130861759185791, "time_total_s": 2027.8937163352966, "pid": 363902, "hostname": "DESKTOP-LQ219J4", "node_ip": "192.168.46.185", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 20, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 5000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 500, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Base_Model", "custom_model_config": {"env": "rware", "env_args": {"n_agents": 4, "column_height": 1, "max_inactivity_steps": null, "max_steps": 500, "fast_obs": true, "msg_bits": 0, "sensor_range": 1, "shelf_rows": 1, "shelf_columns": 3, "request_queue_size": 4, "reward_type": "RewardType.INDIVIDUAL", "map_name": "customized_map", "map_size": "tiny", "difficulty": "medium"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": true, "force_coop": false, "local_mode": true, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 4, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 100, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64}, "algorithm": "ia2c", "space_obs": "Dict(obs:Box([-100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100.], [100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.], (112,), float32))", "space_act": "Discrete(5)", "num_agents": 4, "episode_limit": 500, "policy_mapping_info": {"all_scenario": {"description": "rware all scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2", "agent_3"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "rware_customized_map", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 10, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.IA2CTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_il.<locals>.<lambda> at 0x7f38082f8430>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "grad_clip": 40.0, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "microbatch_size": null}, "time_since_restore": 2027.8937163352966, "timesteps_since_restore": 0, "iterations_since_restore": 197, "perf": {"cpu_util_percent": 4.2733333333333325, "ram_util_percent": 86.77333333333331}}
{"episode_reward_max": 29.0, "episode_reward_min": 2.0, "episode_reward_mean": 15.22, "episode_len_mean": 500.0, "episode_media": {}, "episodes_this_iter": 20, "policy_reward_min": {"shared_policy": 0.0}, "policy_reward_max": {"shared_policy": 11.0}, "policy_reward_mean": {"shared_policy": 3.805}, "custom_metrics": {}, "hist_stats": {"episode_reward": [11.0, 16.0, 14.0, 11.0, 27.0, 7.0, 12.0, 11.0, 28.0, 15.0, 17.0, 26.0, 10.0, 19.0, 15.0, 18.0, 18.0, 29.0, 12.0, 10.0, 18.0, 13.0, 20.0, 15.0, 9.0, 18.0, 11.0, 13.0, 9.0, 10.0, 12.0, 25.0, 20.0, 23.0, 14.0, 15.0, 21.0, 29.0, 4.0, 21.0, 2.0, 22.0, 9.0, 14.0, 23.0, 5.0, 12.0, 10.0, 20.0, 22.0, 15.0, 14.0, 12.0, 17.0, 20.0, 19.0, 15.0, 12.0, 13.0, 18.0, 13.0, 18.0, 12.0, 17.0, 21.0, 11.0, 8.0, 18.0, 15.0, 7.0, 13.0, 6.0, 25.0, 18.0, 22.0, 12.0, 18.0, 17.0, 9.0, 18.0, 4.0, 28.0, 13.0, 14.0, 21.0, 13.0, 13.0, 18.0, 11.0, 10.0, 19.0, 11.0, 12.0, 22.0, 19.0, 8.0, 20.0, 3.0, 16.0, 9.0], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500], "policy_shared_policy_reward": [1.0, 4.0, 3.0, 3.0, 3.0, 4.0, 5.0, 4.0, 4.0, 3.0, 1.0, 6.0, 4.0, 3.0, 2.0, 2.0, 7.0, 7.0, 6.0, 7.0, 1.0, 1.0, 2.0, 3.0, 2.0, 5.0, 4.0, 1.0, 3.0, 3.0, 3.0, 2.0, 11.0, 5.0, 6.0, 6.0, 6.0, 3.0, 3.0, 3.0, 5.0, 4.0, 3.0, 5.0, 5.0, 7.0, 5.0, 9.0, 3.0, 2.0, 3.0, 2.0, 5.0, 6.0, 5.0, 3.0, 3.0, 4.0, 2.0, 6.0, 4.0, 4.0, 6.0, 4.0, 5.0, 4.0, 4.0, 5.0, 7.0, 8.0, 6.0, 8.0, 3.0, 3.0, 2.0, 4.0, 1.0, 2.0, 3.0, 4.0, 4.0, 3.0, 7.0, 4.0, 3.0, 3.0, 4.0, 3.0, 6.0, 6.0, 4.0, 4.0, 4.0, 3.0, 5.0, 3.0, 3.0, 1.0, 1.0, 4.0, 6.0, 4.0, 3.0, 5.0, 2.0, 3.0, 4.0, 2.0, 3.0, 2.0, 3.0, 5.0, 2.0, 2.0, 2.0, 3.0, 3.0, 2.0, 2.0, 3.0, 3.0, 3.0, 4.0, 2.0, 3.0, 7.0, 6.0, 9.0, 7.0, 2.0, 4.0, 7.0, 3.0, 7.0, 9.0, 4.0, 4.0, 2.0, 4.0, 4.0, 4.0, 2.0, 5.0, 4.0, 5.0, 6.0, 7.0, 3.0, 7.0, 9.0, 5.0, 8.0, 1.0, 1.0, 2.0, 0.0, 5.0, 4.0, 7.0, 5.0, 0.0, 1.0, 0.0, 1.0, 4.0, 8.0, 5.0, 5.0, 1.0, 3.0, 3.0, 2.0, 3.0, 3.0, 4.0, 4.0, 4.0, 5.0, 7.0, 7.0, 0.0, 1.0, 2.0, 2.0, 2.0, 3.0, 5.0, 2.0, 4.0, 1.0, 2.0, 3.0, 4.0, 7.0, 5.0, 4.0, 7.0, 6.0, 4.0, 5.0, 3.0, 4.0, 4.0, 4.0, 5.0, 3.0, 4.0, 2.0, 4.0, 4.0, 1.0, 3.0, 4.0, 5.0, 4.0, 4.0, 3.0, 5.0, 5.0, 7.0, 7.0, 4.0, 5.0, 3.0, 3.0, 5.0, 3.0, 4.0, 3.0, 3.0, 3.0, 3.0, 4.0, 2.0, 4.0, 3.0, 3.0, 4.0, 5.0, 6.0, 4.0, 3.0, 2.0, 4.0, 5.0, 5.0, 4.0, 4.0, 3.0, 3.0, 3.0, 3.0, 4.0, 5.0, 6.0, 2.0, 5.0, 5.0, 5.0, 6.0, 2.0, 3.0, 4.0, 2.0, 3.0, 1.0, 1.0, 3.0, 6.0, 3.0, 3.0, 6.0, 6.0, 3.0, 3.0, 3.0, 1.0, 2.0, 2.0, 2.0, 3.0, 3.0, 4.0, 3.0, 2.0, 1.0, 1.0, 2.0, 7.0, 4.0, 7.0, 7.0, 5.0, 7.0, 4.0, 2.0, 6.0, 4.0, 7.0, 5.0, 2.0, 3.0, 2.0, 5.0, 5.0, 4.0, 4.0, 5.0, 7.0, 1.0, 6.0, 3.0, 2.0, 1.0, 2.0, 4.0, 4.0, 4.0, 5.0, 5.0, 0.0, 1.0, 1.0, 2.0, 7.0, 9.0, 8.0, 4.0, 2.0, 5.0, 3.0, 3.0, 4.0, 5.0, 0.0, 5.0, 5.0, 6.0, 6.0, 4.0, 2.0, 6.0, 2.0, 3.0, 5.0, 3.0, 1.0, 4.0, 4.0, 4.0, 7.0, 3.0, 1.0, 4.0, 3.0, 3.0, 3.0, 2.0, 2.0, 3.0, 8.0, 2.0, 4.0, 5.0, 4.0, 2.0, 2.0, 3.0, 3.0, 3.0, 2.0, 4.0, 2.0, 8.0, 7.0, 5.0, 5.0, 5.0, 6.0, 3.0, 0.0, 3.0, 2.0, 3.0, 6.0, 3.0, 4.0, 7.0, 1.0, 0.0, 1.0, 1.0, 5.0, 3.0, 5.0, 3.0, 3.0, 3.0, 2.0, 1.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.13391737023122666, "mean_inference_ms": 0.39093753984968765, "mean_action_processing_ms": 0.029170085186022873, "mean_env_wait_ms": 0.4026198928683034, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 1990800, "timesteps_this_iter": 0, "agent_timesteps_total": 7963200, "timers": {"sample_time_ms": 5097.505, "sample_throughput": 988.719, "load_time_ms": 0.181, "load_throughput": 27818518.437, "learn_time_ms": 145.558, "learn_throughput": 34625.305, "update_time_ms": 2.44}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 453.5140686035156, "policy_entropy": 7437.6102294921875, "policy_loss": -58.74726343154907, "vf_loss": 165.16375541687012}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 1990800, "num_agent_steps_sampled": 7963200, "num_steps_trained": 1990800, "num_agent_steps_trained": 7963200, "num_steps_trained_this_iter": 0}, "done": false, "episodes_total": 3980, "training_iteration": 198, "trial_id": "71426_00000", "experiment_id": "84bca2f7b35f43248fca18d21abe2ebf", "date": "2024-06-12_03-19-52", "timestamp": 1718129992, "time_this_iter_s": 10.242592573165894, "time_total_s": 2038.1363089084625, "pid": 363902, "hostname": "DESKTOP-LQ219J4", "node_ip": "192.168.46.185", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 20, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 5000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 500, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Base_Model", "custom_model_config": {"env": "rware", "env_args": {"n_agents": 4, "column_height": 1, "max_inactivity_steps": null, "max_steps": 500, "fast_obs": true, "msg_bits": 0, "sensor_range": 1, "shelf_rows": 1, "shelf_columns": 3, "request_queue_size": 4, "reward_type": "RewardType.INDIVIDUAL", "map_name": "customized_map", "map_size": "tiny", "difficulty": "medium"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": true, "force_coop": false, "local_mode": true, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 4, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 100, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64}, "algorithm": "ia2c", "space_obs": "Dict(obs:Box([-100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100.], [100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.], (112,), float32))", "space_act": "Discrete(5)", "num_agents": 4, "episode_limit": 500, "policy_mapping_info": {"all_scenario": {"description": "rware all scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2", "agent_3"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "rware_customized_map", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 10, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.IA2CTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_il.<locals>.<lambda> at 0x7f3808268dc0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "grad_clip": 40.0, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "microbatch_size": null}, "time_since_restore": 2038.1363089084625, "timesteps_since_restore": 0, "iterations_since_restore": 198, "perf": {"cpu_util_percent": 4.314285714285714, "ram_util_percent": 87.03571428571429}}
{"episode_reward_max": 37.0, "episode_reward_min": 2.0, "episode_reward_mean": 15.24, "episode_len_mean": 500.0, "episode_media": {}, "episodes_this_iter": 20, "policy_reward_min": {"shared_policy": 0.0}, "policy_reward_max": {"shared_policy": 12.0}, "policy_reward_mean": {"shared_policy": 3.81}, "custom_metrics": {}, "hist_stats": {"episode_reward": [18.0, 13.0, 20.0, 15.0, 9.0, 18.0, 11.0, 13.0, 9.0, 10.0, 12.0, 25.0, 20.0, 23.0, 14.0, 15.0, 21.0, 29.0, 4.0, 21.0, 2.0, 22.0, 9.0, 14.0, 23.0, 5.0, 12.0, 10.0, 20.0, 22.0, 15.0, 14.0, 12.0, 17.0, 20.0, 19.0, 15.0, 12.0, 13.0, 18.0, 13.0, 18.0, 12.0, 17.0, 21.0, 11.0, 8.0, 18.0, 15.0, 7.0, 13.0, 6.0, 25.0, 18.0, 22.0, 12.0, 18.0, 17.0, 9.0, 18.0, 4.0, 28.0, 13.0, 14.0, 21.0, 13.0, 13.0, 18.0, 11.0, 10.0, 19.0, 11.0, 12.0, 22.0, 19.0, 8.0, 20.0, 3.0, 16.0, 9.0, 17.0, 14.0, 16.0, 10.0, 24.0, 16.0, 11.0, 17.0, 18.0, 13.0, 37.0, 23.0, 10.0, 22.0, 7.0, 16.0, 16.0, 20.0, 11.0, 10.0], "episode_lengths": [500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500], "policy_shared_policy_reward": [4.0, 3.0, 7.0, 4.0, 3.0, 3.0, 4.0, 3.0, 6.0, 6.0, 4.0, 4.0, 4.0, 3.0, 5.0, 3.0, 3.0, 1.0, 1.0, 4.0, 6.0, 4.0, 3.0, 5.0, 2.0, 3.0, 4.0, 2.0, 3.0, 2.0, 3.0, 5.0, 2.0, 2.0, 2.0, 3.0, 3.0, 2.0, 2.0, 3.0, 3.0, 3.0, 4.0, 2.0, 3.0, 7.0, 6.0, 9.0, 7.0, 2.0, 4.0, 7.0, 3.0, 7.0, 9.0, 4.0, 4.0, 2.0, 4.0, 4.0, 4.0, 2.0, 5.0, 4.0, 5.0, 6.0, 7.0, 3.0, 7.0, 9.0, 5.0, 8.0, 1.0, 1.0, 2.0, 0.0, 5.0, 4.0, 7.0, 5.0, 0.0, 1.0, 0.0, 1.0, 4.0, 8.0, 5.0, 5.0, 1.0, 3.0, 3.0, 2.0, 3.0, 3.0, 4.0, 4.0, 4.0, 5.0, 7.0, 7.0, 0.0, 1.0, 2.0, 2.0, 2.0, 3.0, 5.0, 2.0, 4.0, 1.0, 2.0, 3.0, 4.0, 7.0, 5.0, 4.0, 7.0, 6.0, 4.0, 5.0, 3.0, 4.0, 4.0, 4.0, 5.0, 3.0, 4.0, 2.0, 4.0, 4.0, 1.0, 3.0, 4.0, 5.0, 4.0, 4.0, 3.0, 5.0, 5.0, 7.0, 7.0, 4.0, 5.0, 3.0, 3.0, 5.0, 3.0, 4.0, 3.0, 3.0, 3.0, 3.0, 4.0, 2.0, 4.0, 3.0, 3.0, 4.0, 5.0, 6.0, 4.0, 3.0, 2.0, 4.0, 5.0, 5.0, 4.0, 4.0, 3.0, 3.0, 3.0, 3.0, 4.0, 5.0, 6.0, 2.0, 5.0, 5.0, 5.0, 6.0, 2.0, 3.0, 4.0, 2.0, 3.0, 1.0, 1.0, 3.0, 6.0, 3.0, 3.0, 6.0, 6.0, 3.0, 3.0, 3.0, 1.0, 2.0, 2.0, 2.0, 3.0, 3.0, 4.0, 3.0, 2.0, 1.0, 1.0, 2.0, 7.0, 4.0, 7.0, 7.0, 5.0, 7.0, 4.0, 2.0, 6.0, 4.0, 7.0, 5.0, 2.0, 3.0, 2.0, 5.0, 5.0, 4.0, 4.0, 5.0, 7.0, 1.0, 6.0, 3.0, 2.0, 1.0, 2.0, 4.0, 4.0, 4.0, 5.0, 5.0, 0.0, 1.0, 1.0, 2.0, 7.0, 9.0, 8.0, 4.0, 2.0, 5.0, 3.0, 3.0, 4.0, 5.0, 0.0, 5.0, 5.0, 6.0, 6.0, 4.0, 2.0, 6.0, 2.0, 3.0, 5.0, 3.0, 1.0, 4.0, 4.0, 4.0, 7.0, 3.0, 1.0, 4.0, 3.0, 3.0, 3.0, 2.0, 2.0, 3.0, 8.0, 2.0, 4.0, 5.0, 4.0, 2.0, 2.0, 3.0, 3.0, 3.0, 2.0, 4.0, 2.0, 8.0, 7.0, 5.0, 5.0, 5.0, 6.0, 3.0, 0.0, 3.0, 2.0, 3.0, 6.0, 3.0, 4.0, 7.0, 1.0, 0.0, 1.0, 1.0, 5.0, 3.0, 5.0, 3.0, 3.0, 3.0, 2.0, 1.0, 4.0, 5.0, 4.0, 4.0, 5.0, 2.0, 5.0, 2.0, 4.0, 4.0, 3.0, 5.0, 2.0, 3.0, 2.0, 3.0, 6.0, 7.0, 6.0, 5.0, 4.0, 6.0, 2.0, 4.0, 3.0, 3.0, 1.0, 4.0, 2.0, 7.0, 5.0, 3.0, 4.0, 4.0, 5.0, 5.0, 4.0, 6.0, 2.0, 1.0, 9.0, 12.0, 8.0, 8.0, 5.0, 7.0, 5.0, 6.0, 4.0, 1.0, 2.0, 3.0, 3.0, 7.0, 7.0, 5.0, 2.0, 3.0, 0.0, 2.0, 7.0, 1.0, 6.0, 2.0, 4.0, 2.0, 4.0, 6.0, 3.0, 3.0, 5.0, 9.0, 1.0, 2.0, 4.0, 4.0, 2.0, 2.0, 2.0, 4.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.13391133635179645, "mean_inference_ms": 0.3909157373403792, "mean_action_processing_ms": 0.029168905414167706, "mean_env_wait_ms": 0.4025789684213725, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 2000880, "timesteps_this_iter": 0, "agent_timesteps_total": 8003520, "timers": {"sample_time_ms": 5087.045, "sample_throughput": 990.752, "load_time_ms": 0.181, "load_throughput": 27877215.034, "learn_time_ms": 146.08, "learn_throughput": 34501.701, "update_time_ms": 2.435}, "info": {"learner": {"shared_policy": {"learner_stats": {"allreduce_latency": 0.0, "grad_gnorm": 321.9449462890625, "policy_entropy": 7422.5557861328125, "policy_loss": -120.45990943908691, "vf_loss": 147.08496284484863}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 2000880, "num_agent_steps_sampled": 8003520, "num_steps_trained": 2000880, "num_agent_steps_trained": 8003520, "num_steps_trained_this_iter": 0}, "done": true, "episodes_total": 4000, "training_iteration": 199, "trial_id": "71426_00000", "experiment_id": "84bca2f7b35f43248fca18d21abe2ebf", "date": "2024-06-12_03-20-02", "timestamp": 1718130002, "time_this_iter_s": 10.083502531051636, "time_total_s": 2048.219811439514, "pid": 363902, "hostname": "DESKTOP-LQ219J4", "node_ip": "192.168.46.185", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 20, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 0.0005, "train_batch_size": 5000, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 500, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": "Base_Model", "custom_model_config": {"env": "rware", "env_args": {"n_agents": 4, "column_height": 1, "max_inactivity_steps": null, "max_steps": 500, "fast_obs": true, "msg_bits": 0, "sensor_range": 1, "shelf_rows": 1, "shelf_columns": 3, "request_queue_size": 4, "reward_type": "RewardType.INDIVIDUAL", "map_name": "customized_map", "map_size": "tiny", "difficulty": "medium"}, "mask_flag": false, "global_state_flag": false, "opp_action_in_cc": true, "agent_level_batch_update": true, "force_coop": false, "local_mode": true, "share_policy": "group", "evaluation_interval": 50, "framework": "torch", "num_workers": 4, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "checkpoint_freq": 100, "checkpoint_end": true, "restore_path": {"model_path": "", "params_path": ""}, "stop_iters": 9999999, "stop_timesteps": 2000000, "stop_reward": 999999, "seed": 321, "local_dir": "", "model_arch_args": {"hidden_state_size": 256, "core_arch": "mlp", "fc_layer": 2, "out_dim_fc_0": 128, "out_dim_fc_1": 64}, "algorithm": "ia2c", "space_obs": "Dict(obs:Box([-100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.\n -100. -100. -100. -100.], [100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.\n 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.], (112,), float32))", "space_act": "Discrete(5)", "num_agents": 4, "episode_limit": 500, "policy_mapping_info": {"all_scenario": {"description": "rware all scenarios", "team_prefix": ["agent_"], "all_agents_one_policy": true, "one_agent_one_policy": true}}, "agent_name_ls": ["agent_0", "agent_1", "agent_2", "agent_3"]}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "rware_customized_map", "observation_space": null, "action_space": null, "env_config": {}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": 50, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "min_iter_time_s": 10, "timesteps_per_iteration": 0, "seed": 321, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"shared_policy": ["<class 'ray.rllib.policy.policy_template.IA2CTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function run_il.<locals>.<lambda> at 0x7f383066a9d0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "grad_clip": 40.0, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.01, "microbatch_size": null}, "time_since_restore": 2048.219811439514, "timesteps_since_restore": 0, "iterations_since_restore": 199, "perf": {"cpu_util_percent": 4.319999999999999, "ram_util_percent": 87.32}}
